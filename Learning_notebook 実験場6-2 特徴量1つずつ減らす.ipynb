{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMえぐい時間かかるので気を付けて(7foldで4時間とか)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "B3WEPx1JJqlG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 14\n",
    "    AUTHOR = 'Yuta.K'\n",
    "    COMPETITION = 'FDUA2'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = [ 'adaboost','lightgbm', 'xgboost', 'catboost']\n",
    "    seed = 42\n",
    "    n_folds = 7\n",
    "    target_col = 'MIS_Status'\n",
    "    metric = 'f1_score'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 500\n",
    "    early_stopping_round = 200\n",
    "    verbose = 25\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'iterations': num_boost_round,\n",
    "        'random_seed': seed,\n",
    "    }\n",
    "    classification_adaboost_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 1.0,\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    model_weight_dict = {'adaboost': 0.10,'lightgbm': 0.25, 'xgboost': 0.10, 'catboost': 0.25}\n",
    "    \n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# f1_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro'), CFG.metric_maximize_flag\n",
    "\n",
    "# ====================================================\n",
    "# XGBoost Metric\n",
    "# ====================================================\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "g6R4KoxhL91E"
   },
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "El2B8eayMmyZ"
   },
   "outputs": [],
   "source": [
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "\n",
    "        #Bankraptcydataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = k[-26]*2\n",
    "        \n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "\n",
    "        #組み合わせ特徴量\n",
    "        df['State_Sector'] = df['State'].astype(str) + '_' + df['Sector'].astype(str)\n",
    "         # 地理的特徴の組み合わせ\n",
    "        df['City_State'] = df['City'] + '_' + df['State']\n",
    "        # 時間的特徴の組み合わせ\n",
    "        df['ApprovalFY_Term'] = df['ApprovalFY'].astype(str) + '_' + df['Term'].astype(str)\n",
    "        \n",
    "        df['FranchiseCode_ApprovalDate'] = df['FranchiseCode'].astype(str) + '_' + df['ApprovalDate'].astype(str)\n",
    "        \n",
    "        df['Term_NoEmp'] = df['Term'].astype(str) + '_' + df['NoEmp'].astype(str)\n",
    "        \n",
    "        df['City_BankState'] = df['City'].astype(str) + '_' + df['BankState'].astype(str)\n",
    "        \n",
    "        df['NoEmp_SBA_Appv'] = df['NoEmp'].astype(str) + '_' + df['SBA_Appv'].astype(str)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #特徴量の加工\n",
    "        #lowdoc ['LowDoc_Y', 'LowDoc_S', 'LowDoc_N', 'LowDoc_A', 'LowDoc_C', 'LowDoc_0', 'LowDoc_UNK']\n",
    "        df['LowDoc_Y'] = (df['LowDoc'] == 'Y').astype(int)\n",
    "        df['LowDoc_S'] = (df['LowDoc'] == 'S').astype(int)\n",
    "        df['LowDoc_N'] = (df['LowDoc'] == 'N').astype(int)\n",
    "        df['LowDoc_C'] = (df['LowDoc'] == 'C').astype(int)\n",
    "        df['LowDoc_A'] = (df['LowDoc'] == 'A').astype(int)\n",
    "        df['LowDoc_0'] = (df['LowDoc'] == '0').astype(int)\n",
    "        df['LowDoc_UNK'] = (df['LowDoc'] == 'UNK').astype(int)\n",
    "\n",
    "        #RevLineCr ['RevLineCr_Y', 'RevLineCr_T', 'RevLineCr_N', 'RevLineCr_0', 'RevLineCr_UNK']\n",
    "        df['RevLineCr_Y'] = (df['RevLineCr'] == 'Y').astype(int)\n",
    "        df['RevLineCr_T'] = (df['RevLineCr'] == 'T').astype(int)\n",
    "        df['RevLineCr_N'] = (df['RevLineCr'] == 'N').astype(int)\n",
    "        df['RevLineCr_0'] = (df['RevLineCr'] == '0').astype(int)\n",
    "        df['RevLineCr_UNK'] = (df['RevLineCr'] == 'UNK').astype(int)\n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "GA0iq9vLNEqS"
   },
   "outputs": [],
   "source": [
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dJ6ijFuQoF5"
   },
   "source": [
    "（以下はPreprocessingに本来組み込むべきだが，コードが煩雑になるので，いったん切り出している．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "wFYHaRqrOfGG"
   },
   "outputs": [],
   "source": [
    "#ラベルエンコーディング\n",
    "for col in categorical_features :\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "categorical_features_unlabelable = ['ApprovalFY_Term','City_State','City','ApprovalDate','BankState','DisbursementDate','State_Sector',\n",
    "                                   'FranchiseCode_ApprovalDate','Term_NoEmp','City_BankState','NoEmp_SBA_Appv']\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    le = LabelEncoder()   \n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else len(le.classes_))\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n",
      "ApprovalYear\n"
     ]
    }
   ],
   "source": [
    "#featuresの作成\n",
    "categorical_features = ['State', 'Sector','RevLineCr_Y', 'RevLineCr_T', 'RevLineCr_N', 'RevLineCr_0', 'RevLineCr_UNK',\n",
    "                       'LowDoc_Y', 'LowDoc_S', 'LowDoc_N', 'LowDoc_A', 'LowDoc_C', 'LowDoc_0', 'LowDoc_UNK',\n",
    "                       'ApprovalFY_Term','City_State','City','ApprovalDate','BankState','State_Sector','UrbanRural',\n",
    "                        'FranchiseCode_ApprovalDate','Term_NoEmp','City_BankState','NoEmp_SBA_Appv']\n",
    "\n",
    "\n",
    "RemoveList=['MIS_Status','ApprovalYear']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "quaQcTgQOjyJ"
   },
   "outputs": [],
   "source": [
    "# AdaBoost training\n",
    "def adaboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = AdaBoostClassifier(**CFG.classification_adaboost_params)\n",
    "    model.fit(x_train, y_train)\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "\n",
    "#svm training\n",
    "def svm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = SVC(**CFG.classification_svm_params)  # SVMモデルの初期化\n",
    "    model.fit(x_train[features], y_train)  # モデルのトレーニング\n",
    "    valid_pred = model.predict_proba(x_valid[features])[:, 1]  # 予測確率の取得\n",
    "    return model, valid_pred\n",
    "\n",
    "# SGDClassifier training\n",
    "def sgd_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = SGDClassifier(**CFG.classification_sgd_params)\n",
    "    model.fit(x_train[features], y_train)\n",
    "    valid_pred = model.predict_proba(x_valid[features])[:, 1]\n",
    "    return model, valid_pred\n",
    "\n",
    "# RandomForest training\n",
    "def randomforest_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = RandomForestClassifier(**CFG.classification_randomforest_params)\n",
    "    model.fit(x_train[features], y_train)\n",
    "    valid_pred = model.predict_proba(x_valid[features])[:, 1]\n",
    "    return model, valid_pred\n",
    "    \n",
    "#lightgbmでの学習メソッドの定義\n",
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "                params = CFG.classification_lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                feval = lgb_metric,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                              verbose=CFG.verbose)]\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "#xgboostでの学習メソッドの定義\n",
    "def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "    model = xgb.train(\n",
    "                CFG.classification_xgb_params,\n",
    "                dtrain = xgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                early_stopping_rounds = CFG.early_stopping_round,\n",
    "                verbose_eval = CFG.verbose,\n",
    "                feval = xgb_metric,\n",
    "                maximize = CFG.metric_maximize_flag,\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "    return model, valid_pred\n",
    "\n",
    "#catboostでの学習メソッドの定義\n",
    "def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "    model.fit(cat_train,\n",
    "              eval_set = [cat_valid],\n",
    "              early_stopping_rounds = CFG.early_stopping_round,\n",
    "              verbose = CFG.verbose,\n",
    "              use_best_model = True)\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "\n",
    "    \n",
    "                    \n",
    "#任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    kfold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df)):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "\n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        \n",
    "        model = None  # モデル変数を初期化する\n",
    "        valid_pred = None\n",
    "        \n",
    "        if method == 'adaboost':\n",
    "            model, valid_pred = adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'lightgbm':\n",
    "            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'xgboost':\n",
    "            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'catboost':\n",
    "            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)  \n",
    "        # Save best model\n",
    "        pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "    print(f'{method} our out of folds CV f1score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "#学習メソッドの定義\n",
    "def Learning(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        gradient_boosting_model_cv_training(method, input_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWzQv798OiQ-",
    "outputId": "57cabf2c-5c42-4084-e263-e00eaeb695ec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "adaboost training fold 1\n",
      "--------------------------------------------------\n",
      "adaboost training fold 2\n",
      "--------------------------------------------------\n",
      "adaboost training fold 3\n",
      "--------------------------------------------------\n",
      "adaboost training fold 4\n",
      "--------------------------------------------------\n",
      "adaboost training fold 5\n",
      "--------------------------------------------------\n",
      "adaboost training fold 6\n",
      "--------------------------------------------------\n",
      "adaboost training fold 7\n",
      "adaboost our out of folds CV f1score is 0.6391065744612927\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.123678 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19034\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.891974\ttraining's f1score: 0.590314\tvalid_1's auc: 0.751713\tvalid_1's f1score: 0.560418\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19156\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's auc: 0.910157\ttraining's f1score: 0.648325\tvalid_1's auc: 0.764776\tvalid_1's f1score: 0.573036\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.138495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19114\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's auc: 0.882352\ttraining's f1score: 0.562166\tvalid_1's auc: 0.768099\tvalid_1's f1score: 0.538944\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.168208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19082\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's auc: 0.894199\ttraining's f1score: 0.597603\tvalid_1's auc: 0.778775\tvalid_1's f1score: 0.575027\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 19132\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's auc: 0.891116\ttraining's f1score: 0.585234\tvalid_1's auc: 0.767853\tvalid_1's f1score: 0.541834\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19095\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's auc: 0.88983\ttraining's f1score: 0.568217\tvalid_1's auc: 0.7759\tvalid_1's f1score: 0.541022\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.119106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 19120\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 45\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's auc: 0.849699\ttraining's f1score: 0.471578\tvalid_1's auc: 0.775751\tvalid_1's f1score: 0.472089\n",
      "lightgbm our out of folds CV f1score is 0.5447308163022696\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1\n",
      "[0]\ttrain-logloss:0.65987\ttrain-f1score:0.09771\teval-logloss:0.65991\teval-f1score:0.09208\n",
      "[25]\ttrain-logloss:0.33437\ttrain-f1score:0.67466\teval-logloss:0.33733\teval-f1score:0.63857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50]\ttrain-logloss:0.27675\ttrain-f1score:0.67204\teval-logloss:0.28694\teval-f1score:0.63579\n",
      "[75]\ttrain-logloss:0.25872\ttrain-f1score:0.67967\teval-logloss:0.27890\teval-f1score:0.63887\n",
      "[100]\ttrain-logloss:0.24815\ttrain-f1score:0.68899\teval-logloss:0.27688\teval-f1score:0.64724\n",
      "[125]\ttrain-logloss:0.24082\ttrain-f1score:0.69676\teval-logloss:0.27607\teval-f1score:0.64973\n",
      "[150]\ttrain-logloss:0.23532\ttrain-f1score:0.70519\teval-logloss:0.27602\teval-f1score:0.65144\n",
      "[175]\ttrain-logloss:0.23110\ttrain-f1score:0.70842\teval-logloss:0.27584\teval-f1score:0.65216\n",
      "[200]\ttrain-logloss:0.22724\ttrain-f1score:0.71417\teval-logloss:0.27589\teval-f1score:0.65408\n",
      "[225]\ttrain-logloss:0.22435\ttrain-f1score:0.71854\teval-logloss:0.27623\teval-f1score:0.65237\n",
      "[250]\ttrain-logloss:0.22075\ttrain-f1score:0.72378\teval-logloss:0.27626\teval-f1score:0.65479\n",
      "[275]\ttrain-logloss:0.21616\ttrain-f1score:0.72915\teval-logloss:0.27629\teval-f1score:0.65355\n",
      "[300]\ttrain-logloss:0.21303\ttrain-f1score:0.73595\teval-logloss:0.27657\teval-f1score:0.65377\n",
      "[325]\ttrain-logloss:0.20957\ttrain-f1score:0.74057\teval-logloss:0.27671\teval-f1score:0.65210\n",
      "[350]\ttrain-logloss:0.20634\ttrain-f1score:0.74630\teval-logloss:0.27692\teval-f1score:0.65163\n",
      "[375]\ttrain-logloss:0.20267\ttrain-f1score:0.75411\teval-logloss:0.27705\teval-f1score:0.65090\n",
      "[400]\ttrain-logloss:0.19923\ttrain-f1score:0.75845\teval-logloss:0.27713\teval-f1score:0.65303\n",
      "[425]\ttrain-logloss:0.19582\ttrain-f1score:0.76509\teval-logloss:0.27730\teval-f1score:0.65232\n",
      "[450]\ttrain-logloss:0.19229\ttrain-f1score:0.77093\teval-logloss:0.27737\teval-f1score:0.65352\n",
      "[451]\ttrain-logloss:0.19225\ttrain-f1score:0.77080\teval-logloss:0.27740\teval-f1score:0.65352\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2\n",
      "[0]\ttrain-logloss:0.65978\ttrain-f1score:0.09652\teval-logloss:0.66031\teval-f1score:0.09925\n",
      "[25]\ttrain-logloss:0.33311\ttrain-f1score:0.67067\teval-logloss:0.34278\teval-f1score:0.66478\n",
      "[50]\ttrain-logloss:0.27589\ttrain-f1score:0.67098\teval-logloss:0.29412\teval-f1score:0.65734\n",
      "[75]\ttrain-logloss:0.25773\ttrain-f1score:0.68246\teval-logloss:0.28593\teval-f1score:0.66202\n",
      "[100]\ttrain-logloss:0.24739\ttrain-f1score:0.69162\teval-logloss:0.28415\teval-f1score:0.66258\n",
      "[125]\ttrain-logloss:0.24023\ttrain-f1score:0.69766\teval-logloss:0.28345\teval-f1score:0.66078\n",
      "[150]\ttrain-logloss:0.23463\ttrain-f1score:0.70335\teval-logloss:0.28309\teval-f1score:0.66046\n",
      "[175]\ttrain-logloss:0.23035\ttrain-f1score:0.70804\teval-logloss:0.28294\teval-f1score:0.66160\n",
      "[200]\ttrain-logloss:0.22644\ttrain-f1score:0.71226\teval-logloss:0.28320\teval-f1score:0.66241\n",
      "[215]\ttrain-logloss:0.22360\ttrain-f1score:0.71634\teval-logloss:0.28309\teval-f1score:0.66192\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3\n",
      "[0]\ttrain-logloss:0.65984\ttrain-f1score:0.09683\teval-logloss:0.66008\teval-f1score:0.09737\n",
      "[25]\ttrain-logloss:0.33329\ttrain-f1score:0.66766\teval-logloss:0.34041\teval-f1score:0.65992\n",
      "[50]\ttrain-logloss:0.27580\ttrain-f1score:0.67156\teval-logloss:0.29138\teval-f1score:0.64919\n",
      "[75]\ttrain-logloss:0.25742\ttrain-f1score:0.67982\teval-logloss:0.28244\teval-f1score:0.65362\n",
      "[100]\ttrain-logloss:0.24689\ttrain-f1score:0.68987\teval-logloss:0.27986\teval-f1score:0.65746\n",
      "[125]\ttrain-logloss:0.23902\ttrain-f1score:0.69920\teval-logloss:0.27931\teval-f1score:0.66234\n",
      "[150]\ttrain-logloss:0.23342\ttrain-f1score:0.70574\teval-logloss:0.27919\teval-f1score:0.66428\n",
      "[175]\ttrain-logloss:0.22871\ttrain-f1score:0.71271\teval-logloss:0.27934\teval-f1score:0.66428\n",
      "[200]\ttrain-logloss:0.22374\ttrain-f1score:0.71886\teval-logloss:0.27917\teval-f1score:0.66620\n",
      "[211]\ttrain-logloss:0.22137\ttrain-f1score:0.72181\teval-logloss:0.27927\teval-f1score:0.66570\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4\n",
      "[0]\ttrain-logloss:0.65993\ttrain-f1score:0.09733\teval-logloss:0.65978\teval-f1score:0.09440\n",
      "[25]\ttrain-logloss:0.33427\ttrain-f1score:0.67066\teval-logloss:0.33433\teval-f1score:0.66317\n",
      "[50]\ttrain-logloss:0.27684\ttrain-f1score:0.67287\teval-logloss:0.28325\teval-f1score:0.65939\n",
      "[75]\ttrain-logloss:0.25850\ttrain-f1score:0.68207\teval-logloss:0.27432\teval-f1score:0.65929\n",
      "[100]\ttrain-logloss:0.24779\ttrain-f1score:0.69047\teval-logloss:0.27280\teval-f1score:0.66507\n",
      "[125]\ttrain-logloss:0.24140\ttrain-f1score:0.69631\teval-logloss:0.27227\teval-f1score:0.66730\n",
      "[150]\ttrain-logloss:0.23629\ttrain-f1score:0.70196\teval-logloss:0.27217\teval-f1score:0.66762\n",
      "[175]\ttrain-logloss:0.23177\ttrain-f1score:0.70730\teval-logloss:0.27207\teval-f1score:0.67109\n",
      "[200]\ttrain-logloss:0.22724\ttrain-f1score:0.71384\teval-logloss:0.27185\teval-f1score:0.67096\n",
      "[225]\ttrain-logloss:0.22335\ttrain-f1score:0.71897\teval-logloss:0.27202\teval-f1score:0.67162\n",
      "[250]\ttrain-logloss:0.21933\ttrain-f1score:0.72394\teval-logloss:0.27197\teval-f1score:0.67202\n",
      "[275]\ttrain-logloss:0.21548\ttrain-f1score:0.72987\teval-logloss:0.27202\teval-f1score:0.67084\n",
      "[300]\ttrain-logloss:0.21225\ttrain-f1score:0.73356\teval-logloss:0.27228\teval-f1score:0.67032\n",
      "[325]\ttrain-logloss:0.20931\ttrain-f1score:0.74088\teval-logloss:0.27226\teval-f1score:0.67189\n",
      "[350]\ttrain-logloss:0.20636\ttrain-f1score:0.74575\teval-logloss:0.27260\teval-f1score:0.66968\n",
      "[375]\ttrain-logloss:0.20343\ttrain-f1score:0.75169\teval-logloss:0.27283\teval-f1score:0.67111\n",
      "[400]\ttrain-logloss:0.19966\ttrain-f1score:0.75707\teval-logloss:0.27340\teval-f1score:0.66943\n",
      "[425]\ttrain-logloss:0.19579\ttrain-f1score:0.76411\teval-logloss:0.27401\teval-f1score:0.67098\n",
      "[450]\ttrain-logloss:0.19272\ttrain-f1score:0.77024\teval-logloss:0.27426\teval-f1score:0.66982\n",
      "[475]\ttrain-logloss:0.18936\ttrain-f1score:0.77737\teval-logloss:0.27480\teval-f1score:0.67008\n",
      "[499]\ttrain-logloss:0.18691\ttrain-f1score:0.78297\teval-logloss:0.27533\teval-f1score:0.67008\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5\n",
      "[0]\ttrain-logloss:0.65984\ttrain-f1score:0.09710\teval-logloss:0.66001\teval-f1score:0.09575\n",
      "[25]\ttrain-logloss:0.33417\ttrain-f1score:0.67190\teval-logloss:0.33752\teval-f1score:0.66293\n",
      "[50]\ttrain-logloss:0.27711\ttrain-f1score:0.67203\teval-logloss:0.28671\teval-f1score:0.65391\n",
      "[75]\ttrain-logloss:0.25872\ttrain-f1score:0.68193\teval-logloss:0.27671\teval-f1score:0.65586\n",
      "[100]\ttrain-logloss:0.24828\ttrain-f1score:0.69105\teval-logloss:0.27433\teval-f1score:0.65937\n",
      "[125]\ttrain-logloss:0.24047\ttrain-f1score:0.69810\teval-logloss:0.27296\teval-f1score:0.66070\n",
      "[150]\ttrain-logloss:0.23428\ttrain-f1score:0.70507\teval-logloss:0.27231\teval-f1score:0.66793\n",
      "[175]\ttrain-logloss:0.22996\ttrain-f1score:0.71042\teval-logloss:0.27201\teval-f1score:0.66756\n",
      "[200]\ttrain-logloss:0.22599\ttrain-f1score:0.71539\teval-logloss:0.27175\teval-f1score:0.66603\n",
      "[225]\ttrain-logloss:0.22294\ttrain-f1score:0.72058\teval-logloss:0.27178\teval-f1score:0.66968\n",
      "[250]\ttrain-logloss:0.21836\ttrain-f1score:0.72612\teval-logloss:0.27163\teval-f1score:0.66917\n",
      "[275]\ttrain-logloss:0.21441\ttrain-f1score:0.73210\teval-logloss:0.27176\teval-f1score:0.66826\n",
      "[300]\ttrain-logloss:0.21059\ttrain-f1score:0.73553\teval-logloss:0.27205\teval-f1score:0.66786\n",
      "[325]\ttrain-logloss:0.20771\ttrain-f1score:0.74172\teval-logloss:0.27228\teval-f1score:0.66877\n",
      "[350]\ttrain-logloss:0.20453\ttrain-f1score:0.74725\teval-logloss:0.27250\teval-f1score:0.66786\n",
      "[375]\ttrain-logloss:0.20125\ttrain-f1score:0.75273\teval-logloss:0.27269\teval-f1score:0.66786\n",
      "[400]\ttrain-logloss:0.19745\ttrain-f1score:0.76019\teval-logloss:0.27308\teval-f1score:0.66943\n",
      "[425]\ttrain-logloss:0.19447\ttrain-f1score:0.76582\teval-logloss:0.27324\teval-f1score:0.66840\n",
      "[437]\ttrain-logloss:0.19334\ttrain-f1score:0.76736\teval-logloss:0.27353\teval-f1score:0.66892\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6\n",
      "[0]\ttrain-logloss:0.65974\ttrain-f1score:0.09575\teval-logloss:0.66037\teval-f1score:0.10380\n",
      "[25]\ttrain-logloss:0.33278\ttrain-f1score:0.65915\teval-logloss:0.34477\teval-f1score:0.66687\n",
      "[50]\ttrain-logloss:0.27540\ttrain-f1score:0.66307\teval-logloss:0.29733\teval-f1score:0.66247\n",
      "[75]\ttrain-logloss:0.25672\ttrain-f1score:0.67687\teval-logloss:0.28914\teval-f1score:0.67560\n",
      "[100]\ttrain-logloss:0.24638\ttrain-f1score:0.68544\teval-logloss:0.28705\teval-f1score:0.67705\n",
      "[125]\ttrain-logloss:0.23849\ttrain-f1score:0.69472\teval-logloss:0.28657\teval-f1score:0.68129\n",
      "[150]\ttrain-logloss:0.23317\ttrain-f1score:0.70231\teval-logloss:0.28683\teval-f1score:0.68161\n",
      "[175]\ttrain-logloss:0.22868\ttrain-f1score:0.70780\teval-logloss:0.28720\teval-f1score:0.67895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain-logloss:0.22566\ttrain-f1score:0.71188\teval-logloss:0.28733\teval-f1score:0.67771\n",
      "[215]\ttrain-logloss:0.22371\ttrain-f1score:0.71422\teval-logloss:0.28750\teval-f1score:0.67853\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7\n",
      "[0]\ttrain-logloss:0.65982\ttrain-f1score:0.09712\teval-logloss:0.66009\teval-f1score:0.09563\n",
      "[25]\ttrain-logloss:0.33341\ttrain-f1score:0.67325\teval-logloss:0.34086\teval-f1score:0.66005\n",
      "[50]\ttrain-logloss:0.27619\ttrain-f1score:0.67256\teval-logloss:0.29152\teval-f1score:0.65862\n",
      "[75]\ttrain-logloss:0.25776\ttrain-f1score:0.68215\teval-logloss:0.28280\teval-f1score:0.66119\n",
      "[100]\ttrain-logloss:0.24749\ttrain-f1score:0.69120\teval-logloss:0.28051\teval-f1score:0.66298\n",
      "[125]\ttrain-logloss:0.24069\ttrain-f1score:0.69848\teval-logloss:0.28044\teval-f1score:0.65900\n",
      "[150]\ttrain-logloss:0.23421\ttrain-f1score:0.70508\teval-logloss:0.28031\teval-f1score:0.66246\n",
      "[175]\ttrain-logloss:0.22892\ttrain-f1score:0.71179\teval-logloss:0.28069\teval-f1score:0.66213\n",
      "[200]\ttrain-logloss:0.22458\ttrain-f1score:0.71618\teval-logloss:0.28104\teval-f1score:0.66373\n",
      "[225]\ttrain-logloss:0.22049\ttrain-f1score:0.72251\teval-logloss:0.28138\teval-f1score:0.66388\n",
      "[250]\ttrain-logloss:0.21732\ttrain-f1score:0.72719\teval-logloss:0.28136\teval-f1score:0.66499\n",
      "[275]\ttrain-logloss:0.21397\ttrain-f1score:0.73186\teval-logloss:0.28145\teval-f1score:0.66538\n",
      "[300]\ttrain-logloss:0.21114\ttrain-f1score:0.73665\teval-logloss:0.28171\teval-f1score:0.66724\n",
      "[325]\ttrain-logloss:0.20840\ttrain-f1score:0.74309\teval-logloss:0.28184\teval-f1score:0.66440\n",
      "[350]\ttrain-logloss:0.20542\ttrain-f1score:0.74763\teval-logloss:0.28219\teval-f1score:0.66502\n",
      "[375]\ttrain-logloss:0.20215\ttrain-f1score:0.75436\teval-logloss:0.28232\teval-f1score:0.66305\n",
      "[400]\ttrain-logloss:0.19966\ttrain-f1score:0.75983\teval-logloss:0.28257\teval-f1score:0.66454\n",
      "[425]\ttrain-logloss:0.19598\ttrain-f1score:0.76430\teval-logloss:0.28271\teval-f1score:0.66343\n",
      "[450]\ttrain-logloss:0.19203\ttrain-f1score:0.77146\teval-logloss:0.28304\teval-f1score:0.66185\n",
      "[475]\ttrain-logloss:0.18850\ttrain-f1score:0.78075\teval-logloss:0.28343\teval-f1score:0.66553\n",
      "[497]\ttrain-logloss:0.18501\ttrain-f1score:0.78767\teval-logloss:0.28412\teval-f1score:0.66688\n",
      "xgboost our out of folds CV f1score is 0.6399758993412323\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "0:\tlearn: 0.6434721\ttest: 0.6429299\tbest: 0.6429299 (0)\ttotal: 299ms\tremaining: 2m 28s\n",
      "25:\tlearn: 0.3094716\ttest: 0.3056986\tbest: 0.3056986 (25)\ttotal: 8.37s\tremaining: 2m 32s\n",
      "50:\tlearn: 0.2812383\ttest: 0.2783481\tbest: 0.2783481 (50)\ttotal: 16.8s\tremaining: 2m 27s\n",
      "75:\tlearn: 0.2754859\ttest: 0.2742755\tbest: 0.2742755 (75)\ttotal: 24.8s\tremaining: 2m 18s\n",
      "100:\tlearn: 0.2725989\ttest: 0.2731974\tbest: 0.2731974 (100)\ttotal: 34.2s\tremaining: 2m 14s\n",
      "125:\tlearn: 0.2702244\ttest: 0.2727336\tbest: 0.2726679 (121)\ttotal: 42.6s\tremaining: 2m 6s\n",
      "150:\tlearn: 0.2685586\ttest: 0.2724868\tbest: 0.2724633 (148)\ttotal: 51.4s\tremaining: 1m 58s\n",
      "175:\tlearn: 0.2667375\ttest: 0.2722268\tbest: 0.2722087 (174)\ttotal: 1m\tremaining: 1m 51s\n",
      "200:\tlearn: 0.2650089\ttest: 0.2723383\tbest: 0.2722087 (174)\ttotal: 1m 9s\tremaining: 1m 42s\n",
      "225:\tlearn: 0.2636764\ttest: 0.2723143\tbest: 0.2722087 (174)\ttotal: 1m 17s\tremaining: 1m 34s\n",
      "250:\tlearn: 0.2621798\ttest: 0.2720812\tbest: 0.2720812 (250)\ttotal: 1m 25s\tremaining: 1m 25s\n",
      "275:\tlearn: 0.2608596\ttest: 0.2720553\tbest: 0.2719798 (265)\ttotal: 1m 34s\tremaining: 1m 16s\n",
      "300:\tlearn: 0.2592928\ttest: 0.2719377\tbest: 0.2719266 (297)\ttotal: 1m 43s\tremaining: 1m 8s\n",
      "325:\tlearn: 0.2579079\ttest: 0.2720587\tbest: 0.2719266 (297)\ttotal: 1m 51s\tremaining: 59.6s\n",
      "350:\tlearn: 0.2567196\ttest: 0.2719325\tbest: 0.2719119 (345)\ttotal: 2m\tremaining: 51.2s\n",
      "375:\tlearn: 0.2552847\ttest: 0.2718740\tbest: 0.2718552 (362)\ttotal: 2m 10s\tremaining: 42.9s\n",
      "400:\tlearn: 0.2538313\ttest: 0.2719861\tbest: 0.2718552 (362)\ttotal: 2m 19s\tremaining: 34.4s\n",
      "425:\tlearn: 0.2524472\ttest: 0.2718310\tbest: 0.2718148 (414)\ttotal: 2m 28s\tremaining: 25.8s\n",
      "450:\tlearn: 0.2507734\ttest: 0.2718775\tbest: 0.2717608 (445)\ttotal: 2m 37s\tremaining: 17.1s\n",
      "475:\tlearn: 0.2495465\ttest: 0.2718714\tbest: 0.2717608 (445)\ttotal: 2m 47s\tremaining: 8.46s\n",
      "499:\tlearn: 0.2482449\ttest: 0.2720120\tbest: 0.2717608 (445)\ttotal: 2m 57s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2717607673\n",
      "bestIteration = 445\n",
      "\n",
      "Shrink model to first 446 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "0:\tlearn: 0.6432291\ttest: 0.6437960\tbest: 0.6437960 (0)\ttotal: 346ms\tremaining: 2m 52s\n",
      "25:\tlearn: 0.3106841\ttest: 0.3161150\tbest: 0.3161150 (25)\ttotal: 8.62s\tremaining: 2m 37s\n",
      "50:\tlearn: 0.2797318\ttest: 0.2886394\tbest: 0.2886394 (50)\ttotal: 17.1s\tremaining: 2m 30s\n",
      "75:\tlearn: 0.2734813\ttest: 0.2844582\tbest: 0.2844582 (75)\ttotal: 25.6s\tremaining: 2m 22s\n",
      "100:\tlearn: 0.2707122\ttest: 0.2831653\tbest: 0.2831653 (100)\ttotal: 34.5s\tremaining: 2m 16s\n",
      "125:\tlearn: 0.2685287\ttest: 0.2822239\tbest: 0.2822126 (124)\ttotal: 44s\tremaining: 2m 10s\n",
      "150:\tlearn: 0.2669020\ttest: 0.2816870\tbest: 0.2816751 (145)\ttotal: 52.9s\tremaining: 2m 2s\n",
      "175:\tlearn: 0.2653906\ttest: 0.2814816\tbest: 0.2814816 (175)\ttotal: 1m 2s\tremaining: 1m 55s\n",
      "200:\tlearn: 0.2639090\ttest: 0.2812842\tbest: 0.2812096 (191)\ttotal: 1m 11s\tremaining: 1m 46s\n",
      "225:\tlearn: 0.2626633\ttest: 0.2810791\tbest: 0.2810791 (225)\ttotal: 1m 21s\tremaining: 1m 38s\n",
      "250:\tlearn: 0.2612423\ttest: 0.2807158\tbest: 0.2807139 (248)\ttotal: 1m 30s\tremaining: 1m 29s\n",
      "275:\tlearn: 0.2599126\ttest: 0.2806327\tbest: 0.2806327 (275)\ttotal: 1m 39s\tremaining: 1m 20s\n",
      "300:\tlearn: 0.2585712\ttest: 0.2804633\tbest: 0.2804633 (300)\ttotal: 1m 48s\tremaining: 1m 11s\n",
      "325:\tlearn: 0.2570936\ttest: 0.2802514\tbest: 0.2802425 (321)\ttotal: 1m 57s\tremaining: 1m 2s\n",
      "350:\tlearn: 0.2560054\ttest: 0.2800697\tbest: 0.2800697 (350)\ttotal: 2m 6s\tremaining: 53.7s\n",
      "375:\tlearn: 0.2545193\ttest: 0.2798955\tbest: 0.2798737 (368)\ttotal: 2m 15s\tremaining: 44.8s\n",
      "400:\tlearn: 0.2533119\ttest: 0.2799248\tbest: 0.2798717 (377)\ttotal: 2m 24s\tremaining: 35.8s\n",
      "425:\tlearn: 0.2519822\ttest: 0.2799629\tbest: 0.2798717 (377)\ttotal: 2m 34s\tremaining: 26.8s\n",
      "450:\tlearn: 0.2508538\ttest: 0.2798789\tbest: 0.2798717 (377)\ttotal: 2m 44s\tremaining: 17.9s\n",
      "475:\tlearn: 0.2496357\ttest: 0.2799319\tbest: 0.2798113 (467)\ttotal: 2m 53s\tremaining: 8.77s\n",
      "499:\tlearn: 0.2483436\ttest: 0.2799598\tbest: 0.2798113 (467)\ttotal: 3m 3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2798112529\n",
      "bestIteration = 467\n",
      "\n",
      "Shrink model to first 468 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "0:\tlearn: 0.6434245\ttest: 0.6436494\tbest: 0.6436494 (0)\ttotal: 291ms\tremaining: 2m 25s\n",
      "25:\tlearn: 0.3096474\ttest: 0.3126862\tbest: 0.3126862 (25)\ttotal: 8.91s\tremaining: 2m 42s\n",
      "50:\tlearn: 0.2802876\ttest: 0.2841854\tbest: 0.2841854 (50)\ttotal: 18.5s\tremaining: 2m 43s\n",
      "75:\tlearn: 0.2746157\ttest: 0.2797410\tbest: 0.2797410 (75)\ttotal: 27.7s\tremaining: 2m 34s\n",
      "100:\tlearn: 0.2715740\ttest: 0.2779573\tbest: 0.2779573 (100)\ttotal: 36.4s\tremaining: 2m 23s\n",
      "125:\tlearn: 0.2694691\ttest: 0.2769457\tbest: 0.2769457 (125)\ttotal: 43.7s\tremaining: 2m 9s\n",
      "150:\tlearn: 0.2678011\ttest: 0.2765261\tbest: 0.2765261 (150)\ttotal: 51.8s\tremaining: 1m 59s\n",
      "175:\tlearn: 0.2665493\ttest: 0.2763094\tbest: 0.2762858 (173)\ttotal: 1m\tremaining: 1m 51s\n",
      "200:\tlearn: 0.2649242\ttest: 0.2760154\tbest: 0.2760154 (200)\ttotal: 1m 9s\tremaining: 1m 42s\n",
      "225:\tlearn: 0.2635759\ttest: 0.2759266\tbest: 0.2758805 (223)\ttotal: 1m 17s\tremaining: 1m 33s\n",
      "250:\tlearn: 0.2620017\ttest: 0.2756754\tbest: 0.2756754 (250)\ttotal: 1m 24s\tremaining: 1m 24s\n",
      "275:\tlearn: 0.2603076\ttest: 0.2754385\tbest: 0.2754209 (274)\ttotal: 1m 31s\tremaining: 1m 14s\n",
      "300:\tlearn: 0.2586948\ttest: 0.2752550\tbest: 0.2752550 (300)\ttotal: 1m 39s\tremaining: 1m 5s\n",
      "325:\tlearn: 0.2573865\ttest: 0.2752086\tbest: 0.2751616 (320)\ttotal: 1m 48s\tremaining: 57.8s\n",
      "350:\tlearn: 0.2561109\ttest: 0.2751846\tbest: 0.2751608 (344)\ttotal: 1m 56s\tremaining: 49.5s\n",
      "375:\tlearn: 0.2548270\ttest: 0.2750271\tbest: 0.2750260 (373)\ttotal: 2m 4s\tremaining: 40.9s\n",
      "400:\tlearn: 0.2537896\ttest: 0.2750690\tbest: 0.2750059 (376)\ttotal: 2m 11s\tremaining: 32.4s\n",
      "425:\tlearn: 0.2524369\ttest: 0.2750310\tbest: 0.2749482 (416)\ttotal: 2m 18s\tremaining: 24s\n",
      "450:\tlearn: 0.2512134\ttest: 0.2748466\tbest: 0.2748466 (450)\ttotal: 2m 25s\tremaining: 15.8s\n",
      "475:\tlearn: 0.2498621\ttest: 0.2749634\tbest: 0.2748466 (450)\ttotal: 2m 32s\tremaining: 7.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499:\tlearn: 0.2486217\ttest: 0.2752142\tbest: 0.2748466 (450)\ttotal: 2m 39s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2748466439\n",
      "bestIteration = 450\n",
      "\n",
      "Shrink model to first 451 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4\n",
      "0:\tlearn: 0.6437064\ttest: 0.6430300\tbest: 0.6430300 (0)\ttotal: 254ms\tremaining: 2m 6s\n",
      "25:\tlearn: 0.3090644\ttest: 0.3016502\tbest: 0.3016502 (25)\ttotal: 6.92s\tremaining: 2m 6s\n",
      "50:\tlearn: 0.2818792\ttest: 0.2749468\tbest: 0.2749468 (50)\ttotal: 13.5s\tremaining: 1m 58s\n",
      "75:\tlearn: 0.2757980\ttest: 0.2704123\tbest: 0.2704123 (75)\ttotal: 19.8s\tremaining: 1m 50s\n",
      "100:\tlearn: 0.2726098\ttest: 0.2690655\tbest: 0.2690655 (100)\ttotal: 26.4s\tremaining: 1m 44s\n",
      "125:\tlearn: 0.2707361\ttest: 0.2684003\tbest: 0.2683836 (124)\ttotal: 32.3s\tremaining: 1m 35s\n",
      "150:\tlearn: 0.2691604\ttest: 0.2680466\tbest: 0.2680458 (149)\ttotal: 39s\tremaining: 1m 30s\n",
      "175:\tlearn: 0.2673552\ttest: 0.2676483\tbest: 0.2676483 (175)\ttotal: 45.9s\tremaining: 1m 24s\n",
      "200:\tlearn: 0.2658064\ttest: 0.2673558\tbest: 0.2673279 (196)\ttotal: 53.5s\tremaining: 1m 19s\n",
      "225:\tlearn: 0.2644410\ttest: 0.2672135\tbest: 0.2671675 (214)\ttotal: 1m 1s\tremaining: 1m 15s\n",
      "250:\tlearn: 0.2628645\ttest: 0.2669890\tbest: 0.2669890 (250)\ttotal: 1m 9s\tremaining: 1m 9s\n",
      "275:\tlearn: 0.2612760\ttest: 0.2668143\tbest: 0.2668122 (273)\ttotal: 1m 17s\tremaining: 1m 3s\n",
      "300:\tlearn: 0.2598113\ttest: 0.2666883\tbest: 0.2666786 (298)\ttotal: 1m 25s\tremaining: 56.5s\n",
      "325:\tlearn: 0.2584060\ttest: 0.2667135\tbest: 0.2666786 (298)\ttotal: 1m 34s\tremaining: 50.2s\n",
      "350:\tlearn: 0.2571774\ttest: 0.2667839\tbest: 0.2666786 (298)\ttotal: 1m 42s\tremaining: 43.5s\n",
      "375:\tlearn: 0.2559195\ttest: 0.2666577\tbest: 0.2666577 (375)\ttotal: 1m 50s\tremaining: 36.4s\n",
      "400:\tlearn: 0.2545092\ttest: 0.2666615\tbest: 0.2666520 (380)\ttotal: 1m 57s\tremaining: 29.1s\n",
      "425:\tlearn: 0.2531374\ttest: 0.2666952\tbest: 0.2666047 (412)\ttotal: 2m 4s\tremaining: 21.6s\n",
      "450:\tlearn: 0.2520280\ttest: 0.2666747\tbest: 0.2666047 (412)\ttotal: 2m 11s\tremaining: 14.3s\n",
      "475:\tlearn: 0.2505186\ttest: 0.2668025\tbest: 0.2665704 (458)\ttotal: 2m 19s\tremaining: 7.04s\n",
      "499:\tlearn: 0.2492629\ttest: 0.2668651\tbest: 0.2665704 (458)\ttotal: 2m 28s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2665703919\n",
      "bestIteration = 458\n",
      "\n",
      "Shrink model to first 459 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5\n",
      "0:\tlearn: 0.6435776\ttest: 0.6434896\tbest: 0.6434896 (0)\ttotal: 363ms\tremaining: 3m\n",
      "25:\tlearn: 0.3088778\ttest: 0.3061520\tbest: 0.3061520 (25)\ttotal: 8.26s\tremaining: 2m 30s\n",
      "50:\tlearn: 0.2813704\ttest: 0.2782098\tbest: 0.2782098 (50)\ttotal: 17.5s\tremaining: 2m 33s\n",
      "75:\tlearn: 0.2755884\ttest: 0.2734594\tbest: 0.2734594 (75)\ttotal: 25.8s\tremaining: 2m 24s\n",
      "100:\tlearn: 0.2729009\ttest: 0.2720656\tbest: 0.2720656 (100)\ttotal: 33.7s\tremaining: 2m 13s\n",
      "125:\tlearn: 0.2706118\ttest: 0.2711462\tbest: 0.2711462 (125)\ttotal: 41.8s\tremaining: 2m 3s\n",
      "150:\tlearn: 0.2688814\ttest: 0.2706870\tbest: 0.2706870 (150)\ttotal: 50.2s\tremaining: 1m 56s\n",
      "175:\tlearn: 0.2675398\ttest: 0.2704669\tbest: 0.2704669 (175)\ttotal: 59.1s\tremaining: 1m 48s\n",
      "200:\tlearn: 0.2660215\ttest: 0.2701558\tbest: 0.2701117 (199)\ttotal: 1m 8s\tremaining: 1m 42s\n",
      "225:\tlearn: 0.2642535\ttest: 0.2698180\tbest: 0.2698180 (225)\ttotal: 1m 20s\tremaining: 1m 37s\n",
      "250:\tlearn: 0.2629535\ttest: 0.2696594\tbest: 0.2696594 (250)\ttotal: 1m 29s\tremaining: 1m 28s\n",
      "275:\tlearn: 0.2616159\ttest: 0.2693467\tbest: 0.2693467 (275)\ttotal: 1m 37s\tremaining: 1m 19s\n",
      "300:\tlearn: 0.2603033\ttest: 0.2691782\tbest: 0.2691782 (300)\ttotal: 1m 44s\tremaining: 1m 9s\n",
      "325:\tlearn: 0.2588957\ttest: 0.2691522\tbest: 0.2691460 (309)\ttotal: 1m 52s\tremaining: 59.8s\n",
      "350:\tlearn: 0.2575550\ttest: 0.2691679\tbest: 0.2691460 (309)\ttotal: 1m 59s\tremaining: 50.7s\n",
      "375:\tlearn: 0.2561355\ttest: 0.2692209\tbest: 0.2691460 (309)\ttotal: 2m 6s\tremaining: 41.6s\n",
      "400:\tlearn: 0.2548971\ttest: 0.2691757\tbest: 0.2690982 (390)\ttotal: 2m 13s\tremaining: 32.9s\n",
      "425:\tlearn: 0.2532042\ttest: 0.2691036\tbest: 0.2690982 (390)\ttotal: 2m 20s\tremaining: 24.4s\n",
      "450:\tlearn: 0.2516917\ttest: 0.2689192\tbest: 0.2688828 (443)\ttotal: 2m 27s\tremaining: 16.1s\n",
      "475:\tlearn: 0.2504460\ttest: 0.2689037\tbest: 0.2688320 (457)\ttotal: 2m 34s\tremaining: 7.81s\n",
      "499:\tlearn: 0.2493205\ttest: 0.2689248\tbest: 0.2688320 (457)\ttotal: 2m 41s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2688319838\n",
      "bestIteration = 457\n",
      "\n",
      "Shrink model to first 458 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6\n",
      "0:\tlearn: 0.6432366\ttest: 0.6439067\tbest: 0.6439067 (0)\ttotal: 278ms\tremaining: 2m 18s\n",
      "25:\tlearn: 0.3072020\ttest: 0.3154847\tbest: 0.3154847 (25)\ttotal: 5.87s\tremaining: 1m 47s\n",
      "50:\tlearn: 0.2794650\ttest: 0.2884780\tbest: 0.2884780 (50)\ttotal: 12s\tremaining: 1m 45s\n",
      "75:\tlearn: 0.2732980\ttest: 0.2836842\tbest: 0.2836842 (75)\ttotal: 18.3s\tremaining: 1m 42s\n",
      "100:\tlearn: 0.2700504\ttest: 0.2818879\tbest: 0.2818879 (100)\ttotal: 25s\tremaining: 1m 38s\n",
      "125:\tlearn: 0.2680032\ttest: 0.2811167\tbest: 0.2811167 (125)\ttotal: 31.2s\tremaining: 1m 32s\n",
      "150:\tlearn: 0.2661830\ttest: 0.2808266\tbest: 0.2807852 (148)\ttotal: 37.3s\tremaining: 1m 26s\n",
      "175:\tlearn: 0.2647217\ttest: 0.2809139\tbest: 0.2807852 (148)\ttotal: 43.3s\tremaining: 1m 19s\n",
      "200:\tlearn: 0.2632373\ttest: 0.2808183\tbest: 0.2807852 (148)\ttotal: 50s\tremaining: 1m 14s\n",
      "225:\tlearn: 0.2618715\ttest: 0.2805993\tbest: 0.2805861 (224)\ttotal: 56.2s\tremaining: 1m 8s\n",
      "250:\tlearn: 0.2604854\ttest: 0.2804029\tbest: 0.2803903 (248)\ttotal: 1m 2s\tremaining: 1m 2s\n",
      "275:\tlearn: 0.2594224\ttest: 0.2803352\tbest: 0.2803044 (273)\ttotal: 1m 9s\tremaining: 56.5s\n",
      "300:\tlearn: 0.2578420\ttest: 0.2804102\tbest: 0.2803044 (273)\ttotal: 1m 17s\tremaining: 51s\n",
      "325:\tlearn: 0.2565699\ttest: 0.2803508\tbest: 0.2803044 (273)\ttotal: 1m 23s\tremaining: 44.7s\n",
      "350:\tlearn: 0.2554688\ttest: 0.2803182\tbest: 0.2803029 (349)\ttotal: 1m 30s\tremaining: 38.4s\n",
      "375:\tlearn: 0.2543975\ttest: 0.2803115\tbest: 0.2803029 (349)\ttotal: 1m 37s\tremaining: 32.3s\n",
      "400:\tlearn: 0.2530822\ttest: 0.2805504\tbest: 0.2803029 (349)\ttotal: 1m 44s\tremaining: 25.9s\n",
      "425:\tlearn: 0.2516889\ttest: 0.2807781\tbest: 0.2803029 (349)\ttotal: 1m 51s\tremaining: 19.4s\n",
      "450:\tlearn: 0.2506270\ttest: 0.2809637\tbest: 0.2803029 (349)\ttotal: 1m 58s\tremaining: 12.8s\n",
      "475:\tlearn: 0.2496586\ttest: 0.2810052\tbest: 0.2803029 (349)\ttotal: 2m 5s\tremaining: 6.32s\n",
      "499:\tlearn: 0.2485607\ttest: 0.2812067\tbest: 0.2803029 (349)\ttotal: 2m 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2803029005\n",
      "bestIteration = 349\n",
      "\n",
      "Shrink model to first 350 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 7\n",
      "0:\tlearn: 0.6462207\ttest: 0.6462375\tbest: 0.6462375 (0)\ttotal: 153ms\tremaining: 1m 16s\n",
      "25:\tlearn: 0.3099930\ttest: 0.3108264\tbest: 0.3108264 (25)\ttotal: 4.48s\tremaining: 1m 21s\n",
      "50:\tlearn: 0.2808601\ttest: 0.2827730\tbest: 0.2827730 (50)\ttotal: 9.68s\tremaining: 1m 25s\n",
      "75:\tlearn: 0.2747820\ttest: 0.2791148\tbest: 0.2791148 (75)\ttotal: 15s\tremaining: 1m 23s\n",
      "100:\tlearn: 0.2716023\ttest: 0.2778275\tbest: 0.2778275 (100)\ttotal: 20.6s\tremaining: 1m 21s\n",
      "125:\tlearn: 0.2696094\ttest: 0.2771599\tbest: 0.2771599 (125)\ttotal: 26.4s\tremaining: 1m 18s\n",
      "150:\tlearn: 0.2681939\ttest: 0.2767794\tbest: 0.2767794 (150)\ttotal: 32.3s\tremaining: 1m 14s\n",
      "175:\tlearn: 0.2666788\ttest: 0.2765446\tbest: 0.2765125 (172)\ttotal: 38.2s\tremaining: 1m 10s\n",
      "200:\tlearn: 0.2652756\ttest: 0.2764403\tbest: 0.2764260 (195)\ttotal: 44s\tremaining: 1m 5s\n",
      "225:\tlearn: 0.2638445\ttest: 0.2764258\tbest: 0.2763204 (214)\ttotal: 49.4s\tremaining: 59.9s\n",
      "250:\tlearn: 0.2624016\ttest: 0.2763965\tbest: 0.2763204 (214)\ttotal: 55.1s\tremaining: 54.6s\n",
      "275:\tlearn: 0.2609923\ttest: 0.2762760\tbest: 0.2762207 (269)\ttotal: 1m 1s\tremaining: 49.8s\n",
      "300:\tlearn: 0.2596091\ttest: 0.2762889\tbest: 0.2761683 (288)\ttotal: 1m 7s\tremaining: 44.7s\n",
      "325:\tlearn: 0.2583494\ttest: 0.2763385\tbest: 0.2761683 (288)\ttotal: 1m 13s\tremaining: 39.2s\n",
      "350:\tlearn: 0.2571628\ttest: 0.2764034\tbest: 0.2761683 (288)\ttotal: 1m 19s\tremaining: 33.7s\n",
      "375:\tlearn: 0.2558465\ttest: 0.2765784\tbest: 0.2761683 (288)\ttotal: 1m 25s\tremaining: 28.1s\n",
      "400:\tlearn: 0.2545837\ttest: 0.2765128\tbest: 0.2761683 (288)\ttotal: 1m 31s\tremaining: 22.5s\n",
      "425:\tlearn: 0.2532727\ttest: 0.2764309\tbest: 0.2761683 (288)\ttotal: 1m 37s\tremaining: 16.9s\n",
      "450:\tlearn: 0.2520445\ttest: 0.2764613\tbest: 0.2761683 (288)\ttotal: 1m 43s\tremaining: 11.3s\n",
      "475:\tlearn: 0.2508646\ttest: 0.2764594\tbest: 0.2761683 (288)\ttotal: 1m 49s\tremaining: 5.53s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2761682807\n",
      "bestIteration = 288\n",
      "\n",
      "Shrink model to first 289 iterations.\n",
      "catboost our out of folds CV f1score is 0.6442945431385723\n"
     ]
    }
   ],
   "source": [
    "Learning(train_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaboost_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'adaboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def svm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'svm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def randomforest_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        # モデルの読み込み\n",
    "        model = pickle.load(open(f'randomforest_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # 予測\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def sgd_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        # モデルの読み込み\n",
    "        model = pickle.load(open(f'sgd_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # 予測 (SGDClassifierはデフォルトでpredict_probaをサポートしていない場合があるので注意)\n",
    "        pred = model.decision_function(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def lightgbm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def xgboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(xgb.DMatrix(x_test))\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    x_test = test_df[features]\n",
    "    if method == 'adaboost':\n",
    "        test_pred = adaboost_inference(x_test)\n",
    "    if method == 'lightgbm':\n",
    "        test_pred = lightgbm_inference(x_test)\n",
    "    if method == 'xgboost':\n",
    "        test_pred = xgboost_inference(x_test)\n",
    "    if method == 'catboost':\n",
    "        test_pred = catboost_inference(x_test)\n",
    "    return test_pred\n",
    "\n",
    "def Predicting(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    output_df = input_df.copy()\n",
    "    output_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, input_df, features, categorical_features)\n",
    "        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = Predicting(test_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#後処理の定義\n",
    "def Postprocessing(train_df: pd.DataFrame(), test_df: pd.DataFrame()) -> (pd.DataFrame(), pd.DataFrame()):\n",
    "    train_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "        train_df['pred_prob'] += CFG.model_weight_dict[method] * oof_df[f'{method}_prediction']\n",
    "    best_score = 0\n",
    "    best_v = 0\n",
    "    for v in tqdm(np.arange(1000) / 1000):\n",
    "        score = f1_score(oof_df[CFG.target_col], train_df[f'pred_prob'] >= v, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_v = v\n",
    "    print(best_score, best_v)\n",
    "    test_df['target'] = np.where(test_df['pred_prob'] >= best_v, 1, 0)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cdb7af7069740f1abfa31e71fa7c113",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6901892477685019 0.517\n"
     ]
    }
   ],
   "source": [
    "#後処理\n",
    "train_df, test_df = Postprocessing(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['target']].to_csv(f'seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下、スタッキング   \n",
    "oofのcsvを一度作ってしまえばこれ以下のセルを動かすだけでいい   \n",
    "重み付けは一番上のリストの要素を変えることで可能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Best Threshold: 0.8, Best F1 Score: 0.6891924429158547\n"
     ]
    }
   ],
   "source": [
    "# 参考: CFG.METHOD_LIST = [ 'randomforest', 'adaboost','lightgbm', 'xgboost', 'catboost']\n",
    "#以下のリストを色々変えて試す\n",
    "method_list_adopted =['adaboost','lightgbm', 'xgboost', 'catboost', 'catboost', 'catboost']\n",
    "\n",
    "# OOF予測を基に新たな特徴量を作成\n",
    "oof_features = np.zeros((train_df.shape[0], len(method_list_adopted)))\n",
    "for i, method in enumerate(method_list_adopted):\n",
    "    oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "    oof_features[:, i] = oof_df[f'{method}_prediction']\n",
    "\n",
    "# テストデータの予測を基に特徴量を作成\n",
    "test_features = np.zeros((test_df.shape[0], len(method_list_adopted)))\n",
    "for i, method in enumerate(method_list_adopted):\n",
    "    test_features[:, i] = test_df[f'{method}_pred_prob']\n",
    "\n",
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "oof_features_scaled = scaler.fit_transform(oof_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# ロジスティック回帰モデルを学習\n",
    "lr = LogisticRegression()\n",
    "lr.fit(oof_features_scaled, train_df[CFG.target_col])\n",
    "\n",
    "# 最適な閾値とその時のF1スコアを探索する関数\n",
    "def find_best_threshold_and_score(y_true, y_pred_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in np.linspace(0, 1, 1001):  # 0.001刻みで閾値を変更\n",
    "        score = f1_score(y_true, y_pred_proba >= threshold, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# ロジスティック回帰モデルの学習データに対する予測確率\n",
    "train_pred_proba_lr = lr.predict_proba(oof_features_scaled)[:, 1]\n",
    "\n",
    "# 最適な閾値とスコアを求める\n",
    "best_threshold_lr, best_score_lr = find_best_threshold_and_score(train_df[CFG.target_col], train_pred_proba_lr)\n",
    "print(f'LR Best Threshold: {best_threshold_lr}, Best F1 Score: {best_score_lr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Best Threshold: 0.75, Best F1 Score: 0.6896358223103198\n"
     ]
    }
   ],
   "source": [
    "# 参考: CFG.METHOD_LIST = ['sgd', 'randomforest', 'adaboost','lightgbm', 'xgboost', 'catboost', 'svm']\n",
    "#以下のリストを色々変えて試す\n",
    "method_list_adopted = ['catboost','lightgbm','adaboost', 'xgboost']\n",
    "\n",
    "# OOF予測を基に新たな特徴量を作成\n",
    "oof_features = np.zeros((train_df.shape[0], len(method_list_adopted)))\n",
    "for i, method in enumerate(method_list_adopted):\n",
    "    oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "    oof_features[:, i] = oof_df[f'{method}_prediction']\n",
    "\n",
    "# テストデータの予測を基に特徴量を作成\n",
    "test_features = np.zeros((test_df.shape[0], len(method_list_adopted)))\n",
    "for i, method in enumerate(method_list_adopted):\n",
    "    test_features[:, i] = test_df[f'{method}_pred_prob']\n",
    "\n",
    "def create_interaction_features(features):\n",
    "    n_features = features.shape[1]\n",
    "    interaction_features = []\n",
    "    for i in range(n_features):\n",
    "        for j in range(i + 1, n_features):\n",
    "            interaction_features.append(features[:, i] * features[:, j])  # 積\n",
    "            # interaction_features.append(features[:, i] / (features[:, j] + 1e-5))  # 比（ゼロ除算を避けるための小さな値を追加）\n",
    "    return np.column_stack(interaction_features)\n",
    "\n",
    "# OOF予測を基に新たな特徴量を作成（相互作用含む）\n",
    "oof_interaction_features = create_interaction_features(oof_features)\n",
    "\n",
    "# テストデータの予測を基に特徴量を作成（相互作用含む）\n",
    "test_interaction_features = create_interaction_features(test_features)\n",
    "\n",
    "# 元の特徴量と相互作用特徴量を組み合わせ\n",
    "oof_combined_features = np.hstack([oof_features, oof_interaction_features])\n",
    "test_combined_features = np.hstack([test_features, test_interaction_features])\n",
    "\n",
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "oof_combined_features_scaled = scaler.fit_transform(oof_combined_features)\n",
    "test_combined_features_scaled = scaler.transform(test_combined_features)\n",
    "\n",
    "# ロジスティック回帰モデルを学習\n",
    "lr = LogisticRegression()\n",
    "lr.fit(oof_combined_features_scaled, train_df[CFG.target_col])\n",
    "\n",
    "\n",
    "# 最適な閾値とその時のF1スコアを探索する関数\n",
    "def find_best_threshold_and_score(y_true, y_pred_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in np.linspace(0, 1, 1001):  # 0.001刻みで閾値を変更\n",
    "        score = f1_score(y_true, y_pred_proba >= threshold, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# ロジスティック回帰モデルの学習データに対する予測確率\n",
    "train_pred_proba_lr = lr.predict_proba(oof_combined_features_scaled)[:, 1]\n",
    "\n",
    "# 最適な閾値とスコアを求める\n",
    "best_threshold_lr, best_score_lr = find_best_threshold_and_score(train_df[CFG.target_col], train_pred_proba_lr)\n",
    "print(f'LR Best Threshold: {best_threshold_lr}, Best F1 Score: {best_score_lr}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータに対する最終予測\n",
    "test_pred_proba_lr = lr.predict_proba(test_features_scaled)[:, 1]\n",
    "test_final_predictions_lr = (test_pred_proba_lr >= best_threshold_lr).astype(int)\n",
    "# 最終予測結果をコンペ提出用のフォーマットでCSVファイルに出力\n",
    "submission_df_lr = pd.DataFrame({'Id': test_df.index, 'target': test_final_predictions_lr}).reset_index(drop=True)\n",
    "submission_df_lr['Id'] = submission_df_lr.index + 42307\n",
    "submission_df_lr.to_csv(f'stacking_lr_submission_best_score{best_score_lr:.4f}_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#少し試してみた感じ\n",
    "#7つにしたとき組み合わせによらず値が同じになるのが面白い\n",
    "#この7はn_folds=7と関係してるのかな\n",
    "\n",
    "# 0.6883853294761878 ['adaboost','lightgbm', 'xgboost', 'catboost', 'catboost', 'catboost', 'catboost']\n",
    "# 0.688452930421711  ['adaboost','lightgbm', 'xgboost', 'catboost', 'catboost', 'catboost']\n",
    "# 0.6883853294761878 ['adaboost','lightgbm', 'xgboost', 'catboost', 'catboost']\n",
    "# 0.6883515386513768 ['adaboost','lightgbm', 'xgboost', 'catboost']\n",
    "# 0.6883853294761878 ['adaboost','lightgbm','lightgbm', 'xgboost', 'catboost', 'catboost', 'catboost']\n",
    "# 0.6882502047393781 ['adaboost','lightgbm','lightgbm', 'xgboost', 'catboost', 'catboost']\n",
    "# 0.6884191267321496 ['adaboost','adaboost','lightgbm', 'xgboost', 'catboost', 'catboost']\n",
    "# 0.6883853294761878 ['adaboost','adaboost','lightgbm', 'xgboost', 'catboost', 'catboost', 'catboost']\n",
    "# 0.6882839762854178 ['adaboost','adaboost','lightgbm', 'xgboost', 'catboost', 'catboost', 'catboost', 'catboost']"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13858cd0c554419bb867071b5c810b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4074a8c3b85548ed9424375a19416c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573ab758539147f1a2bc21ac9f0347ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5de7c5cebd814e1caa8437775031ea12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6762ef5aab7e4d18b98e7d837dedc03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f14799525cf44158bbffc0e9a08891b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7dceec9910a46cea90915015ca58358",
      "placeholder": "​",
      "style": "IPY_MODEL_573ab758539147f1a2bc21ac9f0347ce",
      "value": "100%"
     }
    },
    "76ddf1599bb144b2a6b4573027c6f662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4074a8c3b85548ed9424375a19416c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_13858cd0c554419bb867071b5c810b30",
      "value": " 1000/1000 [00:19&lt;00:00, 37.91it/s]"
     }
    },
    "b0ab4a4e03b242e2ae3610b6a52b5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7dceec9910a46cea90915015ca58358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d239d2ff297a4c00aa350f8699ca6bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de7c5cebd814e1caa8437775031ea12",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0ab4a4e03b242e2ae3610b6a52b5c14",
      "value": 1000
     }
    },
    "ef58b4abcf0f43cd90a523a3875a2f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f14799525cf44158bbffc0e9a08891b",
       "IPY_MODEL_d239d2ff297a4c00aa350f8699ca6bb1",
       "IPY_MODEL_76ddf1599bb144b2a6b4573027c6f662"
      ],
      "layout": "IPY_MODEL_6762ef5aab7e4d18b98e7d837dedc03f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
