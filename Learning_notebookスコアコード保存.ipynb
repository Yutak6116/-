{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "id": "B3WEPx1JJqlG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "#import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 1.3\n",
    "    AUTHOR = 'naokisusami'\n",
    "    COMPETITION = 'FDUA2'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = ['lightgbm', 'xgboost', 'catboost']\n",
    "    seed = 42\n",
    "    n_folds = 7\n",
    "    target_col = 'MIS_Status'\n",
    "    metric = 'f1_score'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 500\n",
    "    early_stopping_round = 200\n",
    "    verbose = 25\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'iterations': num_boost_round,\n",
    "        'random_seed': seed,\n",
    "    }\n",
    "    model_weight_dict = {'lightgbm': 0.50, 'xgboost': 0.10, 'catboost': 0.40}\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# f1_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro'), CFG.metric_maximize_flag\n",
    "\n",
    "# ====================================================\n",
    "# XGBoost Metric\n",
    "# ====================================================\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "id": "g6R4KoxhL91E"
   },
   "outputs": [],
   "source": [
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "id": "El2B8eayMmyZ"
   },
   "outputs": [],
   "source": [
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        #df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "\n",
    "        #Bankraptcydataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = k[-26]*2\n",
    "        \n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "\n",
    "        \n",
    "         # 地理的特徴の組み合わせ\n",
    "        df['City_State'] = df['City'] + '_' + df['State']\n",
    "        # 時間的特徴の組み合わせ\n",
    "        df['ApprovalFY_Term'] = df['ApprovalFY'].astype(str) + '_' + df['Term'].astype(str)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "id": "GA0iq9vLNEqS"
   },
   "outputs": [],
   "source": [
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42307 entries, 0 to 42306\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Term                42307 non-null  int64  \n",
      " 1   NoEmp               42307 non-null  int64  \n",
      " 2   NewExist            42307 non-null  int32  \n",
      " 3   CreateJob           42307 non-null  int64  \n",
      " 4   RetainedJob         42307 non-null  int64  \n",
      " 5   FranchiseCode       42307 non-null  int64  \n",
      " 6   RevLineCr           42307 non-null  object \n",
      " 7   LowDoc              42307 non-null  object \n",
      " 8   DisbursementDate    42307 non-null  object \n",
      " 9   MIS_Status          42307 non-null  int64  \n",
      " 10  Sector              42307 non-null  int64  \n",
      " 11  ApprovalDate        42307 non-null  object \n",
      " 12  ApprovalFY          42307 non-null  int64  \n",
      " 13  City                42307 non-null  object \n",
      " 14  State               42307 non-null  object \n",
      " 15  BankState           42307 non-null  object \n",
      " 16  DisbursementGross   42307 non-null  float64\n",
      " 17  GrAppv              42307 non-null  float64\n",
      " 18  SBA_Appv            42307 non-null  float64\n",
      " 19  UrbanRural          42307 non-null  int64  \n",
      " 20  DisbursementDay     42307 non-null  int32  \n",
      " 21  DisbursementMonth   42307 non-null  int64  \n",
      " 22  DisbursementYear    42307 non-null  int64  \n",
      " 23  ApprovalDay         42307 non-null  int32  \n",
      " 24  ApprovalMonth       42307 non-null  int64  \n",
      " 25  ApprovalYear        42307 non-null  int64  \n",
      " 26  CompanyLong         42307 non-null  int64  \n",
      " 27  Bankraptcy_By_Year  42307 non-null  float64\n",
      " 28  City_State          42307 non-null  object \n",
      " 29  ApprovalFY_Term     42307 non-null  object \n",
      "dtypes: float64(4), int32(3), int64(14), object(9)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0dJ6ijFuQoF5"
   },
   "source": [
    "（以下はPreprocessingに本来組み込むべきだが，コードが煩雑になるので，いったん切り出している．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "id": "wFYHaRqrOfGG"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#カウントエンコーディング\n",
    "for col in categorical_features:\n",
    "    count_dict = dict(train_df[col].value_counts())\n",
    "    train_df[f'{col}_count_encoding'] = train_df[col].map(count_dict).astype(int)\n",
    "    test_df[f'{col}_count_encoding'] = test_df[col].map(count_dict).fillna(1).astype(int)\n",
    "'''\n",
    "\n",
    "#ラベルエンコーディング\n",
    "for col in categorical_features :\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "categorical_features_unlabelable = ['ApprovalFY_Term','City_State','City','ApprovalDate','BankState','DisbursementDate']\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    le = LabelEncoder()   \n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else len(le.classes_))\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42307 entries, 0 to 42306\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Term                42307 non-null  int64  \n",
      " 1   NoEmp               42307 non-null  int64  \n",
      " 2   NewExist            42307 non-null  int32  \n",
      " 3   CreateJob           42307 non-null  int64  \n",
      " 4   RetainedJob         42307 non-null  int64  \n",
      " 5   FranchiseCode       42307 non-null  int64  \n",
      " 6   RevLineCr           42307 non-null  int32  \n",
      " 7   LowDoc              42307 non-null  int32  \n",
      " 8   DisbursementDate    42307 non-null  int32  \n",
      " 9   MIS_Status          42307 non-null  int64  \n",
      " 10  Sector              42307 non-null  int64  \n",
      " 11  ApprovalDate        42307 non-null  int32  \n",
      " 12  ApprovalFY          42307 non-null  int64  \n",
      " 13  City                42307 non-null  int32  \n",
      " 14  State               42307 non-null  int32  \n",
      " 15  BankState           42307 non-null  int32  \n",
      " 16  DisbursementGross   42307 non-null  float64\n",
      " 17  GrAppv              42307 non-null  float64\n",
      " 18  SBA_Appv            42307 non-null  float64\n",
      " 19  UrbanRural          42307 non-null  int64  \n",
      " 20  DisbursementDay     42307 non-null  int32  \n",
      " 21  DisbursementMonth   42307 non-null  int64  \n",
      " 22  DisbursementYear    42307 non-null  int64  \n",
      " 23  ApprovalDay         42307 non-null  int32  \n",
      " 24  ApprovalMonth       42307 non-null  int64  \n",
      " 25  ApprovalYear        42307 non-null  int64  \n",
      " 26  CompanyLong         42307 non-null  int64  \n",
      " 27  Bankraptcy_By_Year  42307 non-null  float64\n",
      " 28  City_State          42307 non-null  int32  \n",
      " 29  ApprovalFY_Term     42307 non-null  int32  \n",
      "dtypes: float64(4), int32(12), int64(14)\n",
      "memory usage: 8.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n"
     ]
    }
   ],
   "source": [
    "#OneHotEncoding\n",
    "train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "OneHotList = ['RevLineCr', 'LowDoc']\n",
    "ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "train_df2 = ohe.fit_transform(train_df2)\n",
    "test_df = ohe.transform(test_df)\n",
    "train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "\n",
    "#featuresの作成\n",
    "categorical_features =['UrbanRural', 'State', 'Sector','RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0',\n",
    "                       'LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0','FranchiseCode',\n",
    "                       'ApprovalFY_Term','City_State','City','ApprovalDate','BankState']\n",
    "RemoveList=['MIS_Status','ApprovalDay','ApprovalMonth','ApprovalYear','DisbursementDay','DisbursementMonth','DisbursementYear']\n",
    "RemoveList=['MIS_Status']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Term  NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
      "0       163     21         1          0            0              1   \n",
      "1        84      6         1          4            0              0   \n",
      "2       242     45         1          4           90              0   \n",
      "3       237      4         1          0            0              0   \n",
      "4       184      0         1          0            0              0   \n",
      "...     ...    ...       ...        ...          ...            ...   \n",
      "42302   283     14         1          0            0              1   \n",
      "42303    53      2         1          0            0              0   \n",
      "42304    59      6         0          0            0              1   \n",
      "42305   295     18         1          0            8              0   \n",
      "42306    84      4         1          0            8              0   \n",
      "\n",
      "       RevLineCr_1.0  RevLineCr_0.0  RevLineCr_4.0  RevLineCr_3.0  \\\n",
      "0                  1              0              0              0   \n",
      "1                  0              1              0              0   \n",
      "2                  1              0              0              0   \n",
      "3                  1              0              0              0   \n",
      "4                  1              0              0              0   \n",
      "...              ...            ...            ...            ...   \n",
      "42302              1              0              0              0   \n",
      "42303              0              0              1              0   \n",
      "42304              1              0              0              0   \n",
      "42305              1              0              0              0   \n",
      "42306              1              0              0              0   \n",
      "\n",
      "       RevLineCr_2.0  LowDoc_3.0  LowDoc_2.0  LowDoc_5.0  LowDoc_6.0  \\\n",
      "0                  0           1           0           0           0   \n",
      "1                  0           1           0           0           0   \n",
      "2                  0           1           0           0           0   \n",
      "3                  0           1           0           0           0   \n",
      "4                  0           1           0           0           0   \n",
      "...              ...         ...         ...         ...         ...   \n",
      "42302              0           1           0           0           0   \n",
      "42303              0           1           0           0           0   \n",
      "42304              0           1           0           0           0   \n",
      "42305              0           1           0           0           0   \n",
      "42306              0           1           0           0           0   \n",
      "\n",
      "       LowDoc_0.0  LowDoc_4.0  LowDoc_1.0  DisbursementDate  Sector  \\\n",
      "0               0           0           0               730       0   \n",
      "1               0           0           0               795      20   \n",
      "2               0           0           0               685       8   \n",
      "3               0           0           0               691       7   \n",
      "4               0           0           0               890       0   \n",
      "...           ...         ...         ...               ...     ...   \n",
      "42302           0           0           0               730       0   \n",
      "42303           0           0           0               603       8   \n",
      "42304           0           0           0               578       8   \n",
      "42305           0           0           0                74       8   \n",
      "42306           0           0           0               791      22   \n",
      "\n",
      "       ApprovalDate  ApprovalFY  City  State  BankState  DisbursementGross  \\\n",
      "0              2084        2006  2208      3         42            80000.0   \n",
      "1              3265        1992  1723     36         36           287000.0   \n",
      "2              1232        2001  1214     31         31            31983.0   \n",
      "3              3793        2004  1906     42         42           229000.0   \n",
      "4              1126        2000  2246      4          4           525000.0   \n",
      "...             ...         ...   ...    ...        ...                ...   \n",
      "42302          1603        1995  2207     38         38            80000.0   \n",
      "42303          3756        2007  1594      4         42             5000.0   \n",
      "42304           747        2003   580     35         35            60000.0   \n",
      "42305          2117        1989   547     23         23           294000.0   \n",
      "42306           379        2011  2489      4         27            67500.0   \n",
      "\n",
      "         GrAppv  SBA_Appv  UrbanRural  DisbursementDay  DisbursementMonth  \\\n",
      "0       80000.0   68000.0           0               31                  1   \n",
      "1      287000.0  229600.0           0               31                 10   \n",
      "2       30000.0   15000.0           1               31                  8   \n",
      "3      229000.0  229000.0           0               31                  8   \n",
      "4      525000.0  393750.0           0                8                  6   \n",
      "...         ...       ...         ...              ...                ...   \n",
      "42302   80000.0   68000.0           0               31                  1   \n",
      "42303    5000.0    4250.0           1                3                  4   \n",
      "42304   60000.0   51000.0           0               28                  2   \n",
      "42305  294000.0  220500.0           0               10                 12   \n",
      "42306   67500.0   50625.0           0               31                 10   \n",
      "\n",
      "       DisbursementYear  ApprovalDay  ApprovalMonth  ApprovalYear  \\\n",
      "0                    -2           22              9             6   \n",
      "1                    -7           30              6            -8   \n",
      "2                     1           18              4             1   \n",
      "3                     7            6             10             3   \n",
      "4                   -17           17             12            -1   \n",
      "...                 ...          ...            ...           ...   \n",
      "42302                -2            2              3            -5   \n",
      "42303                -9            6              6             7   \n",
      "42304                 3           14              3             3   \n",
      "42305                -3           23              8           -11   \n",
      "42306               -11           12              4            11   \n",
      "\n",
      "       CompanyLong  Bankraptcy_By_Year  City_State  ApprovalFY_Term  \\\n",
      "0               -8             38377.0        2578             3645   \n",
      "1                1             53300.0        2008             1201   \n",
      "2                0             36284.4        1406             2707   \n",
      "3                4             48317.0        2231             3294   \n",
      "4              -16             72700.0        2624             2476   \n",
      "...            ...                 ...         ...              ...   \n",
      "42302            3             38377.0        2576             1612   \n",
      "42303          -16             59900.0        1851             3961   \n",
      "42304            0             31346.0         682             3170   \n",
      "42305            8             41067.4         640              708   \n",
      "42306          -22             65600.0        2899             4670   \n",
      "\n",
      "       MIS_Status  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "...           ...  \n",
      "42302           1  \n",
      "42303           1  \n",
      "42304           1  \n",
      "42305           1  \n",
      "42306           1  \n",
      "\n",
      "[42307 rows x 40 columns]\n",
      "['Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'RevLineCr_1.0', 'RevLineCr_0.0', 'RevLineCr_4.0', 'RevLineCr_3.0', 'RevLineCr_2.0', 'LowDoc_3.0', 'LowDoc_2.0', 'LowDoc_5.0', 'LowDoc_6.0', 'LowDoc_0.0', 'LowDoc_4.0', 'LowDoc_1.0', 'DisbursementDate', 'Sector', 'ApprovalDate', 'ApprovalFY', 'City', 'State', 'BankState', 'DisbursementGross', 'GrAppv', 'SBA_Appv', 'UrbanRural', 'DisbursementDay', 'DisbursementMonth', 'DisbursementYear', 'ApprovalDay', 'ApprovalMonth', 'ApprovalYear', 'CompanyLong', 'Bankraptcy_By_Year', 'City_State', 'ApprovalFY_Term']\n"
     ]
    }
   ],
   "source": [
    "print(train_df)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "id": "quaQcTgQOjyJ"
   },
   "outputs": [],
   "source": [
    "#lightgbmでの学習メソッドの定義\n",
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "                params = CFG.classification_lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                feval = lgb_metric,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                              verbose=CFG.verbose)]\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "#xgboostでの学習メソッドの定義\n",
    "def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "    model = xgb.train(\n",
    "                CFG.classification_xgb_params,\n",
    "                dtrain = xgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                early_stopping_rounds = CFG.early_stopping_round,\n",
    "                verbose_eval = CFG.verbose,\n",
    "                feval = xgb_metric,\n",
    "                maximize = CFG.metric_maximize_flag,\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "    return model, valid_pred\n",
    "\n",
    "#catboostでの学習メソッドの定義\n",
    "def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "    model.fit(cat_train,\n",
    "              eval_set = [cat_valid],\n",
    "              early_stopping_rounds = CFG.early_stopping_round,\n",
    "              verbose = CFG.verbose,\n",
    "              use_best_model = True)\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "#任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    kfold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df)):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "\n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        if method == 'lightgbm':\n",
    "            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'xgboost':\n",
    "            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'catboost':\n",
    "            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "\n",
    "        # Save best model\n",
    "        pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "    print(f'{method} our out of folds CV f1score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "#学習メソッドの定義\n",
    "def Learning(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        gradient_boosting_model_cv_training(method, input_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWzQv798OiQ-",
    "outputId": "57cabf2c-5c42-4084-e263-e00eaeb695ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-08 22:45:25,066] A new study created in memory with name: no-name-6134e9b1-6b65-41fa-baef-66297088e25c\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017567 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.753009:  14%|######4                                      | 1/7 [00:14<01:29, 14.83s/it][I 2024-02-08 22:45:39,905] Trial 0 finished with value: 0.7530087531460232 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.7530087531460232.\n",
      "feature_fraction, val_score: 0.753009:  14%|######4                                      | 1/7 [00:14<01:29, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.893477\tvalid_0's f1score: 0.67943\tvalid_1's auc: 0.753009\tvalid_1's f1score: 0.602664\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.764592:  29%|############8                                | 2/7 [00:25<01:00, 12.13s/it][I 2024-02-08 22:45:50,136] Trial 1 finished with value: 0.7645915553962915 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.7645915553962915.\n",
      "feature_fraction, val_score: 0.764592:  29%|############8                                | 2/7 [00:25<01:00, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.835928\tvalid_0's f1score: 0.471377\tvalid_1's auc: 0.764592\tvalid_1's f1score: 0.47329\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.764592:  43%|###################2                         | 3/7 [00:36<00:47, 12.00s/it][I 2024-02-08 22:46:01,981] Trial 2 finished with value: 0.7548609982629476 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7645915553962915.\n",
      "feature_fraction, val_score: 0.764592:  43%|###################2                         | 3/7 [00:36<00:47, 12.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.870891\tvalid_0's f1score: 0.630041\tvalid_1's auc: 0.754861\tvalid_1's f1score: 0.585432\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004073 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.764592:  57%|#########################7                   | 4/7 [00:47<00:34, 11.36s/it][I 2024-02-08 22:46:12,358] Trial 3 finished with value: 0.7610773509455566 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7645915553962915.\n",
      "feature_fraction, val_score: 0.764592:  57%|#########################7                   | 4/7 [00:47<00:34, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's auc: 0.863659\tvalid_0's f1score: 0.613714\tvalid_1's auc: 0.761077\tvalid_1's f1score: 0.575956\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.764592:  71%|################################1            | 5/7 [00:58<00:22, 11.16s/it][I 2024-02-08 22:46:23,162] Trial 4 finished with value: 0.7552652992322787 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7645915553962915.\n",
      "feature_fraction, val_score: 0.764592:  71%|################################1            | 5/7 [00:58<00:22, 11.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.878687\tvalid_0's f1score: 0.650554\tvalid_1's auc: 0.755265\tvalid_1's f1score: 0.593429\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003670 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.764592:  86%|######################################5      | 6/7 [01:09<00:11, 11.32s/it][I 2024-02-08 22:46:34,802] Trial 5 finished with value: 0.7529438727527279 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.7645915553962915.\n",
      "feature_fraction, val_score: 0.764592:  86%|######################################5      | 6/7 [01:09<00:11, 11.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.885444\tvalid_0's f1score: 0.66573\tvalid_1's auc: 0.752944\tvalid_1's f1score: 0.598584\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014466 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.764592: 100%|#############################################| 7/7 [01:19<00:00, 10.77s/it][I 2024-02-08 22:46:44,454] Trial 6 finished with value: 0.7598845729743725 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.7645915553962915.\n",
      "feature_fraction, val_score: 0.764592: 100%|#############################################| 7/7 [01:19<00:00, 11.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.856584\tvalid_0's f1score: 0.576826\tvalid_1's auc: 0.759885\tvalid_1's f1score: 0.565148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.764592:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:   5%|##5                                               | 1/20 [00:10<03:22, 10.64s/it][I 2024-02-08 22:46:55,093] Trial 7 finished with value: 0.766784572764112 and parameters: {'num_leaves': 91}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:   5%|##5                                               | 1/20 [00:10<03:22, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.869969\tvalid_0's f1score: 0.473465\tvalid_1's auc: 0.766785\tvalid_1's f1score: 0.474911\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  10%|#####                                             | 2/20 [00:21<03:14, 10.80s/it][I 2024-02-08 22:47:06,006] Trial 8 finished with value: 0.7637686857785482 and parameters: {'num_leaves': 90}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  10%|#####                                             | 2/20 [00:21<03:14, 10.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.870824\tvalid_0's f1score: 0.472422\tvalid_1's auc: 0.763769\tvalid_1's f1score: 0.474863\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003177 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  15%|#######5                                          | 3/20 [00:35<03:28, 12.29s/it][I 2024-02-08 22:47:20,068] Trial 9 finished with value: 0.7595337382550719 and parameters: {'num_leaves': 168}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  15%|#######5                                          | 3/20 [00:35<03:28, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.93812\tvalid_0's f1score: 0.669898\tvalid_1's auc: 0.759534\tvalid_1's f1score: 0.591597\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  20%|##########                                        | 4/20 [00:51<03:39, 13.71s/it][I 2024-02-08 22:47:35,952] Trial 10 finished with value: 0.7567024299809895 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  20%|##########                                        | 4/20 [00:51<03:39, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[298]\tvalid_0's auc: 0.813551\tvalid_0's f1score: 0.617064\tvalid_1's auc: 0.756702\tvalid_1's f1score: 0.589997\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005816 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  25%|############5                                     | 5/20 [01:07<03:37, 14.53s/it][I 2024-02-08 22:47:51,928] Trial 11 finished with value: 0.7616150171677726 and parameters: {'num_leaves': 239}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  25%|############5                                     | 5/20 [01:07<03:37, 14.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.959781\tvalid_0's f1score: 0.695634\tvalid_1's auc: 0.761615\tvalid_1's f1score: 0.593442\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  30%|###############                                   | 6/20 [01:18<03:07, 13.42s/it][I 2024-02-08 22:48:03,225] Trial 12 finished with value: 0.7640228006522882 and parameters: {'num_leaves': 73}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  30%|###############                                   | 6/20 [01:18<03:07, 13.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.880558\tvalid_0's f1score: 0.578059\tvalid_1's auc: 0.764023\tvalid_1's f1score: 0.54173\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  35%|#################5                                | 7/20 [01:30<02:47, 12.91s/it][I 2024-02-08 22:48:15,066] Trial 13 finished with value: 0.7607601579116684 and parameters: {'num_leaves': 151}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  35%|#################5                                | 7/20 [01:30<02:47, 12.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.884888\tvalid_0's f1score: 0.471377\tvalid_1's auc: 0.76076\tvalid_1's f1score: 0.47329\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.766785:  40%|####################                              | 8/20 [01:40<02:21, 11.82s/it][I 2024-02-08 22:48:24,555] Trial 14 finished with value: 0.7629543767682535 and parameters: {'num_leaves': 15}. Best is trial 7 with value: 0.766784572764112.\n",
      "num_leaves, val_score: 0.766785:  40%|####################                              | 8/20 [01:40<02:21, 11.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.846187\tvalid_0's f1score: 0.623826\tvalid_1's auc: 0.762954\tvalid_1's f1score: 0.589148\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002199 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  45%|######################5                           | 9/20 [01:51<02:09, 11.73s/it][I 2024-02-08 22:48:36,082] Trial 15 finished with value: 0.7674817366198456 and parameters: {'num_leaves': 87}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  45%|######################5                           | 9/20 [01:51<02:09, 11.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.884503\tvalid_0's f1score: 0.562974\tvalid_1's auc: 0.767482\tvalid_1's f1score: 0.534\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  50%|########################5                        | 10/20 [02:03<01:57, 11.74s/it][I 2024-02-08 22:48:47,826] Trial 16 finished with value: 0.7644084785457661 and parameters: {'num_leaves': 81}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  50%|########################5                        | 10/20 [02:03<01:57, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.90113\tvalid_0's f1score: 0.643486\tvalid_1's auc: 0.764408\tvalid_1's f1score: 0.591802\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  55%|##########################9                      | 11/20 [02:15<01:45, 11.76s/it][I 2024-02-08 22:48:59,654] Trial 17 finished with value: 0.7592838285920084 and parameters: {'num_leaves': 114}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  55%|##########################9                      | 11/20 [02:15<01:45, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.8988\tvalid_0's f1score: 0.591107\tvalid_1's auc: 0.759284\tvalid_1's f1score: 0.542314\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  60%|#############################4                   | 12/20 [02:25<01:31, 11.41s/it][I 2024-02-08 22:49:10,257] Trial 18 finished with value: 0.7651675190728832 and parameters: {'num_leaves': 47}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  60%|#############################4                   | 12/20 [02:25<01:31, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.879783\tvalid_0's f1score: 0.630437\tvalid_1's auc: 0.765168\tvalid_1's f1score: 0.586615\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002693 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  65%|###############################8                 | 13/20 [02:40<01:26, 12.32s/it][I 2024-02-08 22:49:24,681] Trial 19 finished with value: 0.7625656951528639 and parameters: {'num_leaves': 197}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  65%|###############################8                 | 13/20 [02:40<01:26, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.94615\tvalid_0's f1score: 0.678875\tvalid_1's auc: 0.762566\tvalid_1's f1score: 0.590582\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005752 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  70%|##################################3              | 14/20 [02:52<01:14, 12.35s/it][I 2024-02-08 22:49:37,085] Trial 20 finished with value: 0.7614654318165639 and parameters: {'num_leaves': 127}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  70%|##################################3              | 14/20 [02:52<01:14, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.903725\tvalid_0's f1score: 0.593941\tvalid_1's auc: 0.761465\tvalid_1's f1score: 0.540893\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002382 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  75%|####################################7            | 15/20 [03:02<00:57, 11.47s/it][I 2024-02-08 22:49:46,533] Trial 21 finished with value: 0.7646348089918218 and parameters: {'num_leaves': 49}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  75%|####################################7            | 15/20 [03:02<00:57, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.846307\tvalid_0's f1score: 0.471377\tvalid_1's auc: 0.764635\tvalid_1's f1score: 0.47329\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  80%|#######################################2         | 16/20 [03:12<00:45, 11.29s/it][I 2024-02-08 22:49:57,375] Trial 22 finished with value: 0.7651675190728832 and parameters: {'num_leaves': 47}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  80%|#######################################2         | 16/20 [03:12<00:45, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.879783\tvalid_0's f1score: 0.630437\tvalid_1's auc: 0.765168\tvalid_1's f1score: 0.586615\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012935 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  85%|#########################################6       | 17/20 [03:22<00:32, 10.87s/it][I 2024-02-08 22:50:07,301] Trial 23 finished with value: 0.7664433499549291 and parameters: {'num_leaves': 48}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  85%|#########################################6       | 17/20 [03:22<00:32, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.847008\tvalid_0's f1score: 0.471377\tvalid_1's auc: 0.766443\tvalid_1's f1score: 0.47329\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  90%|############################################1    | 18/20 [03:34<00:22, 11.13s/it][I 2024-02-08 22:50:19,029] Trial 24 finished with value: 0.7632398805359721 and parameters: {'num_leaves': 104}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  90%|############################################1    | 18/20 [03:34<00:22, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.889887\tvalid_0's f1score: 0.555813\tvalid_1's auc: 0.76324\tvalid_1's f1score: 0.522648\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010206 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482:  95%|##############################################5  | 19/20 [03:45<00:10, 10.95s/it][I 2024-02-08 22:50:29,566] Trial 25 finished with value: 0.7637339927904667 and parameters: {'num_leaves': 67}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482:  95%|##############################################5  | 19/20 [03:45<00:10, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.872626\tvalid_0's f1score: 0.53953\tvalid_1's auc: 0.763734\tvalid_1's f1score: 0.521276\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.767482: 100%|#################################################| 20/20 [03:53<00:00, 10.33s/it][I 2024-02-08 22:50:38,451] Trial 26 finished with value: 0.7653256650315405 and parameters: {'num_leaves': 26}. Best is trial 15 with value: 0.7674817366198456.\n",
      "num_leaves, val_score: 0.767482: 100%|#################################################| 20/20 [03:53<00:00, 11.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.831866\tvalid_0's f1score: 0.471377\tvalid_1's auc: 0.765326\tvalid_1's f1score: 0.47329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.767482:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.767482:  10%|#####3                                               | 1/10 [00:10<01:30, 10.06s/it][I 2024-02-08 22:50:48,508] Trial 27 finished with value: 0.7628689208798622 and parameters: {'bagging_fraction': 0.46867745377540565, 'bagging_freq': 4}. Best is trial 27 with value: 0.7628689208798622.\n",
      "bagging, val_score: 0.767482:  10%|#####3                                               | 1/10 [00:10<01:30, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836182\tvalid_0's f1score: 0.471377\tvalid_1's auc: 0.762869\tvalid_1's f1score: 0.47329\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002913 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.767482:  20%|##########6                                          | 2/10 [00:23<01:34, 11.77s/it][I 2024-02-08 22:51:01,475] Trial 28 finished with value: 0.7645340341216802 and parameters: {'bagging_fraction': 0.9460683501073659, 'bagging_freq': 7}. Best is trial 28 with value: 0.7645340341216802.\n",
      "bagging, val_score: 0.767482:  20%|##########6                                          | 2/10 [00:23<01:34, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.912213\tvalid_0's f1score: 0.668515\tvalid_1's auc: 0.764534\tvalid_1's f1score: 0.602222\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  30%|###############9                                     | 3/10 [00:34<01:22, 11.85s/it][I 2024-02-08 22:51:13,442] Trial 29 finished with value: 0.7703420308103771 and parameters: {'bagging_fraction': 0.40814859250782104, 'bagging_freq': 1}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  30%|###############9                                     | 3/10 [00:34<01:22, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.885964\tvalid_0's f1score: 0.658317\tvalid_1's auc: 0.770342\tvalid_1's f1score: 0.606947\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  40%|#####################2                               | 4/10 [00:47<01:12, 12.07s/it][I 2024-02-08 22:51:25,838] Trial 30 finished with value: 0.76807362002257 and parameters: {'bagging_fraction': 0.4076809533385892, 'bagging_freq': 1}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  40%|#####################2                               | 4/10 [00:47<01:12, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.903484\tvalid_0's f1score: 0.681359\tvalid_1's auc: 0.768074\tvalid_1's f1score: 0.611967\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  50%|##########################5                          | 5/10 [00:57<00:57, 11.47s/it][I 2024-02-08 22:51:36,245] Trial 31 finished with value: 0.7680689642536066 and parameters: {'bagging_fraction': 0.40049319410024903, 'bagging_freq': 1}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  50%|##########################5                          | 5/10 [00:57<00:57, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.856887\tvalid_0's f1score: 0.560611\tvalid_1's auc: 0.768069\tvalid_1's f1score: 0.547161\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  60%|###############################8                     | 6/10 [01:08<00:44, 11.13s/it][I 2024-02-08 22:51:46,707] Trial 32 finished with value: 0.7664903582028492 and parameters: {'bagging_fraction': 0.41425683456383416, 'bagging_freq': 1}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  60%|###############################8                     | 6/10 [01:08<00:44, 11.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.856589\tvalid_0's f1score: 0.566838\tvalid_1's auc: 0.76649\tvalid_1's f1score: 0.546855\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  70%|#####################################                | 7/10 [01:20<00:34, 11.48s/it][I 2024-02-08 22:51:58,919] Trial 33 finished with value: 0.7665990929360571 and parameters: {'bagging_fraction': 0.41667340370878864, 'bagging_freq': 1}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  70%|#####################################                | 7/10 [01:20<00:34, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.904991\tvalid_0's f1score: 0.680237\tvalid_1's auc: 0.766599\tvalid_1's f1score: 0.611047\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  80%|##########################################4          | 8/10 [01:30<00:22, 11.17s/it][I 2024-02-08 22:52:09,428] Trial 34 finished with value: 0.7663829751445016 and parameters: {'bagging_fraction': 0.5769951841386489, 'bagging_freq': 1}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  80%|##########################################4          | 8/10 [01:30<00:22, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.853768\tvalid_0's f1score: 0.478372\tvalid_1's auc: 0.766383\tvalid_1's f1score: 0.478284\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011439 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342:  90%|###############################################7     | 9/10 [01:41<00:10, 10.94s/it][I 2024-02-08 22:52:19,837] Trial 35 finished with value: 0.7641615726046144 and parameters: {'bagging_fraction': 0.40949157196721986, 'bagging_freq': 3}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342:  90%|###############################################7     | 9/10 [01:41<00:10, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.855095\tvalid_0's f1score: 0.563317\tvalid_1's auc: 0.764162\tvalid_1's f1score: 0.547314\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.770342: 100%|####################################################| 10/10 [01:52<00:00, 11.10s/it][I 2024-02-08 22:52:31,308] Trial 36 finished with value: 0.7608852629292957 and parameters: {'bagging_fraction': 0.5809283005476082, 'bagging_freq': 2}. Best is trial 29 with value: 0.7703420308103771.\n",
      "bagging, val_score: 0.770342: 100%|####################################################| 10/10 [01:52<00:00, 11.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.889316\tvalid_0's f1score: 0.642024\tvalid_1's auc: 0.760885\tvalid_1's f1score: 0.588467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.770342:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002737 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.770342:  33%|############6                         | 1/3 [00:12<00:24, 12.07s/it][I 2024-02-08 22:52:43,386] Trial 37 finished with value: 0.7647986620221116 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.7647986620221116.\n",
      "feature_fraction_stage2, val_score: 0.770342:  33%|############6                         | 1/3 [00:12<00:24, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.895132\tvalid_0's f1score: 0.669368\tvalid_1's auc: 0.764799\tvalid_1's f1score: 0.604159\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002585 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.770342:  67%|#########################3            | 2/3 [00:24<00:12, 12.28s/it][I 2024-02-08 22:52:55,809] Trial 38 finished with value: 0.7658535691575431 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 0.7658535691575431.\n",
      "feature_fraction_stage2, val_score: 0.770342:  67%|#########################3            | 2/3 [00:24<00:12, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.893457\tvalid_0's f1score: 0.66836\tvalid_1's auc: 0.765854\tvalid_1's f1score: 0.599001\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002997 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.770342: 100%|######################################| 3/3 [00:36<00:00, 11.99s/it][I 2024-02-08 22:53:07,442] Trial 39 finished with value: 0.7703420308103771 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.7703420308103771.\n",
      "feature_fraction_stage2, val_score: 0.770342: 100%|######################################| 3/3 [00:36<00:00, 12.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.885964\tvalid_0's f1score: 0.658317\tvalid_1's auc: 0.770342\tvalid_1's f1score: 0.606947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012319 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:   5%|#9                                    | 1/20 [00:12<03:53, 12.29s/it][I 2024-02-08 22:53:19,747] Trial 40 finished with value: 0.7689684287801014 and parameters: {'lambda_l1': 0.00018867402570380565, 'lambda_l2': 0.0035076265772908894}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:   5%|#9                                    | 1/20 [00:12<03:53, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.902263\tvalid_0's f1score: 0.679563\tvalid_1's auc: 0.768968\tvalid_1's f1score: 0.60732\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004994 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  10%|###8                                  | 2/20 [00:22<03:22, 11.23s/it][I 2024-02-08 22:53:30,216] Trial 41 finished with value: 0.7669422681644826 and parameters: {'lambda_l1': 8.312678449880136e-05, 'lambda_l2': 0.006192292029004087}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  10%|###8                                  | 2/20 [00:22<03:22, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.856007\tvalid_0's f1score: 0.563011\tvalid_1's auc: 0.766942\tvalid_1's f1score: 0.531626\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002469 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  15%|#####7                                | 3/20 [00:34<03:14, 11.47s/it][I 2024-02-08 22:53:41,986] Trial 42 finished with value: 0.76792373429917 and parameters: {'lambda_l1': 1.4216451267890677, 'lambda_l2': 1.5070838350720115e-07}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  15%|#####7                                | 3/20 [00:34<03:14, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.875795\tvalid_0's f1score: 0.646429\tvalid_1's auc: 0.767924\tvalid_1's f1score: 0.595869\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003438 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  20%|#######6                              | 4/20 [00:49<03:28, 13.02s/it][I 2024-02-08 22:53:57,382] Trial 43 finished with value: 0.7683700873752667 and parameters: {'lambda_l1': 1.3605029215846115e-08, 'lambda_l2': 9.94738699569493}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  20%|#######6                              | 4/20 [00:49<03:28, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's auc: 0.89425\tvalid_0's f1score: 0.681704\tvalid_1's auc: 0.76837\tvalid_1's f1score: 0.615594\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  25%|#########5                            | 5/20 [01:02<03:14, 12.95s/it][I 2024-02-08 22:54:10,226] Trial 44 finished with value: 0.7667084284136474 and parameters: {'lambda_l1': 7.129118240840794e-08, 'lambda_l2': 7.586041320086872}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  25%|#########5                            | 5/20 [01:02<03:14, 12.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.866075\tvalid_0's f1score: 0.6341\tvalid_1's auc: 0.766708\tvalid_1's f1score: 0.595662\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002274 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  30%|###########4                          | 6/20 [01:17<03:11, 13.65s/it][I 2024-02-08 22:54:25,215] Trial 45 finished with value: 0.7651768306108099 and parameters: {'lambda_l1': 1.0990640970227265e-07, 'lambda_l2': 5.872775600711727}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  30%|###########4                          | 6/20 [01:17<03:11, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.905095\tvalid_0's f1score: 0.691808\tvalid_1's auc: 0.765177\tvalid_1's f1score: 0.618707\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003250 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  35%|#############3                        | 7/20 [01:30<02:52, 13.28s/it][I 2024-02-08 22:54:37,726] Trial 46 finished with value: 0.7669601403098579 and parameters: {'lambda_l1': 0.014520723079615053, 'lambda_l2': 0.0006918738332562812}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  35%|#############3                        | 7/20 [01:30<02:52, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.899103\tvalid_0's f1score: 0.67468\tvalid_1's auc: 0.76696\tvalid_1's f1score: 0.605515\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002586 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  40%|###############2                      | 8/20 [01:43<02:37, 13.14s/it][I 2024-02-08 22:54:50,574] Trial 47 finished with value: 0.768401926827532 and parameters: {'lambda_l1': 9.438004890954639e-06, 'lambda_l2': 0.04651642763357354}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  40%|###############2                      | 8/20 [01:43<02:37, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.900689\tvalid_0's f1score: 0.678036\tvalid_1's auc: 0.768402\tvalid_1's f1score: 0.605643\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  45%|#################1                    | 9/20 [01:57<02:29, 13.62s/it][I 2024-02-08 22:55:05,236] Trial 48 finished with value: 0.766268983897948 and parameters: {'lambda_l1': 3.941932343431692e-05, 'lambda_l2': 0.04406007192866289}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  45%|#################1                    | 9/20 [01:57<02:29, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.930297\tvalid_0's f1score: 0.712511\tvalid_1's auc: 0.766269\tvalid_1's f1score: 0.61941\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  50%|##################5                  | 10/20 [02:10<02:13, 13.35s/it][I 2024-02-08 22:55:18,014] Trial 49 finished with value: 0.7673581334631743 and parameters: {'lambda_l1': 2.3738968459055385e-06, 'lambda_l2': 0.09004703584652231}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  50%|##################5                  | 10/20 [02:10<02:13, 13.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.897408\tvalid_0's f1score: 0.672229\tvalid_1's auc: 0.767358\tvalid_1's f1score: 0.610292\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002402 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  55%|####################3                | 11/20 [02:21<01:54, 12.71s/it][I 2024-02-08 22:55:29,273] Trial 50 finished with value: 0.7681475115816008 and parameters: {'lambda_l1': 0.008157179138262843, 'lambda_l2': 1.0954202698257243e-05}. Best is trial 40 with value: 0.7689684287801014.\n",
      "regularization_factors, val_score: 0.770342:  55%|####################3                | 11/20 [02:21<01:54, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.874066\tvalid_0's f1score: 0.634187\tvalid_1's auc: 0.768148\tvalid_1's f1score: 0.586022\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010365 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  60%|######################2              | 12/20 [02:34<01:41, 12.73s/it][I 2024-02-08 22:55:42,033] Trial 51 finished with value: 0.769119515992266 and parameters: {'lambda_l1': 0.005728048486940007, 'lambda_l2': 8.126911550778387e-06}. Best is trial 51 with value: 0.769119515992266.\n",
      "regularization_factors, val_score: 0.770342:  60%|######################2              | 12/20 [02:34<01:41, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.905231\tvalid_0's f1score: 0.681828\tvalid_1's auc: 0.76912\tvalid_1's f1score: 0.613326\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  65%|########################             | 13/20 [02:47<01:28, 12.71s/it][I 2024-02-08 22:55:54,688] Trial 52 finished with value: 0.7689302815118213 and parameters: {'lambda_l1': 0.007124556718042115, 'lambda_l2': 1.559957450455352e-05}. Best is trial 51 with value: 0.769119515992266.\n",
      "regularization_factors, val_score: 0.770342:  65%|########################             | 13/20 [02:47<01:28, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.906026\tvalid_0's f1score: 0.682578\tvalid_1's auc: 0.76893\tvalid_1's f1score: 0.605171\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002577 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  70%|#########################9           | 14/20 [02:59<01:15, 12.65s/it][I 2024-02-08 22:56:07,187] Trial 53 finished with value: 0.7658742948387347 and parameters: {'lambda_l1': 0.014134998259986839, 'lambda_l2': 1.3827621691414374e-05}. Best is trial 51 with value: 0.769119515992266.\n",
      "regularization_factors, val_score: 0.770342:  70%|#########################9           | 14/20 [02:59<01:15, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.892862\tvalid_0's f1score: 0.669227\tvalid_1's auc: 0.765874\tvalid_1's f1score: 0.60573\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003026 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  75%|###########################7         | 15/20 [03:12<01:03, 12.66s/it][I 2024-02-08 22:56:19,895] Trial 54 finished with value: 0.7649374339744377 and parameters: {'lambda_l1': 0.00124313488181687, 'lambda_l2': 1.1441055039959521e-05}. Best is trial 51 with value: 0.769119515992266.\n",
      "regularization_factors, val_score: 0.770342:  75%|###########################7         | 15/20 [03:12<01:03, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.90223\tvalid_0's f1score: 0.676231\tvalid_1's auc: 0.764937\tvalid_1's f1score: 0.607391\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  80%|#############################6       | 16/20 [03:23<00:48, 12.11s/it][I 2024-02-08 22:56:30,718] Trial 55 finished with value: 0.763714768970231 and parameters: {'lambda_l1': 8.029603390590472e-06, 'lambda_l2': 0.0003110226479733936}. Best is trial 51 with value: 0.769119515992266.\n",
      "regularization_factors, val_score: 0.770342:  80%|#############################6       | 16/20 [03:23<00:48, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.85714\tvalid_0's f1score: 0.561614\tvalid_1's auc: 0.763715\tvalid_1's f1score: 0.529641\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004361 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  85%|###############################4     | 17/20 [03:35<00:36, 12.26s/it][I 2024-02-08 22:56:43,316] Trial 56 finished with value: 0.7660052571140901 and parameters: {'lambda_l1': 0.0006471684165461173, 'lambda_l2': 7.124729251639975e-07}. Best is trial 51 with value: 0.769119515992266.\n",
      "regularization_factors, val_score: 0.770342:  85%|###############################4     | 17/20 [03:35<00:36, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.898717\tvalid_0's f1score: 0.677571\tvalid_1's auc: 0.766005\tvalid_1's f1score: 0.60624\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002812 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  90%|#################################3   | 18/20 [03:47<00:24, 12.02s/it][I 2024-02-08 22:56:54,790] Trial 57 finished with value: 0.7691339338574428 and parameters: {'lambda_l1': 0.3394287340592489, 'lambda_l2': 0.0002256699678892512}. Best is trial 57 with value: 0.7691339338574428.\n",
      "regularization_factors, val_score: 0.770342:  90%|#################################3   | 18/20 [03:47<00:24, 12.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.876307\tvalid_0's f1score: 0.637453\tvalid_1's auc: 0.769134\tvalid_1's f1score: 0.588948\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002191 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342:  95%|###################################1 | 19/20 [03:57<00:11, 11.61s/it][I 2024-02-08 22:57:05,445] Trial 58 finished with value: 0.7678208568236903 and parameters: {'lambda_l1': 0.5480177574116796, 'lambda_l2': 0.00012027431854031548}. Best is trial 57 with value: 0.7691339338574428.\n",
      "regularization_factors, val_score: 0.770342:  95%|###################################1 | 19/20 [03:58<00:11, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.852122\tvalid_0's f1score: 0.526143\tvalid_1's auc: 0.767821\tvalid_1's f1score: 0.512761\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.770342: 100%|#####################################| 20/20 [04:08<00:00, 11.23s/it][I 2024-02-08 22:57:15,789] Trial 59 finished with value: 0.7660693865769075 and parameters: {'lambda_l1': 0.3253487205784592, 'lambda_l2': 1.5791382074177768e-06}. Best is trial 57 with value: 0.7691339338574428.\n",
      "regularization_factors, val_score: 0.770342: 100%|#####################################| 20/20 [04:08<00:00, 12.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.842661\tvalid_0's f1score: 0.480689\tvalid_1's auc: 0.766069\tvalid_1's f1score: 0.479938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.770342:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002520 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.770342:  20%|########8                                   | 1/5 [00:10<00:42, 10.66s/it][I 2024-02-08 22:57:26,473] Trial 60 finished with value: 0.7667973385822372 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.7667973385822372.\n",
      "min_child_samples, val_score: 0.770342:  20%|########8                                   | 1/5 [00:10<00:42, 10.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.843629\tvalid_0's f1score: 0.507669\tvalid_1's auc: 0.766797\tvalid_1's f1score: 0.503487\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.770342:  40%|#################6                          | 2/5 [00:23<00:35, 11.77s/it][I 2024-02-08 22:57:39,020] Trial 61 finished with value: 0.767686139895945 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.767686139895945.\n",
      "min_child_samples, val_score: 0.770342:  40%|#################6                          | 2/5 [00:23<00:35, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.88971\tvalid_0's f1score: 0.666917\tvalid_1's auc: 0.767686\tvalid_1's f1score: 0.607608\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.770342:  60%|##########################4                 | 3/5 [00:36<00:25, 12.69s/it][I 2024-02-08 22:57:52,790] Trial 62 finished with value: 0.76034384205469 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.767686139895945.\n",
      "min_child_samples, val_score: 0.770342:  60%|##########################4                 | 3/5 [00:36<00:25, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.93846\tvalid_0's f1score: 0.712234\tvalid_1's auc: 0.760344\tvalid_1's f1score: 0.62374\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.770342:  80%|###################################2        | 4/5 [00:47<00:11, 11.98s/it][I 2024-02-08 22:58:03,679] Trial 63 finished with value: 0.7656595287220395 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.767686139895945.\n",
      "min_child_samples, val_score: 0.770342:  80%|###################################2        | 4/5 [00:47<00:11, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.877693\tvalid_0's f1score: 0.616532\tvalid_1's auc: 0.76566\tvalid_1's f1score: 0.571682\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9720\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.770342: 100%|############################################| 5/5 [01:00<00:00, 12.13s/it][I 2024-02-08 22:58:16,071] Trial 64 finished with value: 0.7675236385405155 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.767686139895945.\n",
      "min_child_samples, val_score: 0.770342: 100%|############################################| 5/5 [01:00<00:00, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.896722\tvalid_0's f1score: 0.675747\tvalid_1's auc: 0.767524\tvalid_1's f1score: 0.611931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2024-02-08 22:58:16,280] A new study created in memory with name: no-name-a70f45f0-f86a-4427-9762-a53469e2ad6f\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012626 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.768763:  14%|######4                                      | 1/7 [00:10<01:02, 10.49s/it][I 2024-02-08 22:58:26,770] Trial 0 finished with value: 0.7687627661130823 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.7687627661130823.\n",
      "feature_fraction, val_score: 0.768763:  14%|######4                                      | 1/7 [00:10<01:02, 10.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's auc: 0.863799\tvalid_0's f1score: 0.615846\tvalid_1's auc: 0.768763\tvalid_1's f1score: 0.568984\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007687 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776951:  29%|############8                                | 2/7 [00:20<00:50, 10.05s/it][I 2024-02-08 22:58:36,513] Trial 1 finished with value: 0.7769508072594722 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.7769508072594722.\n",
      "feature_fraction, val_score: 0.776951:  29%|############8                                | 2/7 [00:20<00:50, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.847931\tvalid_0's f1score: 0.544977\tvalid_1's auc: 0.776951\tvalid_1's f1score: 0.519561\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776951:  43%|###################2                         | 3/7 [00:31<00:42, 10.51s/it][I 2024-02-08 22:58:47,590] Trial 2 finished with value: 0.7657462222356235 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.7769508072594722.\n",
      "feature_fraction, val_score: 0.776951:  43%|###################2                         | 3/7 [00:31<00:42, 10.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.873839\tvalid_0's f1score: 0.647056\tvalid_1's auc: 0.765746\tvalid_1's f1score: 0.588474\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776951:  57%|#########################7                   | 4/7 [00:41<00:30, 10.25s/it][I 2024-02-08 22:58:57,444] Trial 3 finished with value: 0.76670441359917 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7769508072594722.\n",
      "feature_fraction, val_score: 0.776951:  57%|#########################7                   | 4/7 [00:41<00:30, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.850039\tvalid_0's f1score: 0.56174\tvalid_1's auc: 0.766704\tvalid_1's f1score: 0.537435\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776951:  71%|################################1            | 5/7 [00:52<00:21, 10.56s/it][I 2024-02-08 22:59:08,543] Trial 4 finished with value: 0.7631146859019674 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.7769508072594722.\n",
      "feature_fraction, val_score: 0.776951:  71%|################################1            | 5/7 [00:52<00:21, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.869177\tvalid_0's f1score: 0.631646\tvalid_1's auc: 0.763115\tvalid_1's f1score: 0.591313\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776951:  86%|######################################5      | 6/7 [01:01<00:10, 10.14s/it][I 2024-02-08 22:59:17,866] Trial 5 finished with value: 0.7714174754896213 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7769508072594722.\n",
      "feature_fraction, val_score: 0.776951:  86%|######################################5      | 6/7 [01:01<00:10, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.839432\tvalid_0's f1score: 0.472315\tvalid_1's auc: 0.771417\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009370 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776951: 100%|#############################################| 7/7 [01:12<00:00, 10.27s/it][I 2024-02-08 22:59:28,405] Trial 6 finished with value: 0.7661305317962067 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7769508072594722.\n",
      "feature_fraction, val_score: 0.776951: 100%|#############################################| 7/7 [01:12<00:00, 10.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.865657\tvalid_0's f1score: 0.628006\tvalid_1's auc: 0.766131\tvalid_1's f1score: 0.585225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.776951:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.776951:   5%|##5                                               | 1/20 [00:10<03:24, 10.74s/it][I 2024-02-08 22:59:39,156] Trial 7 finished with value: 0.7767356888312634 and parameters: {'num_leaves': 74}. Best is trial 7 with value: 0.7767356888312634.\n",
      "num_leaves, val_score: 0.776951:   5%|##5                                               | 1/20 [00:10<03:24, 10.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.87781\tvalid_0's f1score: 0.578373\tvalid_1's auc: 0.776736\tvalid_1's f1score: 0.53453\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  10%|#####                                             | 2/20 [00:20<03:00, 10.03s/it][I 2024-02-08 22:59:48,686] Trial 8 finished with value: 0.7800734445862746 and parameters: {'num_leaves': 45}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  10%|#####                                             | 2/20 [00:20<03:00, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780073\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003078 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  15%|#######5                                          | 3/20 [00:33<03:15, 11.48s/it][I 2024-02-08 23:00:01,880] Trial 9 finished with value: 0.7758979693713796 and parameters: {'num_leaves': 141}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  15%|#######5                                          | 3/20 [00:33<03:15, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's auc: 0.928198\tvalid_0's f1score: 0.656362\tvalid_1's auc: 0.775898\tvalid_1's f1score: 0.582308\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008936 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  20%|##########                                        | 4/20 [00:47<03:21, 12.59s/it][I 2024-02-08 23:00:16,175] Trial 10 finished with value: 0.7700248593703409 and parameters: {'num_leaves': 2}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  20%|##########                                        | 4/20 [00:47<03:21, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's auc: 0.808604\tvalid_0's f1score: 0.608047\tvalid_1's auc: 0.770025\tvalid_1's f1score: 0.59391\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  25%|############5                                     | 5/20 [01:02<03:18, 13.25s/it][I 2024-02-08 23:00:30,589] Trial 11 finished with value: 0.7769871023868793 and parameters: {'num_leaves': 196}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  25%|############5                                     | 5/20 [01:02<03:18, 13.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.945095\tvalid_0's f1score: 0.676364\tvalid_1's auc: 0.776987\tvalid_1's f1score: 0.585225\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006664 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  30%|###############                                   | 6/20 [01:16<03:10, 13.62s/it][I 2024-02-08 23:00:44,945] Trial 12 finished with value: 0.7748433167269165 and parameters: {'num_leaves': 254}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  30%|###############                                   | 6/20 [01:16<03:10, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.934864\tvalid_0's f1score: 0.608966\tvalid_1's auc: 0.774843\tvalid_1's f1score: 0.545563\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002444 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  35%|#################5                                | 7/20 [01:30<02:57, 13.69s/it][I 2024-02-08 23:00:58,785] Trial 13 finished with value: 0.7725900872981573 and parameters: {'num_leaves': 195}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  35%|#################5                                | 7/20 [01:30<02:57, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.935811\tvalid_0's f1score: 0.652449\tvalid_1's auc: 0.77259\tvalid_1's f1score: 0.563967\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003480 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  40%|####################                              | 8/20 [01:42<02:36, 13.05s/it][I 2024-02-08 23:01:10,457] Trial 14 finished with value: 0.7774386975298094 and parameters: {'num_leaves': 64}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  40%|####################                              | 8/20 [01:42<02:36, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.889132\tvalid_0's f1score: 0.63402\tvalid_1's auc: 0.777439\tvalid_1's f1score: 0.577628\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003088 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  45%|######################5                           | 9/20 [01:51<02:12, 12.01s/it][I 2024-02-08 23:01:20,182] Trial 15 finished with value: 0.7793111073140824 and parameters: {'num_leaves': 47}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  45%|######################5                           | 9/20 [01:51<02:12, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841941\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779311\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005228 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  50%|########################5                        | 10/20 [01:59<01:47, 10.76s/it][I 2024-02-08 23:01:28,164] Trial 16 finished with value: 0.7736600955734463 and parameters: {'num_leaves': 13}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  50%|########################5                        | 10/20 [01:59<01:47, 10.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.814649\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.77366\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002451 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  55%|##########################9                      | 11/20 [02:11<01:38, 10.95s/it][I 2024-02-08 23:01:39,546] Trial 17 finished with value: 0.7770179532451753 and parameters: {'num_leaves': 67}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  55%|##########################9                      | 11/20 [02:11<01:38, 10.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.89068\tvalid_0's f1score: 0.632483\tvalid_1's auc: 0.777018\tvalid_1's f1score: 0.584595\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002335 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  60%|#############################4                   | 12/20 [02:22<01:28, 11.10s/it][I 2024-02-08 23:01:50,982] Trial 18 finished with value: 0.7798195182910691 and parameters: {'num_leaves': 100}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  60%|#############################4                   | 12/20 [02:22<01:28, 11.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.868266\tvalid_0's f1score: 0.47205\tvalid_1's auc: 0.77982\tvalid_1's f1score: 0.470799\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  65%|###############################8                 | 13/20 [02:35<01:22, 11.78s/it][I 2024-02-08 23:02:04,324] Trial 19 finished with value: 0.7737149570544885 and parameters: {'num_leaves': 131}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  65%|###############################8                 | 13/20 [02:35<01:22, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.926027\tvalid_0's f1score: 0.656402\tvalid_1's auc: 0.773715\tvalid_1's f1score: 0.577089\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001847 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  70%|##################################3              | 14/20 [02:47<01:10, 11.78s/it][I 2024-02-08 23:02:16,124] Trial 20 finished with value: 0.7755837373260207 and parameters: {'num_leaves': 103}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  70%|##################################3              | 14/20 [02:47<01:10, 11.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.891372\tvalid_0's f1score: 0.578844\tvalid_1's auc: 0.775584\tvalid_1's f1score: 0.526791\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  75%|####################################7            | 15/20 [02:57<00:55, 11.11s/it][I 2024-02-08 23:02:25,659] Trial 21 finished with value: 0.7749247015702947 and parameters: {'num_leaves': 40}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  75%|####################################7            | 15/20 [02:57<00:55, 11.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.855249\tvalid_0's f1score: 0.555775\tvalid_1's auc: 0.774925\tvalid_1's f1score: 0.520825\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002265 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  80%|#######################################2         | 16/20 [03:08<00:44, 11.04s/it][I 2024-02-08 23:02:36,546] Trial 22 finished with value: 0.7769286113930963 and parameters: {'num_leaves': 97}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  80%|#######################################2         | 16/20 [03:08<00:44, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.867526\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.776929\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005951 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  85%|#########################################6       | 17/20 [03:17<00:31, 10.50s/it][I 2024-02-08 23:02:45,782] Trial 23 finished with value: 0.7783483092612881 and parameters: {'num_leaves': 37}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  85%|#########################################6       | 17/20 [03:17<00:31, 10.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.837153\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.778348\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  90%|############################################1    | 18/20 [03:27<00:20, 10.36s/it][I 2024-02-08 23:02:55,816] Trial 24 finished with value: 0.7749247015702947 and parameters: {'num_leaves': 40}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  90%|############################################1    | 18/20 [03:27<00:20, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.855249\tvalid_0's f1score: 0.555775\tvalid_1's auc: 0.774925\tvalid_1's f1score: 0.520825\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002629 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073:  95%|##############################################5  | 19/20 [03:39<00:10, 10.82s/it][I 2024-02-08 23:03:07,701] Trial 25 finished with value: 0.7755837373260207 and parameters: {'num_leaves': 103}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073:  95%|##############################################5  | 19/20 [03:39<00:10, 10.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.891372\tvalid_0's f1score: 0.578844\tvalid_1's auc: 0.775584\tvalid_1's f1score: 0.526791\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780073: 100%|#################################################| 20/20 [03:50<00:00, 10.83s/it][I 2024-02-08 23:03:18,565] Trial 26 finished with value: 0.777487695951809 and parameters: {'num_leaves': 84}. Best is trial 8 with value: 0.7800734445862746.\n",
      "num_leaves, val_score: 0.780073: 100%|#################################################| 20/20 [03:50<00:00, 11.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.860787\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.777488\tvalid_1's f1score: 0.470846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002844 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  10%|#####3                                               | 1/10 [00:12<01:49, 12.22s/it][I 2024-02-08 23:03:30,810] Trial 27 finished with value: 0.7767065131326939 and parameters: {'bagging_fraction': 0.6364961969348776, 'bagging_freq': 2}. Best is trial 27 with value: 0.7767065131326939.\n",
      "bagging, val_score: 0.780073:  10%|#####3                                               | 1/10 [00:12<01:49, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.898106\tvalid_0's f1score: 0.681055\tvalid_1's auc: 0.776707\tvalid_1's f1score: 0.619167\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002413 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  20%|##########6                                          | 2/10 [00:22<01:28, 11.05s/it][I 2024-02-08 23:03:41,024] Trial 28 finished with value: 0.7797290596658392 and parameters: {'bagging_fraction': 0.9964010422949874, 'bagging_freq': 7}. Best is trial 28 with value: 0.7797290596658392.\n",
      "bagging, val_score: 0.780073:  20%|##########6                                          | 2/10 [00:22<01:28, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840308\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779729\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  30%|###############9                                     | 3/10 [00:32<01:14, 10.69s/it][I 2024-02-08 23:03:51,294] Trial 29 finished with value: 0.7774775053968063 and parameters: {'bagging_fraction': 0.9827188898219295, 'bagging_freq': 7}. Best is trial 28 with value: 0.7797290596658392.\n",
      "bagging, val_score: 0.780073:  30%|###############9                                     | 3/10 [00:32<01:14, 10.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841957\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.777478\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014416 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  40%|#####################2                               | 4/10 [00:43<01:03, 10.55s/it][I 2024-02-08 23:04:01,625] Trial 30 finished with value: 0.7785133124943463 and parameters: {'bagging_fraction': 0.9947520330469766, 'bagging_freq': 7}. Best is trial 28 with value: 0.7797290596658392.\n",
      "bagging, val_score: 0.780073:  40%|#####################2                               | 4/10 [00:43<01:03, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841945\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.778513\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  50%|##########################5                          | 5/10 [00:53<00:52, 10.44s/it][I 2024-02-08 23:04:11,883] Trial 31 finished with value: 0.7771861672010426 and parameters: {'bagging_fraction': 0.4047007661377974, 'bagging_freq': 4}. Best is trial 28 with value: 0.7797290596658392.\n",
      "bagging, val_score: 0.780073:  50%|##########################5                          | 5/10 [00:53<00:52, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's auc: 0.844822\tvalid_0's f1score: 0.613871\tvalid_1's auc: 0.777186\tvalid_1's f1score: 0.564849\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003795 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  60%|###############################8                     | 6/10 [01:02<00:40, 10.07s/it][I 2024-02-08 23:04:21,216] Trial 32 finished with value: 0.7797156583880273 and parameters: {'bagging_fraction': 0.7665684614237519, 'bagging_freq': 5}. Best is trial 28 with value: 0.7797290596658392.\n",
      "bagging, val_score: 0.780073:  60%|###############################8                     | 6/10 [01:02<00:40, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.835442\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779716\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  70%|#####################################                | 7/10 [01:11<00:29,  9.81s/it][I 2024-02-08 23:04:30,494] Trial 33 finished with value: 0.7798563718050516 and parameters: {'bagging_fraction': 0.7793124333382476, 'bagging_freq': 5}. Best is trial 33 with value: 0.7798563718050516.\n",
      "bagging, val_score: 0.780073:  70%|#####################################                | 7/10 [01:11<00:29,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.835554\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779856\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002331 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  80%|##########################################4          | 8/10 [01:21<00:19,  9.85s/it][I 2024-02-08 23:04:40,425] Trial 34 finished with value: 0.7772072462942675 and parameters: {'bagging_fraction': 0.7983500554411332, 'bagging_freq': 5}. Best is trial 33 with value: 0.7798563718050516.\n",
      "bagging, val_score: 0.780073:  80%|##########################################4          | 8/10 [01:21<00:19,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.853354\tvalid_0's f1score: 0.554669\tvalid_1's auc: 0.777207\tvalid_1's f1score: 0.520365\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073:  90%|###############################################7     | 9/10 [01:32<00:09,  9.98s/it][I 2024-02-08 23:04:50,695] Trial 35 finished with value: 0.7793243689952504 and parameters: {'bagging_fraction': 0.8379242182786532, 'bagging_freq': 6}. Best is trial 33 with value: 0.7798563718050516.\n",
      "bagging, val_score: 0.780073:  90%|###############################################7     | 9/10 [01:32<00:09,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.854736\tvalid_0's f1score: 0.558556\tvalid_1's auc: 0.779324\tvalid_1's f1score: 0.524453\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.780073: 100%|####################################################| 10/10 [01:41<00:00,  9.76s/it][I 2024-02-08 23:04:59,971] Trial 36 finished with value: 0.7760255607038797 and parameters: {'bagging_fraction': 0.5950111750930763, 'bagging_freq': 3}. Best is trial 33 with value: 0.7798563718050516.\n",
      "bagging, val_score: 0.780073: 100%|####################################################| 10/10 [01:41<00:00, 10.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.82579\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.776026\tvalid_1's f1score: 0.470846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.780073:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002396 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.780073:  33%|############6                         | 1/3 [00:09<00:19,  9.62s/it][I 2024-02-08 23:05:09,598] Trial 37 finished with value: 0.7759818669543475 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.7759818669543475.\n",
      "feature_fraction_stage2, val_score: 0.780073:  33%|############6                         | 1/3 [00:09<00:19,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.845109\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.775982\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.780073:  67%|#########################3            | 2/3 [00:19<00:09,  9.52s/it][I 2024-02-08 23:05:19,055] Trial 38 finished with value: 0.7800734445862746 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 38 with value: 0.7800734445862746.\n",
      "feature_fraction_stage2, val_score: 0.780073:  67%|#########################3            | 2/3 [00:19<00:09,  9.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780073\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.780073: 100%|######################################| 3/3 [00:28<00:00,  9.64s/it][I 2024-02-08 23:05:28,828] Trial 39 finished with value: 0.7732013810016785 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 0.7800734445862746.\n",
      "feature_fraction_stage2, val_score: 0.780073: 100%|######################################| 3/3 [00:28<00:00,  9.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.84561\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.773201\tvalid_1's f1score: 0.470846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780073:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780073:   5%|#9                                    | 1/20 [00:09<02:56,  9.29s/it][I 2024-02-08 23:05:38,130] Trial 40 finished with value: 0.7758252395199216 and parameters: {'lambda_l1': 4.345404235766503e-05, 'lambda_l2': 4.130217103300683}. Best is trial 40 with value: 0.7758252395199216.\n",
      "regularization_factors, val_score: 0.780073:   5%|#9                                    | 1/20 [00:09<02:56,  9.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.844484\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.775825\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002356 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780073:  10%|###8                                  | 2/20 [00:18<02:51,  9.53s/it][I 2024-02-08 23:05:47,843] Trial 41 finished with value: 0.7782352359797506 and parameters: {'lambda_l1': 3.8710428147813776, 'lambda_l2': 4.171144858767006e-08}. Best is trial 41 with value: 0.7782352359797506.\n",
      "regularization_factors, val_score: 0.780073:  10%|###8                                  | 2/20 [00:19<02:51,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.842504\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.778235\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780073:  15%|#####7                                | 3/20 [00:28<02:38,  9.34s/it][I 2024-02-08 23:05:56,950] Trial 42 finished with value: 0.7790620669014123 and parameters: {'lambda_l1': 1.918979142966496e-08, 'lambda_l2': 0.0014648360602127412}. Best is trial 42 with value: 0.7790620669014123.\n",
      "regularization_factors, val_score: 0.780073:  15%|#####7                                | 3/20 [00:28<02:38,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841154\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779062\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002292 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780073:  20%|#######6                              | 4/20 [00:37<02:30,  9.38s/it][I 2024-02-08 23:06:06,395] Trial 43 finished with value: 0.7794346503439102 and parameters: {'lambda_l1': 6.476657317250783, 'lambda_l2': 1.9125415841058477e-08}. Best is trial 43 with value: 0.7794346503439102.\n",
      "regularization_factors, val_score: 0.780073:  20%|#######6                              | 4/20 [00:37<02:30,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841327\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779435\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780073:  25%|#########5                            | 5/20 [00:46<02:20,  9.39s/it][I 2024-02-08 23:06:15,817] Trial 44 finished with value: 0.776480506166263 and parameters: {'lambda_l1': 0.0006508541252671094, 'lambda_l2': 8.968094860111842}. Best is trial 43 with value: 0.7794346503439102.\n",
      "regularization_factors, val_score: 0.780073:  25%|#########5                            | 5/20 [00:46<02:20,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.842816\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.776481\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  30%|###########4                          | 6/20 [00:56<02:10,  9.36s/it][I 2024-02-08 23:06:25,101] Trial 45 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 3.7712123212943855e-08, 'lambda_l2': 7.567468365136322e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  30%|###########4                          | 6/20 [00:56<02:10,  9.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  35%|#############3                        | 7/20 [01:05<02:01,  9.37s/it][I 2024-02-08 23:06:34,479] Trial 46 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.3921262078850517e-08, 'lambda_l2': 8.049462391471669e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  35%|#############3                        | 7/20 [01:05<02:01,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  40%|###############2                      | 8/20 [01:15<01:53,  9.45s/it][I 2024-02-08 23:06:44,090] Trial 47 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.2052114228608734e-08, 'lambda_l2': 7.96107170557732e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  40%|###############2                      | 8/20 [01:15<01:53,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  45%|#################1                    | 9/20 [01:24<01:43,  9.44s/it][I 2024-02-08 23:06:53,527] Trial 48 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.9782166843066313e-08, 'lambda_l2': 7.830334151183986e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  45%|#################1                    | 9/20 [01:24<01:43,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  50%|##################5                  | 10/20 [01:34<01:34,  9.46s/it][I 2024-02-08 23:07:03,017] Trial 49 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.1062676933227972e-08, 'lambda_l2': 7.06713690439483e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  50%|##################5                  | 10/20 [01:34<01:34,  9.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  55%|####################3                | 11/20 [01:43<01:24,  9.39s/it][I 2024-02-08 23:07:12,271] Trial 50 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.1275093935135264e-08, 'lambda_l2': 7.46252150970577e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  55%|####################3                | 11/20 [01:43<01:24,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003216 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  60%|######################2              | 12/20 [01:52<01:15,  9.44s/it][I 2024-02-08 23:07:21,823] Trial 51 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.0171351393332188e-08, 'lambda_l2': 7.404101231747066e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  60%|######################2              | 12/20 [01:52<01:15,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  65%|########################             | 13/20 [02:02<01:06,  9.48s/it][I 2024-02-08 23:07:31,372] Trial 52 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 1.2985610644209761e-08, 'lambda_l2': 7.746548203067729e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  65%|########################             | 13/20 [02:02<01:06,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010840 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  70%|#########################9           | 14/20 [02:11<00:56,  9.44s/it][I 2024-02-08 23:07:40,716] Trial 53 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 5.260664120993082e-08, 'lambda_l2': 8.173977479527679e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  70%|#########################9           | 14/20 [02:11<00:56,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004187 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  75%|###########################7         | 15/20 [02:21<00:47,  9.51s/it][I 2024-02-08 23:07:50,410] Trial 54 finished with value: 0.7800737237795624 and parameters: {'lambda_l1': 3.1250675153475816e-07, 'lambda_l2': 4.887862173764743e-05}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  75%|###########################7         | 15/20 [02:21<00:47,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780074\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  80%|#############################6       | 16/20 [02:30<00:37,  9.49s/it][I 2024-02-08 23:07:59,835] Trial 55 finished with value: 0.7800734445862746 and parameters: {'lambda_l1': 4.364827110560552e-07, 'lambda_l2': 7.388655589756826e-06}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  80%|#############################6       | 16/20 [02:30<00:37,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780073\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  85%|###############################4     | 17/20 [02:40<00:28,  9.53s/it][I 2024-02-08 23:08:09,451] Trial 56 finished with value: 0.7790629044812756 and parameters: {'lambda_l1': 1.0396558587819549e-08, 'lambda_l2': 0.0012151711120644562}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  85%|###############################4     | 17/20 [02:40<00:28,  9.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841154\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779063\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004928 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  90%|#################################3   | 18/20 [02:50<00:19,  9.61s/it][I 2024-02-08 23:08:19,263] Trial 57 finished with value: 0.7800734445862746 and parameters: {'lambda_l1': 3.3353920053909763e-07, 'lambda_l2': 3.249323549081556e-06}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  90%|#################################3   | 18/20 [02:50<00:19,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780073\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005364 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074:  95%|###################################1 | 19/20 [03:00<00:09,  9.73s/it][I 2024-02-08 23:08:29,255] Trial 58 finished with value: 0.7790629044812756 and parameters: {'lambda_l1': 1.6723798575654826e-07, 'lambda_l2': 0.0012726479622625706}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074:  95%|###################################1 | 19/20 [03:00<00:09,  9.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.841154\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779063\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005881 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.780074: 100%|#####################################| 20/20 [03:09<00:00,  9.67s/it][I 2024-02-08 23:08:38,802] Trial 59 finished with value: 0.7800734445862746 and parameters: {'lambda_l1': 1.0967768732123984e-07, 'lambda_l2': 4.6878133801014695e-06}. Best is trial 45 with value: 0.7800737237795624.\n",
      "regularization_factors, val_score: 0.780074: 100%|#####################################| 20/20 [03:09<00:00,  9.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840709\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.780073\tvalid_1's f1score: 0.470846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.780074:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.780074:  20%|########8                                   | 1/5 [00:09<00:38,  9.72s/it][I 2024-02-08 23:08:48,531] Trial 60 finished with value: 0.7793764385434151 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.7793764385434151.\n",
      "min_child_samples, val_score: 0.780074:  20%|########8                                   | 1/5 [00:09<00:38,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.842329\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.779376\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002376 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.780074:  40%|#################6                          | 2/5 [00:19<00:29,  9.87s/it][I 2024-02-08 23:08:58,520] Trial 61 finished with value: 0.7777180304142 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.7793764385434151.\n",
      "min_child_samples, val_score: 0.780074:  40%|#################6                          | 2/5 [00:19<00:29,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.861486\tvalid_0's f1score: 0.555581\tvalid_1's auc: 0.777718\tvalid_1's f1score: 0.522081\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003220 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.780074:  60%|##########################4                 | 3/5 [00:30<00:20, 10.19s/it][I 2024-02-08 23:09:09,082] Trial 62 finished with value: 0.7754486077747513 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.7793764385434151.\n",
      "min_child_samples, val_score: 0.780074:  60%|##########################4                 | 3/5 [00:30<00:20, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.873492\tvalid_0's f1score: 0.615503\tvalid_1's auc: 0.775449\tvalid_1's f1score: 0.575983\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007040 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.780074:  80%|###################################2        | 4/5 [00:39<00:09,  9.93s/it][I 2024-02-08 23:09:18,598] Trial 63 finished with value: 0.7786279213389663 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.7793764385434151.\n",
      "min_child_samples, val_score: 0.780074:  80%|###################################2        | 4/5 [00:39<00:09,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.84175\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.778628\tvalid_1's f1score: 0.470846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002580 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9746\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.780074: 100%|############################################| 5/5 [00:49<00:00,  9.85s/it][I 2024-02-08 23:09:28,304] Trial 64 finished with value: 0.7764525868374883 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.7793764385434151.\n",
      "min_child_samples, val_score: 0.780074: 100%|############################################| 5/5 [00:49<00:00,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.84275\tvalid_0's f1score: 0.471785\tvalid_1's auc: 0.776453\tvalid_1's f1score: 0.470846\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2024-02-08 23:09:28,496] A new study created in memory with name: no-name-fc8a36e7-53dd-4c8d-af16-772ca9bf2cc0\n",
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013043 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.773639:  14%|######4                                      | 1/7 [00:09<00:58,  9.79s/it][I 2024-02-08 23:09:38,305] Trial 0 finished with value: 0.773639031239191 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.773639031239191.\n",
      "feature_fraction, val_score: 0.773639:  14%|######4                                      | 1/7 [00:09<00:58,  9.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.854048\tvalid_0's f1score: 0.579171\tvalid_1's auc: 0.773639\tvalid_1's f1score: 0.553254\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776811:  29%|############8                                | 2/7 [00:20<00:51, 10.30s/it][I 2024-02-08 23:09:48,949] Trial 1 finished with value: 0.7768114771258487 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7768114771258487.\n",
      "feature_fraction, val_score: 0.776811:  29%|############8                                | 2/7 [00:20<00:51, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.867954\tvalid_0's f1score: 0.633586\tvalid_1's auc: 0.776811\tvalid_1's f1score: 0.591925\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776811:  43%|###################2                         | 3/7 [00:31<00:42, 10.64s/it][I 2024-02-08 23:10:00,012] Trial 2 finished with value: 0.7708431941890735 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7768114771258487.\n",
      "feature_fraction, val_score: 0.776811:  43%|###################2                         | 3/7 [00:31<00:42, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.885272\tvalid_0's f1score: 0.667726\tvalid_1's auc: 0.770843\tvalid_1's f1score: 0.607149\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776811:  57%|#########################7                   | 4/7 [00:43<00:33, 11.05s/it][I 2024-02-08 23:10:11,694] Trial 3 finished with value: 0.7700885542771841 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.7768114771258487.\n",
      "feature_fraction, val_score: 0.776811:  57%|#########################7                   | 4/7 [00:43<00:33, 11.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.882473\tvalid_0's f1score: 0.662964\tvalid_1's auc: 0.770089\tvalid_1's f1score: 0.610378\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.776811:  71%|################################1            | 5/7 [00:52<00:20, 10.42s/it][I 2024-02-08 23:10:20,975] Trial 4 finished with value: 0.775907644362928 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.7768114771258487.\n",
      "feature_fraction, val_score: 0.776811:  71%|################################1            | 5/7 [00:52<00:20, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.838993\tvalid_0's f1score: 0.472205\tvalid_1's auc: 0.775908\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.784003:  86%|######################################5      | 6/7 [01:01<00:09,  9.95s/it][I 2024-02-08 23:10:30,020] Trial 5 finished with value: 0.7840033121097376 and parameters: {'feature_fraction': 0.4}. Best is trial 5 with value: 0.7840033121097376.\n",
      "feature_fraction, val_score: 0.784003:  86%|######################################5      | 6/7 [01:01<00:09,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.829765\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784003\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.784003: 100%|#############################################| 7/7 [01:12<00:00, 10.34s/it][I 2024-02-08 23:10:41,172] Trial 6 finished with value: 0.770072340754765 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 5 with value: 0.7840033121097376.\n",
      "feature_fraction, val_score: 0.784003: 100%|#############################################| 7/7 [01:12<00:00, 10.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.87465\tvalid_0's f1score: 0.646744\tvalid_1's auc: 0.770072\tvalid_1's f1score: 0.59495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784003:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:   5%|##5                                               | 1/20 [00:08<02:42,  8.58s/it][I 2024-02-08 23:10:49,754] Trial 7 finished with value: 0.7842762397371248 and parameters: {'num_leaves': 21}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:   5%|##5                                               | 1/20 [00:08<02:42,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826592\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  10%|#####                                             | 2/20 [00:17<02:42,  9.05s/it][I 2024-02-08 23:10:59,125] Trial 8 finished with value: 0.7837545625420983 and parameters: {'num_leaves': 39}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  10%|#####                                             | 2/20 [00:17<02:42,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.840227\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783755\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  15%|#######5                                          | 3/20 [00:30<03:02, 10.75s/it][I 2024-02-08 23:11:11,910] Trial 9 finished with value: 0.7798458236241831 and parameters: {'num_leaves': 207}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  15%|#######5                                          | 3/20 [00:30<03:02, 10.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.90786\tvalid_0's f1score: 0.477716\tvalid_1's auc: 0.779846\tvalid_1's f1score: 0.476144\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008494 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  20%|##########                                        | 4/20 [00:46<03:21, 12.56s/it][I 2024-02-08 23:11:27,262] Trial 10 finished with value: 0.7794791704593035 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  20%|##########                                        | 4/20 [00:46<03:21, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's auc: 0.808092\tvalid_0's f1score: 0.608031\tvalid_1's auc: 0.779479\tvalid_1's f1score: 0.590406\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003360 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  25%|############5                                     | 5/20 [00:57<03:04, 12.29s/it][I 2024-02-08 23:11:39,075] Trial 11 finished with value: 0.7809723789845442 and parameters: {'num_leaves': 106}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  25%|############5                                     | 5/20 [00:57<03:04, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.870406\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.780972\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  30%|###############                                   | 6/20 [01:09<02:47, 11.98s/it][I 2024-02-08 23:11:50,433] Trial 12 finished with value: 0.7802643885055798 and parameters: {'num_leaves': 98}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  30%|###############                                   | 6/20 [01:09<02:47, 11.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.869057\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.780264\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  35%|#################5                                | 7/20 [01:23<02:46, 12.83s/it][I 2024-02-08 23:12:05,040] Trial 13 finished with value: 0.7789099904880669 and parameters: {'num_leaves': 240}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  35%|#################5                                | 7/20 [01:23<02:46, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[17]\tvalid_0's auc: 0.920466\tvalid_0's f1score: 0.520521\tvalid_1's auc: 0.77891\tvalid_1's f1score: 0.498587\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005611 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  40%|####################                              | 8/20 [01:37<02:35, 12.96s/it][I 2024-02-08 23:12:18,266] Trial 14 finished with value: 0.7780434203819337 and parameters: {'num_leaves': 164}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  40%|####################                              | 8/20 [01:37<02:35, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.917432\tvalid_0's f1score: 0.603996\tvalid_1's auc: 0.778043\tvalid_1's f1score: 0.555837\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002375 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  45%|######################5                           | 9/20 [01:47<02:13, 12.10s/it][I 2024-02-08 23:12:28,460] Trial 15 finished with value: 0.7841399892592525 and parameters: {'num_leaves': 58}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  45%|######################5                           | 9/20 [01:47<02:13, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.851824\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.78414\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012097 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  50%|########################5                        | 10/20 [01:56<01:53, 11.36s/it][I 2024-02-08 23:12:38,167] Trial 16 finished with value: 0.7837399134823688 and parameters: {'num_leaves': 57}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  50%|########################5                        | 10/20 [01:56<01:53, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.852497\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.78374\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008038 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  55%|##########################9                      | 11/20 [02:05<01:35, 10.59s/it][I 2024-02-08 23:12:47,025] Trial 17 finished with value: 0.7836139031239191 and parameters: {'num_leaves': 5}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  55%|##########################9                      | 11/20 [02:05<01:35, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.812434\tvalid_0's f1score: 0.606982\tvalid_1's auc: 0.783614\tvalid_1's f1score: 0.581445\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005838 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  60%|#############################4                   | 12/20 [02:15<01:23, 10.45s/it][I 2024-02-08 23:12:57,142] Trial 18 finished with value: 0.781907643225137 and parameters: {'num_leaves': 63}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  60%|#############################4                   | 12/20 [02:15<01:23, 10.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.855015\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.781908\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  65%|###############################8                 | 13/20 [02:27<01:16, 10.88s/it][I 2024-02-08 23:13:09,031] Trial 19 finished with value: 0.782507828002403 and parameters: {'num_leaves': 140}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  65%|###############################8                 | 13/20 [02:27<01:16, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.884393\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782508\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003134 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  70%|##################################3              | 14/20 [02:36<01:02, 10.35s/it][I 2024-02-08 23:13:18,157] Trial 20 finished with value: 0.7818220244488541 and parameters: {'num_leaves': 44}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  70%|##################################3              | 14/20 [02:36<01:02, 10.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.841687\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.781822\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  75%|####################################7            | 15/20 [02:47<00:52, 10.40s/it][I 2024-02-08 23:13:28,679] Trial 21 finished with value: 0.782058258314977 and parameters: {'num_leaves': 81}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  75%|####################################7            | 15/20 [02:47<00:52, 10.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.863789\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782058\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  80%|#######################################2         | 16/20 [02:56<00:39,  9.90s/it][I 2024-02-08 23:13:37,416] Trial 22 finished with value: 0.783431998780288 and parameters: {'num_leaves': 26}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  80%|#######################################2         | 16/20 [02:56<00:39,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.831909\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783432\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003001 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  85%|#########################################6       | 17/20 [03:07<00:30, 10.27s/it][I 2024-02-08 23:13:48,542] Trial 23 finished with value: 0.7836929796016822 and parameters: {'num_leaves': 119}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  85%|#########################################6       | 17/20 [03:07<00:30, 10.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.871774\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783693\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  90%|############################################1    | 18/20 [03:17<00:20, 10.34s/it][I 2024-02-08 23:13:59,050] Trial 24 finished with value: 0.782058258314977 and parameters: {'num_leaves': 81}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  90%|############################################1    | 18/20 [03:17<00:20, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.863789\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782058\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003181 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276:  95%|##############################################5  | 19/20 [03:30<00:10, 10.91s/it][I 2024-02-08 23:14:11,280] Trial 25 finished with value: 0.7817214721650798 and parameters: {'num_leaves': 150}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276:  95%|##############################################5  | 19/20 [03:30<00:10, 10.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.889767\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.781721\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784276: 100%|#################################################| 20/20 [03:42<00:00, 11.47s/it][I 2024-02-08 23:14:24,047] Trial 26 finished with value: 0.7783696819646465 and parameters: {'num_leaves': 187}. Best is trial 7 with value: 0.7842762397371248.\n",
      "num_leaves, val_score: 0.784276: 100%|#################################################| 20/20 [03:42<00:00, 11.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.900237\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.77837\tvalid_1's f1score: 0.471494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005701 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  10%|#####3                                               | 1/10 [00:08<01:20,  8.97s/it][I 2024-02-08 23:14:33,029] Trial 27 finished with value: 0.7828938236150808 and parameters: {'bagging_fraction': 0.9819448281967894, 'bagging_freq': 3}. Best is trial 27 with value: 0.7828938236150808.\n",
      "bagging, val_score: 0.784276:  10%|#####3                                               | 1/10 [00:08<01:20,  8.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827296\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782894\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  20%|##########6                                          | 2/10 [00:18<01:12,  9.03s/it][I 2024-02-08 23:14:42,093] Trial 28 finished with value: 0.7779566638146038 and parameters: {'bagging_fraction': 0.42082809904393254, 'bagging_freq': 7}. Best is trial 27 with value: 0.7828938236150808.\n",
      "bagging, val_score: 0.784276:  20%|##########6                                          | 2/10 [00:18<01:12,  9.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.823001\tvalid_0's f1score: 0.594305\tvalid_1's auc: 0.777957\tvalid_1's f1score: 0.570882\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  30%|###############9                                     | 3/10 [00:26<01:01,  8.85s/it][I 2024-02-08 23:14:50,735] Trial 29 finished with value: 0.7827847378984544 and parameters: {'bagging_fraction': 0.7244041728634738, 'bagging_freq': 1}. Best is trial 27 with value: 0.7828938236150808.\n",
      "bagging, val_score: 0.784276:  30%|###############9                                     | 3/10 [00:26<01:01,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.817422\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782785\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  40%|#####################2                               | 4/10 [00:35<00:53,  8.94s/it][I 2024-02-08 23:14:59,809] Trial 30 finished with value: 0.7752298053467077 and parameters: {'bagging_fraction': 0.41313252925475147, 'bagging_freq': 7}. Best is trial 27 with value: 0.7828938236150808.\n",
      "bagging, val_score: 0.784276:  40%|#####################2                               | 4/10 [00:35<00:53,  8.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.822256\tvalid_0's f1score: 0.592715\tvalid_1's auc: 0.77523\tvalid_1's f1score: 0.56518\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005511 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  50%|##########################5                          | 5/10 [00:44<00:44,  8.95s/it][I 2024-02-08 23:15:08,760] Trial 31 finished with value: 0.7832300408694544 and parameters: {'bagging_fraction': 0.9671241542240103, 'bagging_freq': 4}. Best is trial 31 with value: 0.7832300408694544.\n",
      "bagging, val_score: 0.784276:  50%|##########################5                          | 5/10 [00:44<00:44,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.820974\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.78323\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005290 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  60%|###############################8                     | 6/10 [00:53<00:35,  8.81s/it][I 2024-02-08 23:15:17,329] Trial 32 finished with value: 0.7838343501392656 and parameters: {'bagging_fraction': 0.6754128321602207, 'bagging_freq': 1}. Best is trial 32 with value: 0.7838343501392656.\n",
      "bagging, val_score: 0.784276:  60%|###############################8                     | 6/10 [00:53<00:35,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.817909\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783834\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  70%|#####################################                | 7/10 [01:01<00:26,  8.78s/it][I 2024-02-08 23:15:26,035] Trial 33 finished with value: 0.7826184781817189 and parameters: {'bagging_fraction': 0.6691267143577212, 'bagging_freq': 1}. Best is trial 32 with value: 0.7838343501392656.\n",
      "bagging, val_score: 0.784276:  70%|#####################################                | 7/10 [01:01<00:26,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.815887\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782618\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002152 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  80%|##########################################4          | 8/10 [01:10<00:17,  8.80s/it][I 2024-02-08 23:15:34,860] Trial 34 finished with value: 0.7833155174218566 and parameters: {'bagging_fraction': 0.6785701428453179, 'bagging_freq': 3}. Best is trial 32 with value: 0.7838343501392656.\n",
      "bagging, val_score: 0.784276:  80%|##########################################4          | 8/10 [01:10<00:17,  8.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.81703\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783316\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276:  90%|###############################################7     | 9/10 [01:19<00:08,  8.82s/it][I 2024-02-08 23:15:43,751] Trial 35 finished with value: 0.7811552788953414 and parameters: {'bagging_fraction': 0.8074372455064215, 'bagging_freq': 5}. Best is trial 32 with value: 0.7838343501392656.\n",
      "bagging, val_score: 0.784276:  90%|###############################################7     | 9/10 [01:19<00:08,  8.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.81803\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.781155\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784276: 100%|####################################################| 10/10 [01:28<00:00,  8.80s/it][I 2024-02-08 23:15:52,507] Trial 36 finished with value: 0.7813710325226193 and parameters: {'bagging_fraction': 0.5381017635356146, 'bagging_freq': 2}. Best is trial 32 with value: 0.7838343501392656.\n",
      "bagging, val_score: 0.784276: 100%|####################################################| 10/10 [01:28<00:00,  8.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.81126\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.781371\tvalid_1's f1score: 0.471494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784276:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002474 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784276:  33%|############6                         | 1/3 [00:09<00:19,  9.83s/it][I 2024-02-08 23:16:02,354] Trial 37 finished with value: 0.7788250828311882 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.7788250828311882.\n",
      "feature_fraction_stage2, val_score: 0.784276:  33%|############6                         | 1/3 [00:09<00:19,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.848309\tvalid_0's f1score: 0.607452\tvalid_1's auc: 0.778825\tvalid_1's f1score: 0.585123\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784276:  67%|#########################3            | 2/3 [00:19<00:09,  9.98s/it][I 2024-02-08 23:16:12,433] Trial 38 finished with value: 0.7802666640876736 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.7802666640876736.\n",
      "feature_fraction_stage2, val_score: 0.784276:  67%|#########################3            | 2/3 [00:19<00:09,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.854854\tvalid_0's f1score: 0.627422\tvalid_1's auc: 0.780267\tvalid_1's f1score: 0.594752\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003457 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784276: 100%|######################################| 3/3 [00:28<00:00,  9.38s/it][I 2024-02-08 23:16:21,083] Trial 39 finished with value: 0.7842762397371248 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.7842762397371248.\n",
      "feature_fraction_stage2, val_score: 0.784276: 100%|######################################| 3/3 [00:28<00:00,  9.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826592\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784276:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007789 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:   5%|#9                                    | 1/20 [00:08<02:41,  8.53s/it][I 2024-02-08 23:16:29,620] Trial 40 finished with value: 0.7842765241848865 and parameters: {'lambda_l1': 0.00014774486692677267, 'lambda_l2': 0.0037108990304266037}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:   5%|#9                                    | 1/20 [00:08<02:41,  8.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826592\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784277\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002419 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  10%|###8                                  | 2/20 [00:17<02:35,  8.64s/it][I 2024-02-08 23:16:38,353] Trial 41 finished with value: 0.7842765241848865 and parameters: {'lambda_l1': 0.0001976832466704969, 'lambda_l2': 0.0056143731358518}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:  10%|###8                                  | 2/20 [00:17<02:35,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784277\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  15%|#####7                                | 3/20 [00:25<02:26,  8.60s/it][I 2024-02-08 23:16:46,880] Trial 42 finished with value: 0.7842765241848865 and parameters: {'lambda_l1': 0.0001302908438226386, 'lambda_l2': 0.007088330551153994}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:  15%|#####7                                | 3/20 [00:25<02:26,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784277\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  20%|#######6                              | 4/20 [00:34<02:18,  8.65s/it][I 2024-02-08 23:16:55,612] Trial 43 finished with value: 0.7842765241848865 and parameters: {'lambda_l1': 0.00014833257087906563, 'lambda_l2': 0.005706662476570116}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:  20%|#######6                              | 4/20 [00:34<02:18,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784277\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  25%|#########5                            | 5/20 [00:43<02:09,  8.65s/it][I 2024-02-08 23:17:04,259] Trial 44 finished with value: 0.784275955289363 and parameters: {'lambda_l1': 0.00013186534736123285, 'lambda_l2': 0.004678674268484011}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:  25%|#########5                            | 5/20 [00:43<02:09,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004578 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  30%|###########4                          | 6/20 [00:51<02:00,  8.63s/it][I 2024-02-08 23:17:12,862] Trial 45 finished with value: 0.784275955289363 and parameters: {'lambda_l1': 0.0001692765095668262, 'lambda_l2': 0.004621759804134747}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:  30%|###########4                          | 6/20 [00:51<02:00,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002554 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  35%|#############3                        | 7/20 [01:00<01:51,  8.59s/it][I 2024-02-08 23:17:21,347] Trial 46 finished with value: 0.7842762397371248 and parameters: {'lambda_l1': 0.00014915874841881288, 'lambda_l2': 0.004279725685502057}. Best is trial 40 with value: 0.7842765241848865.\n",
      "regularization_factors, val_score: 0.784277:  35%|#############3                        | 7/20 [01:00<01:51,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003064 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  40%|###############2                      | 8/20 [01:08<01:43,  8.60s/it][I 2024-02-08 23:17:30,005] Trial 47 finished with value: 0.7842773775281717 and parameters: {'lambda_l1': 0.00015366705354059756, 'lambda_l2': 0.007895862063083618}. Best is trial 47 with value: 0.7842773775281717.\n",
      "regularization_factors, val_score: 0.784277:  40%|###############2                      | 8/20 [01:08<01:43,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784277\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784277:  45%|#################1                    | 9/20 [01:17<01:34,  8.61s/it][I 2024-02-08 23:17:38,643] Trial 48 finished with value: 0.784275955289363 and parameters: {'lambda_l1': 0.0001697225548282862, 'lambda_l2': 0.004660186730148122}. Best is trial 47 with value: 0.7842773775281717.\n",
      "regularization_factors, val_score: 0.784277:  45%|#################1                    | 9/20 [01:17<01:34,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002131 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  50%|##################5                  | 10/20 [01:26<01:27,  8.71s/it][I 2024-02-08 23:17:47,556] Trial 49 finished with value: 0.7842796531102656 and parameters: {'lambda_l1': 0.00018080562630559043, 'lambda_l2': 0.01512568876741925}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  50%|##################5                  | 10/20 [01:26<01:27,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.82659\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.78428\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003814 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  55%|####################3                | 11/20 [01:35<01:18,  8.74s/it][I 2024-02-08 23:17:56,390] Trial 50 finished with value: 0.7835548802133586 and parameters: {'lambda_l1': 0.029923945765022365, 'lambda_l2': 0.6992774359119923}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  55%|####################3                | 11/20 [01:35<01:18,  8.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827653\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783555\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006227 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  60%|######################2              | 12/20 [01:44<01:10,  8.81s/it][I 2024-02-08 23:18:05,339] Trial 51 finished with value: 0.7842773775281717 and parameters: {'lambda_l1': 7.90450877327519e-05, 'lambda_l2': 0.008146411536233251}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  60%|######################2              | 12/20 [01:44<01:10,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784277\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  65%|########################             | 13/20 [01:52<01:01,  8.77s/it][I 2024-02-08 23:18:14,003] Trial 52 finished with value: 0.7842793686625039 and parameters: {'lambda_l1': 4.13847206904251e-06, 'lambda_l2': 0.014347013732086631}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  65%|########################             | 13/20 [01:52<01:01,  8.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.82659\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784279\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005194 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  70%|#########################9           | 14/20 [02:01<00:52,  8.72s/it][I 2024-02-08 23:18:22,616] Trial 53 finished with value: 0.7833482289144563 and parameters: {'lambda_l1': 7.251630469084808e-07, 'lambda_l2': 0.0813274545888642}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  70%|#########################9           | 14/20 [02:01<00:52,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.822372\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783348\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002325 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  75%|###########################7         | 15/20 [02:10<00:43,  8.70s/it][I 2024-02-08 23:18:31,260] Trial 54 finished with value: 0.7842762397371248 and parameters: {'lambda_l1': 1.671156107184864e-06, 'lambda_l2': 1.621032211719616e-07}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  75%|###########################7         | 15/20 [02:10<00:43,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826592\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005470 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  80%|#############################6       | 16/20 [02:18<00:34,  8.70s/it][I 2024-02-08 23:18:39,959] Trial 55 finished with value: 0.784275955289363 and parameters: {'lambda_l1': 1.0028386914348767e-05, 'lambda_l2': 0.0002679555554532763}. Best is trial 49 with value: 0.7842796531102656.\n",
      "regularization_factors, val_score: 0.784280:  80%|#############################6       | 16/20 [02:18<00:34,  8.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826592\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784276\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004667 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  85%|###############################4     | 17/20 [02:27<00:26,  8.78s/it][I 2024-02-08 23:18:48,943] Trial 56 finished with value: 0.7842799375580274 and parameters: {'lambda_l1': 0.005551360204263949, 'lambda_l2': 0.00018114820822107394}. Best is trial 56 with value: 0.7842799375580274.\n",
      "regularization_factors, val_score: 0.784280:  85%|###############################4     | 17/20 [02:27<00:26,  8.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.78428\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  90%|#################################3   | 18/20 [02:37<00:17,  8.91s/it][I 2024-02-08 23:18:58,167] Trial 57 finished with value: 0.7842796531102656 and parameters: {'lambda_l1': 0.005763256298356813, 'lambda_l2': 7.86534259884526e-05}. Best is trial 56 with value: 0.7842799375580274.\n",
      "regularization_factors, val_score: 0.784280:  90%|#################################3   | 18/20 [02:37<00:17,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826591\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.78428\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003142 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280:  95%|###################################1 | 19/20 [02:45<00:08,  8.89s/it][I 2024-02-08 23:19:06,984] Trial 58 finished with value: 0.7842782308714569 and parameters: {'lambda_l1': 0.017488437186627258, 'lambda_l2': 2.617110212058372e-05}. Best is trial 56 with value: 0.7842799375580274.\n",
      "regularization_factors, val_score: 0.784280:  95%|###################################1 | 19/20 [02:45<00:08,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826589\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784278\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784280: 100%|#####################################| 20/20 [02:54<00:00,  8.77s/it][I 2024-02-08 23:19:15,496] Trial 59 finished with value: 0.7842782308714569 and parameters: {'lambda_l1': 0.020945880283297923, 'lambda_l2': 4.976004992709732e-05}. Best is trial 56 with value: 0.7842799375580274.\n",
      "regularization_factors, val_score: 0.784280: 100%|#####################################| 20/20 [02:54<00:00,  8.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.826588\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784278\tvalid_1's f1score: 0.471494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784280:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002573 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784280:  20%|########8                                   | 1/5 [00:08<00:33,  8.37s/it][I 2024-02-08 23:19:23,869] Trial 60 finished with value: 0.7834312876608837 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.7834312876608837.\n",
      "min_child_samples, val_score: 0.784280:  20%|########8                                   | 1/5 [00:08<00:33,  8.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827818\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783431\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003266 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784280:  40%|#################6                          | 2/5 [00:16<00:25,  8.51s/it][I 2024-02-08 23:19:32,488] Trial 61 finished with value: 0.7838270967213413 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.7838270967213413.\n",
      "min_child_samples, val_score: 0.784280:  40%|#################6                          | 2/5 [00:16<00:25,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827047\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783827\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784280:  60%|##########################4                 | 3/5 [00:25<00:17,  8.55s/it][I 2024-02-08 23:19:41,097] Trial 62 finished with value: 0.7826170559429102 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 0.7838270967213413.\n",
      "min_child_samples, val_score: 0.784280:  60%|##########################4                 | 3/5 [00:25<00:17,  8.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827702\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.782617\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009345 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784280:  80%|###################################2        | 4/5 [00:33<00:08,  8.49s/it][I 2024-02-08 23:19:49,497] Trial 63 finished with value: 0.7837174421091916 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.7838270967213413.\n",
      "min_child_samples, val_score: 0.784280:  80%|###################################2        | 4/5 [00:34<00:08,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827609\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.783717\tvalid_1's f1score: 0.471494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002777 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9769\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784280: 100%|############################################| 5/5 [00:42<00:00,  8.58s/it][I 2024-02-08 23:19:58,220] Trial 64 finished with value: 0.7840609127814895 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.7840609127814895.\n",
      "min_child_samples, val_score: 0.784280: 100%|############################################| 5/5 [00:42<00:00,  8.54s/it]\n",
      "[I 2024-02-08 23:19:58,393] A new study created in memory with name: no-name-5b349afe-3048-496d-8580-1732d55bdf1a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.827181\tvalid_0's f1score: 0.471677\tvalid_1's auc: 0.784061\tvalid_1's f1score: 0.471494\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.771254:  14%|######4                                      | 1/7 [00:11<01:11, 11.84s/it][I 2024-02-08 23:20:10,236] Trial 0 finished with value: 0.7712544197582986 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.7712544197582986.\n",
      "feature_fraction, val_score: 0.771254:  14%|######4                                      | 1/7 [00:11<01:11, 11.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.892204\tvalid_0's f1score: 0.672079\tvalid_1's auc: 0.771254\tvalid_1's f1score: 0.626766\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003726 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783234:  29%|############8                                | 2/7 [00:22<00:54, 10.90s/it][I 2024-02-08 23:20:20,468] Trial 1 finished with value: 0.7832340903360482 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.7832340903360482.\n",
      "feature_fraction, val_score: 0.783234:  29%|############8                                | 2/7 [00:22<00:54, 10.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.862186\tvalid_0's f1score: 0.615032\tvalid_1's auc: 0.783234\tvalid_1's f1score: 0.588186\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783234:  43%|###################2                         | 3/7 [00:32<00:43, 10.85s/it][I 2024-02-08 23:20:31,276] Trial 2 finished with value: 0.7706539776358764 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7832340903360482.\n",
      "feature_fraction, val_score: 0.783234:  43%|###################2                         | 3/7 [00:32<00:43, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.859422\tvalid_0's f1score: 0.596931\tvalid_1's auc: 0.770654\tvalid_1's f1score: 0.5652\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783234:  57%|#########################7                   | 4/7 [00:44<00:33, 11.27s/it][I 2024-02-08 23:20:43,199] Trial 3 finished with value: 0.7743154138887423 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7832340903360482.\n",
      "feature_fraction, val_score: 0.783234:  57%|#########################7                   | 4/7 [00:44<00:33, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.895931\tvalid_0's f1score: 0.676787\tvalid_1's auc: 0.774315\tvalid_1's f1score: 0.636881\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012776 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783234:  71%|################################1            | 5/7 [00:56<00:22, 11.41s/it][I 2024-02-08 23:20:54,849] Trial 4 finished with value: 0.7769700541218827 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7832340903360482.\n",
      "feature_fraction, val_score: 0.783234:  71%|################################1            | 5/7 [00:56<00:22, 11.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.892979\tvalid_0's f1score: 0.673807\tvalid_1's auc: 0.77697\tvalid_1's f1score: 0.635913\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783234:  86%|######################################5      | 6/7 [01:07<00:11, 11.14s/it][I 2024-02-08 23:21:05,460] Trial 5 finished with value: 0.7777613594384928 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.7832340903360482.\n",
      "feature_fraction, val_score: 0.783234:  86%|######################################5      | 6/7 [01:07<00:11, 11.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.874708\tvalid_0's f1score: 0.642023\tvalid_1's auc: 0.777761\tvalid_1's f1score: 0.6133\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783234: 100%|#############################################| 7/7 [01:19<00:00, 11.45s/it][I 2024-02-08 23:21:17,537] Trial 6 finished with value: 0.7708787036548396 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.7832340903360482.\n",
      "feature_fraction, val_score: 0.783234: 100%|#############################################| 7/7 [01:19<00:00, 11.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.88987\tvalid_0's f1score: 0.666417\tvalid_1's auc: 0.770879\tvalid_1's f1score: 0.627552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:   5%|##5                                               | 1/20 [00:10<03:28, 10.99s/it][I 2024-02-08 23:21:28,542] Trial 7 finished with value: 0.7819703179880498 and parameters: {'num_leaves': 74}. Best is trial 7 with value: 0.7819703179880498.\n",
      "num_leaves, val_score: 0.783234:   5%|##5                                               | 1/20 [00:11<03:28, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.877958\tvalid_0's f1score: 0.566561\tvalid_1's auc: 0.78197\tvalid_1's f1score: 0.538196\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010420 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  10%|#####                                             | 2/20 [00:22<03:27, 11.50s/it][I 2024-02-08 23:21:40,392] Trial 8 finished with value: 0.7816624741264564 and parameters: {'num_leaves': 79}. Best is trial 7 with value: 0.7819703179880498.\n",
      "num_leaves, val_score: 0.783234:  10%|#####                                             | 2/20 [00:22<03:27, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.903255\tvalid_0's f1score: 0.640232\tvalid_1's auc: 0.781662\tvalid_1's f1score: 0.600398\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  15%|#######5                                          | 3/20 [00:37<03:36, 12.75s/it][I 2024-02-08 23:21:54,616] Trial 9 finished with value: 0.7830266622102603 and parameters: {'num_leaves': 170}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  15%|#######5                                          | 3/20 [00:37<03:36, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.940979\tvalid_0's f1score: 0.668192\tvalid_1's auc: 0.783027\tvalid_1's f1score: 0.601583\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003291 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  20%|##########                                        | 4/20 [00:52<03:39, 13.70s/it][I 2024-02-08 23:22:09,787] Trial 10 finished with value: 0.7804343237110137 and parameters: {'num_leaves': 2}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  20%|##########                                        | 4/20 [00:52<03:39, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's auc: 0.807512\tvalid_0's f1score: 0.6055\tvalid_1's auc: 0.780434\tvalid_1's f1score: 0.587792\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011308 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  25%|############5                                     | 5/20 [01:06<03:27, 13.85s/it][I 2024-02-08 23:22:23,878] Trial 11 finished with value: 0.7806568508452513 and parameters: {'num_leaves': 244}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  25%|############5                                     | 5/20 [01:06<03:27, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.934527\tvalid_0's f1score: 0.593346\tvalid_1's auc: 0.780657\tvalid_1's f1score: 0.536234\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004207 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  30%|###############                                   | 6/20 [01:19<03:12, 13.76s/it][I 2024-02-08 23:22:37,480] Trial 12 finished with value: 0.7794978920025096 and parameters: {'num_leaves': 205}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  30%|###############                                   | 6/20 [01:19<03:12, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.927634\tvalid_0's f1score: 0.598144\tvalid_1's auc: 0.779498\tvalid_1's f1score: 0.54583\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002556 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  35%|#################5                                | 7/20 [01:33<02:57, 13.63s/it][I 2024-02-08 23:22:50,823] Trial 13 finished with value: 0.7813899590127887 and parameters: {'num_leaves': 164}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  35%|#################5                                | 7/20 [01:33<02:57, 13.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.915465\tvalid_0's f1score: 0.59096\tvalid_1's auc: 0.78139\tvalid_1's f1score: 0.54598\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003807 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  40%|####################                              | 8/20 [01:45<02:37, 13.13s/it][I 2024-02-08 23:23:02,893] Trial 14 finished with value: 0.7797453398303047 and parameters: {'num_leaves': 134}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  40%|####################                              | 8/20 [01:45<02:37, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.895745\tvalid_0's f1score: 0.516592\tvalid_1's auc: 0.779745\tvalid_1's f1score: 0.488265\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  45%|######################5                           | 9/20 [01:58<02:25, 13.24s/it][I 2024-02-08 23:23:16,360] Trial 15 finished with value: 0.7799420667170944 and parameters: {'num_leaves': 184}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  45%|######################5                           | 9/20 [01:58<02:25, 13.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.919955\tvalid_0's f1score: 0.593344\tvalid_1's auc: 0.779942\tvalid_1's f1score: 0.54628\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003498 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  50%|########################5                        | 10/20 [02:14<02:19, 13.90s/it][I 2024-02-08 23:23:31,768] Trial 16 finished with value: 0.7791715775092206 and parameters: {'num_leaves': 250}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  50%|########################5                        | 10/20 [02:14<02:19, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.95789\tvalid_0's f1score: 0.683537\tvalid_1's auc: 0.779172\tvalid_1's f1score: 0.606593\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783234:  55%|##########################9                      | 11/20 [02:26<02:01, 13.45s/it][I 2024-02-08 23:23:44,175] Trial 17 finished with value: 0.7808472742624941 and parameters: {'num_leaves': 95}. Best is trial 9 with value: 0.7830266622102603.\n",
      "num_leaves, val_score: 0.783234:  55%|##########################9                      | 11/20 [02:26<02:01, 13.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.911039\tvalid_0's f1score: 0.646501\tvalid_1's auc: 0.780847\tvalid_1's f1score: 0.601371\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  60%|#############################4                   | 12/20 [02:36<01:38, 12.36s/it][I 2024-02-08 23:23:54,065] Trial 18 finished with value: 0.7837810262634791 and parameters: {'num_leaves': 11}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  60%|#############################4                   | 12/20 [02:36<01:38, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.845314\tvalid_0's f1score: 0.64089\tvalid_1's auc: 0.783781\tvalid_1's f1score: 0.619841\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  65%|###############################8                 | 13/20 [02:52<01:33, 13.41s/it][I 2024-02-08 23:24:09,874] Trial 19 finished with value: 0.7824183041028258 and parameters: {'num_leaves': 3}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  65%|###############################8                 | 13/20 [02:52<01:33, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[275]\tvalid_0's auc: 0.828557\tvalid_0's f1score: 0.63779\tvalid_1's auc: 0.782418\tvalid_1's f1score: 0.614265\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003728 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  70%|##################################3              | 14/20 [03:01<01:13, 12.27s/it][I 2024-02-08 23:24:19,494] Trial 20 finished with value: 0.7829694912073929 and parameters: {'num_leaves': 40}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  70%|##################################3              | 14/20 [03:01<01:13, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.844152\tvalid_0's f1score: 0.471763\tvalid_1's auc: 0.782969\tvalid_1's f1score: 0.472508\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004759 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  75%|####################################7            | 15/20 [03:14<01:01, 12.34s/it][I 2024-02-08 23:24:32,023] Trial 21 finished with value: 0.7822812402882592 and parameters: {'num_leaves': 130}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  75%|####################################7            | 15/20 [03:14<01:01, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.894811\tvalid_0's f1score: 0.525596\tvalid_1's auc: 0.782281\tvalid_1's f1score: 0.500498\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002387 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  80%|#######################################2         | 16/20 [03:28<00:50, 12.72s/it][I 2024-02-08 23:24:45,608] Trial 22 finished with value: 0.781097507344275 and parameters: {'num_leaves': 163}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  80%|#######################################2         | 16/20 [03:28<00:50, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.938108\tvalid_0's f1score: 0.667156\tvalid_1's auc: 0.781098\tvalid_1's f1score: 0.601583\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010622 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  85%|#########################################6       | 17/20 [03:39<00:36, 12.21s/it][I 2024-02-08 23:24:56,636] Trial 23 finished with value: 0.7819882022504853 and parameters: {'num_leaves': 44}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  85%|#########################################6       | 17/20 [03:39<00:36, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.875931\tvalid_0's f1score: 0.623065\tvalid_1's auc: 0.781988\tvalid_1's f1score: 0.597241\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  90%|############################################1    | 18/20 [03:53<00:25, 12.90s/it][I 2024-02-08 23:25:11,153] Trial 24 finished with value: 0.7794413073689025 and parameters: {'num_leaves': 211}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  90%|############################################1    | 18/20 [03:53<00:25, 12.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.948054\tvalid_0's f1score: 0.671907\tvalid_1's auc: 0.779441\tvalid_1's f1score: 0.595629\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781:  95%|##############################################5  | 19/20 [04:06<00:12, 12.86s/it][I 2024-02-08 23:25:23,897] Trial 25 finished with value: 0.7817703660703291 and parameters: {'num_leaves': 107}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781:  95%|##############################################5  | 19/20 [04:06<00:12, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.915518\tvalid_0's f1score: 0.651121\tvalid_1's auc: 0.78177\tvalid_1's f1score: 0.59963\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.783781: 100%|#################################################| 20/20 [04:19<00:00, 12.81s/it][I 2024-02-08 23:25:36,624] Trial 26 finished with value: 0.7795726540831823 and parameters: {'num_leaves': 154}. Best is trial 18 with value: 0.7837810262634791.\n",
      "num_leaves, val_score: 0.783781: 100%|#################################################| 20/20 [04:19<00:00, 12.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.911778\tvalid_0's f1score: 0.590755\tvalid_1's auc: 0.779573\tvalid_1's f1score: 0.542777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.783781:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002238 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784265:  10%|#####3                                               | 1/10 [00:08<01:19,  8.81s/it][I 2024-02-08 23:25:45,439] Trial 27 finished with value: 0.7842652206800711 and parameters: {'bagging_fraction': 0.764619523670073, 'bagging_freq': 3}. Best is trial 27 with value: 0.7842652206800711.\n",
      "bagging, val_score: 0.784265:  10%|#####3                                               | 1/10 [00:08<01:19,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.827233\tvalid_0's f1score: 0.576238\tvalid_1's auc: 0.784265\tvalid_1's f1score: 0.563985\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003093 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784265:  20%|##########6                                          | 2/10 [00:17<01:12,  9.02s/it][I 2024-02-08 23:25:54,614] Trial 28 finished with value: 0.7839424244023432 and parameters: {'bagging_fraction': 0.772379296786217, 'bagging_freq': 3}. Best is trial 27 with value: 0.7842652206800711.\n",
      "bagging, val_score: 0.784265:  20%|##########6                                          | 2/10 [00:17<01:12,  9.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.82785\tvalid_0's f1score: 0.587475\tvalid_1's auc: 0.783942\tvalid_1's f1score: 0.580432\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784502:  30%|###############9                                     | 3/10 [00:27<01:05,  9.38s/it][I 2024-02-08 23:26:04,432] Trial 29 finished with value: 0.7845019672688679 and parameters: {'bagging_fraction': 0.7771126550029889, 'bagging_freq': 3}. Best is trial 29 with value: 0.7845019672688679.\n",
      "bagging, val_score: 0.784502:  30%|###############9                                     | 3/10 [00:27<01:05,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.836408\tvalid_0's f1score: 0.624547\tvalid_1's auc: 0.784502\tvalid_1's f1score: 0.605301\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784502:  40%|#####################2                               | 4/10 [00:36<00:55,  9.31s/it][I 2024-02-08 23:26:13,637] Trial 30 finished with value: 0.7842652206800711 and parameters: {'bagging_fraction': 0.7646242269554925, 'bagging_freq': 3}. Best is trial 29 with value: 0.7845019672688679.\n",
      "bagging, val_score: 0.784502:  40%|#####################2                               | 4/10 [00:37<00:55,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.827233\tvalid_0's f1score: 0.576238\tvalid_1's auc: 0.784265\tvalid_1's f1score: 0.563985\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784502:  50%|##########################5                          | 5/10 [00:46<00:46,  9.28s/it][I 2024-02-08 23:26:22,855] Trial 31 finished with value: 0.7840003283667857 and parameters: {'bagging_fraction': 0.7733177575963655, 'bagging_freq': 3}. Best is trial 29 with value: 0.7845019672688679.\n",
      "bagging, val_score: 0.784502:  50%|##########################5                          | 5/10 [00:46<00:46,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.826285\tvalid_0's f1score: 0.578508\tvalid_1's auc: 0.784\tvalid_1's f1score: 0.57702\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003408 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784502:  60%|###############################8                     | 6/10 [00:56<00:38,  9.51s/it][I 2024-02-08 23:26:32,832] Trial 32 finished with value: 0.7839371470790015 and parameters: {'bagging_fraction': 0.7619890748616631, 'bagging_freq': 3}. Best is trial 29 with value: 0.7845019672688679.\n",
      "bagging, val_score: 0.784502:  60%|###############################8                     | 6/10 [00:56<00:38,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.838965\tvalid_0's f1score: 0.633875\tvalid_1's auc: 0.783937\tvalid_1's f1score: 0.622057\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003660 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784502:  70%|#####################################                | 7/10 [01:05<00:28,  9.33s/it][I 2024-02-08 23:26:41,798] Trial 33 finished with value: 0.7840938542637841 and parameters: {'bagging_fraction': 0.7652891738439511, 'bagging_freq': 3}. Best is trial 29 with value: 0.7845019672688679.\n",
      "bagging, val_score: 0.784502:  70%|#####################################                | 7/10 [01:05<00:28,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.829177\tvalid_0's f1score: 0.591772\tvalid_1's auc: 0.784094\tvalid_1's f1score: 0.582553\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003035 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784502:  80%|##########################################4          | 8/10 [01:15<00:19,  9.62s/it][I 2024-02-08 23:26:52,027] Trial 34 finished with value: 0.7824040846482664 and parameters: {'bagging_fraction': 0.7639241286386256, 'bagging_freq': 3}. Best is trial 29 with value: 0.7845019672688679.\n",
      "bagging, val_score: 0.784502:  80%|##########################################4          | 8/10 [01:15<00:19,  9.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.838385\tvalid_0's f1score: 0.633881\tvalid_1's auc: 0.782404\tvalid_1's f1score: 0.618955\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002583 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784997:  90%|###############################################7     | 9/10 [01:24<00:09,  9.55s/it][I 2024-02-08 23:27:01,433] Trial 35 finished with value: 0.7849971561090882 and parameters: {'bagging_fraction': 0.9233177049160479, 'bagging_freq': 1}. Best is trial 35 with value: 0.7849971561090882.\n",
      "bagging, val_score: 0.784997:  90%|###############################################7     | 9/10 [01:24<00:09,  9.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831713\tvalid_0's f1score: 0.598528\tvalid_1's auc: 0.784997\tvalid_1's f1score: 0.581113\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005647 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784997: 100%|####################################################| 10/10 [01:35<00:00,  9.78s/it][I 2024-02-08 23:27:11,719] Trial 36 finished with value: 0.7842435250174444 and parameters: {'bagging_fraction': 0.9772288999234858, 'bagging_freq': 1}. Best is trial 35 with value: 0.7849971561090882.\n",
      "bagging, val_score: 0.784997: 100%|####################################################| 10/10 [01:35<00:00,  9.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.844645\tvalid_0's f1score: 0.640238\tvalid_1's auc: 0.784244\tvalid_1's f1score: 0.6227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784997:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784997:  33%|############6                         | 1/3 [00:09<00:18,  9.47s/it][I 2024-02-08 23:27:21,196] Trial 37 finished with value: 0.7824511407813957 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.7824511407813957.\n",
      "feature_fraction_stage2, val_score: 0.784997:  33%|############6                         | 1/3 [00:09<00:18,  9.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.832473\tvalid_0's f1score: 0.608498\tvalid_1's auc: 0.782451\tvalid_1's f1score: 0.594838\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003103 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784997:  67%|#########################3            | 2/3 [00:19<00:09,  9.81s/it][I 2024-02-08 23:27:31,234] Trial 38 finished with value: 0.7841117385262195 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.7841117385262195.\n",
      "feature_fraction_stage2, val_score: 0.784997:  67%|#########################3            | 2/3 [00:19<00:09,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.842871\tvalid_0's f1score: 0.638489\tvalid_1's auc: 0.784112\tvalid_1's f1score: 0.616721\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784997: 100%|######################################| 3/3 [00:28<00:00,  9.52s/it][I 2024-02-08 23:27:40,423] Trial 39 finished with value: 0.7849971561090882 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 39 with value: 0.7849971561090882.\n",
      "feature_fraction_stage2, val_score: 0.784997: 100%|######################################| 3/3 [00:28<00:00,  9.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831713\tvalid_0's f1score: 0.598528\tvalid_1's auc: 0.784997\tvalid_1's f1score: 0.581113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784997:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003863 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785283:   5%|#9                                    | 1/20 [00:10<03:14, 10.26s/it][I 2024-02-08 23:27:50,688] Trial 40 finished with value: 0.7852827179387948 and parameters: {'lambda_l1': 0.2720054608048245, 'lambda_l2': 1.2974600876896731e-05}. Best is trial 40 with value: 0.7852827179387948.\n",
      "regularization_factors, val_score: 0.785283:   5%|#9                                    | 1/20 [00:10<03:14, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842731\tvalid_0's f1score: 0.63666\tvalid_1's auc: 0.785283\tvalid_1's f1score: 0.61357\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002235 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  10%|###8                                  | 2/20 [00:19<02:57,  9.83s/it][I 2024-02-08 23:28:00,218] Trial 41 finished with value: 0.7858025342879424 and parameters: {'lambda_l1': 1.3793174187834716, 'lambda_l2': 8.848288884727243e-06}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  10%|###8                                  | 2/20 [00:19<02:57,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831861\tvalid_0's f1score: 0.597794\tvalid_1's auc: 0.785803\tvalid_1's f1score: 0.585496\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  15%|#####7                                | 3/20 [00:30<02:51, 10.11s/it][I 2024-02-08 23:28:10,663] Trial 42 finished with value: 0.7840995713640708 and parameters: {'lambda_l1': 1.9086326124420099, 'lambda_l2': 8.567191858176764e-06}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  15%|#####7                                | 3/20 [00:30<02:51, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842862\tvalid_0's f1score: 0.635063\tvalid_1's auc: 0.7841\tvalid_1's f1score: 0.615823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  20%|#######6                              | 4/20 [00:40<02:42, 10.16s/it][I 2024-02-08 23:28:20,905] Trial 43 finished with value: 0.7847870893216294 and parameters: {'lambda_l1': 0.8147585016817792, 'lambda_l2': 2.1640267269969383e-05}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  20%|#######6                              | 4/20 [00:40<02:42, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842638\tvalid_0's f1score: 0.636675\tvalid_1's auc: 0.784787\tvalid_1's f1score: 0.613349\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005111 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  25%|#########5                            | 5/20 [00:50<02:31, 10.13s/it][I 2024-02-08 23:28:30,972] Trial 44 finished with value: 0.7855480500290253 and parameters: {'lambda_l1': 0.7511867573172402, 'lambda_l2': 1.5626496463963092e-05}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  25%|#########5                            | 5/20 [00:50<02:31, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.843223\tvalid_0's f1score: 0.636485\tvalid_1's auc: 0.785548\tvalid_1's f1score: 0.609031\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  30%|###########4                          | 6/20 [01:00<02:21, 10.10s/it][I 2024-02-08 23:28:41,032] Trial 45 finished with value: 0.7849845491699943 and parameters: {'lambda_l1': 0.48800578351200047, 'lambda_l2': 1.0265180530677905e-05}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  30%|###########4                          | 6/20 [01:00<02:21, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842716\tvalid_0's f1score: 0.638963\tvalid_1's auc: 0.784985\tvalid_1's f1score: 0.616721\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006221 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  35%|#############3                        | 7/20 [01:10<02:11, 10.14s/it][I 2024-02-08 23:28:51,243] Trial 46 finished with value: 0.7853549879501117 and parameters: {'lambda_l1': 0.0016942292170375706, 'lambda_l2': 9.364088478282662e-07}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  35%|#############3                        | 7/20 [01:10<02:11, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842792\tvalid_0's f1score: 0.637212\tvalid_1's auc: 0.785355\tvalid_1's f1score: 0.615823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003965 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  40%|###############2                      | 8/20 [01:20<01:58,  9.90s/it][I 2024-02-08 23:29:00,640] Trial 47 finished with value: 0.7849971561090882 and parameters: {'lambda_l1': 5.708329677582101e-05, 'lambda_l2': 2.1627735367090928e-06}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  40%|###############2                      | 8/20 [01:20<01:58,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831713\tvalid_0's f1score: 0.598528\tvalid_1's auc: 0.784997\tvalid_1's f1score: 0.581113\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  45%|#################1                    | 9/20 [01:30<01:49,  9.99s/it][I 2024-02-08 23:29:10,823] Trial 48 finished with value: 0.7857191232606822 and parameters: {'lambda_l1': 0.02519812497372037, 'lambda_l2': 7.923832975697639e-08}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  45%|#################1                    | 9/20 [01:30<01:49,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842752\tvalid_0's f1score: 0.638545\tvalid_1's auc: 0.785719\tvalid_1's f1score: 0.617171\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002219 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  50%|##################5                  | 10/20 [01:40<01:40, 10.07s/it][I 2024-02-08 23:29:21,072] Trial 49 finished with value: 0.7857170709682716 and parameters: {'lambda_l1': 0.019985942758741715, 'lambda_l2': 2.5783312820898057e-08}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  50%|##################5                  | 10/20 [01:40<01:40, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842754\tvalid_0's f1score: 0.638545\tvalid_1's auc: 0.785717\tvalid_1's f1score: 0.617171\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002147 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  55%|####################3                | 11/20 [01:50<01:29, 10.00s/it][I 2024-02-08 23:29:30,909] Trial 50 finished with value: 0.7853544015808516 and parameters: {'lambda_l1': 0.0037554532045815546, 'lambda_l2': 1.26444288827355e-08}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  55%|####################3                | 11/20 [01:50<01:29, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842791\tvalid_0's f1score: 0.637212\tvalid_1's auc: 0.785354\tvalid_1's f1score: 0.615823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  60%|######################2              | 12/20 [02:00<01:19,  9.99s/it][I 2024-02-08 23:29:40,889] Trial 51 finished with value: 0.7853549879501117 and parameters: {'lambda_l1': 0.0030478236927872797, 'lambda_l2': 1.1445965487641033e-08}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  60%|######################2              | 12/20 [02:00<01:19,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842791\tvalid_0's f1score: 0.637212\tvalid_1's auc: 0.785355\tvalid_1's f1score: 0.615823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002334 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  65%|########################             | 13/20 [02:10<01:09, 10.00s/it][I 2024-02-08 23:29:50,891] Trial 52 finished with value: 0.7853549879501117 and parameters: {'lambda_l1': 0.0031763367835810057, 'lambda_l2': 1.309889687862821e-08}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  65%|########################             | 13/20 [02:10<01:09, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842791\tvalid_0's f1score: 0.637212\tvalid_1's auc: 0.785355\tvalid_1's f1score: 0.615823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002417 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  70%|#########################9           | 14/20 [02:20<01:00, 10.02s/it][I 2024-02-08 23:30:00,947] Trial 53 finished with value: 0.7853552811347418 and parameters: {'lambda_l1': 0.0068474731379239585, 'lambda_l2': 8.613705670228984e-08}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  70%|#########################9           | 14/20 [02:20<01:00, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.84279\tvalid_0's f1score: 0.637212\tvalid_1's auc: 0.785355\tvalid_1's f1score: 0.615823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  75%|###########################7         | 15/20 [02:30<00:50, 10.06s/it][I 2024-02-08 23:30:11,112] Trial 54 finished with value: 0.7850807137286635 and parameters: {'lambda_l1': 0.017546908057424978, 'lambda_l2': 3.3612853959033826e-07}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  75%|###########################7         | 15/20 [02:30<00:50, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842536\tvalid_0's f1score: 0.638208\tvalid_1's auc: 0.785081\tvalid_1's f1score: 0.614921\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  80%|#############################6       | 16/20 [02:40<00:39,  9.88s/it][I 2024-02-08 23:30:20,579] Trial 55 finished with value: 0.7849971561090882 and parameters: {'lambda_l1': 3.7008427907422814e-07, 'lambda_l2': 2.7292210806029155e-07}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  80%|#############################6       | 16/20 [02:40<00:39,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831713\tvalid_0's f1score: 0.598528\tvalid_1's auc: 0.784997\tvalid_1's f1score: 0.581113\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  85%|###############################4     | 17/20 [02:50<00:29,  9.94s/it][I 2024-02-08 23:30:30,687] Trial 56 finished with value: 0.7851176549920547 and parameters: {'lambda_l1': 0.03686097591722446, 'lambda_l2': 0.001010408469895973}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  85%|###############################4     | 17/20 [02:50<00:29,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842482\tvalid_0's f1score: 0.638249\tvalid_1's auc: 0.785118\tvalid_1's f1score: 0.613349\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  90%|#################################3   | 18/20 [03:00<00:20, 10.00s/it][I 2024-02-08 23:30:40,804] Trial 57 finished with value: 0.7850679601972547 and parameters: {'lambda_l1': 0.00022734129101855137, 'lambda_l2': 2.2204782258654405}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  90%|#################################3   | 18/20 [03:00<00:20, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842146\tvalid_0's f1score: 0.634631\tvalid_1's auc: 0.785068\tvalid_1's f1score: 0.615376\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803:  95%|###################################1 | 19/20 [03:10<00:09, 10.00s/it][I 2024-02-08 23:30:50,799] Trial 58 finished with value: 0.7851182413613149 and parameters: {'lambda_l1': 0.032377560713287096, 'lambda_l2': 2.9610694516548557e-07}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803:  95%|###################################1 | 19/20 [03:10<00:09, 10.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842483\tvalid_0's f1score: 0.638249\tvalid_1's auc: 0.785118\tvalid_1's f1score: 0.613349\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003388 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.785803: 100%|#####################################| 20/20 [03:20<00:00, 10.08s/it][I 2024-02-08 23:31:01,061] Trial 59 finished with value: 0.7844675180748324 and parameters: {'lambda_l1': 9.390847891573216, 'lambda_l2': 2.0888319801303503e-07}. Best is trial 41 with value: 0.7858025342879424.\n",
      "regularization_factors, val_score: 0.785803: 100%|#####################################| 20/20 [03:20<00:00, 10.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.842716\tvalid_0's f1score: 0.634495\tvalid_1's auc: 0.784468\tvalid_1's f1score: 0.613349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.785803:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002286 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.785803:  20%|########8                                   | 1/5 [00:09<00:37,  9.28s/it][I 2024-02-08 23:31:10,353] Trial 60 finished with value: 0.7837820524096845 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.7837820524096845.\n",
      "min_child_samples, val_score: 0.785803:  20%|########8                                   | 1/5 [00:09<00:37,  9.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831843\tvalid_0's f1score: 0.594488\tvalid_1's auc: 0.783782\tvalid_1's f1score: 0.589377\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004636 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.785803:  40%|#################6                          | 2/5 [00:19<00:29,  9.75s/it][I 2024-02-08 23:31:20,427] Trial 61 finished with value: 0.7837536135005658 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.7837820524096845.\n",
      "min_child_samples, val_score: 0.785803:  40%|#################6                          | 2/5 [00:19<00:29,  9.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842249\tvalid_0's f1score: 0.63508\tvalid_1's auc: 0.783754\tvalid_1's f1score: 0.614698\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002995 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.785803:  60%|##########################4                 | 3/5 [00:28<00:19,  9.54s/it][I 2024-02-08 23:31:29,723] Trial 62 finished with value: 0.7858025342879424 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.7858025342879424.\n",
      "min_child_samples, val_score: 0.785803:  60%|##########################4                 | 3/5 [00:28<00:19,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831861\tvalid_0's f1score: 0.597794\tvalid_1's auc: 0.785803\tvalid_1's f1score: 0.585496\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008898 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.785803:  80%|###################################2        | 4/5 [00:38<00:09,  9.72s/it][I 2024-02-08 23:31:39,720] Trial 63 finished with value: 0.7851446279780229 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.7858025342879424.\n",
      "min_child_samples, val_score: 0.785803:  80%|###################################2        | 4/5 [00:38<00:09,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.842931\tvalid_0's f1score: 0.636445\tvalid_1's auc: 0.785145\tvalid_1's f1score: 0.613127\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002144 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.785803: 100%|############################################| 5/5 [00:48<00:00,  9.63s/it][I 2024-02-08 23:31:49,204] Trial 64 finished with value: 0.7858025342879424 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.7858025342879424.\n",
      "min_child_samples, val_score: 0.785803: 100%|############################################| 5/5 [00:48<00:00,  9.63s/it]\n",
      "[I 2024-02-08 23:31:49,366] A new study created in memory with name: no-name-c1474ea3-9e6f-4068-b72a-e93f99e72e45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.831861\tvalid_0's f1score: 0.597794\tvalid_1's auc: 0.785803\tvalid_1's f1score: 0.585496\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002920 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.781236:  14%|######4                                      | 1/7 [00:11<01:11, 11.88s/it][I 2024-02-08 23:32:01,256] Trial 0 finished with value: 0.7812355431162102 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.7812355431162102.\n",
      "feature_fraction, val_score: 0.781236:  14%|######4                                      | 1/7 [00:11<01:11, 11.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.88882\tvalid_0's f1score: 0.672519\tvalid_1's auc: 0.781236\tvalid_1's f1score: 0.605962\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008256 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786376:  29%|############8                                | 2/7 [00:22<00:55, 11.12s/it][I 2024-02-08 23:32:11,843] Trial 1 finished with value: 0.7863759772853441 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.7863759772853441.\n",
      "feature_fraction, val_score: 0.786376:  29%|############8                                | 2/7 [00:22<00:55, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.869703\tvalid_0's f1score: 0.636749\tvalid_1's auc: 0.786376\tvalid_1's f1score: 0.59498\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786376:  43%|###################2                         | 3/7 [00:33<00:44, 11.23s/it][I 2024-02-08 23:32:23,216] Trial 2 finished with value: 0.7775188228626942 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7863759772853441.\n",
      "feature_fraction, val_score: 0.786376:  43%|###################2                         | 3/7 [00:33<00:44, 11.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.876172\tvalid_0's f1score: 0.65072\tvalid_1's auc: 0.777519\tvalid_1's f1score: 0.595144\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011112 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786376:  57%|#########################7                   | 4/7 [00:46<00:35, 11.85s/it][I 2024-02-08 23:32:36,019] Trial 3 finished with value: 0.7734450175795707 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.7863759772853441.\n",
      "feature_fraction, val_score: 0.786376:  57%|#########################7                   | 4/7 [00:46<00:35, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.890339\tvalid_0's f1score: 0.674241\tvalid_1's auc: 0.773445\tvalid_1's f1score: 0.602232\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786376:  71%|################################1            | 5/7 [00:58<00:23, 11.77s/it][I 2024-02-08 23:32:47,652] Trial 4 finished with value: 0.7725900374722428 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.7863759772853441.\n",
      "feature_fraction, val_score: 0.786376:  71%|################################1            | 5/7 [00:58<00:23, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.881756\tvalid_0's f1score: 0.658273\tvalid_1's auc: 0.77259\tvalid_1's f1score: 0.603083\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786376:  86%|######################################5      | 6/7 [01:09<00:11, 11.60s/it][I 2024-02-08 23:32:58,915] Trial 5 finished with value: 0.7777423262860844 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.7863759772853441.\n",
      "feature_fraction, val_score: 0.786376:  86%|######################################5      | 6/7 [01:09<00:11, 11.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.891431\tvalid_0's f1score: 0.674133\tvalid_1's auc: 0.777742\tvalid_1's f1score: 0.607093\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012125 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786376: 100%|#############################################| 7/7 [01:21<00:00, 11.59s/it][I 2024-02-08 23:33:10,484] Trial 6 finished with value: 0.7763242505551443 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7863759772853441.\n",
      "feature_fraction, val_score: 0.786376: 100%|#############################################| 7/7 [01:21<00:00, 11.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's auc: 0.883201\tvalid_0's f1score: 0.664508\tvalid_1's auc: 0.776324\tvalid_1's f1score: 0.610868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002424 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:   5%|##5                                               | 1/20 [00:09<03:08,  9.93s/it][I 2024-02-08 23:33:20,423] Trial 7 finished with value: 0.7827156388786084 and parameters: {'num_leaves': 4}. Best is trial 7 with value: 0.7827156388786084.\n",
      "num_leaves, val_score: 0.786376:   5%|##5                                               | 1/20 [00:09<03:08,  9.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.811617\tvalid_0's f1score: 0.614336\tvalid_1's auc: 0.782716\tvalid_1's f1score: 0.575653\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010916 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  10%|#####                                             | 2/20 [00:22<03:25, 11.42s/it][I 2024-02-08 23:33:32,897] Trial 8 finished with value: 0.7825488064396743 and parameters: {'num_leaves': 85}. Best is trial 7 with value: 0.7827156388786084.\n",
      "num_leaves, val_score: 0.786376:  10%|#####                                             | 2/20 [00:22<03:25, 11.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.913593\tvalid_0's f1score: 0.661676\tvalid_1's auc: 0.782549\tvalid_1's f1score: 0.602663\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002960 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  15%|#######5                                          | 3/20 [00:33<03:11, 11.29s/it][I 2024-02-08 23:33:44,021] Trial 9 finished with value: 0.7841934215396003 and parameters: {'num_leaves': 48}. Best is trial 9 with value: 0.7841934215396003.\n",
      "num_leaves, val_score: 0.786376:  15%|#######5                                          | 3/20 [00:33<03:11, 11.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.886311\tvalid_0's f1score: 0.647369\tvalid_1's auc: 0.784193\tvalid_1's f1score: 0.603406\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005403 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  20%|##########                                        | 4/20 [00:49<03:27, 12.96s/it][I 2024-02-08 23:33:59,547] Trial 10 finished with value: 0.7825274102516654 and parameters: {'num_leaves': 252}. Best is trial 9 with value: 0.7841934215396003.\n",
      "num_leaves, val_score: 0.786376:  20%|##########                                        | 4/20 [00:49<03:27, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.950237\tvalid_0's f1score: 0.66198\tvalid_1's auc: 0.782527\tvalid_1's f1score: 0.566309\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006661 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  25%|############5                                     | 5/20 [01:00<03:03, 12.24s/it][I 2024-02-08 23:34:10,511] Trial 11 finished with value: 0.7846473676905995 and parameters: {'num_leaves': 60}. Best is trial 11 with value: 0.7846473676905995.\n",
      "num_leaves, val_score: 0.786376:  25%|############5                                     | 5/20 [01:00<03:03, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.87223\tvalid_0's f1score: 0.574675\tvalid_1's auc: 0.784647\tvalid_1's f1score: 0.533484\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003422 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  30%|###############                                   | 6/20 [01:14<03:01, 13.00s/it][I 2024-02-08 23:34:24,972] Trial 12 finished with value: 0.7844958595484826 and parameters: {'num_leaves': 159}. Best is trial 11 with value: 0.7846473676905995.\n",
      "num_leaves, val_score: 0.786376:  30%|###############                                   | 6/20 [01:14<03:01, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.949395\tvalid_0's f1score: 0.701315\tvalid_1's auc: 0.784496\tvalid_1's f1score: 0.600026\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002318 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  35%|#################5                                | 7/20 [01:27<02:50, 13.09s/it][I 2024-02-08 23:34:38,262] Trial 13 finished with value: 0.7830086799130274 and parameters: {'num_leaves': 161}. Best is trial 11 with value: 0.7846473676905995.\n",
      "num_leaves, val_score: 0.786376:  35%|#################5                                | 7/20 [01:27<02:50, 13.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.916369\tvalid_0's f1score: 0.604612\tvalid_1's auc: 0.783009\tvalid_1's f1score: 0.535851\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011141 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  40%|####################                              | 8/20 [01:41<02:38, 13.22s/it][I 2024-02-08 23:34:51,762] Trial 14 finished with value: 0.7838904052553664 and parameters: {'num_leaves': 101}. Best is trial 11 with value: 0.7846473676905995.\n",
      "num_leaves, val_score: 0.786376:  40%|####################                              | 8/20 [01:41<02:38, 13.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.921802\tvalid_0's f1score: 0.669312\tvalid_1's auc: 0.78389\tvalid_1's f1score: 0.59693\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008932 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  45%|######################5                           | 9/20 [01:51<02:14, 12.26s/it][I 2024-02-08 23:35:01,909] Trial 15 finished with value: 0.785593570734641 and parameters: {'num_leaves': 23}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  45%|######################5                           | 9/20 [01:51<02:14, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.857513\tvalid_0's f1score: 0.631141\tvalid_1's auc: 0.785594\tvalid_1's f1score: 0.592606\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  50%|########################5                        | 10/20 [02:00<01:53, 11.35s/it][I 2024-02-08 23:35:11,242] Trial 16 finished with value: 0.7845719027572169 and parameters: {'num_leaves': 6}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  50%|########################5                        | 10/20 [02:00<01:53, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.819881\tvalid_0's f1score: 0.619929\tvalid_1's auc: 0.784572\tvalid_1's f1score: 0.591017\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006115 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  55%|##########################9                      | 11/20 [02:16<01:54, 12.67s/it][I 2024-02-08 23:35:26,888] Trial 17 finished with value: 0.7829446359178386 and parameters: {'num_leaves': 227}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  55%|##########################9                      | 11/20 [02:16<01:54, 12.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.959585\tvalid_0's f1score: 0.703833\tvalid_1's auc: 0.782945\tvalid_1's f1score: 0.589628\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  60%|#############################4                   | 12/20 [02:30<01:43, 12.97s/it][I 2024-02-08 23:35:40,531] Trial 18 finished with value: 0.7850651716321243 and parameters: {'num_leaves': 143}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  60%|#############################4                   | 12/20 [02:30<01:43, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.934803\tvalid_0's f1score: 0.676031\tvalid_1's auc: 0.785065\tvalid_1's f1score: 0.594776\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  65%|###############################8                 | 13/20 [02:44<01:34, 13.51s/it][I 2024-02-08 23:35:55,290] Trial 19 finished with value: 0.7829862717431533 and parameters: {'num_leaves': 195}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  65%|###############################8                 | 13/20 [02:44<01:34, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.957245\tvalid_0's f1score: 0.706506\tvalid_1's auc: 0.782986\tvalid_1's f1score: 0.60098\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004969 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  70%|##################################3              | 14/20 [02:56<01:18, 13.00s/it][I 2024-02-08 23:36:07,110] Trial 20 finished with value: 0.7830874699296817 and parameters: {'num_leaves': 43}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  70%|##################################3              | 14/20 [02:56<01:18, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.90341\tvalid_0's f1score: 0.676623\tvalid_1's auc: 0.783087\tvalid_1's f1score: 0.611373\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002407 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  75%|####################################7            | 15/20 [03:09<01:04, 12.94s/it][I 2024-02-08 23:36:19,924] Trial 21 finished with value: 0.7823160506106588 and parameters: {'num_leaves': 128}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  75%|####################################7            | 15/20 [03:09<01:04, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.904297\tvalid_0's f1score: 0.598941\tvalid_1's auc: 0.782316\tvalid_1's f1score: 0.529921\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  80%|#######################################2         | 16/20 [03:22<00:51, 12.97s/it][I 2024-02-08 23:36:32,949] Trial 22 finished with value: 0.7844096965210955 and parameters: {'num_leaves': 132}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  80%|#######################################2         | 16/20 [03:22<00:51, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.934511\tvalid_0's f1score: 0.679244\tvalid_1's auc: 0.78441\tvalid_1's f1score: 0.604143\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002607 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  85%|#########################################6       | 17/20 [03:36<00:40, 13.39s/it][I 2024-02-08 23:36:47,330] Trial 23 finished with value: 0.7834300980754997 and parameters: {'num_leaves': 189}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  85%|#########################################6       | 17/20 [03:36<00:40, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.953614\tvalid_0's f1score: 0.69908\tvalid_1's auc: 0.78343\tvalid_1's f1score: 0.601282\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004532 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  90%|############################################1    | 18/20 [03:49<00:26, 13.08s/it][I 2024-02-08 23:36:59,693] Trial 24 finished with value: 0.7828425703182827 and parameters: {'num_leaves': 110}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  90%|############################################1    | 18/20 [03:49<00:26, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.89641\tvalid_0's f1score: 0.589296\tvalid_1's auc: 0.782843\tvalid_1's f1score: 0.535851\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376:  95%|##############################################5  | 19/20 [04:01<00:12, 12.75s/it][I 2024-02-08 23:37:11,661] Trial 25 finished with value: 0.7835733657938564 and parameters: {'num_leaves': 80}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376:  95%|##############################################5  | 19/20 [04:01<00:12, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.894508\tvalid_0's f1score: 0.621696\tvalid_1's auc: 0.783573\tvalid_1's f1score: 0.563746\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002644 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786376: 100%|#################################################| 20/20 [04:15<00:00, 13.18s/it][I 2024-02-08 23:37:25,864] Trial 26 finished with value: 0.783823036176906 and parameters: {'num_leaves': 154}. Best is trial 15 with value: 0.785593570734641.\n",
      "num_leaves, val_score: 0.786376: 100%|#################################################| 20/20 [04:15<00:00, 12.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.94288\tvalid_0's f1score: 0.687042\tvalid_1's auc: 0.783823\tvalid_1's f1score: 0.603406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786376:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787484:  10%|#####3                                               | 1/10 [00:09<01:28,  9.86s/it][I 2024-02-08 23:37:35,733] Trial 27 finished with value: 0.787484386565507 and parameters: {'bagging_fraction': 0.6490174443607272, 'bagging_freq': 7}. Best is trial 27 with value: 0.787484386565507.\n",
      "bagging, val_score: 0.787484:  10%|#####3                                               | 1/10 [00:09<01:28,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.846411\tvalid_0's f1score: 0.609221\tvalid_1's auc: 0.787484\tvalid_1's f1score: 0.573373\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003024 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787802:  20%|##########6                                          | 2/10 [00:19<01:17,  9.65s/it][I 2024-02-08 23:37:45,245] Trial 28 finished with value: 0.7878022934400444 and parameters: {'bagging_fraction': 0.6618848184644689, 'bagging_freq': 7}. Best is trial 28 with value: 0.7878022934400444.\n",
      "bagging, val_score: 0.787802:  20%|##########6                                          | 2/10 [00:19<01:17,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.833966\tvalid_0's f1score: 0.550017\tvalid_1's auc: 0.787802\tvalid_1's f1score: 0.519029\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002963 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787802:  30%|###############9                                     | 3/10 [00:28<01:06,  9.49s/it][I 2024-02-08 23:37:54,546] Trial 29 finished with value: 0.7843742771558105 and parameters: {'bagging_fraction': 0.6228682920119855, 'bagging_freq': 7}. Best is trial 28 with value: 0.7878022934400444.\n",
      "bagging, val_score: 0.787802:  30%|###############9                                     | 3/10 [00:28<01:06,  9.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.830832\tvalid_0's f1score: 0.548711\tvalid_1's auc: 0.784374\tvalid_1's f1score: 0.521755\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787802:  40%|#####################2                               | 4/10 [00:38<00:56,  9.48s/it][I 2024-02-08 23:38:04,005] Trial 30 finished with value: 0.787171684169134 and parameters: {'bagging_fraction': 0.6725425401214272, 'bagging_freq': 7}. Best is trial 28 with value: 0.7878022934400444.\n",
      "bagging, val_score: 0.787802:  40%|#####################2                               | 4/10 [00:38<00:56,  9.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.833901\tvalid_0's f1score: 0.542\tvalid_1's auc: 0.787172\tvalid_1's f1score: 0.516501\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005091 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787802:  50%|##########################5                          | 5/10 [00:47<00:46,  9.39s/it][I 2024-02-08 23:38:13,257] Trial 31 finished with value: 0.7863385339563287 and parameters: {'bagging_fraction': 0.6745873105010554, 'bagging_freq': 7}. Best is trial 28 with value: 0.7878022934400444.\n",
      "bagging, val_score: 0.787802:  50%|##########################5                          | 5/10 [00:47<00:46,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.835187\tvalid_0's f1score: 0.545143\tvalid_1's auc: 0.786339\tvalid_1's f1score: 0.516501\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002349 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787802:  60%|###############################8                     | 6/10 [00:56<00:37,  9.35s/it][I 2024-02-08 23:38:22,511] Trial 32 finished with value: 0.7863425818837898 and parameters: {'bagging_fraction': 0.6746193988505692, 'bagging_freq': 7}. Best is trial 28 with value: 0.7878022934400444.\n",
      "bagging, val_score: 0.787802:  60%|###############################8                     | 6/10 [00:56<00:37,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.835185\tvalid_0's f1score: 0.545143\tvalid_1's auc: 0.786343\tvalid_1's f1score: 0.516501\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013790 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787925:  70%|#####################################                | 7/10 [01:06<00:28,  9.58s/it][I 2024-02-08 23:38:32,564] Trial 33 finished with value: 0.7879251769522576 and parameters: {'bagging_fraction': 0.7588541758612531, 'bagging_freq': 4}. Best is trial 33 with value: 0.7879251769522576.\n",
      "bagging, val_score: 0.787925:  70%|#####################################                | 7/10 [01:06<00:28,  9.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853179\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787925\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787925:  80%|##########################################4          | 8/10 [01:17<00:19,  9.87s/it][I 2024-02-08 23:38:43,039] Trial 34 finished with value: 0.7855432607790526 and parameters: {'bagging_fraction': 0.7511466054331826, 'bagging_freq': 3}. Best is trial 33 with value: 0.7879251769522576.\n",
      "bagging, val_score: 0.787925:  80%|##########################################4          | 8/10 [01:17<00:19,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.85722\tvalid_0's f1score: 0.628525\tvalid_1's auc: 0.785543\tvalid_1's f1score: 0.586969\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015450 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787925:  90%|###############################################7     | 9/10 [01:27<00:10, 10.02s/it][I 2024-02-08 23:38:53,409] Trial 35 finished with value: 0.7853702118800888 and parameters: {'bagging_fraction': 0.8635293001971487, 'bagging_freq': 4}. Best is trial 33 with value: 0.7879251769522576.\n",
      "bagging, val_score: 0.787925:  90%|###############################################7     | 9/10 [01:27<00:10, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.860395\tvalid_0's f1score: 0.623931\tvalid_1's auc: 0.78537\tvalid_1's f1score: 0.583948\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004834 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787925: 100%|####################################################| 10/10 [01:36<00:00,  9.81s/it][I 2024-02-08 23:39:02,757] Trial 36 finished with value: 0.7854777710954848 and parameters: {'bagging_fraction': 0.44998300024387317, 'bagging_freq': 6}. Best is trial 33 with value: 0.7879251769522576.\n",
      "bagging, val_score: 0.787925: 100%|####################################################| 10/10 [01:36<00:00,  9.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.832245\tvalid_0's f1score: 0.600814\tvalid_1's auc: 0.785478\tvalid_1's f1score: 0.571572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787925:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008466 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787925:  33%|############6                         | 1/3 [00:10<00:20, 10.02s/it][I 2024-02-08 23:39:12,781] Trial 37 finished with value: 0.7879251769522576 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.7879251769522576.\n",
      "feature_fraction_stage2, val_score: 0.787925:  33%|############6                         | 1/3 [00:10<00:20, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853179\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787925\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006443 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787925:  67%|#########################3            | 2/3 [00:19<00:09,  9.65s/it][I 2024-02-08 23:39:22,190] Trial 38 finished with value: 0.786005447353812 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.7879251769522576.\n",
      "feature_fraction_stage2, val_score: 0.787925:  67%|#########################3            | 2/3 [00:19<00:09,  9.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.836751\tvalid_0's f1score: 0.552046\tvalid_1's auc: 0.786005\tvalid_1's f1score: 0.521638\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787925: 100%|######################################| 3/3 [00:28<00:00,  9.33s/it][I 2024-02-08 23:39:31,129] Trial 39 finished with value: 0.7872175124907476 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.7879251769522576.\n",
      "feature_fraction_stage2, val_score: 0.787925: 100%|######################################| 3/3 [00:28<00:00,  9.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.825142\tvalid_0's f1score: 0.471585\tvalid_1's auc: 0.787218\tvalid_1's f1score: 0.472048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787925:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787925:   5%|#9                                    | 1/20 [00:10<03:21, 10.60s/it][I 2024-02-08 23:39:41,748] Trial 40 finished with value: 0.7852617852516655 and parameters: {'lambda_l1': 4.2834307284516315, 'lambda_l2': 2.871397635155217e-07}. Best is trial 40 with value: 0.7852617852516655.\n",
      "regularization_factors, val_score: 0.787925:   5%|#9                                    | 1/20 [00:10<03:21, 10.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.849828\tvalid_0's f1score: 0.611726\tvalid_1's auc: 0.785262\tvalid_1's f1score: 0.576935\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003950 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  10%|###8                                  | 2/20 [00:20<03:07, 10.42s/it][I 2024-02-08 23:39:52,037] Trial 41 finished with value: 0.789124809169134 and parameters: {'lambda_l1': 1.2417704495808592e-07, 'lambda_l2': 5.881040234212917}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  10%|###8                                  | 2/20 [00:20<03:07, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.849348\tvalid_0's f1score: 0.590284\tvalid_1's auc: 0.789125\tvalid_1's f1score: 0.556298\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  15%|#####7                                | 3/20 [00:31<02:57, 10.43s/it][I 2024-02-08 23:40:02,477] Trial 42 finished with value: 0.7874147043856403 and parameters: {'lambda_l1': 2.6866930076034345e-08, 'lambda_l2': 3.2826536350022604}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  15%|#####7                                | 3/20 [00:31<02:57, 10.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.850051\tvalid_0's f1score: 0.598609\tvalid_1's auc: 0.787415\tvalid_1's f1score: 0.567411\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002320 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  20%|#######6                              | 4/20 [00:41<02:47, 10.48s/it][I 2024-02-08 23:40:13,044] Trial 43 finished with value: 0.7884368060695781 and parameters: {'lambda_l1': 2.9697428892413196e-08, 'lambda_l2': 6.247817083991302}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  20%|#######6                              | 4/20 [00:41<02:47, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.849183\tvalid_0's f1score: 0.587873\tvalid_1's auc: 0.788437\tvalid_1's f1score: 0.558093\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  25%|#########5                            | 5/20 [00:52<02:36, 10.42s/it][I 2024-02-08 23:40:23,375] Trial 44 finished with value: 0.7864168902664693 and parameters: {'lambda_l1': 1.218998870472467e-08, 'lambda_l2': 7.237510022700462}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  25%|#########5                            | 5/20 [00:52<02:36, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.848591\tvalid_0's f1score: 0.586034\tvalid_1's auc: 0.786417\tvalid_1's f1score: 0.555147\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014460 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  30%|###########4                          | 6/20 [01:01<02:20, 10.01s/it][I 2024-02-08 23:40:32,564] Trial 45 finished with value: 0.7861049107142857 and parameters: {'lambda_l1': 1.061134050252791e-05, 'lambda_l2': 0.02359479181759801}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  30%|###########4                          | 6/20 [01:01<02:20, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.827723\tvalid_0's f1score: 0.471585\tvalid_1's auc: 0.786105\tvalid_1's f1score: 0.472048\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  35%|#############3                        | 7/20 [01:11<02:12, 10.16s/it][I 2024-02-08 23:40:43,043] Trial 46 finished with value: 0.7875620200314581 and parameters: {'lambda_l1': 6.661851194341794e-06, 'lambda_l2': 0.0027812269960412633}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  35%|#############3                        | 7/20 [01:11<02:12, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853495\tvalid_0's f1score: 0.61126\tvalid_1's auc: 0.787562\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002234 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  40%|###############2                      | 8/20 [01:21<01:58,  9.91s/it][I 2024-02-08 23:40:52,405] Trial 47 finished with value: 0.7873863688934123 and parameters: {'lambda_l1': 7.303510611855879e-07, 'lambda_l2': 0.266921975273613}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  40%|###############2                      | 8/20 [01:21<01:58,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.827171\tvalid_0's f1score: 0.471585\tvalid_1's auc: 0.787386\tvalid_1's f1score: 0.472048\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  45%|#################1                    | 9/20 [01:31<01:50, 10.02s/it][I 2024-02-08 23:41:02,691] Trial 48 finished with value: 0.7872276323094004 and parameters: {'lambda_l1': 0.01152232332582676, 'lambda_l2': 3.294385292858878e-06}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  45%|#################1                    | 9/20 [01:31<01:50, 10.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.852932\tvalid_0's f1score: 0.612752\tvalid_1's auc: 0.787228\tvalid_1's f1score: 0.578735\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002198 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  50%|##################5                  | 10/20 [01:41<01:40, 10.10s/it][I 2024-02-08 23:41:12,952] Trial 49 finished with value: 0.7879254660899334 and parameters: {'lambda_l1': 0.0007769100953984001, 'lambda_l2': 6.56061192506112e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  50%|##################5                  | 10/20 [01:41<01:40, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853177\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787925\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005268 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  55%|####################3                | 11/20 [01:52<01:31, 10.20s/it][I 2024-02-08 23:41:23,381] Trial 50 finished with value: 0.7878419053016285 and parameters: {'lambda_l1': 0.0014907088906265862, 'lambda_l2': 0.0004911187723003049}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  55%|####################3                | 11/20 [01:52<01:31, 10.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853203\tvalid_0's f1score: 0.611494\tvalid_1's auc: 0.787842\tvalid_1's f1score: 0.57661\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003811 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  60%|######################2              | 12/20 [02:02<01:22, 10.25s/it][I 2024-02-08 23:41:33,748] Trial 51 finished with value: 0.7883098746299038 and parameters: {'lambda_l1': 0.00287400156321822, 'lambda_l2': 5.009078698080156e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  60%|######################2              | 12/20 [02:02<01:22, 10.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853517\tvalid_0's f1score: 0.611838\tvalid_1's auc: 0.78831\tvalid_1's f1score: 0.571394\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  65%|########################             | 13/20 [02:12<01:11, 10.26s/it][I 2024-02-08 23:41:44,033] Trial 52 finished with value: 0.7867683371113989 and parameters: {'lambda_l1': 0.018479819008209865, 'lambda_l2': 1.706529686444544e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  65%|########################             | 13/20 [02:12<01:11, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.855308\tvalid_0's f1score: 0.619972\tvalid_1's auc: 0.786768\tvalid_1's f1score: 0.580648\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002197 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  70%|#########################9           | 14/20 [02:23<01:01, 10.30s/it][I 2024-02-08 23:41:54,410] Trial 53 finished with value: 0.787926044365285 and parameters: {'lambda_l1': 0.00017012871484664715, 'lambda_l2': 6.162430557865135e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  70%|#########################9           | 14/20 [02:23<01:01, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853178\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787926\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  75%|###########################7         | 15/20 [02:33<00:51, 10.23s/it][I 2024-02-08 23:42:04,494] Trial 54 finished with value: 0.7879257552276092 and parameters: {'lambda_l1': 0.00029765508711722237, 'lambda_l2': 3.127602838073758e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  75%|###########################7         | 15/20 [02:33<00:51, 10.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853178\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787926\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  80%|#############################6       | 16/20 [02:43<00:40, 10.17s/it][I 2024-02-08 23:42:14,513] Trial 55 finished with value: 0.787926044365285 and parameters: {'lambda_l1': 0.00023532147031468933, 'lambda_l2': 4.928119969919625e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  80%|#############################6       | 16/20 [02:43<00:40, 10.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853178\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787926\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  85%|###############################4     | 17/20 [02:53<00:30, 10.07s/it][I 2024-02-08 23:42:24,347] Trial 56 finished with value: 0.787926044365285 and parameters: {'lambda_l1': 0.00010962485932104835, 'lambda_l2': 3.5858471135969215e-05}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  85%|###############################4     | 17/20 [02:53<00:30, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853178\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787926\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002741 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  90%|#################################3   | 18/20 [03:03<00:20, 10.03s/it][I 2024-02-08 23:42:34,287] Trial 57 finished with value: 0.7879254660899334 and parameters: {'lambda_l1': 7.108364178802569e-05, 'lambda_l2': 0.00026630876414170395}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  90%|#################################3   | 18/20 [03:03<00:20, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853178\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787925\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125:  95%|###################################1 | 19/20 [03:13<00:09,  9.99s/it][I 2024-02-08 23:42:44,182] Trial 58 finished with value: 0.7879251769522576 and parameters: {'lambda_l1': 1.9880660263131195e-07, 'lambda_l2': 5.714318682208131e-06}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125:  95%|###################################1 | 19/20 [03:13<00:09,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853179\tvalid_0's f1score: 0.610878\tvalid_1's auc: 0.787925\tvalid_1's f1score: 0.575356\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003501 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789125: 100%|#####################################| 20/20 [03:23<00:00, 10.04s/it][I 2024-02-08 23:42:54,349] Trial 59 finished with value: 0.7872792433845299 and parameters: {'lambda_l1': 0.006662876188383683, 'lambda_l2': 0.0003280201206907055}. Best is trial 41 with value: 0.789124809169134.\n",
      "regularization_factors, val_score: 0.789125: 100%|#####################################| 20/20 [03:23<00:00, 10.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.853866\tvalid_0's f1score: 0.611384\tvalid_1's auc: 0.787279\tvalid_1's f1score: 0.573916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.789125:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003222 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.789125:  20%|########8                                   | 1/5 [00:10<00:40, 10.16s/it][I 2024-02-08 23:43:04,525] Trial 60 finished with value: 0.7863315946521096 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.7863315946521096.\n",
      "min_child_samples, val_score: 0.789125:  20%|########8                                   | 1/5 [00:10<00:40, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.850975\tvalid_0's f1score: 0.602224\tvalid_1's auc: 0.786332\tvalid_1's f1score: 0.567759\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002420 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.789125:  40%|#################6                          | 2/5 [00:20<00:30, 10.24s/it][I 2024-02-08 23:43:14,815] Trial 61 finished with value: 0.7861054889896373 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.7863315946521096.\n",
      "min_child_samples, val_score: 0.789125:  40%|#################6                          | 2/5 [00:20<00:30, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.850305\tvalid_0's f1score: 0.601907\tvalid_1's auc: 0.786105\tvalid_1's f1score: 0.566891\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005610 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.789125:  60%|##########################4                 | 3/5 [00:29<00:19,  9.87s/it][I 2024-02-08 23:43:24,254] Trial 62 finished with value: 0.7866714759900074 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.7866714759900074.\n",
      "min_child_samples, val_score: 0.789125:  60%|##########################4                 | 3/5 [00:29<00:19,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.835496\tvalid_0's f1score: 0.477346\tvalid_1's auc: 0.786671\tvalid_1's f1score: 0.480006\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.789125:  80%|###################################2        | 4/5 [00:39<00:09,  9.96s/it][I 2024-02-08 23:43:34,345] Trial 63 finished with value: 0.7876360392764619 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.7876360392764619.\n",
      "min_child_samples, val_score: 0.789125:  80%|###################################2        | 4/5 [00:39<00:09,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.850021\tvalid_0's f1score: 0.586833\tvalid_1's auc: 0.787636\tvalid_1's f1score: 0.556459\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004463 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9756\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.789125: 100%|############################################| 5/5 [00:49<00:00,  9.76s/it][I 2024-02-08 23:43:43,749] Trial 64 finished with value: 0.7858944184863065 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.7876360392764619.\n",
      "min_child_samples, val_score: 0.789125: 100%|############################################| 5/5 [00:49<00:00,  9.88s/it]\n",
      "[I 2024-02-08 23:43:43,920] A new study created in memory with name: no-name-433152fe-475f-4f6a-9b5d-7cea633468e2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.835343\tvalid_0's f1score: 0.474735\tvalid_1's auc: 0.785894\tvalid_1's f1score: 0.475245\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012257 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786587:  14%|######4                                      | 1/7 [00:09<00:54,  9.13s/it][I 2024-02-08 23:43:53,066] Trial 0 finished with value: 0.7865866926860564 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.7865866926860564.\n",
      "feature_fraction, val_score: 0.786587:  14%|######4                                      | 1/7 [00:09<00:54,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.829578\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.786587\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011461 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786587:  29%|############8                                | 2/7 [00:19<00:50, 10.03s/it][I 2024-02-08 23:44:03,718] Trial 1 finished with value: 0.7797803945680069 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.7865866926860564.\n",
      "feature_fraction, val_score: 0.786587:  29%|############8                                | 2/7 [00:19<00:50, 10.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.85147\tvalid_0's f1score: 0.563959\tvalid_1's auc: 0.77978\tvalid_1's f1score: 0.552002\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786587:  43%|###################2                         | 3/7 [00:29<00:39,  9.87s/it][I 2024-02-08 23:44:13,395] Trial 2 finished with value: 0.7859227972626176 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.7865866926860564.\n",
      "feature_fraction, val_score: 0.786587:  43%|###################2                         | 3/7 [00:29<00:39,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.849663\tvalid_0's f1score: 0.55032\tvalid_1's auc: 0.785923\tvalid_1's f1score: 0.531042\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786587:  57%|#########################7                   | 4/7 [00:39<00:29,  9.98s/it][I 2024-02-08 23:44:23,555] Trial 3 finished with value: 0.7800731127031652 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.7865866926860564.\n",
      "feature_fraction, val_score: 0.786587:  57%|#########################7                   | 4/7 [00:39<00:29,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.847362\tvalid_0's f1score: 0.53482\tvalid_1's auc: 0.780073\tvalid_1's f1score: 0.524023\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011403 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786587:  71%|################################1            | 5/7 [00:48<00:19,  9.76s/it][I 2024-02-08 23:44:32,930] Trial 4 finished with value: 0.7847537959794696 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.7865866926860564.\n",
      "feature_fraction, val_score: 0.786587:  71%|################################1            | 5/7 [00:49<00:19,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's auc: 0.822196\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.784754\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011683 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786587:  86%|######################################5      | 6/7 [00:58<00:09,  9.68s/it][I 2024-02-08 23:44:42,438] Trial 5 finished with value: 0.7819209794696321 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.7865866926860564.\n",
      "feature_fraction, val_score: 0.786587:  86%|######################################5      | 6/7 [00:58<00:09,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.833179\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.781921\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002223 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.790706: 100%|#############################################| 7/7 [01:07<00:00,  9.53s/it][I 2024-02-08 23:44:51,691] Trial 6 finished with value: 0.7907062660393499 and parameters: {'feature_fraction': 0.4}. Best is trial 6 with value: 0.7907062660393499.\n",
      "feature_fraction, val_score: 0.790706: 100%|#############################################| 7/7 [01:07<00:00,  9.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.837826\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.790706\tvalid_1's f1score: 0.469266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.790706:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.023352 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.790706:   5%|##5                                               | 1/20 [00:13<04:22, 13.83s/it][I 2024-02-08 23:45:05,533] Trial 7 finished with value: 0.7861230218135158 and parameters: {'num_leaves': 243}. Best is trial 7 with value: 0.7861230218135158.\n",
      "num_leaves, val_score: 0.790706:   5%|##5                                               | 1/20 [00:13<04:22, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.93349\tvalid_0's f1score: 0.606874\tvalid_1's auc: 0.786123\tvalid_1's f1score: 0.543517\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  10%|#####                                             | 2/20 [00:25<03:46, 12.60s/it][I 2024-02-08 23:45:17,288] Trial 8 finished with value: 0.7912979843883661 and parameters: {'num_leaves': 134}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  10%|#####                                             | 2/20 [00:25<03:46, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.88658\tvalid_0's f1score: 0.481047\tvalid_1's auc: 0.791298\tvalid_1's f1score: 0.476508\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  15%|#######5                                          | 3/20 [00:37<03:30, 12.37s/it][I 2024-02-08 23:45:29,369] Trial 9 finished with value: 0.7860099443969204 and parameters: {'num_leaves': 158}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  15%|#######5                                          | 3/20 [00:37<03:30, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.89131\tvalid_0's f1score: 0.476571\tvalid_1's auc: 0.78601\tvalid_1's f1score: 0.475058\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014447 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  20%|##########                                        | 4/20 [00:45<02:48, 10.54s/it][I 2024-02-08 23:45:37,097] Trial 10 finished with value: 0.7853226582549188 and parameters: {'num_leaves': 9}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  20%|##########                                        | 4/20 [00:45<02:48, 10.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.812308\tvalid_0's f1score: 0.487986\tvalid_1's auc: 0.785323\tvalid_1's f1score: 0.485122\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004546 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  25%|############5                                     | 5/20 [00:56<02:43, 10.88s/it][I 2024-02-08 23:45:48,596] Trial 11 finished with value: 0.7908034377673225 and parameters: {'num_leaves': 95}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  25%|############5                                     | 5/20 [00:56<02:43, 10.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.888311\tvalid_0's f1score: 0.575432\tvalid_1's auc: 0.790803\tvalid_1's f1score: 0.548617\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  30%|###############                                   | 6/20 [01:08<02:34, 11.06s/it][I 2024-02-08 23:46:00,013] Trial 12 finished with value: 0.7888380827630453 and parameters: {'num_leaves': 96}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  30%|###############                                   | 6/20 [01:08<02:34, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.888688\tvalid_0's f1score: 0.579283\tvalid_1's auc: 0.788838\tvalid_1's f1score: 0.547674\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009663 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  35%|#################5                                | 7/20 [01:20<02:27, 11.33s/it][I 2024-02-08 23:46:11,876] Trial 13 finished with value: 0.7893836879811805 and parameters: {'num_leaves': 116}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  35%|#################5                                | 7/20 [01:20<02:27, 11.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.897707\tvalid_0's f1score: 0.583331\tvalid_1's auc: 0.789384\tvalid_1's f1score: 0.550146\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002208 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  40%|####################                              | 8/20 [01:30<02:10, 10.86s/it][I 2024-02-08 23:46:21,758] Trial 14 finished with value: 0.7907809826775022 and parameters: {'num_leaves': 64}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  40%|####################                              | 8/20 [01:30<02:10, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.858799\tvalid_0's f1score: 0.473115\tvalid_1's auc: 0.790781\tvalid_1's f1score: 0.470734\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  45%|######################5                           | 9/20 [01:42<02:06, 11.47s/it][I 2024-02-08 23:46:34,564] Trial 15 finished with value: 0.7846536837040206 and parameters: {'num_leaves': 168}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  45%|######################5                           | 9/20 [01:42<02:06, 11.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.914676\tvalid_0's f1score: 0.592862\tvalid_1's auc: 0.784654\tvalid_1's f1score: 0.543659\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  50%|########################5                        | 10/20 [01:55<01:58, 11.87s/it][I 2024-02-08 23:46:47,336] Trial 16 finished with value: 0.789432875320787 and parameters: {'num_leaves': 191}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  50%|########################5                        | 10/20 [01:55<01:58, 11.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.9032\tvalid_0's f1score: 0.48419\tvalid_1's auc: 0.789433\tvalid_1's f1score: 0.476508\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003156 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  55%|##########################9                      | 11/20 [02:05<01:42, 11.35s/it][I 2024-02-08 23:46:57,497] Trial 17 finished with value: 0.7877770797690333 and parameters: {'num_leaves': 59}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  55%|##########################9                      | 11/20 [02:05<01:42, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.856671\tvalid_0's f1score: 0.473115\tvalid_1's auc: 0.787777\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002359 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791298:  60%|#############################4                   | 12/20 [02:17<01:30, 11.37s/it][I 2024-02-08 23:47:08,913] Trial 18 finished with value: 0.7891295979469632 and parameters: {'num_leaves': 127}. Best is trial 8 with value: 0.7912979843883661.\n",
      "num_leaves, val_score: 0.791298:  60%|#############################4                   | 12/20 [02:17<01:30, 11.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.858914\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.78913\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  65%|###############################8                 | 13/20 [02:27<01:18, 11.18s/it][I 2024-02-08 23:47:19,645] Trial 19 finished with value: 0.7920980806244654 and parameters: {'num_leaves': 77}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  65%|###############################8                 | 13/20 [02:27<01:18, 11.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.866552\tvalid_0's f1score: 0.476827\tvalid_1's auc: 0.792098\tvalid_1's f1score: 0.473604\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003657 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  70%|##################################3              | 14/20 [02:36<01:02, 10.37s/it][I 2024-02-08 23:47:28,171] Trial 20 finished with value: 0.7889774914456801 and parameters: {'num_leaves': 21}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  70%|##################################3              | 14/20 [02:36<01:02, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.824268\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.788977\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  75%|####################################7            | 15/20 [02:46<00:52, 10.41s/it][I 2024-02-08 23:47:38,649] Trial 21 finished with value: 0.7897809292130026 and parameters: {'num_leaves': 79}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  75%|####################################7            | 15/20 [02:46<00:52, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.866142\tvalid_0's f1score: 0.476032\tvalid_1's auc: 0.789781\tvalid_1's f1score: 0.470734\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004459 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  80%|#######################################2         | 16/20 [02:58<00:42, 10.65s/it][I 2024-02-08 23:47:49,884] Trial 22 finished with value: 0.7907482356715141 and parameters: {'num_leaves': 103}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  80%|#######################################2         | 16/20 [02:58<00:42, 10.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.878887\tvalid_0's f1score: 0.482621\tvalid_1's auc: 0.790748\tvalid_1's f1score: 0.475003\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  85%|#########################################6       | 17/20 [03:07<00:31, 10.37s/it][I 2024-02-08 23:47:59,576] Trial 23 finished with value: 0.7894112221984603 and parameters: {'num_leaves': 44}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  85%|#########################################6       | 17/20 [03:07<00:31, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.847285\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.789411\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  90%|############################################1    | 18/20 [03:20<00:21, 10.98s/it][I 2024-02-08 23:48:11,988] Trial 24 finished with value: 0.7915054266467065 and parameters: {'num_leaves': 146}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  90%|############################################1    | 18/20 [03:20<00:21, 10.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.892773\tvalid_0's f1score: 0.480784\tvalid_1's auc: 0.791505\tvalid_1's f1score: 0.472197\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002316 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098:  95%|##############################################5  | 19/20 [03:32<00:11, 11.40s/it][I 2024-02-08 23:48:24,362] Trial 25 finished with value: 0.7895857837895637 and parameters: {'num_leaves': 151}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098:  95%|##############################################5  | 19/20 [03:32<00:11, 11.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.888781\tvalid_0's f1score: 0.475236\tvalid_1's auc: 0.789586\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003485 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792098: 100%|#################################################| 20/20 [03:46<00:00, 12.19s/it][I 2024-02-08 23:48:38,403] Trial 26 finished with value: 0.7871996631736526 and parameters: {'num_leaves': 216}. Best is trial 19 with value: 0.7920980806244654.\n",
      "num_leaves, val_score: 0.792098: 100%|#################################################| 20/20 [03:46<00:00, 11.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.927495\tvalid_0's f1score: 0.60301\tvalid_1's auc: 0.7872\tvalid_1's f1score: 0.535731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.792098:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  10%|#####3                                               | 1/10 [00:09<01:29,  9.90s/it][I 2024-02-08 23:48:48,309] Trial 27 finished with value: 0.7948921353721129 and parameters: {'bagging_fraction': 0.5260104036398686, 'bagging_freq': 1}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  10%|#####3                                               | 1/10 [00:09<01:29,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836685\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794892\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  20%|##########6                                          | 2/10 [00:20<01:20, 10.06s/it][I 2024-02-08 23:48:58,490] Trial 28 finished with value: 0.7912612275449101 and parameters: {'bagging_fraction': 0.5086553465878649, 'bagging_freq': 1}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  20%|##########6                                          | 2/10 [00:20<01:20, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.844641\tvalid_0's f1score: 0.481572\tvalid_1's auc: 0.791261\tvalid_1's f1score: 0.477953\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002702 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  30%|###############9                                     | 3/10 [00:30<01:10, 10.13s/it][I 2024-02-08 23:49:08,694] Trial 29 finished with value: 0.7899291595380667 and parameters: {'bagging_fraction': 0.8144198599481497, 'bagging_freq': 1}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  30%|###############9                                     | 3/10 [00:30<01:10, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.850732\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.789929\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003110 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  40%|#####################2                               | 4/10 [00:40<01:01, 10.18s/it][I 2024-02-08 23:49:18,948] Trial 30 finished with value: 0.7886937286142002 and parameters: {'bagging_fraction': 0.4242213935979234, 'bagging_freq': 6}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  40%|#####################2                               | 4/10 [00:40<01:01, 10.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.854227\tvalid_0's f1score: 0.568393\tvalid_1's auc: 0.788694\tvalid_1's f1score: 0.549553\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  50%|##########################5                          | 5/10 [00:50<00:50, 10.13s/it][I 2024-02-08 23:49:28,998] Trial 31 finished with value: 0.7923180870402053 and parameters: {'bagging_fraction': 0.6353000369704714, 'bagging_freq': 4}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  50%|##########################5                          | 5/10 [00:50<00:50, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.838138\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.792318\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  60%|###############################8                     | 6/10 [01:01<00:40, 10.24s/it][I 2024-02-08 23:49:39,449] Trial 32 finished with value: 0.7900267322497861 and parameters: {'bagging_fraction': 0.6410712022198811, 'bagging_freq': 4}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  60%|###############################8                     | 6/10 [01:01<00:40, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.855252\tvalid_0's f1score: 0.51262\tvalid_1's auc: 0.790027\tvalid_1's f1score: 0.501486\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003477 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  70%|#####################################                | 7/10 [01:11<00:30, 10.30s/it][I 2024-02-08 23:49:49,869] Trial 33 finished with value: 0.79187125748503 and parameters: {'bagging_fraction': 0.6439164536234288, 'bagging_freq': 4}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  70%|#####################################                | 7/10 [01:11<00:30, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.849219\tvalid_0's f1score: 0.477621\tvalid_1's auc: 0.791871\tvalid_1's f1score: 0.475058\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002943 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  80%|##########################################4          | 8/10 [01:21<00:20, 10.33s/it][I 2024-02-08 23:50:00,265] Trial 34 finished with value: 0.7919769835329341 and parameters: {'bagging_fraction': 0.6420046593610387, 'bagging_freq': 4}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  80%|##########################################4          | 8/10 [01:21<00:20, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.841544\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.791977\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892:  90%|###############################################7     | 9/10 [01:32<00:10, 10.44s/it][I 2024-02-08 23:50:10,938] Trial 35 finished with value: 0.7896455303678358 and parameters: {'bagging_fraction': 0.5875463740588429, 'bagging_freq': 3}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892:  90%|###############################################7     | 9/10 [01:32<00:10, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.850896\tvalid_0's f1score: 0.499509\tvalid_1's auc: 0.789646\tvalid_1's f1score: 0.496226\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.794892: 100%|####################################################| 10/10 [01:43<00:00, 10.52s/it][I 2024-02-08 23:50:21,651] Trial 36 finished with value: 0.7910150235243798 and parameters: {'bagging_fraction': 0.7701654231493711, 'bagging_freq': 6}. Best is trial 27 with value: 0.7948921353721129.\n",
      "bagging, val_score: 0.794892: 100%|####################################################| 10/10 [01:43<00:00, 10.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.846079\tvalid_0's f1score: 0.472314\tvalid_1's auc: 0.791015\tvalid_1's f1score: 0.469266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.794892:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.794892:  33%|############6                         | 1/3 [00:10<00:20, 10.07s/it][I 2024-02-08 23:50:31,716] Trial 37 finished with value: 0.7948921353721129 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.7948921353721129.\n",
      "feature_fraction_stage2, val_score: 0.794892:  33%|############6                         | 1/3 [00:10<00:20, 10.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836685\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794892\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003864 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.794892:  67%|#########################3            | 2/3 [00:20<00:10, 10.22s/it][I 2024-02-08 23:50:42,045] Trial 38 finished with value: 0.790088884730539 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.7948921353721129.\n",
      "feature_fraction_stage2, val_score: 0.794892:  67%|#########################3            | 2/3 [00:20<00:10, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.839843\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.790089\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002385 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.794892: 100%|######################################| 3/3 [00:30<00:00, 10.29s/it][I 2024-02-08 23:50:52,413] Trial 39 finished with value: 0.793452871043627 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.7948921353721129.\n",
      "feature_fraction_stage2, val_score: 0.794892: 100%|######################################| 3/3 [00:30<00:00, 10.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's auc: 0.829215\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.793453\tvalid_1's f1score: 0.469266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.794892:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.794892:   5%|#9                                    | 1/20 [00:10<03:14, 10.24s/it][I 2024-02-08 23:51:02,649] Trial 40 finished with value: 0.7946095754918734 and parameters: {'lambda_l1': 2.174964759349715, 'lambda_l2': 1.706160931357336e-06}. Best is trial 40 with value: 0.7946095754918734.\n",
      "regularization_factors, val_score: 0.794892:   5%|#9                                    | 1/20 [00:10<03:14, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.832462\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.79461\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008778 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  10%|###8                                  | 2/20 [00:20<03:05, 10.30s/it][I 2024-02-08 23:51:12,999] Trial 41 finished with value: 0.7964518284858854 and parameters: {'lambda_l1': 2.9588310073061437, 'lambda_l2': 9.849878570369126e-07}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  10%|###8                                  | 2/20 [00:20<03:05, 10.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.828861\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.796452\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008020 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  15%|#####7                                | 3/20 [00:30<02:51, 10.06s/it][I 2024-02-08 23:51:22,773] Trial 42 finished with value: 0.7936673973481608 and parameters: {'lambda_l1': 5.739937785923825, 'lambda_l2': 2.3257268105890806e-06}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  15%|#####7                                | 3/20 [00:30<02:51, 10.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.820093\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.793667\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003505 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  20%|#######6                              | 4/20 [00:40<02:41, 10.10s/it][I 2024-02-08 23:51:32,951] Trial 43 finished with value: 0.7938903443113773 and parameters: {'lambda_l1': 6.2923084664928615, 'lambda_l2': 6.421013101183292e-07}. Best is trial 41 with value: 0.7964518284858854.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.818447\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.79389\tvalid_1's f1score: 0.469266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 0.796452:  20%|#######6                              | 4/20 [00:40<02:41, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002707 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  25%|#########5                            | 5/20 [00:50<02:30, 10.01s/it][I 2024-02-08 23:51:42,805] Trial 44 finished with value: 0.7960017910607357 and parameters: {'lambda_l1': 4.380550855203211, 'lambda_l2': 6.47323828054191e-07}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  25%|#########5                            | 5/20 [00:50<02:30, 10.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.828663\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.796002\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002813 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  30%|###########4                          | 6/20 [01:00<02:20, 10.05s/it][I 2024-02-08 23:51:52,917] Trial 45 finished with value: 0.7950426379384089 and parameters: {'lambda_l1': 2.0208828091808946, 'lambda_l2': 6.179489989531575e-07}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  30%|###########4                          | 6/20 [01:00<02:20, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.838633\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.795043\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002279 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  35%|#############3                        | 7/20 [01:10<02:09,  9.99s/it][I 2024-02-08 23:52:02,781] Trial 46 finished with value: 0.7949466691616767 and parameters: {'lambda_l1': 0.0014954919016681373, 'lambda_l2': 1.0003474502955038e-08}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  35%|#############3                        | 7/20 [01:10<02:09,  9.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836471\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794947\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  40%|###############2                      | 8/20 [01:20<01:58,  9.91s/it][I 2024-02-08 23:52:12,516] Trial 47 finished with value: 0.7948921353721129 and parameters: {'lambda_l1': 6.721242625512549e-06, 'lambda_l2': 1.1225550183352535e-08}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  40%|###############2                      | 8/20 [01:20<01:58,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836685\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794892\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002460 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  45%|#################1                    | 9/20 [01:30<01:49,  9.95s/it][I 2024-02-08 23:52:22,554] Trial 48 finished with value: 0.7934388366124893 and parameters: {'lambda_l1': 0.015393413016178012, 'lambda_l2': 2.0998175422450493e-08}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  45%|#################1                    | 9/20 [01:30<01:49,  9.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.835572\tvalid_0's f1score: 0.472314\tvalid_1's auc: 0.793439\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002341 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  50%|##################5                  | 10/20 [01:39<01:38,  9.87s/it][I 2024-02-08 23:52:32,236] Trial 49 finished with value: 0.7935536516253208 and parameters: {'lambda_l1': 0.02245580677584671, 'lambda_l2': 0.005399621248248893}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  50%|##################5                  | 10/20 [01:39<01:38,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.829097\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.793554\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  55%|####################3                | 11/20 [01:49<01:28,  9.86s/it][I 2024-02-08 23:52:42,089] Trial 50 finished with value: 0.7948921353721129 and parameters: {'lambda_l1': 1.5765741964890058e-08, 'lambda_l2': 2.745391857722893e-05}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  55%|####################3                | 11/20 [01:49<01:28,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836685\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794892\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009837 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  60%|######################2              | 12/20 [01:59<01:18,  9.85s/it][I 2024-02-08 23:52:51,913] Trial 51 finished with value: 0.794164750855432 and parameters: {'lambda_l1': 0.1090568487366881, 'lambda_l2': 2.629792432232918}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  60%|######################2              | 12/20 [01:59<01:18,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836803\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794165\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  65%|########################             | 13/20 [02:09<01:09,  9.87s/it][I 2024-02-08 23:53:01,834] Trial 52 finished with value: 0.7948603239948674 and parameters: {'lambda_l1': 0.3383279753782928, 'lambda_l2': 2.3768394688560782e-07}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  65%|########################             | 13/20 [02:09<01:09,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's auc: 0.833591\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.79486\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004508 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  70%|#########################9           | 14/20 [02:19<00:59,  9.92s/it][I 2024-02-08 23:53:11,844] Trial 53 finished with value: 0.7949906437125749 and parameters: {'lambda_l1': 0.00021567260203378313, 'lambda_l2': 0.00011282427651684522}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  70%|#########################9           | 14/20 [02:19<00:59,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.842056\tvalid_0's f1score: 0.476306\tvalid_1's auc: 0.794991\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  75%|###########################7         | 15/20 [02:29<00:49,  9.89s/it][I 2024-02-08 23:53:21,672] Trial 54 finished with value: 0.794861125962361 and parameters: {'lambda_l1': 7.693116872438892e-05, 'lambda_l2': 0.000500861646505386}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  75%|###########################7         | 15/20 [02:29<00:49,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836504\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794861\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  80%|#############################6       | 16/20 [02:39<00:39,  9.94s/it][I 2024-02-08 23:53:31,724] Trial 55 finished with value: 0.7949434612917023 and parameters: {'lambda_l1': 0.0005072927551107617, 'lambda_l2': 2.61143298342845e-05}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  80%|#############################6       | 16/20 [02:39<00:39,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836472\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794943\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002718 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  85%|###############################4     | 17/20 [02:49<00:29,  9.97s/it][I 2024-02-08 23:53:41,765] Trial 56 finished with value: 0.794990376390077 and parameters: {'lambda_l1': 0.00025227292003949256, 'lambda_l2': 6.353329430812254e-05}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  85%|###############################4     | 17/20 [02:49<00:29,  9.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.842056\tvalid_0's f1score: 0.476306\tvalid_1's auc: 0.79499\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002716 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  90%|#################################3   | 18/20 [02:59<00:20, 10.09s/it][I 2024-02-08 23:53:52,144] Trial 57 finished with value: 0.7949434612917023 and parameters: {'lambda_l1': 0.000685703998822281, 'lambda_l2': 9.092090818144962e-05}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  90%|#################################3   | 18/20 [02:59<00:20, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836472\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794943\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452:  95%|###################################1 | 19/20 [03:09<00:10, 10.12s/it][I 2024-02-08 23:54:02,317] Trial 58 finished with value: 0.7948926700171086 and parameters: {'lambda_l1': 4.4574548325622765e-05, 'lambda_l2': 1.5729046287948604e-07}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452:  95%|###################################1 | 19/20 [03:09<00:10, 10.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.836685\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.794893\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006009 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.796452: 100%|#####################################| 20/20 [03:20<00:00, 10.17s/it][I 2024-02-08 23:54:12,625] Trial 59 finished with value: 0.7920917985457656 and parameters: {'lambda_l1': 0.5445439782168581, 'lambda_l2': 0.002953462344647737}. Best is trial 41 with value: 0.7964518284858854.\n",
      "regularization_factors, val_score: 0.796452: 100%|#####################################| 20/20 [03:20<00:00, 10.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.843614\tvalid_0's f1score: 0.472314\tvalid_1's auc: 0.792092\tvalid_1's f1score: 0.469266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.796452:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.796452:  20%|########8                                   | 1/5 [00:10<00:40, 10.13s/it][I 2024-02-08 23:54:22,759] Trial 60 finished with value: 0.7938044001283148 and parameters: {'min_child_samples': 100}. Best is trial 60 with value: 0.7938044001283148.\n",
      "min_child_samples, val_score: 0.796452:  20%|########8                                   | 1/5 [00:10<00:40, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.822576\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.793804\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002527 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.796452:  40%|#################6                          | 2/5 [00:20<00:30, 10.09s/it][I 2024-02-08 23:54:32,839] Trial 61 finished with value: 0.7943895690761335 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.7943895690761335.\n",
      "min_child_samples, val_score: 0.796452:  40%|#################6                          | 2/5 [00:20<00:30, 10.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.82857\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.79439\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.796452:  60%|##########################4                 | 3/5 [00:29<00:19,  9.85s/it][I 2024-02-08 23:54:42,390] Trial 62 finished with value: 0.7955002940547476 and parameters: {'min_child_samples': 25}. Best is trial 62 with value: 0.7955002940547476.\n",
      "min_child_samples, val_score: 0.796452:  60%|##########################4                 | 3/5 [00:29<00:19,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.8306\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.7955\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.796452:  80%|###################################2        | 4/5 [00:39<00:09,  9.90s/it][I 2024-02-08 23:54:52,355] Trial 63 finished with value: 0.7924398524379812 and parameters: {'min_child_samples': 50}. Best is trial 62 with value: 0.7955002940547476.\n",
      "min_child_samples, val_score: 0.796452:  80%|###################################2        | 4/5 [00:39<00:09,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.827409\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.79244\tvalid_1's f1score: 0.469266\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9739\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.797101: 100%|############################################| 5/5 [00:49<00:00,  9.85s/it][I 2024-02-08 23:55:02,111] Trial 64 finished with value: 0.7971008875106929 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.7971008875106929.\n",
      "min_child_samples, val_score: 0.797101: 100%|############################################| 5/5 [00:49<00:00,  9.90s/it]\n",
      "[I 2024-02-08 23:55:02,293] A new study created in memory with name: no-name-49ab52b0-bebc-499a-8675-e5d239d2c03e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.824139\tvalid_0's f1score: 0.472047\tvalid_1's auc: 0.797101\tvalid_1's f1score: 0.469266\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012599 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.769283:  14%|######4                                      | 1/7 [00:10<01:00, 10.15s/it][I 2024-02-08 23:55:12,466] Trial 0 finished with value: 0.7692825056267368 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.7692825056267368.\n",
      "feature_fraction, val_score: 0.769283:  14%|######4                                      | 1/7 [00:10<01:00, 10.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.857667\tvalid_0's f1score: 0.597276\tvalid_1's auc: 0.769283\tvalid_1's f1score: 0.573008\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010937 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.773035:  29%|############8                                | 2/7 [00:20<00:52, 10.42s/it][I 2024-02-08 23:55:23,076] Trial 1 finished with value: 0.7730348701303966 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7730348701303966.\n",
      "feature_fraction, val_score: 0.773035:  29%|############8                                | 2/7 [00:20<00:52, 10.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.873316\tvalid_0's f1score: 0.635988\tvalid_1's auc: 0.773035\tvalid_1's f1score: 0.596543\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.774797:  43%|###################2                         | 3/7 [00:30<00:40, 10.04s/it][I 2024-02-08 23:55:32,660] Trial 2 finished with value: 0.7747974606418013 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.7747974606418013.\n",
      "feature_fraction, val_score: 0.774797:  43%|###################2                         | 3/7 [00:30<00:40, 10.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's auc: 0.856001\tvalid_0's f1score: 0.586032\tvalid_1's auc: 0.774797\tvalid_1's f1score: 0.56596\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.774797:  57%|#########################7                   | 4/7 [00:40<00:29,  9.96s/it][I 2024-02-08 23:55:42,491] Trial 3 finished with value: 0.7700015579950631 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.7747974606418013.\n",
      "feature_fraction, val_score: 0.774797:  57%|#########################7                   | 4/7 [00:40<00:29,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.847882\tvalid_0's f1score: 0.554562\tvalid_1's auc: 0.770002\tvalid_1's f1score: 0.543903\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002504 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.780231:  71%|################################1            | 5/7 [00:50<00:20, 10.05s/it][I 2024-02-08 23:55:52,696] Trial 4 finished with value: 0.7802308960267071 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.7802308960267071.\n",
      "feature_fraction, val_score: 0.780231:  71%|################################1            | 5/7 [00:50<00:20, 10.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.864589\tvalid_0's f1score: 0.628427\tvalid_1's auc: 0.780231\tvalid_1's f1score: 0.603897\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004648 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.780231:  86%|######################################5      | 6/7 [01:00<00:09,  9.91s/it][I 2024-02-08 23:56:02,330] Trial 5 finished with value: 0.7716950812532072 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.7802308960267071.\n",
      "feature_fraction, val_score: 0.780231:  86%|######################################5      | 6/7 [01:00<00:09,  9.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.843695\tvalid_0's f1score: 0.522975\tvalid_1's auc: 0.771695\tvalid_1's f1score: 0.519252\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003614 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.780231: 100%|#############################################| 7/7 [01:10<00:00,  9.99s/it][I 2024-02-08 23:56:12,499] Trial 6 finished with value: 0.7748047003958118 and parameters: {'feature_fraction': 0.5}. Best is trial 4 with value: 0.7802308960267071.\n",
      "feature_fraction, val_score: 0.780231: 100%|#############################################| 7/7 [01:10<00:00, 10.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.867809\tvalid_0's f1score: 0.636249\tvalid_1's auc: 0.774805\tvalid_1's f1score: 0.602131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780231:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782346:   5%|##5                                               | 1/20 [00:12<03:53, 12.30s/it][I 2024-02-08 23:56:24,805] Trial 7 finished with value: 0.7823459177633446 and parameters: {'num_leaves': 143}. Best is trial 7 with value: 0.7823459177633446.\n",
      "num_leaves, val_score: 0.782346:   5%|##5                                               | 1/20 [00:12<03:53, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.906365\tvalid_0's f1score: 0.592699\tvalid_1's auc: 0.782346\tvalid_1's f1score: 0.558088\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782346:  10%|#####                                             | 2/20 [00:22<03:18, 11.01s/it][I 2024-02-08 23:56:34,911] Trial 8 finished with value: 0.7802308960267071 and parameters: {'num_leaves': 31}. Best is trial 7 with value: 0.7823459177633446.\n",
      "num_leaves, val_score: 0.782346:  10%|#####                                             | 2/20 [00:22<03:18, 11.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.864589\tvalid_0's f1score: 0.628427\tvalid_1's auc: 0.780231\tvalid_1's f1score: 0.603897\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003158 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782617:  15%|#######5                                          | 3/20 [00:36<03:28, 12.24s/it][I 2024-02-08 23:56:48,607] Trial 9 finished with value: 0.7826168293584188 and parameters: {'num_leaves': 240}. Best is trial 9 with value: 0.7826168293584188.\n",
      "num_leaves, val_score: 0.782617:  15%|#######5                                          | 3/20 [00:36<03:28, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.922101\tvalid_0's f1score: 0.540108\tvalid_1's auc: 0.782617\tvalid_1's f1score: 0.522339\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782939:  20%|##########                                        | 4/20 [00:50<03:28, 13.03s/it][I 2024-02-08 23:57:02,852] Trial 10 finished with value: 0.7829387088217271 and parameters: {'num_leaves': 253}. Best is trial 10 with value: 0.7829387088217271.\n",
      "num_leaves, val_score: 0.782939:  20%|##########                                        | 4/20 [00:50<03:28, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.922872\tvalid_0's f1score: 0.541557\tvalid_1's auc: 0.782939\tvalid_1's f1score: 0.516717\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784304:  25%|############5                                     | 5/20 [01:04<03:20, 13.40s/it][I 2024-02-08 23:57:16,919] Trial 11 finished with value: 0.7843044160182743 and parameters: {'num_leaves': 244}. Best is trial 11 with value: 0.7843044160182743.\n",
      "num_leaves, val_score: 0.784304:  25%|############5                                     | 5/20 [01:04<03:20, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.917874\tvalid_0's f1score: 0.49549\tvalid_1's auc: 0.784304\tvalid_1's f1score: 0.484458\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  30%|###############                                   | 6/20 [01:18<03:11, 13.66s/it][I 2024-02-08 23:57:31,076] Trial 12 finished with value: 0.7864237816073181 and parameters: {'num_leaves': 254}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  30%|###############                                   | 6/20 [01:18<03:11, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.923356\tvalid_0's f1score: 0.538496\tvalid_1's auc: 0.786424\tvalid_1's f1score: 0.515272\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  35%|#################5                                | 7/20 [01:31<02:54, 13.45s/it][I 2024-02-08 23:57:44,099] Trial 13 finished with value: 0.7812687871616574 and parameters: {'num_leaves': 189}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  35%|#################5                                | 7/20 [01:31<02:54, 13.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.920688\tvalid_0's f1score: 0.600111\tvalid_1's auc: 0.781269\tvalid_1's f1score: 0.556454\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002365 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  40%|####################                              | 8/20 [01:46<02:46, 13.86s/it][I 2024-02-08 23:57:58,823] Trial 14 finished with value: 0.7826790912429094 and parameters: {'num_leaves': 256}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  40%|####################                              | 8/20 [01:46<02:46, 13.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.936999\tvalid_0's f1score: 0.608448\tvalid_1's auc: 0.782679\tvalid_1's f1score: 0.555972\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  45%|######################5                           | 9/20 [01:59<02:30, 13.67s/it][I 2024-02-08 23:58:12,087] Trial 15 finished with value: 0.7825287939496507 and parameters: {'num_leaves': 184}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  45%|######################5                           | 9/20 [01:59<02:30, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.907391\tvalid_0's f1score: 0.530613\tvalid_1's auc: 0.782529\tvalid_1's f1score: 0.504661\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004821 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  50%|########################5                        | 10/20 [02:10<02:07, 12.73s/it][I 2024-02-08 23:58:22,723] Trial 16 finished with value: 0.7823790758367128 and parameters: {'num_leaves': 62}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  50%|########################5                        | 10/20 [02:10<02:07, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.870245\tvalid_0's f1score: 0.568636\tvalid_1's auc: 0.782379\tvalid_1's f1score: 0.551341\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002947 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  55%|##########################9                      | 11/20 [02:24<01:58, 13.18s/it][I 2024-02-08 23:58:36,917] Trial 17 finished with value: 0.7789844999762536 and parameters: {'num_leaves': 200}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  55%|##########################9                      | 11/20 [02:24<01:58, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.938852\tvalid_0's f1score: 0.657829\tvalid_1's auc: 0.778984\tvalid_1's f1score: 0.586846\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  60%|#############################4                   | 12/20 [02:36<01:41, 12.72s/it][I 2024-02-08 23:58:48,591] Trial 18 finished with value: 0.7819073334653864 and parameters: {'num_leaves': 115}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  60%|#############################4                   | 12/20 [02:36<01:41, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.887257\tvalid_0's f1score: 0.514848\tvalid_1's auc: 0.781907\tvalid_1's f1score: 0.497686\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002449 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  65%|###############################8                 | 13/20 [02:49<01:31, 13.08s/it][I 2024-02-08 23:59:02,504] Trial 19 finished with value: 0.7805045587283054 and parameters: {'num_leaves': 216}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  65%|###############################8                 | 13/20 [02:50<01:31, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.926465\tvalid_0's f1score: 0.606625\tvalid_1's auc: 0.780505\tvalid_1's f1score: 0.552885\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  70%|##################################3              | 14/20 [03:03<01:19, 13.28s/it][I 2024-02-08 23:59:16,242] Trial 20 finished with value: 0.7810715762624104 and parameters: {'num_leaves': 148}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  70%|##################################3              | 14/20 [03:03<01:19, 13.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.93406\tvalid_0's f1score: 0.67392\tvalid_1's auc: 0.781072\tvalid_1's f1score: 0.609641\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008917 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  75%|####################################7            | 15/20 [03:17<01:07, 13.51s/it][I 2024-02-08 23:59:30,263] Trial 21 finished with value: 0.7864237816073181 and parameters: {'num_leaves': 254}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  75%|####################################7            | 15/20 [03:17<01:07, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.923356\tvalid_0's f1score: 0.538496\tvalid_1's auc: 0.786424\tvalid_1's f1score: 0.515272\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002662 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  80%|#######################################2         | 16/20 [03:31<00:54, 13.54s/it][I 2024-02-08 23:59:43,882] Trial 22 finished with value: 0.783143449065145 and parameters: {'num_leaves': 223}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  80%|#######################################2         | 16/20 [03:31<00:54, 13.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's auc: 0.907152\tvalid_0's f1score: 0.474727\tvalid_1's auc: 0.783143\tvalid_1's f1score: 0.473595\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003393 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786424:  85%|#########################################6       | 17/20 [03:45<00:41, 13.79s/it][I 2024-02-08 23:59:58,251] Trial 23 finished with value: 0.785674611862308 and parameters: {'num_leaves': 228}. Best is trial 12 with value: 0.7864237816073181.\n",
      "num_leaves, val_score: 0.786424:  85%|#########################################6       | 17/20 [03:45<00:41, 13.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.92951\tvalid_0's f1score: 0.606949\tvalid_1's auc: 0.785675\tvalid_1's f1score: 0.556615\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004646 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786678:  90%|############################################1    | 18/20 [04:01<00:28, 14.31s/it][I 2024-02-09 00:00:13,786] Trial 24 finished with value: 0.7866778969730878 and parameters: {'num_leaves': 217}. Best is trial 24 with value: 0.7866778969730878.\n",
      "num_leaves, val_score: 0.786678:  90%|############################################1    | 18/20 [04:01<00:28, 14.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.927539\tvalid_0's f1score: 0.606316\tvalid_1's auc: 0.786678\tvalid_1's f1score: 0.554348\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786678:  95%|##############################################5  | 19/20 [04:13<00:13, 13.83s/it][I 2024-02-09 00:00:26,491] Trial 25 finished with value: 0.7850934044103423 and parameters: {'num_leaves': 174}. Best is trial 24 with value: 0.7866778969730878.\n",
      "num_leaves, val_score: 0.786678:  95%|##############################################5  | 19/20 [04:13<00:13, 13.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.904327\tvalid_0's f1score: 0.529632\tvalid_1's auc: 0.785093\tvalid_1's f1score: 0.515163\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786678: 100%|#################################################| 20/20 [04:25<00:00, 13.18s/it][I 2024-02-09 00:00:38,175] Trial 26 finished with value: 0.7816358426899914 and parameters: {'num_leaves': 99}. Best is trial 24 with value: 0.7866778969730878.\n",
      "num_leaves, val_score: 0.786678: 100%|#################################################| 20/20 [04:25<00:00, 13.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.888319\tvalid_0's f1score: 0.580033\tvalid_1's auc: 0.781636\tvalid_1's f1score: 0.554143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005650 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  10%|#####3                                               | 1/10 [00:14<02:12, 14.72s/it][I 2024-02-09 00:00:52,917] Trial 27 finished with value: 0.7815951552724523 and parameters: {'bagging_fraction': 0.8709964528952929, 'bagging_freq': 3}. Best is trial 27 with value: 0.7815951552724523.\n",
      "bagging, val_score: 0.786678:  10%|#####3                                               | 1/10 [00:14<02:12, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.939594\tvalid_0's f1score: 0.660155\tvalid_1's auc: 0.781595\tvalid_1's f1score: 0.58646\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004018 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  20%|##########6                                          | 2/10 [00:30<02:02, 15.33s/it][I 2024-02-09 00:01:08,658] Trial 28 finished with value: 0.7772867776607834 and parameters: {'bagging_fraction': 0.40489065027860366, 'bagging_freq': 7}. Best is trial 27 with value: 0.7815951552724523.\n",
      "bagging, val_score: 0.786678:  20%|##########6                                          | 2/10 [00:30<02:02, 15.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.956823\tvalid_0's f1score: 0.741837\tvalid_1's auc: 0.777287\tvalid_1's f1score: 0.619867\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012866 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  30%|###############9                                     | 3/10 [00:44<01:44, 14.93s/it][I 2024-02-09 00:01:23,109] Trial 29 finished with value: 0.7795940872639405 and parameters: {'bagging_fraction': 0.5350177747298313, 'bagging_freq': 1}. Best is trial 27 with value: 0.7815951552724523.\n",
      "bagging, val_score: 0.786678:  30%|###############9                                     | 3/10 [00:44<01:44, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's auc: 0.944698\tvalid_0's f1score: 0.689366\tvalid_1's auc: 0.779594\tvalid_1's f1score: 0.607893\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003755 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  40%|#####################2                               | 4/10 [01:00<01:31, 15.29s/it][I 2024-02-09 00:01:38,971] Trial 30 finished with value: 0.782476088540454 and parameters: {'bagging_fraction': 0.9951407010022517, 'bagging_freq': 7}. Best is trial 30 with value: 0.782476088540454.\n",
      "bagging, val_score: 0.786678:  40%|#####################2                               | 4/10 [01:00<01:31, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.956507\tvalid_0's f1score: 0.701141\tvalid_1's auc: 0.782476\tvalid_1's f1score: 0.609\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002725 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  50%|##########################5                          | 5/10 [01:15<01:15, 15.18s/it][I 2024-02-09 00:01:53,927] Trial 31 finished with value: 0.7777412894175647 and parameters: {'bagging_fraction': 0.7024423766020799, 'bagging_freq': 4}. Best is trial 30 with value: 0.782476088540454.\n",
      "bagging, val_score: 0.786678:  50%|##########################5                          | 5/10 [01:15<01:15, 15.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's auc: 0.953365\tvalid_0's f1score: 0.707489\tvalid_1's auc: 0.777741\tvalid_1's f1score: 0.614494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  60%|###############################8                     | 6/10 [01:28<00:57, 14.45s/it][I 2024-02-09 00:02:06,981] Trial 32 finished with value: 0.7825707845229118 and parameters: {'bagging_fraction': 0.7131927884570076, 'bagging_freq': 1}. Best is trial 32 with value: 0.7825707845229118.\n",
      "bagging, val_score: 0.786678:  60%|###############################8                     | 6/10 [01:28<00:57, 14.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.908014\tvalid_0's f1score: 0.542714\tvalid_1's auc: 0.782571\tvalid_1's f1score: 0.526225\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003705 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  70%|#####################################                | 7/10 [01:43<00:43, 14.60s/it][I 2024-02-09 00:02:21,888] Trial 33 finished with value: 0.7791555029659825 and parameters: {'bagging_fraction': 0.5390173567219672, 'bagging_freq': 5}. Best is trial 32 with value: 0.7825707845229118.\n",
      "bagging, val_score: 0.786678:  70%|#####################################                | 7/10 [01:43<00:43, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.949662\tvalid_0's f1score: 0.704861\tvalid_1's auc: 0.779156\tvalid_1's f1score: 0.61276\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007867 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  80%|##########################################4          | 8/10 [01:58<00:29, 14.63s/it][I 2024-02-09 00:02:36,602] Trial 34 finished with value: 0.7841027164715408 and parameters: {'bagging_fraction': 0.8565672706615799, 'bagging_freq': 5}. Best is trial 34 with value: 0.7841027164715408.\n",
      "bagging, val_score: 0.786678:  80%|##########################################4          | 8/10 [01:58<00:29, 14.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.937978\tvalid_0's f1score: 0.653797\tvalid_1's auc: 0.784103\tvalid_1's f1score: 0.591008\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002399 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678:  90%|###############################################7     | 9/10 [02:12<00:14, 14.43s/it][I 2024-02-09 00:02:50,580] Trial 35 finished with value: 0.7817247468692408 and parameters: {'bagging_fraction': 0.4136958462718839, 'bagging_freq': 3}. Best is trial 34 with value: 0.7841027164715408.\n",
      "bagging, val_score: 0.786678:  90%|###############################################7     | 9/10 [02:12<00:14, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.928576\tvalid_0's f1score: 0.672034\tvalid_1's auc: 0.781725\tvalid_1's f1score: 0.61099\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786678: 100%|####################################################| 10/10 [02:25<00:00, 14.00s/it][I 2024-02-09 00:03:03,603] Trial 36 finished with value: 0.7742819901562513 and parameters: {'bagging_fraction': 0.5852086619967433, 'bagging_freq': 2}. Best is trial 34 with value: 0.7841027164715408.\n",
      "bagging, val_score: 0.786678: 100%|####################################################| 10/10 [02:25<00:00, 14.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.901285\tvalid_0's f1score: 0.542521\tvalid_1's auc: 0.774282\tvalid_1's f1score: 0.519252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.786678:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.786678:  33%|############6                         | 1/3 [00:14<00:28, 14.14s/it][I 2024-02-09 00:03:17,741] Trial 37 finished with value: 0.7761856110757811 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.7761856110757811.\n",
      "feature_fraction_stage2, val_score: 0.786678:  33%|############6                         | 1/3 [00:14<00:28, 14.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.929002\tvalid_0's f1score: 0.613981\tvalid_1's auc: 0.776186\tvalid_1's f1score: 0.558576\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008467 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.786678:  67%|#########################3            | 2/3 [00:27<00:13, 13.78s/it][I 2024-02-09 00:03:31,268] Trial 38 finished with value: 0.7866778969730878 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 38 with value: 0.7866778969730878.\n",
      "feature_fraction_stage2, val_score: 0.786678:  67%|#########################3            | 2/3 [00:27<00:13, 13.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.927539\tvalid_0's f1score: 0.606316\tvalid_1's auc: 0.786678\tvalid_1's f1score: 0.554348\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.786678: 100%|######################################| 3/3 [00:42<00:00, 14.05s/it][I 2024-02-09 00:03:45,665] Trial 39 finished with value: 0.782293212354148 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.7866778969730878.\n",
      "feature_fraction_stage2, val_score: 0.786678: 100%|######################################| 3/3 [00:42<00:00, 14.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.928092\tvalid_0's f1score: 0.618213\tvalid_1's auc: 0.782293\tvalid_1's f1score: 0.561287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002330 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:   5%|#9                                    | 1/20 [00:14<04:36, 14.54s/it][I 2024-02-09 00:04:00,216] Trial 40 finished with value: 0.7799595500463924 and parameters: {'lambda_l1': 3.979440944425293e-08, 'lambda_l2': 0.32813643567129397}. Best is trial 40 with value: 0.7799595500463924.\n",
      "regularization_factors, val_score: 0.786678:   5%|#9                                    | 1/20 [00:14<04:36, 14.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.928532\tvalid_0's f1score: 0.603692\tvalid_1's auc: 0.77996\tvalid_1's f1score: 0.565711\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  10%|###8                                  | 2/20 [00:27<04:05, 13.64s/it][I 2024-02-09 00:04:13,222] Trial 41 finished with value: 0.7818256690401476 and parameters: {'lambda_l1': 9.17977124705322, 'lambda_l2': 2.6652473852905683e-08}. Best is trial 41 with value: 0.7818256690401476.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.870926\tvalid_0's f1score: 0.60293\tvalid_1's auc: 0.781826\tvalid_1's f1score: 0.585024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "regularization_factors, val_score: 0.786678:  10%|###8                                  | 2/20 [00:27<04:05, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002306 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  15%|#####7                                | 3/20 [00:41<03:51, 13.59s/it][I 2024-02-09 00:04:26,751] Trial 42 finished with value: 0.7803648314759021 and parameters: {'lambda_l1': 0.005656332105134822, 'lambda_l2': 2.40096209493662e-06}. Best is trial 41 with value: 0.7818256690401476.\n",
      "regularization_factors, val_score: 0.786678:  15%|#####7                                | 3/20 [00:41<03:51, 13.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.915553\tvalid_0's f1score: 0.535279\tvalid_1's auc: 0.780365\tvalid_1's f1score: 0.507688\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003565 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  20%|#######6                              | 4/20 [00:54<03:37, 13.61s/it][I 2024-02-09 00:04:40,386] Trial 43 finished with value: 0.783755787459356 and parameters: {'lambda_l1': 3.520800447740544e-08, 'lambda_l2': 7.535271168455583}. Best is trial 43 with value: 0.783755787459356.\n",
      "regularization_factors, val_score: 0.786678:  20%|#######6                              | 4/20 [00:54<03:37, 13.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.888222\tvalid_0's f1score: 0.471578\tvalid_1's auc: 0.783756\tvalid_1's f1score: 0.472089\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005691 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  25%|#########5                            | 5/20 [01:09<03:28, 13.91s/it][I 2024-02-09 00:04:54,858] Trial 44 finished with value: 0.7829599936985181 and parameters: {'lambda_l1': 0.0013754788890128012, 'lambda_l2': 0.0014586135694502165}. Best is trial 43 with value: 0.783755787459356.\n",
      "regularization_factors, val_score: 0.786678:  25%|#########5                            | 5/20 [01:09<03:28, 13.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.929459\tvalid_0's f1score: 0.61009\tvalid_1's auc: 0.78296\tvalid_1's f1score: 0.563066\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007999 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  30%|###########4                          | 6/20 [01:21<03:07, 13.40s/it][I 2024-02-09 00:05:07,242] Trial 45 finished with value: 0.7821213405939378 and parameters: {'lambda_l1': 9.41027262675817, 'lambda_l2': 0.0003579260871581033}. Best is trial 43 with value: 0.783755787459356.\n",
      "regularization_factors, val_score: 0.786678:  30%|###########4                          | 6/20 [01:21<03:07, 13.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.872193\tvalid_0's f1score: 0.61503\tvalid_1's auc: 0.782121\tvalid_1's f1score: 0.5955\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  35%|#############3                        | 7/20 [01:35<02:55, 13.49s/it][I 2024-02-09 00:05:20,918] Trial 46 finished with value: 0.7818880757197184 and parameters: {'lambda_l1': 4.611273989352507e-06, 'lambda_l2': 3.32552096660424e-08}. Best is trial 43 with value: 0.783755787459356.\n",
      "regularization_factors, val_score: 0.786678:  35%|#############3                        | 7/20 [01:35<02:55, 13.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.916462\tvalid_0's f1score: 0.537549\tvalid_1's auc: 0.781888\tvalid_1's f1score: 0.512579\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  40%|###############2                      | 8/20 [01:49<02:45, 13.75s/it][I 2024-02-09 00:05:35,225] Trial 47 finished with value: 0.7856155354695821 and parameters: {'lambda_l1': 0.06892256449573807, 'lambda_l2': 0.016903178764361062}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  40%|###############2                      | 8/20 [01:49<02:45, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.928152\tvalid_0's f1score: 0.602687\tvalid_1's auc: 0.785616\tvalid_1's f1score: 0.551576\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  45%|#################1                    | 9/20 [02:03<02:31, 13.73s/it][I 2024-02-09 00:05:48,919] Trial 48 finished with value: 0.7818880757197184 and parameters: {'lambda_l1': 1.1584368260475475e-05, 'lambda_l2': 4.361890863099971e-06}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  45%|#################1                    | 9/20 [02:03<02:31, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.916462\tvalid_0's f1score: 0.537549\tvalid_1's auc: 0.781888\tvalid_1's f1score: 0.512579\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  50%|##################5                  | 10/20 [02:16<02:16, 13.62s/it][I 2024-02-09 00:06:02,279] Trial 49 finished with value: 0.7818880757197184 and parameters: {'lambda_l1': 2.1822510797290033e-05, 'lambda_l2': 3.65403714980607e-06}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  50%|##################5                  | 10/20 [02:16<02:16, 13.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.916462\tvalid_0's f1score: 0.537549\tvalid_1's auc: 0.781888\tvalid_1's f1score: 0.512579\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  55%|####################3                | 11/20 [02:30<02:03, 13.67s/it][I 2024-02-09 00:06:16,069] Trial 50 finished with value: 0.7827613348484691 and parameters: {'lambda_l1': 0.22389034060458798, 'lambda_l2': 8.390963402060862}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  55%|####################3                | 11/20 [02:30<02:03, 13.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.891302\tvalid_0's f1score: 0.513114\tvalid_1's auc: 0.782761\tvalid_1's f1score: 0.508082\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002307 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  60%|######################2              | 12/20 [02:44<01:51, 13.95s/it][I 2024-02-09 00:06:30,643] Trial 51 finished with value: 0.7832927327928423 and parameters: {'lambda_l1': 0.06963520665888957, 'lambda_l2': 0.02094842917499225}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  60%|######################2              | 12/20 [02:44<01:51, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.947058\tvalid_0's f1score: 0.673831\tvalid_1's auc: 0.783293\tvalid_1's f1score: 0.598371\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003679 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  65%|########################             | 13/20 [02:59<01:39, 14.21s/it][I 2024-02-09 00:06:45,464] Trial 52 finished with value: 0.7806212635629551 and parameters: {'lambda_l1': 0.12491992514526008, 'lambda_l2': 0.022438750763380526}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  65%|########################             | 13/20 [02:59<01:39, 14.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.942531\tvalid_0's f1score: 0.656323\tvalid_1's auc: 0.780621\tvalid_1's f1score: 0.583437\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002776 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  70%|#########################9           | 14/20 [03:13<01:24, 14.12s/it][I 2024-02-09 00:06:59,378] Trial 53 finished with value: 0.7843062983543171 and parameters: {'lambda_l1': 0.00018481061043572507, 'lambda_l2': 0.08896829837779209}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  70%|#########################9           | 14/20 [03:13<01:24, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's auc: 0.922531\tvalid_0's f1score: 0.570434\tvalid_1's auc: 0.784306\tvalid_1's f1score: 0.527132\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002374 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  75%|###########################7         | 15/20 [03:27<01:10, 14.16s/it][I 2024-02-09 00:07:13,621] Trial 54 finished with value: 0.7824526317374598 and parameters: {'lambda_l1': 0.013134067210588844, 'lambda_l2': 2.3758044959610306e-05}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  75%|###########################7         | 15/20 [03:27<01:10, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.928859\tvalid_0's f1score: 0.614279\tvalid_1's auc: 0.782453\tvalid_1's f1score: 0.556631\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003066 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  80%|#############################6       | 16/20 [03:41<00:56, 14.00s/it][I 2024-02-09 00:07:27,264] Trial 55 finished with value: 0.7815101605603686 and parameters: {'lambda_l1': 5.59598127085164e-07, 'lambda_l2': 0.002311994552624129}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  80%|#############################6       | 16/20 [03:41<00:56, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.927307\tvalid_0's f1score: 0.603724\tvalid_1's auc: 0.78151\tvalid_1's f1score: 0.552196\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  85%|###############################4     | 17/20 [03:53<00:40, 13.37s/it][I 2024-02-09 00:07:39,170] Trial 56 finished with value: 0.7822740994035601 and parameters: {'lambda_l1': 1.1812198687172664, 'lambda_l2': 0.4470905662714163}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  85%|###############################4     | 17/20 [03:53<00:40, 13.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's auc: 0.896607\tvalid_0's f1score: 0.471578\tvalid_1's auc: 0.782274\tvalid_1's f1score: 0.472089\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011967 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  90%|#################################3   | 18/20 [04:06<00:26, 13.21s/it][I 2024-02-09 00:07:52,018] Trial 57 finished with value: 0.7818701211297723 and parameters: {'lambda_l1': 0.00014638405390634288, 'lambda_l2': 0.00016813361520632116}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  90%|#################################3   | 18/20 [04:06<00:26, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.916758\tvalid_0's f1score: 0.549542\tvalid_1's auc: 0.78187\tvalid_1's f1score: 0.525059\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006294 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678:  95%|###################################1 | 19/20 [04:19<00:13, 13.27s/it][I 2024-02-09 00:08:05,426] Trial 58 finished with value: 0.7824881065321115 and parameters: {'lambda_l1': 0.001962125002712974, 'lambda_l2': 0.0053960244135256505}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678:  95%|###################################1 | 19/20 [04:19<00:13, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.918752\tvalid_0's f1score: 0.547586\tvalid_1's auc: 0.782488\tvalid_1's f1score: 0.516386\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002377 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.786678: 100%|#####################################| 20/20 [04:34<00:00, 13.76s/it][I 2024-02-09 00:08:20,314] Trial 59 finished with value: 0.779933197341794 and parameters: {'lambda_l1': 0.9483231106632255, 'lambda_l2': 3.758090010965331e-07}. Best is trial 47 with value: 0.7856155354695821.\n",
      "regularization_factors, val_score: 0.786678: 100%|#####################################| 20/20 [04:34<00:00, 13.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.946015\tvalid_0's f1score: 0.674497\tvalid_1's auc: 0.779933\tvalid_1's f1score: 0.607789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.786678:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003025 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.786678:  20%|########8                                   | 1/5 [00:14<00:59, 14.86s/it][I 2024-02-09 00:08:35,202] Trial 60 finished with value: 0.7815050927325612 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.7815050927325612.\n",
      "min_child_samples, val_score: 0.786678:  20%|########8                                   | 1/5 [00:14<00:59, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.962129\tvalid_0's f1score: 0.702766\tvalid_1's auc: 0.781505\tvalid_1's f1score: 0.606238\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.786678:  40%|#################6                          | 2/5 [00:28<00:42, 14.17s/it][I 2024-02-09 00:08:48,879] Trial 61 finished with value: 0.7853184159649897 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 0.7853184159649897.\n",
      "min_child_samples, val_score: 0.786678:  40%|#################6                          | 2/5 [00:28<00:42, 14.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's auc: 0.912833\tvalid_0's f1score: 0.564497\tvalid_1's auc: 0.785318\tvalid_1's f1score: 0.546306\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.786678:  60%|##########################4                 | 3/5 [00:41<00:27, 13.68s/it][I 2024-02-09 00:09:01,962] Trial 62 finished with value: 0.7798370534085342 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.7853184159649897.\n",
      "min_child_samples, val_score: 0.786678:  60%|##########################4                 | 3/5 [00:41<00:27, 13.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.914487\tvalid_0's f1score: 0.531784\tvalid_1's auc: 0.779837\tvalid_1's f1score: 0.50955\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.786678:  80%|###################################2        | 4/5 [00:54<00:13, 13.51s/it][I 2024-02-09 00:09:15,211] Trial 63 finished with value: 0.7772064163912664 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.7853184159649897.\n",
      "min_child_samples, val_score: 0.786678:  80%|###################################2        | 4/5 [00:54<00:13, 13.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's auc: 0.920694\tvalid_0's f1score: 0.544709\tvalid_1's auc: 0.777206\tvalid_1's f1score: 0.506223\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 9731\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 39\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.786678: 100%|############################################| 5/5 [01:08<00:00, 13.59s/it][I 2024-02-09 00:09:28,944] Trial 64 finished with value: 0.7813284427347041 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.7853184159649897.\n",
      "min_child_samples, val_score: 0.786678: 100%|############################################| 5/5 [01:08<00:00, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.923884\tvalid_0's f1score: 0.604179\tvalid_1's auc: 0.781328\tvalid_1's f1score: 0.56758\n",
      "lightgbm our out of folds CV f1score is 0.5333425568131269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "xgboost training fold 1\n",
      "[0]\ttrain-logloss:0.65990\ttrain-f1score:0.09771\teval-logloss:0.65989\teval-f1score:0.09208\n",
      "[25]\ttrain-logloss:0.33451\ttrain-f1score:0.67413\teval-logloss:0.33700\teval-f1score:0.64005\n",
      "[50]\ttrain-logloss:0.27751\ttrain-f1score:0.66936\teval-logloss:0.28661\teval-f1score:0.63481\n",
      "[75]\ttrain-logloss:0.25968\ttrain-f1score:0.68228\teval-logloss:0.27752\teval-f1score:0.64392\n",
      "[100]\ttrain-logloss:0.24985\ttrain-f1score:0.68873\teval-logloss:0.27604\teval-f1score:0.64873\n",
      "[125]\ttrain-logloss:0.24253\ttrain-f1score:0.69495\teval-logloss:0.27576\teval-f1score:0.65366\n",
      "[150]\ttrain-logloss:0.23768\ttrain-f1score:0.70174\teval-logloss:0.27578\teval-f1score:0.65730\n",
      "[175]\ttrain-logloss:0.23221\ttrain-f1score:0.70764\teval-logloss:0.27554\teval-f1score:0.65801\n",
      "[200]\ttrain-logloss:0.22809\ttrain-f1score:0.71201\teval-logloss:0.27584\teval-f1score:0.65776\n",
      "[225]\ttrain-logloss:0.22398\ttrain-f1score:0.71802\teval-logloss:0.27575\teval-f1score:0.65700\n",
      "[250]\ttrain-logloss:0.22096\ttrain-f1score:0.72255\teval-logloss:0.27584\teval-f1score:0.65700\n",
      "[275]\ttrain-logloss:0.21681\ttrain-f1score:0.72872\teval-logloss:0.27581\teval-f1score:0.65650\n",
      "[300]\ttrain-logloss:0.21328\ttrain-f1score:0.73361\teval-logloss:0.27619\teval-f1score:0.65600\n",
      "[325]\ttrain-logloss:0.21055\ttrain-f1score:0.73837\teval-logloss:0.27631\teval-f1score:0.65816\n",
      "[350]\ttrain-logloss:0.20696\ttrain-f1score:0.74624\teval-logloss:0.27636\teval-f1score:0.65716\n",
      "[362]\ttrain-logloss:0.20516\ttrain-f1score:0.74914\teval-logloss:0.27662\teval-f1score:0.65716\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2\n",
      "[0]\ttrain-logloss:0.65981\ttrain-f1score:0.09652\teval-logloss:0.66031\teval-f1score:0.09925\n",
      "[25]\ttrain-logloss:0.33390\ttrain-f1score:0.66238\teval-logloss:0.34260\teval-f1score:0.66020\n",
      "[50]\ttrain-logloss:0.27725\ttrain-f1score:0.66768\teval-logloss:0.29426\teval-f1score:0.66226\n",
      "[75]\ttrain-logloss:0.25853\ttrain-f1score:0.67974\teval-logloss:0.28511\teval-f1score:0.66829\n",
      "[100]\ttrain-logloss:0.24907\ttrain-f1score:0.68881\teval-logloss:0.28336\teval-f1score:0.66666\n",
      "[125]\ttrain-logloss:0.24151\ttrain-f1score:0.69564\teval-logloss:0.28261\teval-f1score:0.66478\n",
      "[150]\ttrain-logloss:0.23617\ttrain-f1score:0.70210\teval-logloss:0.28261\teval-f1score:0.66592\n",
      "[175]\ttrain-logloss:0.23330\ttrain-f1score:0.70565\teval-logloss:0.28279\teval-f1score:0.66531\n",
      "[200]\ttrain-logloss:0.23016\ttrain-f1score:0.71080\teval-logloss:0.28327\teval-f1score:0.66379\n",
      "[225]\ttrain-logloss:0.22694\ttrain-f1score:0.71669\teval-logloss:0.28368\teval-f1score:0.66314\n",
      "[250]\ttrain-logloss:0.22386\ttrain-f1score:0.71976\teval-logloss:0.28422\teval-f1score:0.66256\n",
      "[264]\ttrain-logloss:0.22255\ttrain-f1score:0.72102\teval-logloss:0.28437\teval-f1score:0.65989\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3\n",
      "[0]\ttrain-logloss:0.65989\ttrain-f1score:0.09683\teval-logloss:0.66008\teval-f1score:0.09737\n",
      "[25]\ttrain-logloss:0.33428\ttrain-f1score:0.66807\teval-logloss:0.34021\teval-f1score:0.66077\n",
      "[50]\ttrain-logloss:0.27691\ttrain-f1score:0.66659\teval-logloss:0.29105\teval-f1score:0.65235\n",
      "[75]\ttrain-logloss:0.25882\ttrain-f1score:0.67909\teval-logloss:0.28116\teval-f1score:0.65484\n",
      "[100]\ttrain-logloss:0.24831\ttrain-f1score:0.68788\teval-logloss:0.27873\teval-f1score:0.66143\n",
      "[125]\ttrain-logloss:0.24122\ttrain-f1score:0.69703\teval-logloss:0.27792\teval-f1score:0.66308\n",
      "[150]\ttrain-logloss:0.23625\ttrain-f1score:0.70158\teval-logloss:0.27798\teval-f1score:0.66339\n",
      "[175]\ttrain-logloss:0.23197\ttrain-f1score:0.70630\teval-logloss:0.27797\teval-f1score:0.66403\n",
      "[200]\ttrain-logloss:0.22769\ttrain-f1score:0.71221\teval-logloss:0.27812\teval-f1score:0.66482\n",
      "[212]\ttrain-logloss:0.22593\ttrain-f1score:0.71517\teval-logloss:0.27830\teval-f1score:0.66609\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4\n",
      "[0]\ttrain-logloss:0.65994\ttrain-f1score:0.09733\teval-logloss:0.65980\teval-f1score:0.09440\n",
      "[25]\ttrain-logloss:0.33517\ttrain-f1score:0.67043\teval-logloss:0.33446\teval-f1score:0.66274\n",
      "[50]\ttrain-logloss:0.27811\ttrain-f1score:0.67080\teval-logloss:0.28363\teval-f1score:0.65934\n",
      "[75]\ttrain-logloss:0.26010\ttrain-f1score:0.67841\teval-logloss:0.27466\teval-f1score:0.66270\n",
      "[100]\ttrain-logloss:0.25002\ttrain-f1score:0.68495\teval-logloss:0.27286\teval-f1score:0.66861\n",
      "[125]\ttrain-logloss:0.24348\ttrain-f1score:0.69128\teval-logloss:0.27253\teval-f1score:0.67066\n",
      "[150]\ttrain-logloss:0.23815\ttrain-f1score:0.69905\teval-logloss:0.27250\teval-f1score:0.67200\n",
      "[175]\ttrain-logloss:0.23352\ttrain-f1score:0.70411\teval-logloss:0.27277\teval-f1score:0.67267\n",
      "[200]\ttrain-logloss:0.23013\ttrain-f1score:0.70973\teval-logloss:0.27269\teval-f1score:0.67068\n",
      "[225]\ttrain-logloss:0.22560\ttrain-f1score:0.71532\teval-logloss:0.27252\teval-f1score:0.67412\n",
      "[250]\ttrain-logloss:0.22180\ttrain-f1score:0.72090\teval-logloss:0.27283\teval-f1score:0.67149\n",
      "[275]\ttrain-logloss:0.21805\ttrain-f1score:0.72605\teval-logloss:0.27306\teval-f1score:0.67267\n",
      "[300]\ttrain-logloss:0.21423\ttrain-f1score:0.73366\teval-logloss:0.27347\teval-f1score:0.67110\n",
      "[325]\ttrain-logloss:0.21103\ttrain-f1score:0.73899\teval-logloss:0.27402\teval-f1score:0.67084\n",
      "[350]\ttrain-logloss:0.20720\ttrain-f1score:0.74566\teval-logloss:0.27456\teval-f1score:0.67136\n",
      "[375]\ttrain-logloss:0.20341\ttrain-f1score:0.75226\teval-logloss:0.27503\teval-f1score:0.67084\n",
      "[400]\ttrain-logloss:0.20008\ttrain-f1score:0.75710\teval-logloss:0.27561\teval-f1score:0.67176\n",
      "[425]\ttrain-logloss:0.19724\ttrain-f1score:0.76349\teval-logloss:0.27611\teval-f1score:0.67254\n",
      "[427]\ttrain-logloss:0.19711\ttrain-f1score:0.76374\teval-logloss:0.27612\teval-f1score:0.67254\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5\n",
      "[0]\ttrain-logloss:0.65985\ttrain-f1score:0.09710\teval-logloss:0.65999\teval-f1score:0.09575\n",
      "[25]\ttrain-logloss:0.33442\ttrain-f1score:0.67092\teval-logloss:0.33736\teval-f1score:0.66132\n",
      "[50]\ttrain-logloss:0.27800\ttrain-f1score:0.67099\teval-logloss:0.28674\teval-f1score:0.64948\n",
      "[75]\ttrain-logloss:0.26004\ttrain-f1score:0.68017\teval-logloss:0.27681\teval-f1score:0.65806\n",
      "[100]\ttrain-logloss:0.25027\ttrain-f1score:0.68878\teval-logloss:0.27437\teval-f1score:0.66361\n",
      "[125]\ttrain-logloss:0.24289\ttrain-f1score:0.69433\teval-logloss:0.27374\teval-f1score:0.66190\n",
      "[150]\ttrain-logloss:0.23672\ttrain-f1score:0.70073\teval-logloss:0.27279\teval-f1score:0.66352\n",
      "[175]\ttrain-logloss:0.23130\ttrain-f1score:0.70724\teval-logloss:0.27233\teval-f1score:0.66623\n",
      "[200]\ttrain-logloss:0.22767\ttrain-f1score:0.71268\teval-logloss:0.27240\teval-f1score:0.66597\n",
      "[225]\ttrain-logloss:0.22388\ttrain-f1score:0.71872\teval-logloss:0.27256\teval-f1score:0.66756\n",
      "[250]\ttrain-logloss:0.22065\ttrain-f1score:0.72463\teval-logloss:0.27275\teval-f1score:0.66808\n",
      "[275]\ttrain-logloss:0.21795\ttrain-f1score:0.72838\teval-logloss:0.27310\teval-f1score:0.66900\n",
      "[300]\ttrain-logloss:0.21496\ttrain-f1score:0.73372\teval-logloss:0.27367\teval-f1score:0.67032\n",
      "[325]\ttrain-logloss:0.21060\ttrain-f1score:0.73986\teval-logloss:0.27423\teval-f1score:0.67306\n",
      "[350]\ttrain-logloss:0.20638\ttrain-f1score:0.74722\teval-logloss:0.27469\teval-f1score:0.66797\n",
      "[375]\ttrain-logloss:0.20265\ttrain-f1score:0.75332\teval-logloss:0.27522\teval-f1score:0.66705\n",
      "[400]\ttrain-logloss:0.19993\ttrain-f1score:0.75824\teval-logloss:0.27548\teval-f1score:0.66797\n",
      "[425]\ttrain-logloss:0.19718\ttrain-f1score:0.76357\teval-logloss:0.27578\teval-f1score:0.66562\n",
      "[450]\ttrain-logloss:0.19367\ttrain-f1score:0.77042\teval-logloss:0.27623\teval-f1score:0.66812\n",
      "[475]\ttrain-logloss:0.19062\ttrain-f1score:0.77673\teval-logloss:0.27638\teval-f1score:0.66968\n",
      "[499]\ttrain-logloss:0.18789\ttrain-f1score:0.78303\teval-logloss:0.27684\teval-f1score:0.66710\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6\n",
      "[0]\ttrain-logloss:0.65975\ttrain-f1score:0.09575\teval-logloss:0.66043\teval-f1score:0.10380\n",
      "[25]\ttrain-logloss:0.33304\ttrain-f1score:0.66086\teval-logloss:0.34506\teval-f1score:0.66257\n",
      "[50]\ttrain-logloss:0.27642\ttrain-f1score:0.66215\teval-logloss:0.29758\teval-f1score:0.65821\n",
      "[75]\ttrain-logloss:0.25814\ttrain-f1score:0.67382\teval-logloss:0.28894\teval-f1score:0.66674\n",
      "[100]\ttrain-logloss:0.24761\ttrain-f1score:0.68220\teval-logloss:0.28691\teval-f1score:0.66725\n",
      "[125]\ttrain-logloss:0.24076\ttrain-f1score:0.68955\teval-logloss:0.28647\teval-f1score:0.67270\n",
      "[150]\ttrain-logloss:0.23592\ttrain-f1score:0.69640\teval-logloss:0.28656\teval-f1score:0.67705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]\ttrain-logloss:0.23209\ttrain-f1score:0.70383\teval-logloss:0.28662\teval-f1score:0.67935\n",
      "[200]\ttrain-logloss:0.22864\ttrain-f1score:0.70817\teval-logloss:0.28677\teval-f1score:0.68123\n",
      "[213]\ttrain-logloss:0.22659\ttrain-f1score:0.71043\teval-logloss:0.28692\teval-f1score:0.68136\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7\n",
      "[0]\ttrain-logloss:0.65984\ttrain-f1score:0.09712\teval-logloss:0.66013\teval-f1score:0.09563\n",
      "[25]\ttrain-logloss:0.33411\ttrain-f1score:0.67020\teval-logloss:0.34068\teval-f1score:0.65997\n",
      "[50]\ttrain-logloss:0.27737\ttrain-f1score:0.66863\teval-logloss:0.29162\teval-f1score:0.65110\n",
      "[75]\ttrain-logloss:0.25947\ttrain-f1score:0.67841\teval-logloss:0.28243\teval-f1score:0.65504\n",
      "[100]\ttrain-logloss:0.24924\ttrain-f1score:0.68823\teval-logloss:0.27992\teval-f1score:0.65587\n",
      "[125]\ttrain-logloss:0.24255\ttrain-f1score:0.69512\teval-logloss:0.27958\teval-f1score:0.65600\n",
      "[150]\ttrain-logloss:0.23679\ttrain-f1score:0.70283\teval-logloss:0.27975\teval-f1score:0.65817\n",
      "[175]\ttrain-logloss:0.23203\ttrain-f1score:0.70839\teval-logloss:0.27970\teval-f1score:0.66086\n",
      "[200]\ttrain-logloss:0.22729\ttrain-f1score:0.71351\teval-logloss:0.27963\teval-f1score:0.66151\n",
      "[225]\ttrain-logloss:0.22338\ttrain-f1score:0.71929\teval-logloss:0.27974\teval-f1score:0.66207\n",
      "[250]\ttrain-logloss:0.22039\ttrain-f1score:0.72185\teval-logloss:0.28002\teval-f1score:0.66334\n",
      "[275]\ttrain-logloss:0.21782\ttrain-f1score:0.72552\teval-logloss:0.28001\teval-f1score:0.66447\n",
      "[300]\ttrain-logloss:0.21540\ttrain-f1score:0.72982\teval-logloss:0.28039\teval-f1score:0.66436\n",
      "[325]\ttrain-logloss:0.21285\ttrain-f1score:0.73309\teval-logloss:0.28053\teval-f1score:0.66475\n",
      "[350]\ttrain-logloss:0.21022\ttrain-f1score:0.73766\teval-logloss:0.28082\teval-f1score:0.66436\n",
      "[375]\ttrain-logloss:0.20718\ttrain-f1score:0.74249\teval-logloss:0.28099\teval-f1score:0.66325\n",
      "[400]\ttrain-logloss:0.20347\ttrain-f1score:0.74912\teval-logloss:0.28124\teval-f1score:0.66276\n",
      "[425]\ttrain-logloss:0.19931\ttrain-f1score:0.75554\teval-logloss:0.28199\teval-f1score:0.66213\n",
      "[450]\ttrain-logloss:0.19598\ttrain-f1score:0.76139\teval-logloss:0.28227\teval-f1score:0.66402\n",
      "[475]\ttrain-logloss:0.19267\ttrain-f1score:0.76773\teval-logloss:0.28236\teval-f1score:0.66315\n",
      "[499]\ttrain-logloss:0.18975\ttrain-f1score:0.77542\teval-logloss:0.28287\teval-f1score:0.66179\n",
      "xgboost our out of folds CV f1score is 0.6394460840077594\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "0:\tlearn: 0.6454802\ttest: 0.6449976\tbest: 0.6449976 (0)\ttotal: 109ms\tremaining: 54.4s\n",
      "25:\tlearn: 0.3082945\ttest: 0.3044877\tbest: 0.3044877 (25)\ttotal: 2.76s\tremaining: 50.4s\n",
      "50:\tlearn: 0.2818806\ttest: 0.2787389\tbest: 0.2787389 (50)\ttotal: 5.54s\tremaining: 48.8s\n",
      "75:\tlearn: 0.2758538\ttest: 0.2746160\tbest: 0.2746160 (75)\ttotal: 8.41s\tremaining: 46.9s\n",
      "100:\tlearn: 0.2727057\ttest: 0.2735446\tbest: 0.2735446 (100)\ttotal: 11.3s\tremaining: 44.8s\n",
      "125:\tlearn: 0.2705694\ttest: 0.2731198\tbest: 0.2730969 (119)\ttotal: 14.3s\tremaining: 42.3s\n",
      "150:\tlearn: 0.2686457\ttest: 0.2728855\tbest: 0.2728742 (138)\ttotal: 17.2s\tremaining: 39.7s\n",
      "175:\tlearn: 0.2670488\ttest: 0.2727240\tbest: 0.2726972 (168)\ttotal: 20.2s\tremaining: 37.2s\n",
      "200:\tlearn: 0.2654010\ttest: 0.2726848\tbest: 0.2726309 (190)\ttotal: 23.2s\tremaining: 34.5s\n",
      "225:\tlearn: 0.2639368\ttest: 0.2727102\tbest: 0.2726309 (190)\ttotal: 26s\tremaining: 31.6s\n",
      "250:\tlearn: 0.2623733\ttest: 0.2726519\tbest: 0.2726309 (190)\ttotal: 29s\tremaining: 28.8s\n",
      "275:\tlearn: 0.2607831\ttest: 0.2726805\tbest: 0.2726309 (190)\ttotal: 32.1s\tremaining: 26s\n",
      "300:\tlearn: 0.2592704\ttest: 0.2727147\tbest: 0.2726309 (190)\ttotal: 35.2s\tremaining: 23.3s\n",
      "325:\tlearn: 0.2578251\ttest: 0.2728036\tbest: 0.2726309 (190)\ttotal: 38.2s\tremaining: 20.4s\n",
      "350:\tlearn: 0.2564208\ttest: 0.2728893\tbest: 0.2726309 (190)\ttotal: 41.2s\tremaining: 17.5s\n",
      "375:\tlearn: 0.2548145\ttest: 0.2730433\tbest: 0.2726309 (190)\ttotal: 44.2s\tremaining: 14.6s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2726309136\n",
      "bestIteration = 190\n",
      "\n",
      "Shrink model to first 191 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "0:\tlearn: 0.6454527\ttest: 0.6458499\tbest: 0.6458499 (0)\ttotal: 117ms\tremaining: 58.5s\n",
      "25:\tlearn: 0.3081611\ttest: 0.3135777\tbest: 0.3135777 (25)\ttotal: 2.84s\tremaining: 51.8s\n",
      "50:\tlearn: 0.2796299\ttest: 0.2880940\tbest: 0.2880940 (50)\ttotal: 5.78s\tremaining: 50.9s\n",
      "75:\tlearn: 0.2736610\ttest: 0.2840949\tbest: 0.2840949 (75)\ttotal: 8.75s\tremaining: 48.8s\n",
      "100:\tlearn: 0.2707380\ttest: 0.2824971\tbest: 0.2824971 (100)\ttotal: 11.7s\tremaining: 46.1s\n",
      "125:\tlearn: 0.2685675\ttest: 0.2816000\tbest: 0.2816000 (125)\ttotal: 14.6s\tremaining: 43.5s\n",
      "150:\tlearn: 0.2664760\ttest: 0.2809411\tbest: 0.2809411 (150)\ttotal: 17.6s\tremaining: 40.7s\n",
      "175:\tlearn: 0.2650010\ttest: 0.2805731\tbest: 0.2805695 (174)\ttotal: 20.6s\tremaining: 37.8s\n",
      "200:\tlearn: 0.2634873\ttest: 0.2803212\tbest: 0.2803051 (195)\ttotal: 23.5s\tremaining: 35s\n",
      "225:\tlearn: 0.2619768\ttest: 0.2802358\tbest: 0.2802162 (214)\ttotal: 26.5s\tremaining: 32.1s\n",
      "250:\tlearn: 0.2602693\ttest: 0.2798365\tbest: 0.2798365 (250)\ttotal: 29.5s\tremaining: 29.2s\n",
      "275:\tlearn: 0.2587593\ttest: 0.2793902\tbest: 0.2793902 (275)\ttotal: 32.5s\tremaining: 26.4s\n",
      "300:\tlearn: 0.2573369\ttest: 0.2793772\tbest: 0.2792931 (291)\ttotal: 35.4s\tremaining: 23.4s\n",
      "325:\tlearn: 0.2561624\ttest: 0.2793345\tbest: 0.2792931 (291)\ttotal: 38.4s\tremaining: 20.5s\n",
      "350:\tlearn: 0.2547566\ttest: 0.2791360\tbest: 0.2790642 (345)\ttotal: 41.4s\tremaining: 17.6s\n",
      "375:\tlearn: 0.2534385\ttest: 0.2790224\tbest: 0.2790224 (375)\ttotal: 44.5s\tremaining: 14.7s\n",
      "400:\tlearn: 0.2522177\ttest: 0.2789747\tbest: 0.2789699 (396)\ttotal: 47.6s\tremaining: 11.8s\n",
      "425:\tlearn: 0.2509383\ttest: 0.2792190\tbest: 0.2789699 (396)\ttotal: 50.7s\tremaining: 8.81s\n",
      "450:\tlearn: 0.2497695\ttest: 0.2792415\tbest: 0.2789699 (396)\ttotal: 53.8s\tremaining: 5.84s\n",
      "475:\tlearn: 0.2484860\ttest: 0.2790836\tbest: 0.2789699 (396)\ttotal: 56.8s\tremaining: 2.86s\n",
      "499:\tlearn: 0.2473376\ttest: 0.2790005\tbest: 0.2789579 (491)\ttotal: 59.7s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2789578743\n",
      "bestIteration = 491\n",
      "\n",
      "Shrink model to first 492 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "0:\tlearn: 0.6451767\ttest: 0.6455721\tbest: 0.6455721 (0)\ttotal: 100ms\tremaining: 50s\n",
      "25:\tlearn: 0.3106320\ttest: 0.3134337\tbest: 0.3134337 (25)\ttotal: 2.6s\tremaining: 47.3s\n",
      "50:\tlearn: 0.2807526\ttest: 0.2844077\tbest: 0.2844077 (50)\ttotal: 5.34s\tremaining: 47s\n",
      "75:\tlearn: 0.2749592\ttest: 0.2800557\tbest: 0.2800557 (75)\ttotal: 8.39s\tremaining: 46.8s\n",
      "100:\tlearn: 0.2720378\ttest: 0.2786628\tbest: 0.2786560 (99)\ttotal: 11.4s\tremaining: 45s\n",
      "125:\tlearn: 0.2698718\ttest: 0.2778470\tbest: 0.2778470 (125)\ttotal: 14.3s\tremaining: 42.5s\n",
      "150:\tlearn: 0.2680009\ttest: 0.2772759\tbest: 0.2772759 (150)\ttotal: 17.2s\tremaining: 39.8s\n",
      "175:\tlearn: 0.2666222\ttest: 0.2770522\tbest: 0.2770522 (175)\ttotal: 20.2s\tremaining: 37.2s\n",
      "200:\tlearn: 0.2650997\ttest: 0.2767825\tbest: 0.2767566 (199)\ttotal: 23.2s\tremaining: 34.5s\n",
      "225:\tlearn: 0.2633706\ttest: 0.2763795\tbest: 0.2763573 (220)\ttotal: 26.2s\tremaining: 31.8s\n",
      "250:\tlearn: 0.2616101\ttest: 0.2761347\tbest: 0.2761347 (250)\ttotal: 29.1s\tremaining: 28.9s\n",
      "275:\tlearn: 0.2601628\ttest: 0.2758939\tbest: 0.2758939 (275)\ttotal: 32.2s\tremaining: 26.1s\n",
      "300:\tlearn: 0.2588901\ttest: 0.2758684\tbest: 0.2757500 (283)\ttotal: 35.2s\tremaining: 23.2s\n",
      "325:\tlearn: 0.2575047\ttest: 0.2756964\tbest: 0.2756498 (317)\ttotal: 38.2s\tremaining: 20.4s\n",
      "350:\tlearn: 0.2562213\ttest: 0.2755223\tbest: 0.2755019 (348)\ttotal: 41.2s\tremaining: 17.5s\n",
      "375:\tlearn: 0.2546193\ttest: 0.2752228\tbest: 0.2752221 (373)\ttotal: 44.3s\tremaining: 14.6s\n",
      "400:\tlearn: 0.2532643\ttest: 0.2749799\tbest: 0.2749799 (400)\ttotal: 47.4s\tremaining: 11.7s\n",
      "425:\tlearn: 0.2519016\ttest: 0.2750159\tbest: 0.2749496 (404)\ttotal: 50.4s\tremaining: 8.75s\n",
      "450:\tlearn: 0.2508549\ttest: 0.2751771\tbest: 0.2749496 (404)\ttotal: 53.4s\tremaining: 5.8s\n",
      "475:\tlearn: 0.2497211\ttest: 0.2750598\tbest: 0.2749496 (404)\ttotal: 56.4s\tremaining: 2.84s\n",
      "499:\tlearn: 0.2484306\ttest: 0.2750461\tbest: 0.2749496 (404)\ttotal: 59.3s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2749495621\n",
      "bestIteration = 404\n",
      "\n",
      "Shrink model to first 405 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4\n",
      "0:\tlearn: 0.6453655\ttest: 0.6446511\tbest: 0.6446511 (0)\ttotal: 109ms\tremaining: 54.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25:\tlearn: 0.3103863\ttest: 0.3033628\tbest: 0.3033628 (25)\ttotal: 2.73s\tremaining: 49.8s\n",
      "50:\tlearn: 0.2825955\ttest: 0.2755723\tbest: 0.2755723 (50)\ttotal: 5.4s\tremaining: 47.5s\n",
      "75:\tlearn: 0.2763892\ttest: 0.2708200\tbest: 0.2708200 (75)\ttotal: 8.23s\tremaining: 45.9s\n",
      "100:\tlearn: 0.2735460\ttest: 0.2696597\tbest: 0.2696597 (100)\ttotal: 11.2s\tremaining: 44.1s\n",
      "125:\tlearn: 0.2713515\ttest: 0.2687493\tbest: 0.2687308 (120)\ttotal: 14.1s\tremaining: 41.8s\n",
      "150:\tlearn: 0.2692913\ttest: 0.2683234\tbest: 0.2683234 (150)\ttotal: 17s\tremaining: 39.3s\n",
      "175:\tlearn: 0.2676192\ttest: 0.2679520\tbest: 0.2679481 (173)\ttotal: 19.9s\tremaining: 36.7s\n",
      "200:\tlearn: 0.2660675\ttest: 0.2675153\tbest: 0.2675153 (200)\ttotal: 22.9s\tremaining: 34.1s\n",
      "225:\tlearn: 0.2644563\ttest: 0.2672783\tbest: 0.2672629 (223)\ttotal: 25.9s\tremaining: 31.4s\n",
      "250:\tlearn: 0.2630275\ttest: 0.2671368\tbest: 0.2671125 (240)\ttotal: 28.7s\tremaining: 28.5s\n",
      "275:\tlearn: 0.2619668\ttest: 0.2671294\tbest: 0.2670777 (265)\ttotal: 31.7s\tremaining: 25.7s\n",
      "300:\tlearn: 0.2607005\ttest: 0.2670591\tbest: 0.2670463 (297)\ttotal: 34.7s\tremaining: 22.9s\n",
      "325:\tlearn: 0.2596878\ttest: 0.2670168\tbest: 0.2669692 (310)\ttotal: 37.7s\tremaining: 20.1s\n",
      "350:\tlearn: 0.2585685\ttest: 0.2668952\tbest: 0.2668507 (334)\ttotal: 40.7s\tremaining: 17.3s\n",
      "375:\tlearn: 0.2572228\ttest: 0.2667674\tbest: 0.2667674 (375)\ttotal: 43.7s\tremaining: 14.4s\n",
      "400:\tlearn: 0.2558275\ttest: 0.2668118\tbest: 0.2667257 (392)\ttotal: 46.8s\tremaining: 11.6s\n",
      "425:\tlearn: 0.2542743\ttest: 0.2668513\tbest: 0.2667257 (392)\ttotal: 49.8s\tremaining: 8.64s\n",
      "450:\tlearn: 0.2529024\ttest: 0.2668213\tbest: 0.2667257 (392)\ttotal: 52.8s\tremaining: 5.73s\n",
      "475:\tlearn: 0.2519466\ttest: 0.2667243\tbest: 0.2666916 (473)\ttotal: 55.8s\tremaining: 2.81s\n",
      "499:\tlearn: 0.2506092\ttest: 0.2668251\tbest: 0.2666916 (473)\ttotal: 58.6s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2666916447\n",
      "bestIteration = 473\n",
      "\n",
      "Shrink model to first 474 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5\n",
      "0:\tlearn: 0.6456354\ttest: 0.6457651\tbest: 0.6457651 (0)\ttotal: 106ms\tremaining: 53s\n",
      "25:\tlearn: 0.3086168\ttest: 0.3067252\tbest: 0.3067252 (25)\ttotal: 2.82s\tremaining: 51.4s\n",
      "50:\tlearn: 0.2812997\ttest: 0.2790653\tbest: 0.2790653 (50)\ttotal: 5.5s\tremaining: 48.4s\n",
      "75:\tlearn: 0.2754968\ttest: 0.2744771\tbest: 0.2744771 (75)\ttotal: 8.43s\tremaining: 47.1s\n",
      "100:\tlearn: 0.2726574\ttest: 0.2728298\tbest: 0.2728298 (100)\ttotal: 11.5s\tremaining: 45.3s\n",
      "125:\tlearn: 0.2704147\ttest: 0.2718833\tbest: 0.2718833 (125)\ttotal: 14.4s\tremaining: 42.8s\n",
      "150:\tlearn: 0.2686223\ttest: 0.2713696\tbest: 0.2713696 (150)\ttotal: 17.3s\tremaining: 39.9s\n",
      "175:\tlearn: 0.2669997\ttest: 0.2709880\tbest: 0.2709880 (175)\ttotal: 20.3s\tremaining: 37.3s\n",
      "200:\tlearn: 0.2653803\ttest: 0.2707295\tbest: 0.2707295 (200)\ttotal: 23.3s\tremaining: 34.7s\n",
      "225:\tlearn: 0.2637844\ttest: 0.2704369\tbest: 0.2704345 (223)\ttotal: 26.3s\tremaining: 31.9s\n",
      "250:\tlearn: 0.2622353\ttest: 0.2701793\tbest: 0.2701793 (250)\ttotal: 29.1s\tremaining: 28.9s\n",
      "275:\tlearn: 0.2608546\ttest: 0.2696629\tbest: 0.2696629 (275)\ttotal: 32s\tremaining: 26s\n",
      "300:\tlearn: 0.2593032\ttest: 0.2697565\tbest: 0.2696109 (278)\ttotal: 35s\tremaining: 23.2s\n",
      "325:\tlearn: 0.2576745\ttest: 0.2698201\tbest: 0.2696109 (278)\ttotal: 38s\tremaining: 20.3s\n",
      "350:\tlearn: 0.2562901\ttest: 0.2697408\tbest: 0.2696109 (278)\ttotal: 41s\tremaining: 17.4s\n",
      "375:\tlearn: 0.2549662\ttest: 0.2697808\tbest: 0.2696109 (278)\ttotal: 44.1s\tremaining: 14.5s\n",
      "400:\tlearn: 0.2534959\ttest: 0.2699284\tbest: 0.2696109 (278)\ttotal: 47.1s\tremaining: 11.6s\n",
      "425:\tlearn: 0.2519600\ttest: 0.2699977\tbest: 0.2696109 (278)\ttotal: 50.1s\tremaining: 8.71s\n",
      "450:\tlearn: 0.2506350\ttest: 0.2698972\tbest: 0.2696109 (278)\ttotal: 53.1s\tremaining: 5.77s\n",
      "475:\tlearn: 0.2493460\ttest: 0.2702376\tbest: 0.2696109 (278)\ttotal: 56.4s\tremaining: 2.84s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2696108931\n",
      "bestIteration = 278\n",
      "\n",
      "Shrink model to first 279 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6\n",
      "0:\tlearn: 0.6450561\ttest: 0.6457277\tbest: 0.6457277 (0)\ttotal: 118ms\tremaining: 59.1s\n",
      "25:\tlearn: 0.3079461\ttest: 0.3167312\tbest: 0.3167312 (25)\ttotal: 3.03s\tremaining: 55.3s\n",
      "50:\tlearn: 0.2793927\ttest: 0.2888193\tbest: 0.2888193 (50)\ttotal: 6.13s\tremaining: 53.9s\n",
      "75:\tlearn: 0.2735411\ttest: 0.2845571\tbest: 0.2845571 (75)\ttotal: 9.27s\tremaining: 51.7s\n",
      "100:\tlearn: 0.2704703\ttest: 0.2829099\tbest: 0.2829099 (100)\ttotal: 12.4s\tremaining: 49s\n",
      "125:\tlearn: 0.2684906\ttest: 0.2825530\tbest: 0.2825530 (125)\ttotal: 15.6s\tremaining: 46.3s\n",
      "150:\tlearn: 0.2666095\ttest: 0.2826087\tbest: 0.2825530 (125)\ttotal: 18.8s\tremaining: 43.4s\n",
      "175:\tlearn: 0.2651043\ttest: 0.2823454\tbest: 0.2822995 (169)\ttotal: 22s\tremaining: 40.5s\n",
      "200:\tlearn: 0.2634354\ttest: 0.2821996\tbest: 0.2821582 (193)\ttotal: 25.1s\tremaining: 37.3s\n",
      "225:\tlearn: 0.2620104\ttest: 0.2820492\tbest: 0.2820247 (224)\ttotal: 28.1s\tremaining: 34s\n",
      "250:\tlearn: 0.2608389\ttest: 0.2820732\tbest: 0.2819875 (239)\ttotal: 31.2s\tremaining: 31s\n",
      "275:\tlearn: 0.2595428\ttest: 0.2821503\tbest: 0.2819875 (239)\ttotal: 34.4s\tremaining: 27.9s\n",
      "300:\tlearn: 0.2582923\ttest: 0.2821433\tbest: 0.2819875 (239)\ttotal: 37.6s\tremaining: 24.8s\n",
      "325:\tlearn: 0.2565589\ttest: 0.2820453\tbest: 0.2819875 (239)\ttotal: 40.8s\tremaining: 21.8s\n",
      "350:\tlearn: 0.2552042\ttest: 0.2823233\tbest: 0.2819875 (239)\ttotal: 43.9s\tremaining: 18.6s\n",
      "375:\tlearn: 0.2538751\ttest: 0.2824299\tbest: 0.2819875 (239)\ttotal: 47.1s\tremaining: 15.5s\n",
      "400:\tlearn: 0.2526100\ttest: 0.2824961\tbest: 0.2819875 (239)\ttotal: 50.3s\tremaining: 12.4s\n",
      "425:\tlearn: 0.2514461\ttest: 0.2826027\tbest: 0.2819875 (239)\ttotal: 53.4s\tremaining: 9.28s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2819874785\n",
      "bestIteration = 239\n",
      "\n",
      "Shrink model to first 240 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 7\n",
      "0:\tlearn: 0.6477380\ttest: 0.6479876\tbest: 0.6479876 (0)\ttotal: 77.1ms\tremaining: 38.5s\n",
      "25:\tlearn: 0.3113020\ttest: 0.3120264\tbest: 0.3120264 (25)\ttotal: 2.94s\tremaining: 53.5s\n",
      "50:\tlearn: 0.2810915\ttest: 0.2827091\tbest: 0.2827091 (50)\ttotal: 5.84s\tremaining: 51.4s\n",
      "75:\tlearn: 0.2748975\ttest: 0.2786957\tbest: 0.2786957 (75)\ttotal: 8.7s\tremaining: 48.5s\n",
      "100:\tlearn: 0.2718809\ttest: 0.2777606\tbest: 0.2777579 (99)\ttotal: 11.8s\tremaining: 46.8s\n",
      "125:\tlearn: 0.2697922\ttest: 0.2772765\tbest: 0.2772755 (124)\ttotal: 15s\tremaining: 44.5s\n",
      "150:\tlearn: 0.2680875\ttest: 0.2768302\tbest: 0.2768155 (141)\ttotal: 18s\tremaining: 41.7s\n",
      "175:\tlearn: 0.2664712\ttest: 0.2765733\tbest: 0.2765583 (172)\ttotal: 21s\tremaining: 38.7s\n",
      "200:\tlearn: 0.2653104\ttest: 0.2764234\tbest: 0.2764053 (193)\ttotal: 23.9s\tremaining: 35.6s\n",
      "225:\tlearn: 0.2638531\ttest: 0.2761914\tbest: 0.2761723 (224)\ttotal: 26.9s\tremaining: 32.6s\n",
      "250:\tlearn: 0.2623692\ttest: 0.2760472\tbest: 0.2760126 (248)\ttotal: 30s\tremaining: 29.8s\n",
      "275:\tlearn: 0.2610790\ttest: 0.2760551\tbest: 0.2759760 (268)\ttotal: 33.2s\tremaining: 27s\n",
      "300:\tlearn: 0.2596665\ttest: 0.2758672\tbest: 0.2758624 (299)\ttotal: 36.3s\tremaining: 24s\n",
      "325:\tlearn: 0.2582379\ttest: 0.2758294\tbest: 0.2758214 (324)\ttotal: 39.4s\tremaining: 21.1s\n",
      "350:\tlearn: 0.2568277\ttest: 0.2758880\tbest: 0.2757180 (340)\ttotal: 42.6s\tremaining: 18.1s\n",
      "375:\tlearn: 0.2553951\ttest: 0.2758810\tbest: 0.2757180 (340)\ttotal: 45.9s\tremaining: 15.1s\n",
      "400:\tlearn: 0.2539249\ttest: 0.2758035\tbest: 0.2757180 (340)\ttotal: 49s\tremaining: 12.1s\n",
      "425:\tlearn: 0.2527524\ttest: 0.2758317\tbest: 0.2757180 (340)\ttotal: 52.2s\tremaining: 9.07s\n",
      "450:\tlearn: 0.2517319\ttest: 0.2759331\tbest: 0.2757180 (340)\ttotal: 55.3s\tremaining: 6s\n",
      "475:\tlearn: 0.2504516\ttest: 0.2759961\tbest: 0.2757180 (340)\ttotal: 58.6s\tremaining: 2.95s\n",
      "499:\tlearn: 0.2493707\ttest: 0.2759170\tbest: 0.2757180 (340)\ttotal: 1m 1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2757179989\n",
      "bestIteration = 340\n",
      "\n",
      "Shrink model to first 341 iterations.\n",
      "catboost our out of folds CV f1score is 0.6463898111303923\n"
     ]
    }
   ],
   "source": [
    "Learning(train_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "id": "PcFYu2WqOzxS"
   },
   "outputs": [],
   "source": [
    "def lightgbm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "def xgboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(xgb.DMatrix(x_test))\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    x_test = test_df[features]\n",
    "    if method == 'lightgbm':\n",
    "        test_pred = lightgbm_inference(x_test)\n",
    "    if method == 'xgboost':\n",
    "        test_pred = xgboost_inference(x_test)\n",
    "    if method == 'catboost':\n",
    "        test_pred = catboost_inference(x_test)\n",
    "    return test_pred\n",
    "\n",
    "def Predicting(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    output_df = input_df.copy()\n",
    "    output_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, input_df, features, categorical_features)\n",
    "        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "id": "mGMj6OftPMpC"
   },
   "outputs": [],
   "source": [
    "test_df = Predicting(test_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "id": "k11-nGPEZS1h"
   },
   "outputs": [],
   "source": [
    "#後処理の定義\n",
    "def Postprocessing(train_df: pd.DataFrame(), test_df: pd.DataFrame()) -> (pd.DataFrame(), pd.DataFrame()):\n",
    "    train_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "        train_df['pred_prob'] += CFG.model_weight_dict[method] * oof_df[f'{method}_prediction']\n",
    "    best_score = 0\n",
    "    best_v = 0\n",
    "    for v in tqdm(np.arange(1000) / 1000):\n",
    "        score = f1_score(oof_df[CFG.target_col], train_df[f'pred_prob'] >= v, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_v = v\n",
    "    print(best_score, best_v)\n",
    "    test_df['target'] = np.where(test_df['pred_prob'] >= best_v, 1, 0)\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#後処理の定義、調和平均版 \\ndef Postprocessing(train_df: pd.DataFrame(), test_df: pd.DataFrame()) -> (pd.DataFrame(), pd.DataFrame()): \\n    train_df['pred_prob'] = 0 \\n    weight_sum = 0 \\n    for method in CFG.METHOD_LIST: \\n        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv') \\n        train_df['pred_prob'] += CFG.model_weight_dict[method] / oof_df[f'{method}_prediction'] \\n        weight_sum += CFG.model_weight_dict[method] \\n    train_df['pred_prob'] = weight_sum / train_df['pred_prob'] \\n    best_score = 0 \\n    best_v = 0 \\n    for v in tqdm(np.arange(1000) / 1000):\\n        score = f1_score(oof_df[CFG.target_col], train_df[f'pred_prob'] >= v, average='macro') \\n        if score > best_score: \\n            best_score = score \\n            best_v = v \\n    print(best_score, best_v) \\n    test_df['target'] = np.where(test_df['pred_prob'] >= best_v, 1, 0)\\n    return train_df, test_df\\n\""
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#後処理の定義、調和平均版 \n",
    "def Postprocessing(train_df: pd.DataFrame(), test_df: pd.DataFrame()) -> (pd.DataFrame(), pd.DataFrame()): \n",
    "    train_df['pred_prob'] = 0 \n",
    "    weight_sum = 0 \n",
    "    for method in CFG.METHOD_LIST: \n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv') \n",
    "        train_df['pred_prob'] += CFG.model_weight_dict[method] / oof_df[f'{method}_prediction'] \n",
    "        weight_sum += CFG.model_weight_dict[method] \n",
    "    train_df['pred_prob'] = weight_sum / train_df['pred_prob'] \n",
    "    best_score = 0 \n",
    "    best_v = 0 \n",
    "    for v in tqdm(np.arange(1000) / 1000):\n",
    "        score = f1_score(oof_df[CFG.target_col], train_df[f'pred_prob'] >= v, average='macro') \n",
    "        if score > best_score: \n",
    "            best_score = score \n",
    "            best_v = v \n",
    "    print(best_score, best_v) \n",
    "    test_df['target'] = np.where(test_df['pred_prob'] >= best_v, 1, 0)\n",
    "    return train_df, test_df\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "ef58b4abcf0f43cd90a523a3875a2f28",
      "6f14799525cf44158bbffc0e9a08891b",
      "d239d2ff297a4c00aa350f8699ca6bb1",
      "76ddf1599bb144b2a6b4573027c6f662",
      "6762ef5aab7e4d18b98e7d837dedc03f",
      "b7dceec9910a46cea90915015ca58358",
      "573ab758539147f1a2bc21ac9f0347ce",
      "5de7c5cebd814e1caa8437775031ea12",
      "b0ab4a4e03b242e2ae3610b6a52b5c14",
      "4074a8c3b85548ed9424375a19416c7d",
      "13858cd0c554419bb867071b5c810b30"
     ]
    },
    "id": "q3P87swwPqf2",
    "outputId": "8d624fd1-4808-44f9-d59b-982a93d06ad5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44dfcf2933114820bdfde5e2c1e4fde2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6873386897430647 0.787\n"
     ]
    }
   ],
   "source": [
    "#後処理\n",
    "train_df, test_df = Postprocessing(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "id": "hK_3WqNDT0yj"
   },
   "outputs": [],
   "source": [
    "test_df[['target']].to_csv(f'seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHZryWelXTi4"
   },
   "source": [
    "特徴量の重要度を確認する方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 708
    },
    "id": "PpCipSr8gkD0",
    "outputId": "86d3f0b2-df9f-4dde-c13d-783497a759df"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DisbursementDate</th>\n",
       "      <td>0.079260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBA_Appv</th>\n",
       "      <td>0.078785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisbursementGross</th>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Term</th>\n",
       "      <td>0.063123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CompanyLong</th>\n",
       "      <td>0.061699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisbursementMonth</th>\n",
       "      <td>0.055055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisbursementYear</th>\n",
       "      <td>0.052682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrAppv</th>\n",
       "      <td>0.049834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NoEmp</th>\n",
       "      <td>0.044139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalDay</th>\n",
       "      <td>0.042715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RetainedJob</th>\n",
       "      <td>0.033223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalMonth</th>\n",
       "      <td>0.033223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalYear</th>\n",
       "      <td>0.032748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bankraptcy_By_Year</th>\n",
       "      <td>0.030138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreateJob</th>\n",
       "      <td>0.029663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalFY</th>\n",
       "      <td>0.027527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>0.019459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalDate</th>\n",
       "      <td>0.019222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BankState</th>\n",
       "      <td>0.018035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ApprovalFY_Term</th>\n",
       "      <td>0.017323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DisbursementDay</th>\n",
       "      <td>0.016849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UrbanRural</th>\n",
       "      <td>0.016374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr_1.0</th>\n",
       "      <td>0.014001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_State</th>\n",
       "      <td>0.013526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0.012103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sector</th>\n",
       "      <td>0.010916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NewExist</th>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_3.0</th>\n",
       "      <td>0.008068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr_4.0</th>\n",
       "      <td>0.007594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_4.0</th>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_5.0</th>\n",
       "      <td>0.006407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr_0.0</th>\n",
       "      <td>0.005933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr_2.0</th>\n",
       "      <td>0.005695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_6.0</th>\n",
       "      <td>0.004983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_1.0</th>\n",
       "      <td>0.003560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FranchiseCode</th>\n",
       "      <td>0.003085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RevLineCr_3.0</th>\n",
       "      <td>0.001187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_2.0</th>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LowDoc_0.0</th>\n",
       "      <td>0.000237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    importance\n",
       "DisbursementDate      0.079260\n",
       "SBA_Appv              0.078785\n",
       "DisbursementGross     0.064072\n",
       "Term                  0.063123\n",
       "CompanyLong           0.061699\n",
       "DisbursementMonth     0.055055\n",
       "DisbursementYear      0.052682\n",
       "GrAppv                0.049834\n",
       "NoEmp                 0.044139\n",
       "ApprovalDay           0.042715\n",
       "RetainedJob           0.033223\n",
       "ApprovalMonth         0.033223\n",
       "ApprovalYear          0.032748\n",
       "Bankraptcy_By_Year    0.030138\n",
       "CreateJob             0.029663\n",
       "ApprovalFY            0.027527\n",
       "City                  0.019459\n",
       "ApprovalDate          0.019222\n",
       "BankState             0.018035\n",
       "ApprovalFY_Term       0.017323\n",
       "DisbursementDay       0.016849\n",
       "UrbanRural            0.016374\n",
       "RevLineCr_1.0         0.014001\n",
       "City_State            0.013526\n",
       "State                 0.012103\n",
       "Sector                0.010916\n",
       "NewExist              0.010204\n",
       "LowDoc_3.0            0.008068\n",
       "RevLineCr_4.0         0.007594\n",
       "LowDoc_4.0            0.007119\n",
       "LowDoc_5.0            0.006407\n",
       "RevLineCr_0.0         0.005933\n",
       "RevLineCr_2.0         0.005695\n",
       "LowDoc_6.0            0.004983\n",
       "LowDoc_1.0            0.003560\n",
       "FranchiseCode         0.003085\n",
       "RevLineCr_3.0         0.001187\n",
       "LowDoc_2.0            0.000237\n",
       "LowDoc_0.0            0.000237"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = pickle.load(open(f'lightgbm_fold1_seed42_ver{CFG.VER}.pkl', 'rb'))\n",
    "importance_df = pd.DataFrame(model.feature_importance(), index=features, columns=['importance'])\n",
    "importance_df['importance'] = importance_df['importance'] / np.sum(importance_df['importance'])\n",
    "importance_df.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13858cd0c554419bb867071b5c810b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4074a8c3b85548ed9424375a19416c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573ab758539147f1a2bc21ac9f0347ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5de7c5cebd814e1caa8437775031ea12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6762ef5aab7e4d18b98e7d837dedc03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f14799525cf44158bbffc0e9a08891b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7dceec9910a46cea90915015ca58358",
      "placeholder": "​",
      "style": "IPY_MODEL_573ab758539147f1a2bc21ac9f0347ce",
      "value": "100%"
     }
    },
    "76ddf1599bb144b2a6b4573027c6f662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4074a8c3b85548ed9424375a19416c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_13858cd0c554419bb867071b5c810b30",
      "value": " 1000/1000 [00:19&lt;00:00, 37.91it/s]"
     }
    },
    "b0ab4a4e03b242e2ae3610b6a52b5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7dceec9910a46cea90915015ca58358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d239d2ff297a4c00aa350f8699ca6bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de7c5cebd814e1caa8437775031ea12",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0ab4a4e03b242e2ae3610b6a52b5c14",
      "value": 1000
     }
    },
    "ef58b4abcf0f43cd90a523a3875a2f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f14799525cf44158bbffc0e9a08891b",
       "IPY_MODEL_d239d2ff297a4c00aa350f8699ca6bb1",
       "IPY_MODEL_76ddf1599bb144b2a6b4573027c6f662"
      ],
      "layout": "IPY_MODEL_6762ef5aab7e4d18b98e7d837dedc03f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
