{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に動いたコードしか突っ込まないこと！！！\n",
    "（ここでエラーが出ると調整が大変です。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "B3WEPx1JJqlG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import category_encoders as ce\n",
    "#import lightgbm as lgb\n",
    "import optuna.integration.lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 5.2\n",
    "    AUTHOR = 'naokisusami'\n",
    "    COMPETITION = 'FDUA2'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = ['lightgbm', 'xgboost', 'catboost']\n",
    "    seed = 42\n",
    "    n_folds = 7\n",
    "    target_col = 'MIS_Status'\n",
    "    metric = 'f1_score'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 500\n",
    "    early_stopping_round = 200\n",
    "    verbose = 25\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'iterations': num_boost_round,\n",
    "        'random_seed': seed,\n",
    "    }\n",
    "    model_weight_dict = {'lightgbm': 0.50, 'xgboost': 0.10, 'catboost': 0.40}\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# f1_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro'), CFG.metric_maximize_flag\n",
    "\n",
    "# ====================================================\n",
    "# XGBoost Metric\n",
    "# ====================================================\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "g6R4KoxhL91E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n",
      "City\n",
      "BankState\n",
      "ApprovalDate\n",
      "DisbursementDate\n",
      "ApprovalFY_Term\n",
      "UrbanRural_Sector_interaction\n",
      "Sector_RevLineCr\n",
      "Sector_LowDoc\n",
      "State_Sector\n",
      "City_State\n"
     ]
    }
   ],
   "source": [
    "#LGB用データ作成\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector']\n",
    "\n",
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "        df['ApprovalTerm'] = 15 - df['ApprovalFY']\n",
    "        df['DisbursementTerm'] = 15 - df['DisbursementYear']\n",
    "\n",
    "        #Bankraptcydataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = k[-26]*2\n",
    "        \n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "        \n",
    "        #State関係の特徴量作成\n",
    "        df['Cor_State'] = (df['State']==df['BankState']).astype(int)\n",
    "        StateList = ['AL','AK','AZ','AR','CA','CO','CT','DE','DC','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA',\n",
    "                      'MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX',\n",
    "                      'UT','VT','VA','WA','WV','WI','WY']\n",
    "        \n",
    "        UnemploymentList = [2.6,3.7,4.0,3.4,4.1,2.8,4.0,4.6,4.2,2.7,3.1,3.7,2.8,4.6,3.1,3.0,2.9,3.9,3.5,3.1,3.0,3.7,4.3,2.9,4.0,\n",
    "                          2.7,2.6,2.7,5.5,2.9,3.3,3.5,4.1,3.8,2.1,4.1,3.2,4.8,4.3,3.2,3.3,2.2,3.5,3.8,2.4,3.0,3.1\n",
    "                            ,4.5,4.1,3.0,3.9]\n",
    "\n",
    "        GDPList = [29603,44807,33655,27781,42376,40805,51911,56496,126421,33417,35265,38850,29843,39568,32724,35814,34770,30364,35181,\n",
    "                   30282,39596,47351,32846,41353,24477,32590,28201,37075,40210,37375,45052,30943,49038,37053,34694,34040,29470,\n",
    "                   38339,35153,36543,28894,35596,33742,37793,32774,34197,41617,40361,24929,34890,40303]\n",
    "        \n",
    "        GDPperPersonList = [37282,71008,48148,35674,53525,54943,63504,76720,164002,45958,48434,50788,39529,49083,40529,44091,43633,\n",
    "                       38148,48366,37734,50729,55364,38433,51829,31127,41012,37966,46803,63662,46400,55320,41878,58126,49625,43172,\n",
    "                       41073,40376,46248,43246,44738,38093,44955,42865,54766,47313,40312,54102,52810,31914,43309,63822]\n",
    "        \n",
    "        AveSalaryList = [40.46,50.81,45.40,37.79,56.10,49.79,60.14,49.66,79.85,43.66,46.17,44.09,36.45,51.71,40.97,38.39,40.96,\n",
    "                        39.54,43.15,39.06,54.28,58.62,45.19,46.99,35.95,42.58,35.81,39.87,44.38,46.38,56.72,40.91,61.04,43.11,41.12,\n",
    "                        43.45,40.75,43.46,46.10,46.38,39.63,35.00,41.88,48.35,41.11,39.54,52.07,51.04,38.48,41.46,44.03]\n",
    "        \n",
    "        Unemploymentdict = dict(zip(StateList,UnemploymentList))\n",
    "        GDPdict = dict(zip(StateList,GDPList))\n",
    "        GDPperPersondict = dict(zip(StateList,GDPperPersonList))\n",
    "        AveSalarydict = dict(zip(StateList,AveSalaryList))\n",
    "        \n",
    "        df['Unemployment_By_State'] = df['State'].map(Unemploymentdict)\n",
    "        df['GDP_By_State'] = df['State'].map(GDPdict)\n",
    "        df['GDPperPerson_By_State'] = df['State'].map(GDPperPersondict)\n",
    "        df['AveSalary_By_State'] = df['State'].map(AveSalarydict)\n",
    "        \n",
    "        \n",
    "        #現状グループ分けされない特徴量の作成\n",
    "        #企業の安定さ、デカさ\n",
    "        df['BCI'] = df['CompanyLong']*(df['NoEmp'])*(df['NewExist']+1)\n",
    "        df['BCI'] = df['BCI'].fillna(df['BCI'].mean)\n",
    "        \n",
    "        #しんどさ指数2\n",
    "        df['TI2'] = (df['SBA_Appv']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "        \n",
    "        #派生特徴量\n",
    "        # Employee to Loan Size Ratio\n",
    "        # 財務関連の派生特徴量\n",
    "        df['GrAppv_SBA_Appv_ratio'] = df['SBA_Appv'] / (df['GrAppv'] + 1) \n",
    "        df['DisbursementGross_GrAppv_ratio'] = df['DisbursementGross'] / (df['GrAppv'] + 1)\n",
    "        # ビジネスの条件関連\n",
    "        df['NewExist_NoEmp_interaction'] = df['NewExist'] * df['NoEmp']\n",
    "        df['UrbanRural_Sector_interaction'] = df['UrbanRural'].astype(str) + '_' + df['Sector'].astype(str)\n",
    "        # リスク関連の派生特徴量\n",
    "        df['RevLineCr_LowDoc_risk_indicator'] = (df['RevLineCr'] == 'Y').astype(int) + (df['LowDoc'] == 'Y').astype(int)\n",
    "        # FranchiseCodeのリスク要因\n",
    "        df['Franchise_risk_factor'] = df['FranchiseCode'].apply(lambda x: 0 if x in [0, 1] else 1)\n",
    "\n",
    "        #組み合わせ特徴量\n",
    "        df['State_Sector'] = df['State'].astype(str) + '_' + df['Sector'].astype(str)\n",
    "        # 地理的特徴の組み合わせ\n",
    "        df['City_State'] = df['City'] + '_' + df['State']\n",
    "        df['Lender_Borrower_SameState'] = (df['BankState'] == df['State']).astype(int)\n",
    "        # 経済的特徴の組み合わせ\n",
    "        df['Emp_to_Loan_Ratio'] = df['NoEmp'] / (df['DisbursementGross'] + 1)\n",
    "        df['JobImpactScore'] = df['CreateJob'] + df['RetainedJob']\n",
    "        df['Employment_creation_ratio'] = df['CreateJob'] / (df['NoEmp'] + 1)\n",
    "        df['Disbursement_per_Term'] = df['DisbursementGross'] / (df['Term']+1)\n",
    "        # 業種と金融条件の組み合わせ\n",
    "        df['Sector_RevLineCr'] = df['Sector'].astype(str) + '_' + df['RevLineCr']\n",
    "        df['Sector_LowDoc'] = df['Sector'].astype(str) + '_' + df['LowDoc']\n",
    "        # 時間的特徴の組み合わせ\n",
    "        df['ApprovalFY_Term'] = df['ApprovalFY'].astype(str) + '_' + df['Term'].astype(str)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df\n",
    "\n",
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)\n",
    "\n",
    "#カウントエンコーディング\n",
    "for col in ['FranchiseCode','UrbanRural', 'State','City', 'Sector', 'City_State',\n",
    "            'ApprovalFY_Term','UrbanRural_Sector_interaction', 'Sector_RevLineCr', 'Sector_LowDoc','State_Sector']:\n",
    "    count_dict = dict(train_df[col].value_counts())\n",
    "    train_df[f'{col}_count_encoding'] = train_df[col].map(count_dict).astype(int)\n",
    "    test_df[f'{col}_count_encoding'] = test_df[col].map(count_dict).fillna(1).astype(int)\n",
    "\n",
    "#ラベルエンコーディング\n",
    "for col in categorical_features :\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "#OneHotEncoding\n",
    "train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "OneHotList = ['RevLineCr', 'LowDoc']\n",
    "ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "train_df2 = ohe.fit_transform(train_df2)\n",
    "test_df = ohe.transform(test_df)\n",
    "train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "\n",
    "#featuresの作成\n",
    "categorical_features =['UrbanRural', 'State', 'Sector','RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0',\n",
    "                       'LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0','FranchiseCode']\n",
    "\n",
    "RemoveList=['MIS_Status','City','BankState','ApprovalDate','DisbursementDate','ApprovalFY_Term','UrbanRural_Sector_interaction',\n",
    "            'Sector_RevLineCr', 'Sector_LowDoc','State_Sector','City_State']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "#専用変数として保存\n",
    "train_df_lgb = train_df\n",
    "test_df_lgb = test_df\n",
    "categorical_features_lgb = categorical_features\n",
    "features_lgb = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n"
     ]
    }
   ],
   "source": [
    "#CTB用データ作成\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector']\n",
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "\n",
    "        #Bankraptcydataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = k[-26]*2\n",
    "        \n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "\n",
    "        \n",
    "         # 地理的特徴の組み合わせ\n",
    "        df['City_State'] = df['City'] + '_' + df['State']\n",
    "        # 時間的特徴の組み合わせ\n",
    "        df['ApprovalFY_Term'] = df['ApprovalFY'].astype(str) + '_' + df['Term'].astype(str)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df\n",
    "\n",
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)\n",
    "\n",
    "#ラベルエンコーディング\n",
    "for col in categorical_features :\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "categorical_features_unlabelable = ['ApprovalFY_Term','City_State','City','ApprovalDate','BankState','DisbursementDate']\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    le = LabelEncoder()   \n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else len(le.classes_))\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "#OneHotEncoding\n",
    "train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "OneHotList = ['RevLineCr', 'LowDoc']\n",
    "ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "train_df2 = ohe.fit_transform(train_df2)\n",
    "test_df = ohe.transform(test_df)\n",
    "train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "\n",
    "#featuresの作成\n",
    "categorical_features =['UrbanRural', 'State', 'Sector','RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0',\n",
    "                       'LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0','FranchiseCode',\n",
    "                       'ApprovalFY_Term','City_State','City','ApprovalDate','BankState']\n",
    "RemoveList=['MIS_Status']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "    \n",
    "#専用変数の作成\n",
    "train_df_ctb = train_df\n",
    "test_df_ctb = test_df\n",
    "categorical_features_ctb = categorical_features\n",
    "features_ctb = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "quaQcTgQOjyJ"
   },
   "outputs": [],
   "source": [
    "#lightgbmでの学習メソッドの定義\n",
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "                params = CFG.classification_lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                feval = lgb_metric,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                              verbose=CFG.verbose)]\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "#xgboostでの学習メソッドの定義\n",
    "def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "    model = xgb.train(\n",
    "                CFG.classification_xgb_params,\n",
    "                dtrain = xgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                early_stopping_rounds = CFG.early_stopping_round,\n",
    "                verbose_eval = CFG.verbose,\n",
    "                feval = xgb_metric,\n",
    "                maximize = CFG.metric_maximize_flag,\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "    return model, valid_pred\n",
    "\n",
    "#catboostでの学習メソッドの定義\n",
    "def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "    model.fit(cat_train,\n",
    "              eval_set = [cat_valid],\n",
    "              early_stopping_rounds = CFG.early_stopping_round,\n",
    "              verbose = CFG.verbose,\n",
    "              use_best_model = True)\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "#任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    kfold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df)):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "\n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        if method == 'lightgbm':\n",
    "            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'xgboost':\n",
    "            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "        if method == 'catboost':\n",
    "            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "\n",
    "        # Save best model\n",
    "        pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "    print(f'{method} our out of folds CV f1score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "#学習メソッドの定義\n",
    "def Learning():\n",
    "    gradient_boosting_model_cv_training('lightgbm', train_df_lgb, features_lgb, categorical_features_lgb)\n",
    "    gradient_boosting_model_cv_training('xgboost',train_df_ctb, features_ctb, categorical_features_ctb)\n",
    "    gradient_boosting_model_cv_training('catboost',train_df_ctb, features_ctb, categorical_features_ctb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWzQv798OiQ-",
    "outputId": "57cabf2c-5c42-4084-e263-e00eaeb695ec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-02-08 15:50:33,590] A new study created in memory with name: no-name-15eef688-9525-4522-b74d-fdd7b088b265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.756429:  14%|######4                                      | 1/7 [00:36<03:36, 36.08s/it][I 2024-02-08 15:51:09,670] Trial 0 finished with value: 0.756429391659205 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.756429391659205.\n",
      "feature_fraction, val_score: 0.756429:  14%|######4                                      | 1/7 [00:36<03:36, 36.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.972858\tvalid_0's f1score: 0.785741\tvalid_1's auc: 0.756429\tvalid_1's f1score: 0.632019\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.043571 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.761945:  29%|############8                                | 2/7 [00:59<02:24, 28.89s/it][I 2024-02-08 15:51:33,535] Trial 1 finished with value: 0.7619454265780728 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.7619454265780728.\n",
      "feature_fraction, val_score: 0.761945:  29%|############8                                | 2/7 [00:59<02:24, 28.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.864097\tvalid_0's f1score: 0.662519\tvalid_1's auc: 0.761945\tvalid_1's f1score: 0.62945\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028188 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.761945:  43%|###################2                         | 3/7 [01:19<01:37, 24.42s/it][I 2024-02-08 15:51:52,625] Trial 2 finished with value: 0.7605874439017386 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7619454265780728.\n",
      "feature_fraction, val_score: 0.761945:  43%|###################2                         | 3/7 [01:19<01:37, 24.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.875424\tvalid_0's f1score: 0.666873\tvalid_1's auc: 0.760587\tvalid_1's f1score: 0.627466\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.031863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.761945:  57%|#########################7                   | 4/7 [01:38<01:07, 22.54s/it][I 2024-02-08 15:52:12,284] Trial 3 finished with value: 0.7564107685833517 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.7619454265780728.\n",
      "feature_fraction, val_score: 0.761945:  57%|#########################7                   | 4/7 [01:38<01:07, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.906679\tvalid_0's f1score: 0.680759\tvalid_1's auc: 0.756411\tvalid_1's f1score: 0.634409\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017628 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.761945:  71%|################################1            | 5/7 [01:56<00:41, 20.90s/it][I 2024-02-08 15:52:30,299] Trial 4 finished with value: 0.7567817282394615 and parameters: {'feature_fraction': 1.0}. Best is trial 1 with value: 0.7619454265780728.\n",
      "feature_fraction, val_score: 0.761945:  71%|################################1            | 5/7 [01:56<00:41, 20.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's auc: 0.901601\tvalid_0's f1score: 0.682271\tvalid_1's auc: 0.756782\tvalid_1's f1score: 0.632022\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012636 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.761945:  86%|######################################5      | 6/7 [02:19<00:21, 21.53s/it][I 2024-02-08 15:52:53,045] Trial 5 finished with value: 0.7595769918506021 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.7619454265780728.\n",
      "feature_fraction, val_score: 0.761945:  86%|######################################5      | 6/7 [02:19<00:21, 21.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's auc: 0.907338\tvalid_0's f1score: 0.68196\tvalid_1's auc: 0.759577\tvalid_1's f1score: 0.626847\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.762743: 100%|#############################################| 7/7 [02:50<00:00, 24.50s/it][I 2024-02-08 15:53:23,644] Trial 6 finished with value: 0.7627429147456614 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.7627429147456614.\n",
      "feature_fraction, val_score: 0.762743: 100%|#############################################| 7/7 [02:50<00:00, 24.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's auc: 0.925723\tvalid_0's f1score: 0.695188\tvalid_1's auc: 0.762743\tvalid_1's f1score: 0.634996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011015 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:   5%|##5                                               | 1/20 [00:21<06:53, 21.77s/it][I 2024-02-08 15:53:45,428] Trial 7 finished with value: 0.7611578506927934 and parameters: {'num_leaves': 7}. Best is trial 7 with value: 0.7611578506927934.\n",
      "num_leaves, val_score: 0.762743:   5%|##5                                               | 1/20 [00:21<06:53, 21.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[290]\tvalid_0's auc: 0.835269\tvalid_0's f1score: 0.651599\tvalid_1's auc: 0.761158\tvalid_1's f1score: 0.625195\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005050 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  10%|#####                                             | 2/20 [00:40<05:57, 19.88s/it][I 2024-02-08 15:54:03,983] Trial 8 finished with value: 0.7605282705800758 and parameters: {'num_leaves': 244}. Best is trial 7 with value: 0.7611578506927934.\n",
      "num_leaves, val_score: 0.762743:  10%|#####                                             | 2/20 [00:40<05:57, 19.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.931817\tvalid_0's f1score: 0.636734\tvalid_1's auc: 0.760528\tvalid_1's f1score: 0.575223\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013911 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  15%|#######5                                          | 3/20 [00:56<05:12, 18.38s/it][I 2024-02-08 15:54:20,592] Trial 9 finished with value: 0.7589010042343468 and parameters: {'num_leaves': 222}. Best is trial 7 with value: 0.7611578506927934.\n",
      "num_leaves, val_score: 0.762743:  15%|#######5                                          | 3/20 [00:56<05:12, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.916474\tvalid_0's f1score: 0.610003\tvalid_1's auc: 0.758901\tvalid_1's f1score: 0.564624\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013669 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  20%|##########                                        | 4/20 [01:18<05:12, 19.53s/it][I 2024-02-08 15:54:41,883] Trial 10 finished with value: 0.7622974627861383 and parameters: {'num_leaves': 57}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  20%|##########                                        | 4/20 [01:18<05:12, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's auc: 0.966656\tvalid_0's f1score: 0.751475\tvalid_1's auc: 0.762297\tvalid_1's f1score: 0.636942\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  25%|############5                                     | 5/20 [01:41<05:14, 20.94s/it][I 2024-02-08 15:55:05,327] Trial 11 finished with value: 0.7622974627861383 and parameters: {'num_leaves': 57}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  25%|############5                                     | 5/20 [01:41<05:14, 20.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's auc: 0.966656\tvalid_0's f1score: 0.751475\tvalid_1's auc: 0.762297\tvalid_1's f1score: 0.636942\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011069 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  30%|###############                                   | 6/20 [02:04<05:00, 21.50s/it][I 2024-02-08 15:55:27,902] Trial 12 finished with value: 0.7604426645055888 and parameters: {'num_leaves': 116}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  30%|###############                                   | 6/20 [02:04<05:00, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.984708\tvalid_0's f1score: 0.793281\tvalid_1's auc: 0.760443\tvalid_1's f1score: 0.631056\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006436 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  35%|#################5                                | 7/20 [02:22<04:26, 20.47s/it][I 2024-02-08 15:55:46,253] Trial 13 finished with value: 0.7604633901867804 and parameters: {'num_leaves': 110}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  35%|#################5                                | 7/20 [02:22<04:26, 20.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.948493\tvalid_0's f1score: 0.709484\tvalid_1's auc: 0.760463\tvalid_1's f1score: 0.631056\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  40%|####################                              | 8/20 [02:45<04:13, 21.10s/it][I 2024-02-08 15:56:08,716] Trial 14 finished with value: 0.7548836763633818 and parameters: {'num_leaves': 3}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  40%|####################                              | 8/20 [02:45<04:13, 21.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.802342\tvalid_0's f1score: 0.637657\tvalid_1's auc: 0.754884\tvalid_1's f1score: 0.615573\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  45%|######################5                           | 9/20 [03:13<04:16, 23.33s/it][I 2024-02-08 15:56:36,938] Trial 15 finished with value: 0.7590915903896518 and parameters: {'num_leaves': 182}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  45%|######################5                           | 9/20 [03:13<04:16, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.981618\tvalid_0's f1score: 0.763368\tvalid_1's auc: 0.759092\tvalid_1's f1score: 0.634678\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012833 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  50%|########################5                        | 10/20 [03:24<03:15, 19.59s/it][I 2024-02-08 15:56:48,139] Trial 16 finished with value: 0.759447381250107 and parameters: {'num_leaves': 66}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  50%|########################5                        | 10/20 [03:24<03:15, 19.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[43]\tvalid_0's auc: 0.867649\tvalid_0's f1score: 0.653608\tvalid_1's auc: 0.759447\tvalid_1's f1score: 0.617864\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013750 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  55%|##########################9                      | 11/20 [03:36<02:36, 17.42s/it][I 2024-02-08 15:57:00,650] Trial 17 finished with value: 0.7583884190900946 and parameters: {'num_leaves': 174}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  55%|##########################9                      | 11/20 [03:36<02:36, 17.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.938848\tvalid_0's f1score: 0.686312\tvalid_1's auc: 0.758388\tvalid_1's f1score: 0.618094\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010190 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  60%|#############################4                   | 12/20 [03:47<02:02, 15.29s/it][I 2024-02-08 15:57:11,068] Trial 18 finished with value: 0.7598130843928712 and parameters: {'num_leaves': 64}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  60%|#############################4                   | 12/20 [03:47<02:02, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.926566\tvalid_0's f1score: 0.691994\tvalid_1's auc: 0.759813\tvalid_1's f1score: 0.622749\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012181 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  65%|###############################8                 | 13/20 [03:57<01:36, 13.72s/it][I 2024-02-08 15:57:21,173] Trial 19 finished with value: 0.7531527816116951 and parameters: {'num_leaves': 150}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  65%|###############################8                 | 13/20 [03:57<01:36, 13.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's auc: 0.899256\tvalid_0's f1score: 0.627108\tvalid_1's auc: 0.753153\tvalid_1's f1score: 0.578906\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014739 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  70%|##################################3              | 14/20 [04:06<01:14, 12.39s/it][I 2024-02-08 15:57:30,487] Trial 20 finished with value: 0.7607403333470504 and parameters: {'num_leaves': 40}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  70%|##################################3              | 14/20 [04:06<01:14, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.8677\tvalid_0's f1score: 0.664487\tvalid_1's auc: 0.76074\tvalid_1's f1score: 0.62298\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011783 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.762743:  75%|####################################7            | 15/20 [04:16<00:58, 11.61s/it][I 2024-02-08 15:57:40,290] Trial 21 finished with value: 0.7597361891119286 and parameters: {'num_leaves': 84}. Best is trial 10 with value: 0.7622974627861383.\n",
      "num_leaves, val_score: 0.762743:  75%|####################################7            | 15/20 [04:16<00:58, 11.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's auc: 0.905109\tvalid_0's f1score: 0.677349\tvalid_1's auc: 0.759736\tvalid_1's f1score: 0.6221\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.765235:  80%|#######################################2         | 16/20 [04:30<00:49, 12.31s/it][I 2024-02-08 15:57:54,239] Trial 22 finished with value: 0.7652351028158991 and parameters: {'num_leaves': 28}. Best is trial 22 with value: 0.7652351028158991.\n",
      "num_leaves, val_score: 0.765235:  80%|#######################################2         | 16/20 [04:30<00:49, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009661 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.765235:  85%|#########################################6       | 17/20 [04:48<00:41, 13.85s/it][I 2024-02-08 15:58:11,660] Trial 23 finished with value: 0.7627429147456614 and parameters: {'num_leaves': 31}. Best is trial 22 with value: 0.7652351028158991.\n",
      "num_leaves, val_score: 0.765235:  85%|#########################################6       | 17/20 [04:48<00:41, 13.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's auc: 0.925723\tvalid_0's f1score: 0.695188\tvalid_1's auc: 0.762743\tvalid_1's f1score: 0.634996\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.765235:  90%|############################################1    | 18/20 [05:01<00:27, 13.69s/it][I 2024-02-08 15:58:24,986] Trial 24 finished with value: 0.7612972233895019 and parameters: {'num_leaves': 19}. Best is trial 22 with value: 0.7652351028158991.\n",
      "num_leaves, val_score: 0.765235:  90%|############################################1    | 18/20 [05:01<00:27, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.860705\tvalid_0's f1score: 0.661545\tvalid_1's auc: 0.761297\tvalid_1's f1score: 0.626927\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.765235:  95%|##############################################5  | 19/20 [05:13<00:13, 13.38s/it][I 2024-02-08 15:58:37,630] Trial 25 finished with value: 0.7630982550478298 and parameters: {'num_leaves': 93}. Best is trial 22 with value: 0.7652351028158991.\n",
      "num_leaves, val_score: 0.765235:  95%|##############################################5  | 19/20 [05:13<00:13, 13.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.951308\tvalid_0's f1score: 0.70808\tvalid_1's auc: 0.763098\tvalid_1's f1score: 0.625362\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011027 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.765235: 100%|#################################################| 20/20 [05:26<00:00, 13.13s/it][I 2024-02-08 15:58:50,196] Trial 26 finished with value: 0.7582463430436654 and parameters: {'num_leaves': 94}. Best is trial 22 with value: 0.7652351028158991.\n",
      "num_leaves, val_score: 0.765235: 100%|#################################################| 20/20 [05:26<00:00, 16.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's auc: 0.954925\tvalid_0's f1score: 0.713528\tvalid_1's auc: 0.758246\tvalid_1's f1score: 0.63214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  10%|#####3                                               | 1/10 [00:11<01:39, 11.04s/it][I 2024-02-08 15:59:01,250] Trial 27 finished with value: 0.7625431672385252 and parameters: {'bagging_fraction': 0.7874003490361077, 'bagging_freq': 2}. Best is trial 27 with value: 0.7625431672385252.\n",
      "bagging, val_score: 0.765235:  10%|#####3                                               | 1/10 [00:11<01:39, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's auc: 0.863613\tvalid_0's f1score: 0.661944\tvalid_1's auc: 0.762543\tvalid_1's f1score: 0.632381\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012281 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  20%|##########6                                          | 2/10 [00:23<01:36, 12.03s/it][I 2024-02-08 15:59:13,955] Trial 28 finished with value: 0.7596340625669267 and parameters: {'bagging_fraction': 0.4876459571782995, 'bagging_freq': 7}. Best is trial 27 with value: 0.7625431672385252.\n",
      "bagging, val_score: 0.765235:  20%|##########6                                          | 2/10 [00:23<01:36, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's auc: 0.886932\tvalid_0's f1score: 0.67042\tvalid_1's auc: 0.759634\tvalid_1's f1score: 0.629494\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009328 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  30%|###############9                                     | 3/10 [00:42<01:44, 14.93s/it][I 2024-02-08 15:59:32,342] Trial 29 finished with value: 0.7596731109517804 and parameters: {'bagging_fraction': 0.9406951240215772, 'bagging_freq': 6}. Best is trial 27 with value: 0.7625431672385252.\n",
      "bagging, val_score: 0.765235:  30%|###############9                                     | 3/10 [00:42<01:44, 14.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's auc: 0.937526\tvalid_0's f1score: 0.703589\tvalid_1's auc: 0.759673\tvalid_1's f1score: 0.633577\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012383 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  40%|#####################2                               | 4/10 [00:53<01:22, 13.69s/it][I 2024-02-08 15:59:44,136] Trial 30 finished with value: 0.761196598705456 and parameters: {'bagging_fraction': 0.408046154314539, 'bagging_freq': 1}. Best is trial 27 with value: 0.7625431672385252.\n",
      "bagging, val_score: 0.765235:  40%|#####################2                               | 4/10 [00:53<01:22, 13.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's auc: 0.871007\tvalid_0's f1score: 0.664242\tvalid_1's auc: 0.761197\tvalid_1's f1score: 0.625024\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010330 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  50%|##########################5                          | 5/10 [01:06<01:06, 13.32s/it][I 2024-02-08 15:59:56,795] Trial 31 finished with value: 0.7650128273944244 and parameters: {'bagging_fraction': 0.6311255479488541, 'bagging_freq': 4}. Best is trial 31 with value: 0.7650128273944244.\n",
      "bagging, val_score: 0.765235:  50%|##########################5                          | 5/10 [01:06<01:06, 13.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's auc: 0.88721\tvalid_0's f1score: 0.67227\tvalid_1's auc: 0.765013\tvalid_1's f1score: 0.630446\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  60%|###############################8                     | 6/10 [01:17<00:50, 12.66s/it][I 2024-02-08 16:00:08,177] Trial 32 finished with value: 0.7627324017189699 and parameters: {'bagging_fraction': 0.6385518270279522, 'bagging_freq': 4}. Best is trial 31 with value: 0.7650128273944244.\n",
      "bagging, val_score: 0.765235:  60%|###############################8                     | 6/10 [01:17<00:50, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.858949\tvalid_0's f1score: 0.659815\tvalid_1's auc: 0.762732\tvalid_1's f1score: 0.626371\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  70%|#####################################                | 7/10 [01:33<00:40, 13.52s/it][I 2024-02-08 16:00:23,468] Trial 33 finished with value: 0.7621010193731053 and parameters: {'bagging_fraction': 0.6765311622984669, 'bagging_freq': 4}. Best is trial 31 with value: 0.7650128273944244.\n",
      "bagging, val_score: 0.765235:  70%|#####################################                | 7/10 [01:33<00:40, 13.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[200]\tvalid_0's auc: 0.91042\tvalid_0's f1score: 0.683603\tvalid_1's auc: 0.762101\tvalid_1's f1score: 0.630446\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004618 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  80%|##########################################4          | 8/10 [01:45<00:26, 13.01s/it][I 2024-02-08 16:00:35,394] Trial 34 finished with value: 0.7583388576785495 and parameters: {'bagging_fraction': 0.5617721627224916, 'bagging_freq': 5}. Best is trial 31 with value: 0.7650128273944244.\n",
      "bagging, val_score: 0.765235:  80%|##########################################4          | 8/10 [01:45<00:26, 13.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.860805\tvalid_0's f1score: 0.663179\tvalid_1's auc: 0.758339\tvalid_1's f1score: 0.625024\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009828 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235:  90%|###############################################7     | 9/10 [02:04<00:14, 14.90s/it][I 2024-02-08 16:00:54,448] Trial 35 finished with value: 0.7597229727355166 and parameters: {'bagging_fraction': 0.8320729451309534, 'bagging_freq': 3}. Best is trial 31 with value: 0.7650128273944244.\n",
      "bagging, val_score: 0.765235:  90%|###############################################7     | 9/10 [02:04<00:14, 14.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.970239\tvalid_0's f1score: 0.749871\tvalid_1's auc: 0.759723\tvalid_1's f1score: 0.630341\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013408 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.765235: 100%|####################################################| 10/10 [02:16<00:00, 13.95s/it][I 2024-02-08 16:01:06,267] Trial 36 finished with value: 0.7614239804541808 and parameters: {'bagging_fraction': 0.7778156750459209, 'bagging_freq': 5}. Best is trial 31 with value: 0.7650128273944244.\n",
      "bagging, val_score: 0.765235: 100%|####################################################| 10/10 [02:16<00:00, 13.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's auc: 0.87664\tvalid_0's f1score: 0.66702\tvalid_1's auc: 0.761424\tvalid_1's f1score: 0.631295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010625 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235:  17%|######3                               | 1/6 [00:12<01:00, 12.18s/it][I 2024-02-08 16:01:18,466] Trial 37 finished with value: 0.7610530207980709 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.7610530207980709.\n",
      "feature_fraction_stage2, val_score: 0.765235:  17%|######3                               | 1/6 [00:12<01:00, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.886285\tvalid_0's f1score: 0.671279\tvalid_1's auc: 0.761053\tvalid_1's f1score: 0.631901\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005496 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235:  33%|############6                         | 2/6 [00:22<00:43, 10.99s/it][I 2024-02-08 16:01:28,600] Trial 38 finished with value: 0.7604678957696481 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.7610530207980709.\n",
      "feature_fraction_stage2, val_score: 0.765235:  33%|############6                         | 2/6 [00:22<00:43, 10.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.845611\tvalid_0's f1score: 0.652853\tvalid_1's auc: 0.760468\tvalid_1's f1score: 0.622141\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235:  50%|###################                   | 3/6 [00:39<00:41, 13.70s/it][I 2024-02-08 16:01:45,532] Trial 39 finished with value: 0.7634340711575713 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.7634340711575713.\n",
      "feature_fraction_stage2, val_score: 0.765235:  50%|###################                   | 3/6 [00:39<00:41, 13.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's auc: 0.927733\tvalid_0's f1score: 0.696095\tvalid_1's auc: 0.763434\tvalid_1's f1score: 0.629257\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010602 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235:  67%|#########################3            | 4/6 [00:51<00:26, 13.02s/it][I 2024-02-08 16:01:57,510] Trial 40 finished with value: 0.7607778798709481 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 39 with value: 0.7634340711575713.\n",
      "feature_fraction_stage2, val_score: 0.765235:  67%|#########################3            | 4/6 [00:51<00:26, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.883575\tvalid_0's f1score: 0.671875\tvalid_1's auc: 0.760778\tvalid_1's f1score: 0.627316\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010968 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235:  83%|###############################6      | 5/6 [01:01<00:12, 12.01s/it][I 2024-02-08 16:02:07,742] Trial 41 finished with value: 0.7576239718635361 and parameters: {'feature_fraction': 0.58}. Best is trial 39 with value: 0.7634340711575713.\n",
      "feature_fraction_stage2, val_score: 0.765235:  83%|###############################6      | 5/6 [01:01<00:12, 12.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.848131\tvalid_0's f1score: 0.657777\tvalid_1's auc: 0.757624\tvalid_1's f1score: 0.626063\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005621 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.765235: 100%|######################################| 6/6 [01:19<00:00, 13.90s/it][I 2024-02-08 16:02:25,307] Trial 42 finished with value: 0.7628447409184721 and parameters: {'feature_fraction': 0.42}. Best is trial 39 with value: 0.7634340711575713.\n",
      "feature_fraction_stage2, val_score: 0.765235: 100%|######################################| 6/6 [01:19<00:00, 13.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's auc: 0.927654\tvalid_0's f1score: 0.697846\tvalid_1's auc: 0.762845\tvalid_1's f1score: 0.635622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005712 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:   5%|#9                                    | 1/20 [00:15<05:01, 15.86s/it][I 2024-02-08 16:02:41,169] Trial 43 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 6.747586749644535e-07, 'lambda_l2': 1.0981342193560801e-07}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:   5%|#9                                    | 1/20 [00:15<05:01, 15.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  10%|###8                                  | 2/20 [00:30<04:37, 15.40s/it][I 2024-02-08 16:02:56,269] Trial 44 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 2.2158601978144697e-07, 'lambda_l2': 1.4746725587676466e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  10%|###8                                  | 2/20 [00:30<04:37, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009229 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  15%|#####7                                | 3/20 [00:42<03:51, 13.64s/it][I 2024-02-08 16:03:07,789] Trial 45 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 2.722806431949267e-07, 'lambda_l2': 4.447397165219726e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  15%|#####7                                | 3/20 [00:42<03:51, 13.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  20%|#######6                              | 4/20 [00:53<03:21, 12.59s/it][I 2024-02-08 16:03:18,779] Trial 46 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 1.3769849342473632e-07, 'lambda_l2': 1.78605982532164e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  20%|#######6                              | 4/20 [00:53<03:21, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  25%|#########5                            | 5/20 [01:03<02:56, 11.80s/it][I 2024-02-08 16:03:29,158] Trial 47 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 1.4397957445075333e-07, 'lambda_l2': 1.5553596437080487e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  25%|#########5                            | 5/20 [01:03<02:56, 11.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010791 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  30%|###########4                          | 6/20 [01:13<02:36, 11.20s/it][I 2024-02-08 16:03:39,209] Trial 48 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 2.7471911623913395e-07, 'lambda_l2': 2.0749209236045368e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  30%|###########4                          | 6/20 [01:13<02:36, 11.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  35%|#############3                        | 7/20 [01:24<02:22, 10.96s/it][I 2024-02-08 16:03:49,691] Trial 49 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 4.4838609529261815e-07, 'lambda_l2': 3.756106424542474e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  35%|#############3                        | 7/20 [01:24<02:22, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  40%|###############2                      | 8/20 [01:34<02:09, 10.78s/it][I 2024-02-08 16:04:00,082] Trial 50 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 1.742407377099199e-07, 'lambda_l2': 4.875658711931854e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  40%|###############2                      | 8/20 [01:34<02:09, 10.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009366 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  45%|#################1                    | 9/20 [01:44<01:56, 10.59s/it][I 2024-02-08 16:04:10,244] Trial 51 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 1.6136278727398584e-07, 'lambda_l2': 1.4768709064556156e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  45%|#################1                    | 9/20 [01:44<01:56, 10.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  50%|##################5                  | 10/20 [01:55<01:45, 10.52s/it][I 2024-02-08 16:04:20,617] Trial 52 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 1.6005409350952272e-07, 'lambda_l2': 1.3479857290796754e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  50%|##################5                  | 10/20 [01:55<01:45, 10.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  55%|####################3                | 11/20 [02:02<01:25,  9.51s/it][I 2024-02-08 16:04:27,824] Trial 53 finished with value: 0.7615486349135213 and parameters: {'lambda_l1': 4.083856684773158e-05, 'lambda_l2': 1.3128684332677396e-05}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  55%|####################3                | 11/20 [02:02<01:25,  9.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.861993\tvalid_0's f1score: 0.661448\tvalid_1's auc: 0.761549\tvalid_1's f1score: 0.626063\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007248 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  60%|######################2              | 12/20 [02:13<01:18,  9.85s/it][I 2024-02-08 16:04:38,454] Trial 54 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 1.3441942764962416e-08, 'lambda_l2': 1.5486298048413726e-06}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  60%|######################2              | 12/20 [02:13<01:18,  9.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008114 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  65%|########################             | 13/20 [02:21<01:06,  9.50s/it][I 2024-02-08 16:04:47,148] Trial 55 finished with value: 0.7607487437684034 and parameters: {'lambda_l1': 4.891400917887847, 'lambda_l2': 0.02085683451181097}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  65%|########################             | 13/20 [02:21<01:06,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.860925\tvalid_0's f1score: 0.666537\tvalid_1's auc: 0.760749\tvalid_1's f1score: 0.630104\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  70%|#########################9           | 14/20 [02:31<00:57,  9.54s/it][I 2024-02-08 16:04:56,793] Trial 56 finished with value: 0.763900248798286 and parameters: {'lambda_l1': 1.3898973612856564e-05, 'lambda_l2': 9.887070606130102e-07}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  70%|#########################9           | 14/20 [02:31<00:57,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's auc: 0.90253\tvalid_0's f1score: 0.680825\tvalid_1's auc: 0.7639\tvalid_1's f1score: 0.631422\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007642 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  75%|###########################7         | 15/20 [02:43<00:50, 10.14s/it][I 2024-02-08 16:05:08,325] Trial 57 finished with value: 0.7650410623803956 and parameters: {'lambda_l1': 3.5745490054225352e-06, 'lambda_l2': 4.888050627878989e-07}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  75%|###########################7         | 15/20 [02:43<00:50, 10.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's auc: 0.917311\tvalid_0's f1score: 0.690956\tvalid_1's auc: 0.765041\tvalid_1's f1score: 0.632022\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  80%|#############################6       | 16/20 [02:53<00:41, 10.31s/it][I 2024-02-08 16:05:19,030] Trial 58 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 2.1268218969753002e-08, 'lambda_l2': 2.0120490265207293e-07}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  80%|#############################6       | 16/20 [02:53<00:41, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008521 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  85%|###############################4     | 17/20 [03:02<00:29,  9.89s/it][I 2024-02-08 16:05:27,944] Trial 59 finished with value: 0.7615558438461097 and parameters: {'lambda_l1': 0.005572300313523764, 'lambda_l2': 6.812276617858467}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  85%|###############################4     | 17/20 [03:02<00:29,  9.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's auc: 0.863358\tvalid_0's f1score: 0.668047\tvalid_1's auc: 0.761556\tvalid_1's f1score: 0.627466\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004769 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  90%|#################################3   | 18/20 [03:13<00:20, 10.33s/it][I 2024-02-08 16:05:39,307] Trial 60 finished with value: 0.7650410623803956 and parameters: {'lambda_l1': 2.046733215717169e-06, 'lambda_l2': 1.6441646353355272e-07}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  90%|#################################3   | 18/20 [03:13<00:20, 10.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's auc: 0.917311\tvalid_0's f1score: 0.690956\tvalid_1's auc: 0.765041\tvalid_1's f1score: 0.632022\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235:  95%|###################################1 | 19/20 [03:24<00:10, 10.41s/it][I 2024-02-08 16:05:49,894] Trial 61 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 3.11119786372053e-07, 'lambda_l2': 1.0004559506600006e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235:  95%|###################################1 | 19/20 [03:24<00:10, 10.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008320 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.765235: 100%|#####################################| 20/20 [03:35<00:00, 10.49s/it][I 2024-02-08 16:06:00,568] Trial 62 finished with value: 0.7652351028158991 and parameters: {'lambda_l1': 4.637694142076834e-08, 'lambda_l2': 2.0776576683937142e-08}. Best is trial 43 with value: 0.7652351028158991.\n",
      "regularization_factors, val_score: 0.765235: 100%|#####################################| 20/20 [03:35<00:00, 10.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's auc: 0.914339\tvalid_0's f1score: 0.686823\tvalid_1's auc: 0.765235\tvalid_1's f1score: 0.630708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.765235:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008256 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.765235:  20%|########8                                   | 1/5 [00:07<00:28,  7.14s/it][I 2024-02-08 16:06:07,723] Trial 63 finished with value: 0.7597848494069 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.7597848494069.\n",
      "min_child_samples, val_score: 0.765235:  20%|########8                                   | 1/5 [00:07<00:28,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.866835\tvalid_0's f1score: 0.659677\tvalid_1's auc: 0.759785\tvalid_1's f1score: 0.626769\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008275 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.765235:  40%|#################6                          | 2/5 [00:15<00:23,  7.79s/it][I 2024-02-08 16:06:15,957] Trial 64 finished with value: 0.7631721466068606 and parameters: {'min_child_samples': 50}. Best is trial 64 with value: 0.7631721466068606.\n",
      "min_child_samples, val_score: 0.765235:  40%|#################6                          | 2/5 [00:15<00:23,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.857807\tvalid_0's f1score: 0.662267\tvalid_1's auc: 0.763172\tvalid_1's f1score: 0.631775\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008631 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.765235:  60%|##########################4                 | 3/5 [00:22<00:15,  7.53s/it][I 2024-02-08 16:06:23,162] Trial 65 finished with value: 0.7595514602143516 and parameters: {'min_child_samples': 100}. Best is trial 64 with value: 0.7631721466068606.\n",
      "min_child_samples, val_score: 0.765235:  60%|##########################4                 | 3/5 [00:22<00:15,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.835455\tvalid_0's f1score: 0.650273\tvalid_1's auc: 0.759551\tvalid_1's f1score: 0.619661\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008546 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.765235:  80%|###################################2        | 4/5 [00:34<00:09,  9.42s/it][I 2024-02-08 16:06:35,500] Trial 66 finished with value: 0.7592273586200661 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.7631721466068606.\n",
      "min_child_samples, val_score: 0.765235:  80%|###################################2        | 4/5 [00:34<00:09,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.961331\tvalid_0's f1score: 0.754808\tvalid_1's auc: 0.759227\tvalid_1's f1score: 0.633464\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008418 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5149\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.765235: 100%|############################################| 5/5 [00:45<00:00,  9.94s/it][I 2024-02-08 16:06:46,347] Trial 67 finished with value: 0.7587906174540874 and parameters: {'min_child_samples': 5}. Best is trial 64 with value: 0.7631721466068606.\n",
      "min_child_samples, val_score: 0.765235: 100%|############################################| 5/5 [00:45<00:00,  9.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's auc: 0.927001\tvalid_0's f1score: 0.687795\tvalid_1's auc: 0.758791\tvalid_1's f1score: 0.639167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2024-02-08 16:06:46,510] A new study created in memory with name: no-name-325fe60d-c3e6-4de7-beb8-684514ac2d13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.785710:  14%|######4                                      | 1/7 [00:10<01:00, 10.13s/it][I 2024-02-08 16:06:56,648] Trial 0 finished with value: 0.7857104966625235 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.7857104966625235.\n",
      "feature_fraction, val_score: 0.785710:  14%|######4                                      | 1/7 [00:10<01:00, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.887374\tvalid_0's f1score: 0.670625\tvalid_1's auc: 0.78571\tvalid_1's f1score: 0.637693\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.785710:  29%|############8                                | 2/7 [00:21<00:53, 10.64s/it][I 2024-02-08 16:07:07,645] Trial 1 finished with value: 0.7844301162449173 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.7857104966625235.\n",
      "feature_fraction, val_score: 0.785710:  29%|############8                                | 2/7 [00:21<00:53, 10.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.879902\tvalid_0's f1score: 0.665918\tvalid_1's auc: 0.78443\tvalid_1's f1score: 0.631265\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011265 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786063:  43%|###################2                         | 3/7 [00:31<00:42, 10.62s/it][I 2024-02-08 16:07:18,235] Trial 2 finished with value: 0.7860631177849474 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.7860631177849474.\n",
      "feature_fraction, val_score: 0.786063:  43%|###################2                         | 3/7 [00:31<00:42, 10.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.886283\tvalid_0's f1score: 0.668867\tvalid_1's auc: 0.786063\tvalid_1's f1score: 0.64486\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010729 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786721:  57%|#########################7                   | 4/7 [00:43<00:32, 10.94s/it][I 2024-02-08 16:07:29,676] Trial 3 finished with value: 0.7867211763641663 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.7867211763641663.\n",
      "feature_fraction, val_score: 0.786721:  57%|#########################7                   | 4/7 [00:43<00:32, 10.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's auc: 0.901826\tvalid_0's f1score: 0.675701\tvalid_1's auc: 0.786721\tvalid_1's f1score: 0.64486\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786721:  71%|################################1            | 5/7 [00:54<00:22, 11.21s/it][I 2024-02-08 16:07:41,365] Trial 4 finished with value: 0.7835764827676319 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 3 with value: 0.7867211763641663.\n",
      "feature_fraction, val_score: 0.786721:  71%|################################1            | 5/7 [00:54<00:22, 11.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.898082\tvalid_0's f1score: 0.679437\tvalid_1's auc: 0.783576\tvalid_1's f1score: 0.647047\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003988 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786721:  86%|######################################5      | 6/7 [01:10<00:12, 12.85s/it][I 2024-02-08 16:07:57,382] Trial 5 finished with value: 0.7864333280844995 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.7867211763641663.\n",
      "feature_fraction, val_score: 0.786721:  86%|######################################5      | 6/7 [01:10<00:12, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[289]\tvalid_0's auc: 0.940485\tvalid_0's f1score: 0.708043\tvalid_1's auc: 0.786433\tvalid_1's f1score: 0.648503\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004005 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786721: 100%|#############################################| 7/7 [01:21<00:00, 11.96s/it][I 2024-02-08 16:08:07,528] Trial 6 finished with value: 0.7855806717837213 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.7867211763641663.\n",
      "feature_fraction, val_score: 0.786721: 100%|#############################################| 7/7 [01:21<00:00, 11.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.872156\tvalid_0's f1score: 0.66268\tvalid_1's auc: 0.785581\tvalid_1's f1score: 0.632375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010863 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:   5%|##5                                               | 1/20 [00:13<04:21, 13.75s/it][I 2024-02-08 16:08:21,286] Trial 7 finished with value: 0.770136117895508 and parameters: {'num_leaves': 2}. Best is trial 7 with value: 0.770136117895508.\n",
      "num_leaves, val_score: 0.786721:   5%|##5                                               | 1/20 [00:13<04:21, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.775023\tvalid_0's f1score: 0.619011\tvalid_1's auc: 0.770136\tvalid_1's f1score: 0.615352\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012344 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  10%|#####                                             | 2/20 [00:34<05:18, 17.68s/it][I 2024-02-08 16:08:41,712] Trial 8 finished with value: 0.7738132330917753 and parameters: {'num_leaves': 246}. Best is trial 8 with value: 0.7738132330917753.\n",
      "num_leaves, val_score: 0.786721:  10%|#####                                             | 2/20 [00:34<05:18, 17.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.990339\tvalid_0's f1score: 0.815042\tvalid_1's auc: 0.773813\tvalid_1's f1score: 0.637398\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  15%|#######5                                          | 3/20 [00:45<04:13, 14.92s/it][I 2024-02-08 16:08:53,339] Trial 9 finished with value: 0.7862958253902843 and parameters: {'num_leaves': 22}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  15%|#######5                                          | 3/20 [00:45<04:13, 14.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.874064\tvalid_0's f1score: 0.665862\tvalid_1's auc: 0.786296\tvalid_1's f1score: 0.642432\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005575 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  20%|##########                                        | 4/20 [01:04<04:23, 16.47s/it][I 2024-02-08 16:09:12,196] Trial 10 finished with value: 0.7756829905398146 and parameters: {'num_leaves': 186}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  20%|##########                                        | 4/20 [01:04<04:23, 16.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.985668\tvalid_0's f1score: 0.789825\tvalid_1's auc: 0.775683\tvalid_1's f1score: 0.639628\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010490 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  25%|############5                                     | 5/20 [01:19<03:57, 15.84s/it][I 2024-02-08 16:09:26,914] Trial 11 finished with value: 0.7817476271362475 and parameters: {'num_leaves': 107}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  25%|############5                                     | 5/20 [01:19<03:57, 15.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.947033\tvalid_0's f1score: 0.704241\tvalid_1's auc: 0.781748\tvalid_1's f1score: 0.645806\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011200 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  30%|###############                                   | 6/20 [01:40<04:04, 17.49s/it][I 2024-02-08 16:09:47,608] Trial 12 finished with value: 0.7803223454023007 and parameters: {'num_leaves': 88}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  30%|###############                                   | 6/20 [01:40<04:04, 17.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.980832\tvalid_0's f1score: 0.783216\tvalid_1's auc: 0.780322\tvalid_1's f1score: 0.646085\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.022445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  35%|#################5                                | 7/20 [02:03<04:11, 19.35s/it][I 2024-02-08 16:10:10,804] Trial 13 finished with value: 0.7792237198150177 and parameters: {'num_leaves': 178}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  35%|#################5                                | 7/20 [02:03<04:11, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's auc: 0.976054\tvalid_0's f1score: 0.748366\tvalid_1's auc: 0.779224\tvalid_1's f1score: 0.642811\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  40%|####################                              | 8/20 [02:40<04:59, 24.96s/it][I 2024-02-08 16:10:47,761] Trial 14 finished with value: 0.7771211151649976 and parameters: {'num_leaves': 252}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  40%|####################                              | 8/20 [02:40<04:59, 24.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.993972\tvalid_0's f1score: 0.852004\tvalid_1's auc: 0.777121\tvalid_1's f1score: 0.633929\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018807 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  45%|######################5                           | 9/20 [02:56<04:06, 22.40s/it][I 2024-02-08 16:11:04,518] Trial 15 finished with value: 0.7840490174071431 and parameters: {'num_leaves': 61}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  45%|######################5                           | 9/20 [02:57<04:06, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.92826\tvalid_0's f1score: 0.692443\tvalid_1's auc: 0.784049\tvalid_1's f1score: 0.638452\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016423 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  50%|########################5                        | 10/20 [03:25<04:03, 24.35s/it][I 2024-02-08 16:11:33,254] Trial 16 finished with value: 0.7805130344178317 and parameters: {'num_leaves': 162}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  50%|########################5                        | 10/20 [03:25<04:03, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.976566\tvalid_0's f1score: 0.753\tvalid_1's auc: 0.780513\tvalid_1's f1score: 0.643085\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018820 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  55%|##########################9                      | 11/20 [03:53<03:49, 25.54s/it][I 2024-02-08 16:12:01,478] Trial 17 finished with value: 0.7834708081082198 and parameters: {'num_leaves': 149}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  55%|##########################9                      | 11/20 [03:53<03:49, 25.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.981363\tvalid_0's f1score: 0.76466\tvalid_1's auc: 0.783471\tvalid_1's f1score: 0.642639\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016997 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  60%|#############################4                   | 12/20 [04:18<03:20, 25.12s/it][I 2024-02-08 16:12:25,653] Trial 18 finished with value: 0.7733691761676142 and parameters: {'num_leaves': 218}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  60%|#############################4                   | 12/20 [04:18<03:20, 25.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.889585\tvalid_0's f1score: 0.505148\tvalid_1's auc: 0.773369\tvalid_1's f1score: 0.488607\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  65%|###############################8                 | 13/20 [04:44<02:58, 25.47s/it][I 2024-02-08 16:12:51,937] Trial 19 finished with value: 0.7862504564810254 and parameters: {'num_leaves': 37}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  65%|###############################8                 | 13/20 [04:44<02:58, 25.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[243]\tvalid_0's auc: 0.950947\tvalid_0's f1score: 0.720394\tvalid_1's auc: 0.78625\tvalid_1's f1score: 0.640748\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006909 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  70%|##################################3              | 14/20 [04:58<02:12, 22.15s/it][I 2024-02-08 16:13:06,413] Trial 20 finished with value: 0.7803377010331268 and parameters: {'num_leaves': 116}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  70%|##################################3              | 14/20 [04:58<02:12, 22.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.964215\tvalid_0's f1score: 0.726404\tvalid_1's auc: 0.780338\tvalid_1's f1score: 0.647525\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  75%|####################################7            | 15/20 [05:15<01:42, 20.52s/it][I 2024-02-08 16:13:23,137] Trial 21 finished with value: 0.7807654251499547 and parameters: {'num_leaves': 8}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  75%|####################################7            | 15/20 [05:15<01:42, 20.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.876533\tvalid_0's f1score: 0.666768\tvalid_1's auc: 0.780765\tvalid_1's f1score: 0.642367\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006637 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  80%|#######################################2         | 16/20 [05:27<01:11, 17.81s/it][I 2024-02-08 16:13:34,649] Trial 22 finished with value: 0.7822370529696673 and parameters: {'num_leaves': 53}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  80%|#######################################2         | 16/20 [05:27<01:11, 17.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.918381\tvalid_0's f1score: 0.686555\tvalid_1's auc: 0.782237\tvalid_1's f1score: 0.64704\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013002 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  85%|#########################################6       | 17/20 [05:42<00:51, 17.06s/it][I 2024-02-08 16:13:49,966] Trial 23 finished with value: 0.7803223454023007 and parameters: {'num_leaves': 88}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  85%|#########################################6       | 17/20 [05:42<00:51, 17.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's auc: 0.980832\tvalid_0's f1score: 0.783216\tvalid_1's auc: 0.780322\tvalid_1's f1score: 0.646085\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  90%|############################################1    | 18/20 [05:57<00:33, 16.54s/it][I 2024-02-08 16:14:05,295] Trial 24 finished with value: 0.7838167285917379 and parameters: {'num_leaves': 25}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  90%|############################################1    | 18/20 [05:57<00:33, 16.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's auc: 0.923006\tvalid_0's f1score: 0.694058\tvalid_1's auc: 0.783817\tvalid_1's f1score: 0.644144\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010705 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721:  95%|##############################################5  | 19/20 [06:11<00:15, 15.59s/it][I 2024-02-08 16:14:18,673] Trial 25 finished with value: 0.7833476838683235 and parameters: {'num_leaves': 66}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721:  95%|##############################################5  | 19/20 [06:11<00:15, 15.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.953554\tvalid_0's f1score: 0.716064\tvalid_1's auc: 0.783348\tvalid_1's f1score: 0.649473\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011056 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786721: 100%|#################################################| 20/20 [06:25<00:00, 15.36s/it][I 2024-02-08 16:14:33,512] Trial 26 finished with value: 0.7786524903482881 and parameters: {'num_leaves': 129}. Best is trial 9 with value: 0.7862958253902843.\n",
      "num_leaves, val_score: 0.786721: 100%|#################################################| 20/20 [06:25<00:00, 19.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.98028\tvalid_0's f1score: 0.760637\tvalid_1's auc: 0.778652\tvalid_1's f1score: 0.645821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786721:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786721:  10%|#####3                                               | 1/10 [00:12<01:55, 12.86s/it][I 2024-02-08 16:14:46,378] Trial 27 finished with value: 0.7832857029584438 and parameters: {'bagging_fraction': 0.7549854006526472, 'bagging_freq': 6}. Best is trial 27 with value: 0.7832857029584438.\n",
      "bagging, val_score: 0.786721:  10%|#####3                                               | 1/10 [00:12<01:55, 12.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's auc: 0.903219\tvalid_0's f1score: 0.679309\tvalid_1's auc: 0.783286\tvalid_1's f1score: 0.638218\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786721:  20%|##########6                                          | 2/10 [00:26<01:45, 13.19s/it][I 2024-02-08 16:14:59,795] Trial 28 finished with value: 0.7843136926439269 and parameters: {'bagging_fraction': 0.4046800085961927, 'bagging_freq': 1}. Best is trial 28 with value: 0.7843136926439269.\n",
      "bagging, val_score: 0.786721:  20%|##########6                                          | 2/10 [00:26<01:45, 13.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's auc: 0.907797\tvalid_0's f1score: 0.673046\tvalid_1's auc: 0.784314\tvalid_1's f1score: 0.636094\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011331 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786721:  30%|###############9                                     | 3/10 [00:38<01:28, 12.61s/it][I 2024-02-08 16:15:11,731] Trial 29 finished with value: 0.7844856757091788 and parameters: {'bagging_fraction': 0.990424956715904, 'bagging_freq': 2}. Best is trial 29 with value: 0.7844856757091788.\n",
      "bagging, val_score: 0.786721:  30%|###############9                                     | 3/10 [00:38<01:28, 12.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.881544\tvalid_0's f1score: 0.670236\tvalid_1's auc: 0.784486\tvalid_1's f1score: 0.63416\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786721:  40%|#####################2                               | 4/10 [00:48<01:10, 11.76s/it][I 2024-02-08 16:15:22,193] Trial 30 finished with value: 0.7754495849512585 and parameters: {'bagging_fraction': 0.40651278143174585, 'bagging_freq': 7}. Best is trial 29 with value: 0.7844856757091788.\n",
      "bagging, val_score: 0.786721:  40%|#####################2                               | 4/10 [00:48<01:10, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.845293\tvalid_0's f1score: 0.651113\tvalid_1's auc: 0.77545\tvalid_1's f1score: 0.624751\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005625 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786721:  50%|##########################5                          | 5/10 [01:01<01:01, 12.31s/it][I 2024-02-08 16:15:35,468] Trial 31 finished with value: 0.7841905684040307 and parameters: {'bagging_fraction': 0.6951006445017279, 'bagging_freq': 4}. Best is trial 29 with value: 0.7844856757091788.\n",
      "bagging, val_score: 0.786721:  50%|##########################5                          | 5/10 [01:01<01:01, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.865884\tvalid_0's f1score: 0.660331\tvalid_1's auc: 0.784191\tvalid_1's f1score: 0.632512\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010386 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786830:  60%|###############################8                     | 6/10 [01:16<00:52, 13.12s/it][I 2024-02-08 16:15:50,142] Trial 32 finished with value: 0.7868297825530998 and parameters: {'bagging_fraction': 0.9878013731812332, 'bagging_freq': 4}. Best is trial 32 with value: 0.7868297825530998.\n",
      "bagging, val_score: 0.786830:  60%|###############################8                     | 6/10 [01:16<00:52, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.888855\tvalid_0's f1score: 0.670263\tvalid_1's auc: 0.78683\tvalid_1's f1score: 0.636631\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012419 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786830:  70%|#####################################                | 7/10 [01:34<00:43, 14.55s/it][I 2024-02-08 16:16:07,667] Trial 33 finished with value: 0.7845839517464657 and parameters: {'bagging_fraction': 0.9916794223589551, 'bagging_freq': 4}. Best is trial 32 with value: 0.7868297825530998.\n",
      "bagging, val_score: 0.786830:  70%|#####################################                | 7/10 [01:34<00:43, 14.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's auc: 0.918542\tvalid_0's f1score: 0.683981\tvalid_1's auc: 0.784584\tvalid_1's f1score: 0.642401\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015961 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786830:  80%|##########################################4          | 8/10 [01:48<00:28, 14.41s/it][I 2024-02-08 16:16:21,765] Trial 34 finished with value: 0.7787111209387149 and parameters: {'bagging_fraction': 0.7888158519258013, 'bagging_freq': 5}. Best is trial 32 with value: 0.7868297825530998.\n",
      "bagging, val_score: 0.786830:  80%|##########################################4          | 8/10 [01:48<00:28, 14.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.878654\tvalid_0's f1score: 0.666173\tvalid_1's auc: 0.778711\tvalid_1's f1score: 0.633154\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011966 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.786830:  90%|###############################################7     | 9/10 [02:03<00:14, 14.74s/it][I 2024-02-08 16:16:37,257] Trial 35 finished with value: 0.7835704801119453 and parameters: {'bagging_fraction': 0.8657275062116052, 'bagging_freq': 3}. Best is trial 32 with value: 0.7868297825530998.\n",
      "bagging, val_score: 0.786830:  90%|###############################################7     | 9/10 [02:03<00:14, 14.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's auc: 0.904935\tvalid_0's f1score: 0.67837\tvalid_1's auc: 0.78357\tvalid_1's f1score: 0.64534\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.788933: 100%|####################################################| 10/10 [02:23<00:00, 16.27s/it][I 2024-02-08 16:16:56,932] Trial 36 finished with value: 0.7889332247829831 and parameters: {'bagging_fraction': 0.5837314618778084, 'bagging_freq': 3}. Best is trial 36 with value: 0.7889332247829831.\n",
      "bagging, val_score: 0.788933: 100%|####################################################| 10/10 [02:23<00:00, 14.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.788933:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.788933:  33%|############6                         | 1/3 [00:17<00:34, 17.45s/it][I 2024-02-08 16:17:14,389] Trial 37 finished with value: 0.784069956903724 and parameters: {'feature_fraction': 0.92}. Best is trial 37 with value: 0.784069956903724.\n",
      "feature_fraction_stage2, val_score: 0.788933:  33%|############6                         | 1/3 [00:17<00:34, 17.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.893042\tvalid_0's f1score: 0.669811\tvalid_1's auc: 0.78407\tvalid_1's f1score: 0.638162\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011757 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.788933:  67%|#########################3            | 2/3 [00:35<00:17, 17.85s/it][I 2024-02-08 16:17:32,504] Trial 38 finished with value: 0.7836494918123776 and parameters: {'feature_fraction': 0.9840000000000001}. Best is trial 37 with value: 0.784069956903724.\n",
      "feature_fraction_stage2, val_score: 0.788933:  67%|#########################3            | 2/3 [00:35<00:17, 17.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's auc: 0.905393\tvalid_0's f1score: 0.67577\tvalid_1's auc: 0.783649\tvalid_1's f1score: 0.64118\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.788933: 100%|######################################| 3/3 [00:53<00:00, 17.67s/it][I 2024-02-08 16:17:49,967] Trial 39 finished with value: 0.7843519421243482 and parameters: {'feature_fraction': 0.9520000000000001}. Best is trial 39 with value: 0.7843519421243482.\n",
      "feature_fraction_stage2, val_score: 0.788933: 100%|######################################| 3/3 [00:53<00:00, 17.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.895265\tvalid_0's f1score: 0.674508\tvalid_1's auc: 0.784352\tvalid_1's f1score: 0.640748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014039 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:   5%|#9                                    | 1/20 [00:19<06:10, 19.51s/it][I 2024-02-08 16:18:09,476] Trial 40 finished with value: 0.7833443335488706 and parameters: {'lambda_l1': 0.03312085918497663, 'lambda_l2': 0.0010317717024815553}. Best is trial 40 with value: 0.7833443335488706.\n",
      "regularization_factors, val_score: 0.788933:   5%|#9                                    | 1/20 [00:19<06:10, 19.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's auc: 0.914923\tvalid_0's f1score: 0.681097\tvalid_1's auc: 0.783344\tvalid_1's f1score: 0.638973\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012980 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  10%|###8                                  | 2/20 [00:34<05:03, 16.89s/it][I 2024-02-08 16:18:24,530] Trial 41 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.9850736602792e-07, 'lambda_l2': 1.8295476815460035e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  10%|###8                                  | 2/20 [00:34<05:03, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  15%|#####7                                | 3/20 [00:47<04:19, 15.27s/it][I 2024-02-08 16:18:37,881] Trial 42 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.555222958547818e-08, 'lambda_l2': 1.255703539623557e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  15%|#####7                                | 3/20 [00:47<04:19, 15.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  20%|#######6                              | 4/20 [00:59<03:43, 13.96s/it][I 2024-02-08 16:18:49,821] Trial 43 finished with value: 0.7882670695984195 and parameters: {'lambda_l1': 2.710374484129673e-08, 'lambda_l2': 1.2392925343605666e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  20%|#######6                              | 4/20 [00:59<03:43, 13.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.934694\tvalid_0's f1score: 0.69306\tvalid_1's auc: 0.788267\tvalid_1's f1score: 0.636762\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  25%|#########5                            | 5/20 [01:12<03:21, 13.41s/it][I 2024-02-08 16:19:02,261] Trial 44 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.4863768266563638e-08, 'lambda_l2': 2.1071270031103646e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  25%|#########5                            | 5/20 [01:12<03:21, 13.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  30%|###########4                          | 6/20 [01:24<03:02, 13.03s/it][I 2024-02-08 16:19:14,549] Trial 45 finished with value: 0.7882670695984195 and parameters: {'lambda_l1': 1.5145559154811948e-08, 'lambda_l2': 1.3564810752541586e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  30%|###########4                          | 6/20 [01:24<03:02, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.934694\tvalid_0's f1score: 0.69306\tvalid_1's auc: 0.788267\tvalid_1's f1score: 0.636762\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  35%|#############3                        | 7/20 [01:37<02:48, 12.96s/it][I 2024-02-08 16:19:27,366] Trial 46 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.294457138400526e-08, 'lambda_l2': 1.257919866177008e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  35%|#############3                        | 7/20 [01:37<02:48, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009843 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  40%|###############2                      | 8/20 [01:51<02:40, 13.39s/it][I 2024-02-08 16:19:41,669] Trial 47 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.7193232593348623e-08, 'lambda_l2': 1.2549723379538109e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  40%|###############2                      | 8/20 [01:51<02:40, 13.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013796 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  45%|#################1                    | 9/20 [02:07<02:35, 14.12s/it][I 2024-02-08 16:19:57,409] Trial 48 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.3548116623152842e-08, 'lambda_l2': 4.4070264324824054e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  45%|#################1                    | 9/20 [02:07<02:35, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  50%|##################5                  | 10/20 [02:22<02:25, 14.51s/it][I 2024-02-08 16:20:12,803] Trial 49 finished with value: 0.7882670695984195 and parameters: {'lambda_l1': 5.313766909212721e-06, 'lambda_l2': 2.4198789640135926e-06}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  50%|##################5                  | 10/20 [02:22<02:25, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.934694\tvalid_0's f1score: 0.69306\tvalid_1's auc: 0.788267\tvalid_1's f1score: 0.636762\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013598 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  55%|####################3                | 11/20 [02:36<02:07, 14.16s/it][I 2024-02-08 16:20:26,149] Trial 50 finished with value: 0.7808838031039593 and parameters: {'lambda_l1': 1.9330853468234737e-06, 'lambda_l2': 0.5495518168755535}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  55%|####################3                | 11/20 [02:36<02:07, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's auc: 0.911144\tvalid_0's f1score: 0.679955\tvalid_1's auc: 0.780884\tvalid_1's f1score: 0.644144\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  60%|######################2              | 12/20 [02:52<01:58, 14.83s/it][I 2024-02-08 16:20:42,507] Trial 51 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.1738633829911034e-08, 'lambda_l2': 1.420552594059096e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  60%|######################2              | 12/20 [02:52<01:58, 14.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014201 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  65%|########################             | 13/20 [03:08<01:46, 15.26s/it][I 2024-02-08 16:20:58,762] Trial 52 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 3.416667070951817e-07, 'lambda_l2': 5.816399746313789e-07}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  65%|########################             | 13/20 [03:08<01:46, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  70%|#########################9           | 14/20 [03:24<01:31, 15.31s/it][I 2024-02-08 16:21:14,181] Trial 53 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.555724515717947e-07, 'lambda_l2': 2.4957924642865765e-07}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  70%|#########################9           | 14/20 [03:24<01:31, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010116 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  75%|###########################7         | 15/20 [03:39<01:16, 15.29s/it][I 2024-02-08 16:21:29,433] Trial 54 finished with value: 0.7882670695984195 and parameters: {'lambda_l1': 1.490801248815801e-07, 'lambda_l2': 1.260824036216318e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  75%|###########################7         | 15/20 [03:39<01:16, 15.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's auc: 0.934694\tvalid_0's f1score: 0.69306\tvalid_1's auc: 0.788267\tvalid_1's f1score: 0.636762\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  80%|#############################6       | 16/20 [03:54<01:01, 15.34s/it][I 2024-02-08 16:21:44,882] Trial 55 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 1.2184534950762011e-08, 'lambda_l2': 3.192238445045921e-06}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  80%|#############################6       | 16/20 [03:54<01:01, 15.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012053 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  85%|###############################4     | 17/20 [04:10<00:46, 15.40s/it][I 2024-02-08 16:22:00,405] Trial 56 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 2.6242142367308257e-05, 'lambda_l2': 1.9733953070683505e-07}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  85%|###############################4     | 17/20 [04:10<00:46, 15.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012648 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  90%|#################################3   | 18/20 [04:26<00:31, 15.51s/it][I 2024-02-08 16:22:16,189] Trial 57 finished with value: 0.7889332247829831 and parameters: {'lambda_l1': 2.651951022252874e-07, 'lambda_l2': 1.4327157245295362e-07}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  90%|#################################3   | 18/20 [04:26<00:31, 15.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's auc: 0.938882\tvalid_0's f1score: 0.696466\tvalid_1's auc: 0.788933\tvalid_1's f1score: 0.632781\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019142 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933:  95%|###################################1 | 19/20 [04:40<00:15, 15.23s/it][I 2024-02-08 16:22:30,780] Trial 58 finished with value: 0.7868677528402334 and parameters: {'lambda_l1': 0.02467590126221716, 'lambda_l2': 2.9512485227992404e-05}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933:  95%|###################################1 | 19/20 [04:40<00:15, 15.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's auc: 0.932191\tvalid_0's f1score: 0.691711\tvalid_1's auc: 0.786868\tvalid_1's f1score: 0.642669\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012207 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.788933: 100%|#####################################| 20/20 [04:56<00:00, 15.36s/it][I 2024-02-08 16:22:46,456] Trial 59 finished with value: 0.7821454775712864 and parameters: {'lambda_l1': 8.662389010499528, 'lambda_l2': 8.924231404337222e-08}. Best is trial 41 with value: 0.7889332247829831.\n",
      "regularization_factors, val_score: 0.788933: 100%|#####################################| 20/20 [04:56<00:00, 14.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.873819\tvalid_0's f1score: 0.671463\tvalid_1's auc: 0.782145\tvalid_1's f1score: 0.630324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.788933:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010519 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.788933:  20%|########8                                   | 1/5 [00:14<00:59, 15.00s/it][I 2024-02-08 16:23:01,467] Trial 60 finished with value: 0.7858914139129832 and parameters: {'min_child_samples': 10}. Best is trial 60 with value: 0.7858914139129832.\n",
      "min_child_samples, val_score: 0.788933:  20%|########8                                   | 1/5 [00:15<00:59, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's auc: 0.934419\tvalid_0's f1score: 0.688197\tvalid_1's auc: 0.785891\tvalid_1's f1score: 0.6441\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013010 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.788933:  40%|#################6                          | 2/5 [00:27<00:41, 13.76s/it][I 2024-02-08 16:23:14,352] Trial 61 finished with value: 0.7871033919750915 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.7871033919750915.\n",
      "min_child_samples, val_score: 0.788933:  40%|#################6                          | 2/5 [00:27<00:41, 13.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.906532\tvalid_0's f1score: 0.679736\tvalid_1's auc: 0.787103\tvalid_1's f1score: 0.638973\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011634 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.788933:  60%|##########################4                 | 3/5 [00:41<00:27, 13.66s/it][I 2024-02-08 16:23:27,908] Trial 62 finished with value: 0.7850063711908264 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 0.7871033919750915.\n",
      "min_child_samples, val_score: 0.788933:  60%|##########################4                 | 3/5 [00:41<00:27, 13.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.892908\tvalid_0's f1score: 0.680658\tvalid_1's auc: 0.785006\tvalid_1's f1score: 0.644362\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010433 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.788933:  80%|###################################2        | 4/5 [00:52<00:12, 12.45s/it][I 2024-02-08 16:23:38,481] Trial 63 finished with value: 0.7819553469423309 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.7871033919750915.\n",
      "min_child_samples, val_score: 0.788933:  80%|###################################2        | 4/5 [00:52<00:12, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.850563\tvalid_0's f1score: 0.65571\tvalid_1's auc: 0.781955\tvalid_1's f1score: 0.631724\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007723 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.788933: 100%|############################################| 5/5 [01:06<00:00, 13.10s/it][I 2024-02-08 16:23:52,735] Trial 64 finished with value: 0.7816406961070405 and parameters: {'min_child_samples': 5}. Best is trial 61 with value: 0.7871033919750915.\n",
      "min_child_samples, val_score: 0.788933: 100%|############################################| 5/5 [01:06<00:00, 13.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's auc: 0.939094\tvalid_0's f1score: 0.685778\tvalid_1's auc: 0.781641\tvalid_1's f1score: 0.646325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2024-02-08 16:23:52,950] A new study created in memory with name: no-name-e5ed3ab1-462f-4988-976a-e27f596d6baf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005047 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.781927:  14%|######4                                      | 1/7 [00:12<01:14, 12.48s/it][I 2024-02-08 16:24:05,429] Trial 0 finished with value: 0.7819272701206968 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.7819272701206968.\n",
      "feature_fraction, val_score: 0.781927:  14%|######4                                      | 1/7 [00:12<01:14, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.900963\tvalid_0's f1score: 0.676608\tvalid_1's auc: 0.781927\tvalid_1's f1score: 0.642606\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010786 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783587:  29%|############8                                | 2/7 [00:25<01:03, 12.69s/it][I 2024-02-08 16:24:18,278] Trial 1 finished with value: 0.7835873072581967 and parameters: {'feature_fraction': 0.4}. Best is trial 1 with value: 0.7835873072581967.\n",
      "feature_fraction, val_score: 0.783587:  29%|############8                                | 2/7 [00:25<01:03, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's auc: 0.907595\tvalid_0's f1score: 0.679091\tvalid_1's auc: 0.783587\tvalid_1's f1score: 0.638752\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016197 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783587:  43%|###################2                         | 3/7 [00:36<00:48, 12.17s/it][I 2024-02-08 16:24:29,832] Trial 2 finished with value: 0.7828904102419398 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7835873072581967.\n",
      "feature_fraction, val_score: 0.783587:  43%|###################2                         | 3/7 [00:36<00:48, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.901949\tvalid_0's f1score: 0.676363\tvalid_1's auc: 0.78289\tvalid_1's f1score: 0.63774\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009638 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783587:  57%|#########################7                   | 4/7 [00:44<00:30, 10.19s/it][I 2024-02-08 16:24:36,994] Trial 3 finished with value: 0.7816132397917387 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7835873072581967.\n",
      "feature_fraction, val_score: 0.783587:  57%|#########################7                   | 4/7 [00:44<00:30, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.878229\tvalid_0's f1score: 0.664337\tvalid_1's auc: 0.781613\tvalid_1's f1score: 0.637032\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.784038:  71%|################################1            | 5/7 [00:55<00:21, 10.53s/it][I 2024-02-08 16:24:48,117] Trial 4 finished with value: 0.7840384414083122 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.7840384414083122.\n",
      "feature_fraction, val_score: 0.784038:  71%|################################1            | 5/7 [00:55<00:21, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[284]\tvalid_0's auc: 0.942125\tvalid_0's f1score: 0.707387\tvalid_1's auc: 0.784038\tvalid_1's f1score: 0.63996\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008040 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.784038:  86%|######################################5      | 6/7 [01:01<00:09,  9.19s/it][I 2024-02-08 16:24:54,701] Trial 5 finished with value: 0.7780104244415722 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.7840384414083122.\n",
      "feature_fraction, val_score: 0.784038:  86%|######################################5      | 6/7 [01:01<00:09,  9.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.893647\tvalid_0's f1score: 0.670518\tvalid_1's auc: 0.77801\tvalid_1's f1score: 0.645304\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.784038: 100%|#############################################| 7/7 [01:08<00:00,  8.31s/it][I 2024-02-08 16:25:01,203] Trial 6 finished with value: 0.780608570297282 and parameters: {'feature_fraction': 0.8}. Best is trial 4 with value: 0.7840384414083122.\n",
      "feature_fraction, val_score: 0.784038: 100%|#############################################| 7/7 [01:08<00:00,  9.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.88456\tvalid_0's f1score: 0.670832\tvalid_1's auc: 0.780609\tvalid_1's f1score: 0.636398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009347 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:   5%|##5                                               | 1/20 [00:06<02:06,  6.65s/it][I 2024-02-08 16:25:07,880] Trial 7 finished with value: 0.7831393020334602 and parameters: {'num_leaves': 61}. Best is trial 7 with value: 0.7831393020334602.\n",
      "num_leaves, val_score: 0.784038:   5%|##5                                               | 1/20 [00:06<02:06,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's auc: 0.936728\tvalid_0's f1score: 0.696515\tvalid_1's auc: 0.783139\tvalid_1's f1score: 0.639678\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  10%|#####                                             | 2/20 [00:11<01:41,  5.66s/it][I 2024-02-08 16:25:12,855] Trial 8 finished with value: 0.7813370410150917 and parameters: {'num_leaves': 45}. Best is trial 7 with value: 0.7831393020334602.\n",
      "num_leaves, val_score: 0.784038:  10%|#####                                             | 2/20 [00:11<01:41,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.844691\tvalid_0's f1score: 0.636294\tvalid_1's auc: 0.781337\tvalid_1's f1score: 0.612972\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006972 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  15%|#######5                                          | 3/20 [00:16<01:31,  5.36s/it][I 2024-02-08 16:25:17,834] Trial 9 finished with value: 0.781647657970909 and parameters: {'num_leaves': 126}. Best is trial 7 with value: 0.7831393020334602.\n",
      "num_leaves, val_score: 0.784038:  15%|#######5                                          | 3/20 [00:16<01:31,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.880241\tvalid_0's f1score: 0.588144\tvalid_1's auc: 0.781648\tvalid_1's f1score: 0.552268\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  20%|##########                                        | 4/20 [00:22<01:29,  5.59s/it][I 2024-02-08 16:25:23,785] Trial 10 finished with value: 0.7804497062223517 and parameters: {'num_leaves': 223}. Best is trial 7 with value: 0.7831393020334602.\n",
      "num_leaves, val_score: 0.784038:  20%|##########                                        | 4/20 [00:22<01:29,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.90559\tvalid_0's f1score: 0.516924\tvalid_1's auc: 0.78045\tvalid_1's f1score: 0.501901\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008052 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  25%|############5                                     | 5/20 [00:28<01:26,  5.78s/it][I 2024-02-08 16:25:29,919] Trial 11 finished with value: 0.7783076723525878 and parameters: {'num_leaves': 243}. Best is trial 7 with value: 0.7831393020334602.\n",
      "num_leaves, val_score: 0.784038:  25%|############5                                     | 5/20 [00:28<01:26,  5.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's auc: 0.911097\tvalid_0's f1score: 0.521001\tvalid_1's auc: 0.778308\tvalid_1's f1score: 0.500241\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008787 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  30%|###############                                   | 6/20 [00:34<01:22,  5.86s/it][I 2024-02-08 16:25:35,908] Trial 12 finished with value: 0.7812036350148368 and parameters: {'num_leaves': 159}. Best is trial 7 with value: 0.7831393020334602.\n",
      "num_leaves, val_score: 0.784038:  30%|###############                                   | 6/20 [00:34<01:22,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's auc: 0.918056\tvalid_0's f1score: 0.65681\tvalid_1's auc: 0.781204\tvalid_1's f1score: 0.59769\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  35%|#################5                                | 7/20 [00:42<01:22,  6.36s/it][I 2024-02-08 16:25:43,307] Trial 13 finished with value: 0.7840074366022829 and parameters: {'num_leaves': 9}. Best is trial 13 with value: 0.7840074366022829.\n",
      "num_leaves, val_score: 0.784038:  35%|#################5                                | 7/20 [00:42<01:22,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's auc: 0.838378\tvalid_0's f1score: 0.65424\tvalid_1's auc: 0.784007\tvalid_1's f1score: 0.632512\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006577 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  40%|####################                              | 8/20 [00:50<01:24,  7.00s/it][I 2024-02-08 16:25:51,673] Trial 14 finished with value: 0.7696883362764195 and parameters: {'num_leaves': 2}. Best is trial 13 with value: 0.7840074366022829.\n",
      "num_leaves, val_score: 0.784038:  40%|####################                              | 8/20 [00:50<01:24,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.774602\tvalid_0's f1score: 0.621635\tvalid_1's auc: 0.769688\tvalid_1's f1score: 0.615145\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  45%|######################5                           | 9/20 [00:55<01:11,  6.52s/it][I 2024-02-08 16:25:57,139] Trial 15 finished with value: 0.7804943645209445 and parameters: {'num_leaves': 107}. Best is trial 13 with value: 0.7840074366022829.\n",
      "num_leaves, val_score: 0.784038:  45%|######################5                           | 9/20 [00:55<01:11,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.880025\tvalid_0's f1score: 0.628089\tvalid_1's auc: 0.780494\tvalid_1's f1score: 0.588648\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  50%|########################5                        | 10/20 [01:02<01:04,  6.41s/it][I 2024-02-08 16:26:03,300] Trial 16 finished with value: 0.7837485891391018 and parameters: {'num_leaves': 16}. Best is trial 13 with value: 0.7840074366022829.\n",
      "num_leaves, val_score: 0.784038:  50%|########################5                        | 10/20 [01:02<01:04,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.837051\tvalid_0's f1score: 0.655053\tvalid_1's auc: 0.783749\tvalid_1's f1score: 0.635711\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007885 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784038:  55%|##########################9                      | 11/20 [01:07<00:56,  6.24s/it][I 2024-02-08 16:26:09,152] Trial 17 finished with value: 0.7781734130090477 and parameters: {'num_leaves': 171}. Best is trial 13 with value: 0.7840074366022829.\n",
      "num_leaves, val_score: 0.784038:  55%|##########################9                      | 11/20 [01:07<00:56,  6.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.881985\tvalid_0's f1score: 0.488556\tvalid_1's auc: 0.778173\tvalid_1's f1score: 0.491579\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007915 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  60%|#############################4                   | 12/20 [01:14<00:49,  6.21s/it][I 2024-02-08 16:26:15,305] Trial 18 finished with value: 0.7845473184540606 and parameters: {'num_leaves': 79}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  60%|#############################4                   | 12/20 [01:14<00:49,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.920395\tvalid_0's f1score: 0.684975\tvalid_1's auc: 0.784547\tvalid_1's f1score: 0.637436\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007456 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  65%|###############################8                 | 13/20 [01:20<00:43,  6.20s/it][I 2024-02-08 16:26:21,461] Trial 19 finished with value: 0.7843763653492564 and parameters: {'num_leaves': 89}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  65%|###############################8                 | 13/20 [01:20<00:43,  6.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.932276\tvalid_0's f1score: 0.688424\tvalid_1's auc: 0.784376\tvalid_1's f1score: 0.62968\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  70%|##################################3              | 14/20 [01:25<00:34,  5.77s/it][I 2024-02-08 16:26:26,249] Trial 20 finished with value: 0.7807579053721942 and parameters: {'num_leaves': 86}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  70%|##################################3              | 14/20 [01:25<00:34,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.900041\tvalid_0's f1score: 0.668088\tvalid_1's auc: 0.780758\tvalid_1's f1score: 0.625059\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  75%|####################################7            | 15/20 [01:30<00:28,  5.68s/it][I 2024-02-08 16:26:31,721] Trial 21 finished with value: 0.7807075581183667 and parameters: {'num_leaves': 76}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  75%|####################################7            | 15/20 [01:30<00:28,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.887622\tvalid_0's f1score: 0.65906\tvalid_1's auc: 0.780708\tvalid_1's f1score: 0.618562\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008255 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  80%|#######################################2         | 16/20 [01:36<00:22,  5.71s/it][I 2024-02-08 16:26:37,493] Trial 22 finished with value: 0.7810035260144546 and parameters: {'num_leaves': 160}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  80%|#######################################2         | 16/20 [01:36<00:22,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.898576\tvalid_0's f1score: 0.597609\tvalid_1's auc: 0.781004\tvalid_1's f1score: 0.553411\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  85%|#########################################6       | 17/20 [01:41<00:16,  5.56s/it][I 2024-02-08 16:26:42,721] Trial 23 finished with value: 0.781614093135024 and parameters: {'num_leaves': 110}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  85%|#########################################6       | 17/20 [01:41<00:16,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.871154\tvalid_0's f1score: 0.582953\tvalid_1's auc: 0.781614\tvalid_1's f1score: 0.543507\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  90%|############################################1    | 18/20 [01:46<00:11,  5.53s/it][I 2024-02-08 16:26:48,191] Trial 24 finished with value: 0.7806469707451166 and parameters: {'num_leaves': 44}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  90%|############################################1    | 18/20 [01:46<00:11,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.872538\tvalid_0's f1score: 0.661733\tvalid_1's auc: 0.780647\tvalid_1's f1score: 0.635867\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005773 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547:  95%|##############################################5  | 19/20 [01:53<00:05,  5.88s/it][I 2024-02-08 16:26:54,871] Trial 25 finished with value: 0.7812278130745844 and parameters: {'num_leaves': 187}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547:  95%|##############################################5  | 19/20 [01:53<00:05,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's auc: 0.964481\tvalid_0's f1score: 0.716514\tvalid_1's auc: 0.781228\tvalid_1's f1score: 0.633815\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007406 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784547: 100%|#################################################| 20/20 [02:00<00:00,  6.27s/it][I 2024-02-08 16:27:02,055] Trial 26 finished with value: 0.7821027743896889 and parameters: {'num_leaves': 95}. Best is trial 18 with value: 0.7845473184540606.\n",
      "num_leaves, val_score: 0.784547: 100%|#################################################| 20/20 [02:00<00:00,  6.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.96271\tvalid_0's f1score: 0.722874\tvalid_1's auc: 0.782103\tvalid_1's f1score: 0.63376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784547:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784547:  10%|#####3                                               | 1/10 [00:06<01:00,  6.70s/it][I 2024-02-08 16:27:08,767] Trial 27 finished with value: 0.7771678901713058 and parameters: {'bagging_fraction': 0.49085756408953385, 'bagging_freq': 1}. Best is trial 27 with value: 0.7771678901713058.\n",
      "bagging, val_score: 0.784547:  10%|#####3                                               | 1/10 [00:06<01:00,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.935749\tvalid_0's f1score: 0.694325\tvalid_1's auc: 0.777168\tvalid_1's f1score: 0.635787\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784547:  20%|##########6                                          | 2/10 [00:11<00:46,  5.79s/it][I 2024-02-08 16:27:13,925] Trial 28 finished with value: 0.7791116639511387 and parameters: {'bagging_fraction': 0.997238078922349, 'bagging_freq': 7}. Best is trial 28 with value: 0.7791116639511387.\n",
      "bagging, val_score: 0.784547:  20%|##########6                                          | 2/10 [00:11<00:46,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.847158\tvalid_0's f1score: 0.572196\tvalid_1's auc: 0.779112\tvalid_1's f1score: 0.542318\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008566 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784547:  30%|###############9                                     | 3/10 [00:18<00:42,  6.04s/it][I 2024-02-08 16:27:20,243] Trial 29 finished with value: 0.7822011933152501 and parameters: {'bagging_fraction': 0.8313933328595103, 'bagging_freq': 4}. Best is trial 29 with value: 0.7822011933152501.\n",
      "bagging, val_score: 0.784547:  30%|###############9                                     | 3/10 [00:18<00:42,  6.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.938472\tvalid_0's f1score: 0.695107\tvalid_1's auc: 0.782201\tvalid_1's f1score: 0.640903\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005003 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784547:  40%|#####################2                               | 4/10 [00:23<00:34,  5.79s/it][I 2024-02-08 16:27:25,666] Trial 30 finished with value: 0.7792036828020608 and parameters: {'bagging_fraction': 0.4271622950915639, 'bagging_freq': 1}. Best is trial 29 with value: 0.7822011933152501.\n",
      "bagging, val_score: 0.784547:  40%|#####################2                               | 4/10 [00:23<00:34,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.882041\tvalid_0's f1score: 0.655104\tvalid_1's auc: 0.779204\tvalid_1's f1score: 0.618434\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784547:  50%|##########################5                          | 5/10 [00:29<00:29,  5.95s/it][I 2024-02-08 16:27:31,913] Trial 31 finished with value: 0.7808554709544702 and parameters: {'bagging_fraction': 0.6548955985677732, 'bagging_freq': 7}. Best is trial 29 with value: 0.7822011933152501.\n",
      "bagging, val_score: 0.784547:  50%|##########################5                          | 5/10 [00:29<00:29,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.904876\tvalid_0's f1score: 0.678869\tvalid_1's auc: 0.780855\tvalid_1's f1score: 0.631855\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784701:  60%|###############################8                     | 6/10 [00:36<00:24,  6.21s/it][I 2024-02-08 16:27:38,595] Trial 32 finished with value: 0.7847009202453987 and parameters: {'bagging_fraction': 0.6688323533147749, 'bagging_freq': 4}. Best is trial 32 with value: 0.7847009202453987.\n",
      "bagging, val_score: 0.784701:  60%|###############################8                     | 6/10 [00:36<00:24,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784701:  70%|#####################################                | 7/10 [00:43<00:19,  6.51s/it][I 2024-02-08 16:27:45,720] Trial 33 finished with value: 0.7801511782964082 and parameters: {'bagging_fraction': 0.6521555096766082, 'bagging_freq': 4}. Best is trial 32 with value: 0.7847009202453987.\n",
      "bagging, val_score: 0.784701:  70%|#####################################                | 7/10 [00:43<00:19,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.943287\tvalid_0's f1score: 0.700929\tvalid_1's auc: 0.780151\tvalid_1's f1score: 0.63934\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008090 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784701:  80%|##########################################4          | 8/10 [00:49<00:12,  6.26s/it][I 2024-02-08 16:27:51,460] Trial 34 finished with value: 0.7780772696655804 and parameters: {'bagging_fraction': 0.8117884567337383, 'bagging_freq': 3}. Best is trial 32 with value: 0.7847009202453987.\n",
      "bagging, val_score: 0.784701:  80%|##########################################4          | 8/10 [00:49<00:12,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.911031\tvalid_0's f1score: 0.677509\tvalid_1's auc: 0.778077\tvalid_1's f1score: 0.632417\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008137 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784701:  90%|###############################################7     | 9/10 [00:56<00:06,  6.37s/it][I 2024-02-08 16:27:58,066] Trial 35 finished with value: 0.7763646096921593 and parameters: {'bagging_fraction': 0.5379461481236242, 'bagging_freq': 6}. Best is trial 32 with value: 0.7847009202453987.\n",
      "bagging, val_score: 0.784701:  90%|###############################################7     | 9/10 [00:56<00:06,  6.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[84]\tvalid_0's auc: 0.926468\tvalid_0's f1score: 0.689657\tvalid_1's auc: 0.776365\tvalid_1's f1score: 0.638278\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007656 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784701: 100%|####################################################| 10/10 [01:04<00:00,  6.88s/it][I 2024-02-08 16:28:06,080] Trial 36 finished with value: 0.7787545397862773 and parameters: {'bagging_fraction': 0.7858260977629635, 'bagging_freq': 5}. Best is trial 32 with value: 0.7847009202453987.\n",
      "bagging, val_score: 0.784701: 100%|####################################################| 10/10 [01:04<00:00,  6.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.916431\tvalid_0's f1score: 0.679253\tvalid_1's auc: 0.778755\tvalid_1's f1score: 0.636181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010299 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701:  17%|######3                               | 1/6 [00:09<00:45,  9.05s/it][I 2024-02-08 16:28:15,134] Trial 37 finished with value: 0.777306416231272 and parameters: {'feature_fraction': 0.616}. Best is trial 37 with value: 0.777306416231272.\n",
      "feature_fraction_stage2, val_score: 0.784701:  17%|######3                               | 1/6 [00:09<00:45,  9.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.922053\tvalid_0's f1score: 0.684097\tvalid_1's auc: 0.777306\tvalid_1's f1score: 0.632881\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009984 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701:  33%|############6                         | 2/6 [00:17<00:34,  8.72s/it][I 2024-02-08 16:28:23,624] Trial 38 finished with value: 0.7793971072800422 and parameters: {'feature_fraction': 0.584}. Best is trial 38 with value: 0.7793971072800422.\n",
      "feature_fraction_stage2, val_score: 0.784701:  33%|############6                         | 2/6 [00:17<00:34,  8.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.91431\tvalid_0's f1score: 0.680452\tvalid_1's auc: 0.779397\tvalid_1's f1score: 0.632649\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009480 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701:  50%|###################                   | 3/6 [00:27<00:28,  9.37s/it][I 2024-02-08 16:28:33,764] Trial 39 finished with value: 0.7766647020807923 and parameters: {'feature_fraction': 0.6479999999999999}. Best is trial 38 with value: 0.7793971072800422.\n",
      "feature_fraction_stage2, val_score: 0.784701:  50%|###################                   | 3/6 [00:27<00:28,  9.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.96013\tvalid_0's f1score: 0.717023\tvalid_1's auc: 0.776665\tvalid_1's f1score: 0.635163\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009721 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701:  67%|#########################3            | 4/6 [00:35<00:17,  8.93s/it][I 2024-02-08 16:28:42,024] Trial 40 finished with value: 0.7813469966867524 and parameters: {'feature_fraction': 0.552}. Best is trial 40 with value: 0.7813469966867524.\n",
      "feature_fraction_stage2, val_score: 0.784701:  67%|#########################3            | 4/6 [00:35<00:17,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's auc: 0.903293\tvalid_0's f1score: 0.670753\tvalid_1's auc: 0.781347\tvalid_1's f1score: 0.631985\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701:  83%|###############################6      | 5/6 [00:43<00:08,  8.49s/it][I 2024-02-08 16:28:49,735] Trial 41 finished with value: 0.7801139156396206 and parameters: {'feature_fraction': 0.52}. Best is trial 40 with value: 0.7813469966867524.\n",
      "feature_fraction_stage2, val_score: 0.784701:  83%|###############################6      | 5/6 [00:43<00:08,  8.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's auc: 0.886749\tvalid_0's f1score: 0.661389\tvalid_1's auc: 0.780114\tvalid_1's f1score: 0.62446\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009220 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.784701: 100%|######################################| 6/6 [00:53<00:00,  8.95s/it][I 2024-02-08 16:28:59,582] Trial 42 finished with value: 0.7762488394531321 and parameters: {'feature_fraction': 0.6799999999999999}. Best is trial 40 with value: 0.7813469966867524.\n",
      "feature_fraction_stage2, val_score: 0.784701: 100%|######################################| 6/6 [00:53<00:00,  8.92s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[58]\tvalid_0's auc: 0.904206\tvalid_0's f1score: 0.676419\tvalid_1's auc: 0.776249\tvalid_1's f1score: 0.635867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:   5%|#9                                    | 1/20 [00:12<03:54, 12.35s/it][I 2024-02-08 16:29:11,951] Trial 43 finished with value: 0.7824910455844605 and parameters: {'lambda_l1': 8.005462171284718e-08, 'lambda_l2': 0.0007379053641346932}. Best is trial 43 with value: 0.7824910455844605.\n",
      "regularization_factors, val_score: 0.784701:   5%|#9                                    | 1/20 [00:12<03:54, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.921488\tvalid_0's f1score: 0.680044\tvalid_1's auc: 0.782491\tvalid_1's f1score: 0.629797\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  10%|###8                                  | 2/20 [00:24<03:41, 12.28s/it][I 2024-02-08 16:29:24,184] Trial 44 finished with value: 0.7829640822122299 and parameters: {'lambda_l1': 3.2017700508460494, 'lambda_l2': 1.7277715160786953e-08}. Best is trial 44 with value: 0.7829640822122299.\n",
      "regularization_factors, val_score: 0.784701:  10%|###8                                  | 2/20 [00:24<03:41, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.901779\tvalid_0's f1score: 0.677051\tvalid_1's auc: 0.782964\tvalid_1's f1score: 0.640815\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015811 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  15%|#####7                                | 3/20 [00:36<03:29, 12.33s/it][I 2024-02-08 16:29:36,574] Trial 45 finished with value: 0.7824122535544592 and parameters: {'lambda_l1': 0.003913705299619832, 'lambda_l2': 6.356462114388729}. Best is trial 44 with value: 0.7829640822122299.\n",
      "regularization_factors, val_score: 0.784701:  15%|#####7                                | 3/20 [00:36<03:29, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.888342\tvalid_0's f1score: 0.666216\tvalid_1's auc: 0.782412\tvalid_1's f1score: 0.632552\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009673 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  20%|#######6                              | 4/20 [00:51<03:29, 13.12s/it][I 2024-02-08 16:29:50,894] Trial 46 finished with value: 0.7846955157379257 and parameters: {'lambda_l1': 3.79891204035597e-08, 'lambda_l2': 2.098338035781475e-08}. Best is trial 46 with value: 0.7846955157379257.\n",
      "regularization_factors, val_score: 0.784701:  20%|#######6                              | 4/20 [00:51<03:29, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010510 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  25%|#########5                            | 5/20 [01:04<03:17, 13.14s/it][I 2024-02-08 16:30:04,077] Trial 47 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 3.2159400186825874e-08, 'lambda_l2': 1.1324579995278007e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  25%|#########5                            | 5/20 [01:04<03:17, 13.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020534 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  30%|###########4                          | 6/20 [01:16<02:59, 12.82s/it][I 2024-02-08 16:30:16,302] Trial 48 finished with value: 0.7846955157379257 and parameters: {'lambda_l1': 2.6527988621877012e-08, 'lambda_l2': 1.9787837821494423e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  30%|###########4                          | 6/20 [01:16<02:59, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  35%|#############3                        | 7/20 [01:28<02:40, 12.33s/it][I 2024-02-08 16:30:27,602] Trial 49 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 1.2763352692807196e-08, 'lambda_l2': 1.1676074185282826e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  35%|#############3                        | 7/20 [01:28<02:40, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012445 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  40%|###############2                      | 8/20 [01:39<02:24, 12.06s/it][I 2024-02-08 16:30:39,074] Trial 50 finished with value: 0.7846955157379257 and parameters: {'lambda_l1': 1.067064658949529e-08, 'lambda_l2': 1.3227963083489514e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  40%|###############2                      | 8/20 [01:39<02:24, 12.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  45%|#################1                    | 9/20 [01:51<02:13, 12.16s/it][I 2024-02-08 16:30:51,452] Trial 51 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 1.2009139265650733e-08, 'lambda_l2': 1.4439805238825965e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  45%|#################1                    | 9/20 [01:51<02:13, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008020 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  50%|##################5                  | 10/20 [02:03<02:01, 12.15s/it][I 2024-02-08 16:31:03,589] Trial 52 finished with value: 0.7846955157379257 and parameters: {'lambda_l1': 2.723693164190521e-08, 'lambda_l2': 1.1020128465236774e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  50%|##################5                  | 10/20 [02:03<02:01, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011632 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  55%|####################3                | 11/20 [02:19<01:57, 13.10s/it][I 2024-02-08 16:31:18,835] Trial 53 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 1.76845264781367e-08, 'lambda_l2': 1.7657602456900405e-08}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  55%|####################3                | 11/20 [02:19<01:57, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  60%|######################2              | 12/20 [02:37<01:56, 14.59s/it][I 2024-02-08 16:31:36,840] Trial 54 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 6.485867059000271e-07, 'lambda_l2': 5.119183379963788e-07}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  60%|######################2              | 12/20 [02:37<01:56, 14.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.025685 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  65%|########################             | 13/20 [02:53<01:46, 15.16s/it][I 2024-02-08 16:31:53,315] Trial 55 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 1.8972673762011481e-06, 'lambda_l2': 1.8044167587361403e-06}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  65%|########################             | 13/20 [02:53<01:46, 15.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  70%|#########################9           | 14/20 [03:11<01:35, 15.85s/it][I 2024-02-08 16:32:10,746] Trial 56 finished with value: 0.7846955157379257 and parameters: {'lambda_l1': 1.2737908987966821e-06, 'lambda_l2': 1.1018130614210538e-06}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  70%|#########################9           | 14/20 [03:11<01:35, 15.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008344 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  75%|###########################7         | 15/20 [03:28<01:22, 16.42s/it][I 2024-02-08 16:32:28,497] Trial 57 finished with value: 0.7846955157379257 and parameters: {'lambda_l1': 9.73546324975596e-07, 'lambda_l2': 7.397877254324663e-07}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  75%|###########################7         | 15/20 [03:28<01:22, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016758 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  80%|#############################6       | 16/20 [03:46<01:07, 16.89s/it][I 2024-02-08 16:32:46,495] Trial 58 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 1.2056675926638388e-08, 'lambda_l2': 3.220025421451649e-07}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  80%|#############################6       | 16/20 [03:46<01:07, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012956 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  85%|###############################4     | 17/20 [04:08<00:55, 18.38s/it][I 2024-02-08 16:33:08,315] Trial 59 finished with value: 0.7847009202453987 and parameters: {'lambda_l1': 4.536949219443212e-07, 'lambda_l2': 2.1218316832055521e-07}. Best is trial 47 with value: 0.7847009202453987.\n",
      "regularization_factors, val_score: 0.784701:  85%|###############################4     | 17/20 [04:08<00:55, 18.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926128\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010191 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  90%|#################################3   | 18/20 [04:28<00:37, 18.77s/it][I 2024-02-08 16:33:28,005] Trial 60 finished with value: 0.7847012046931605 and parameters: {'lambda_l1': 2.167515407909908e-07, 'lambda_l2': 3.2088101173059495e-05}. Best is trial 60 with value: 0.7847012046931605.\n",
      "regularization_factors, val_score: 0.784701:  90%|#################################3   | 18/20 [04:28<00:37, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926127\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784701\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019535 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701:  95%|###################################1 | 19/20 [04:49<00:19, 19.43s/it][I 2024-02-08 16:33:48,981] Trial 61 finished with value: 0.7846960846334492 and parameters: {'lambda_l1': 2.0770652618044192e-07, 'lambda_l2': 5.297355894786374e-05}. Best is trial 60 with value: 0.7847012046931605.\n",
      "regularization_factors, val_score: 0.784701:  95%|###################################1 | 19/20 [04:49<00:19, 19.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.926127\tvalid_0's f1score: 0.688931\tvalid_1's auc: 0.784696\tvalid_1's f1score: 0.633114\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.784701: 100%|#####################################| 20/20 [05:09<00:00, 19.79s/it][I 2024-02-08 16:34:09,612] Trial 62 finished with value: 0.7821499927181373 and parameters: {'lambda_l1': 1.3195400786228088e-05, 'lambda_l2': 3.14124574831752e-05}. Best is trial 60 with value: 0.7847012046931605.\n",
      "regularization_factors, val_score: 0.784701: 100%|#####################################| 20/20 [05:10<00:00, 15.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's auc: 0.914806\tvalid_0's f1score: 0.679909\tvalid_1's auc: 0.78215\tvalid_1's f1score: 0.629452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784701:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.024303 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784701:  20%|########8                                   | 1/5 [00:20<01:21, 20.34s/it][I 2024-02-08 16:34:29,972] Trial 63 finished with value: 0.7840373036172653 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.7840373036172653.\n",
      "min_child_samples, val_score: 0.784701:  20%|########8                                   | 1/5 [00:20<01:21, 20.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.910866\tvalid_0's f1score: 0.675186\tvalid_1's auc: 0.784037\tvalid_1's f1score: 0.632218\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784701:  40%|#################6                          | 2/5 [00:40<01:00, 20.21s/it][I 2024-02-08 16:34:50,081] Trial 64 finished with value: 0.7795199887131128 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.7840373036172653.\n",
      "min_child_samples, val_score: 0.784701:  40%|#################6                          | 2/5 [00:40<01:00, 20.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.902626\tvalid_0's f1score: 0.67251\tvalid_1's auc: 0.77952\tvalid_1's f1score: 0.627956\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784701:  60%|##########################4                 | 3/5 [01:05<00:45, 22.60s/it][I 2024-02-08 16:35:15,515] Trial 65 finished with value: 0.7824347249276364 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.7840373036172653.\n",
      "min_child_samples, val_score: 0.784701:  60%|##########################4                 | 3/5 [01:05<00:45, 22.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.96993\tvalid_0's f1score: 0.724402\tvalid_1's auc: 0.782435\tvalid_1's f1score: 0.642534\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.020547 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784701:  80%|###################################2        | 4/5 [01:24<00:20, 20.87s/it][I 2024-02-08 16:35:33,745] Trial 66 finished with value: 0.7779094454861554 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.7840373036172653.\n",
      "min_child_samples, val_score: 0.784701:  80%|###################################2        | 4/5 [01:24<00:20, 20.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.869483\tvalid_0's f1score: 0.641846\tvalid_1's auc: 0.777909\tvalid_1's f1score: 0.621135\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.026662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5151\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.784701: 100%|############################################| 5/5 [01:42<00:00, 19.82s/it][I 2024-02-08 16:35:51,689] Trial 67 finished with value: 0.7776355222916022 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.7840373036172653.\n",
      "min_child_samples, val_score: 0.784701: 100%|############################################| 5/5 [01:42<00:00, 20.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.867954\tvalid_0's f1score: 0.638935\tvalid_1's auc: 0.777636\tvalid_1's f1score: 0.614938\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2024-02-08 16:35:51,878] A new study created in memory with name: no-name-63e96d65-2f6c-4a34-aaab-b4afe1ddde6d\n",
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018862 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779458:  14%|######4                                      | 1/7 [00:20<02:02, 20.43s/it][I 2024-02-08 16:36:12,307] Trial 0 finished with value: 0.7794575791158724 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.7794575791158724.\n",
      "feature_fraction, val_score: 0.779458:  14%|######4                                      | 1/7 [00:20<02:02, 20.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's auc: 0.90438\tvalid_0's f1score: 0.68127\tvalid_1's auc: 0.779458\tvalid_1's f1score: 0.652\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021717 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779458:  29%|############8                                | 2/7 [00:44<01:51, 22.28s/it][I 2024-02-08 16:36:35,884] Trial 1 finished with value: 0.7791602899009622 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.7794575791158724.\n",
      "feature_fraction, val_score: 0.779458:  29%|############8                                | 2/7 [00:44<01:51, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's auc: 0.908234\tvalid_0's f1score: 0.681455\tvalid_1's auc: 0.77916\tvalid_1's f1score: 0.652\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.020711 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779458:  43%|###################2                         | 3/7 [01:02<01:21, 20.39s/it][I 2024-02-08 16:36:54,040] Trial 2 finished with value: 0.7770651925343466 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.7794575791158724.\n",
      "feature_fraction, val_score: 0.779458:  43%|###################2                         | 3/7 [01:02<01:21, 20.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.86387\tvalid_0's f1score: 0.660179\tvalid_1's auc: 0.777065\tvalid_1's f1score: 0.646835\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010895 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779458:  57%|#########################7                   | 4/7 [01:25<01:04, 21.51s/it][I 2024-02-08 16:37:17,259] Trial 3 finished with value: 0.7775161104954234 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.7794575791158724.\n",
      "feature_fraction, val_score: 0.779458:  57%|#########################7                   | 4/7 [01:25<01:04, 21.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.856728\tvalid_0's f1score: 0.655199\tvalid_1's auc: 0.777516\tvalid_1's f1score: 0.643951\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779458:  71%|################################1            | 5/7 [01:44<00:41, 20.71s/it][I 2024-02-08 16:37:36,552] Trial 4 finished with value: 0.7791887288100808 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.7794575791158724.\n",
      "feature_fraction, val_score: 0.779458:  71%|################################1            | 5/7 [01:44<00:41, 20.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.874556\tvalid_0's f1score: 0.661946\tvalid_1's auc: 0.779189\tvalid_1's f1score: 0.655067\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016025 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779458:  86%|######################################5      | 6/7 [02:07<00:21, 21.30s/it][I 2024-02-08 16:37:58,995] Trial 5 finished with value: 0.7793320960941944 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.7794575791158724.\n",
      "feature_fraction, val_score: 0.779458:  86%|######################################5      | 6/7 [02:07<00:21, 21.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.863354\tvalid_0's f1score: 0.66175\tvalid_1's auc: 0.779332\tvalid_1's f1score: 0.650459\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017085 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.780462: 100%|#############################################| 7/7 [02:28<00:00, 21.17s/it][I 2024-02-08 16:38:19,894] Trial 6 finished with value: 0.7804615898816121 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.7804615898816121.\n",
      "feature_fraction, val_score: 0.780462: 100%|#############################################| 7/7 [02:28<00:00, 21.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's auc: 0.933787\tvalid_0's f1score: 0.703064\tvalid_1's auc: 0.780462\tvalid_1's f1score: 0.650733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.780462:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782475:   5%|##5                                               | 1/20 [00:17<05:28, 17.27s/it][I 2024-02-08 16:38:37,182] Trial 7 finished with value: 0.782475328513378 and parameters: {'num_leaves': 49}. Best is trial 7 with value: 0.782475328513378.\n",
      "num_leaves, val_score: 0.782475:   5%|##5                                               | 1/20 [00:17<05:28, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's auc: 0.941447\tvalid_0's f1score: 0.704469\tvalid_1's auc: 0.782475\tvalid_1's f1score: 0.655046\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009441 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782475:  10%|#####                                             | 2/20 [00:25<03:33, 11.85s/it][I 2024-02-08 16:38:45,229] Trial 8 finished with value: 0.7754773045777849 and parameters: {'num_leaves': 224}. Best is trial 7 with value: 0.782475328513378.\n",
      "num_leaves, val_score: 0.782475:  10%|#####                                             | 2/20 [00:25<03:33, 11.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.936978\tvalid_0's f1score: 0.659221\tvalid_1's auc: 0.775477\tvalid_1's f1score: 0.602552\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.782475:  15%|#######5                                          | 3/20 [00:37<03:22, 11.91s/it][I 2024-02-08 16:38:57,207] Trial 9 finished with value: 0.7802444866630311 and parameters: {'num_leaves': 6}. Best is trial 7 with value: 0.782475328513378.\n",
      "num_leaves, val_score: 0.782475:  15%|#######5                                          | 3/20 [00:37<03:22, 11.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.847305\tvalid_0's f1score: 0.656241\tvalid_1's auc: 0.780244\tvalid_1's f1score: 0.640121\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  20%|##########                                        | 4/20 [00:45<02:47, 10.44s/it][I 2024-02-08 16:39:05,417] Trial 10 finished with value: 0.7842331169630763 and parameters: {'num_leaves': 46}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  20%|##########                                        | 4/20 [00:45<02:47, 10.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.927448\tvalid_0's f1score: 0.687801\tvalid_1's auc: 0.784233\tvalid_1's f1score: 0.65405\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  25%|############5                                     | 5/20 [00:52<02:20,  9.35s/it][I 2024-02-08 16:39:12,841] Trial 11 finished with value: 0.7784928550905648 and parameters: {'num_leaves': 44}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  25%|############5                                     | 5/20 [00:52<02:20,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.919831\tvalid_0's f1score: 0.686384\tvalid_1's auc: 0.778493\tvalid_1's f1score: 0.655563\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008228 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  30%|###############                                   | 6/20 [00:59<01:56,  8.30s/it][I 2024-02-08 16:39:19,073] Trial 12 finished with value: 0.7798265519728393 and parameters: {'num_leaves': 85}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  30%|###############                                   | 6/20 [00:59<01:56,  8.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's auc: 0.876725\tvalid_0's f1score: 0.642951\tvalid_1's auc: 0.779827\tvalid_1's f1score: 0.623028\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008561 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  35%|#################5                                | 7/20 [01:07<01:49,  8.43s/it][I 2024-02-08 16:39:27,771] Trial 13 finished with value: 0.782537630247272 and parameters: {'num_leaves': 134}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  35%|#################5                                | 7/20 [01:07<01:49,  8.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.980574\tvalid_0's f1score: 0.761282\tvalid_1's auc: 0.782538\tvalid_1's f1score: 0.655326\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  40%|####################                              | 8/20 [01:17<01:46,  8.91s/it][I 2024-02-08 16:39:37,716] Trial 14 finished with value: 0.7765493341777051 and parameters: {'num_leaves': 170}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  40%|####################                              | 8/20 [01:17<01:46,  8.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.992736\tvalid_0's f1score: 0.833132\tvalid_1's auc: 0.776549\tvalid_1's f1score: 0.650479\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007333 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  45%|######################5                           | 9/20 [01:24<01:30,  8.26s/it][I 2024-02-08 16:39:44,562] Trial 15 finished with value: 0.7825487712632153 and parameters: {'num_leaves': 131}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  45%|######################5                           | 9/20 [01:24<01:30,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.949977\tvalid_0's f1score: 0.702089\tvalid_1's auc: 0.782549\tvalid_1's f1score: 0.647341\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  50%|########################5                        | 10/20 [01:34<01:26,  8.67s/it][I 2024-02-08 16:39:54,143] Trial 16 finished with value: 0.7811822377023707 and parameters: {'num_leaves': 119}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  50%|########################5                        | 10/20 [01:34<01:26,  8.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's auc: 0.991515\tvalid_0's f1score: 0.838634\tvalid_1's auc: 0.781182\tvalid_1's f1score: 0.648929\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006755 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  55%|##########################9                      | 11/20 [01:40<01:12,  8.03s/it][I 2024-02-08 16:40:00,700] Trial 17 finished with value: 0.7761888636750107 and parameters: {'num_leaves': 181}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  55%|##########################9                      | 11/20 [01:40<01:12,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's auc: 0.920025\tvalid_0's f1score: 0.653796\tvalid_1's auc: 0.776189\tvalid_1's f1score: 0.59963\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  60%|#############################4                   | 12/20 [01:48<01:03,  7.93s/it][I 2024-02-08 16:40:08,394] Trial 18 finished with value: 0.7807848259362851 and parameters: {'num_leaves': 92}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  60%|#############################4                   | 12/20 [01:48<01:03,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.93768\tvalid_0's f1score: 0.696331\tvalid_1's auc: 0.780785\tvalid_1's f1score: 0.652265\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007955 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  65%|###############################8                 | 13/20 [01:58<00:58,  8.42s/it][I 2024-02-08 16:40:17,959] Trial 19 finished with value: 0.7807503767422497 and parameters: {'num_leaves': 156}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  65%|###############################8                 | 13/20 [01:58<00:58,  8.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's auc: 0.989485\tvalid_0's f1score: 0.814852\tvalid_1's auc: 0.78075\tvalid_1's f1score: 0.64817\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  70%|##################################3              | 14/20 [02:09<00:56,  9.44s/it][I 2024-02-08 16:40:29,752] Trial 20 finished with value: 0.7783834972235415 and parameters: {'num_leaves': 221}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  70%|##################################3              | 14/20 [02:09<00:56,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's auc: 0.997283\tvalid_0's f1score: 0.895623\tvalid_1's auc: 0.778383\tvalid_1's f1score: 0.650984\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009044 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  75%|####################################7            | 15/20 [02:19<00:47,  9.56s/it][I 2024-02-08 16:40:39,612] Trial 21 finished with value: 0.7807327856644444 and parameters: {'num_leaves': 124}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  75%|####################################7            | 15/20 [02:19<00:47,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.969987\tvalid_0's f1score: 0.735448\tvalid_1's auc: 0.780733\tvalid_1's f1score: 0.653792\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010569 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  80%|#######################################2         | 16/20 [02:31<00:40, 10.24s/it][I 2024-02-08 16:40:51,409] Trial 22 finished with value: 0.7793750476425024 and parameters: {'num_leaves': 147}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  80%|#######################################2         | 16/20 [02:31<00:40, 10.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.994833\tvalid_0's f1score: 0.864471\tvalid_1's auc: 0.779375\tvalid_1's f1score: 0.648675\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  85%|#########################################6       | 17/20 [02:39<00:29,  9.71s/it][I 2024-02-08 16:40:59,880] Trial 23 finished with value: 0.7807848259362851 and parameters: {'num_leaves': 92}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  85%|#########################################6       | 17/20 [02:39<00:29,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.93768\tvalid_0's f1score: 0.696331\tvalid_1's auc: 0.780785\tvalid_1's f1score: 0.652265\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  90%|############################################1    | 18/20 [02:48<00:18,  9.45s/it][I 2024-02-08 16:41:08,722] Trial 24 finished with value: 0.7763583243912021 and parameters: {'num_leaves': 190}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  90%|############################################1    | 18/20 [02:48<00:18,  9.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.971894\tvalid_0's f1score: 0.73157\tvalid_1's auc: 0.776358\tvalid_1's f1score: 0.642595\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009038 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233:  95%|##############################################5  | 19/20 [02:57<00:09,  9.31s/it][I 2024-02-08 16:41:17,724] Trial 25 finished with value: 0.7818266575193062 and parameters: {'num_leaves': 118}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233:  95%|##############################################5  | 19/20 [02:57<00:09,  9.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.944617\tvalid_0's f1score: 0.698858\tvalid_1's auc: 0.781827\tvalid_1's f1score: 0.64655\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008060 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.784233: 100%|#################################################| 20/20 [03:06<00:00,  9.00s/it][I 2024-02-08 16:41:26,011] Trial 26 finished with value: 0.7807780826897931 and parameters: {'num_leaves': 57}. Best is trial 10 with value: 0.7842331169630763.\n",
      "num_leaves, val_score: 0.784233: 100%|#################################################| 20/20 [03:06<00:00,  9.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.892501\tvalid_0's f1score: 0.670795\tvalid_1's auc: 0.780778\tvalid_1's f1score: 0.650459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784233:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784233:  10%|#####3                                               | 1/10 [00:13<02:01, 13.46s/it][I 2024-02-08 16:41:39,487] Trial 27 finished with value: 0.778230161662005 and parameters: {'bagging_fraction': 0.4344737210847696, 'bagging_freq': 4}. Best is trial 27 with value: 0.778230161662005.\n",
      "bagging, val_score: 0.784233:  10%|#####3                                               | 1/10 [00:13<02:01, 13.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's auc: 0.965788\tvalid_0's f1score: 0.732186\tvalid_1's auc: 0.77823\tvalid_1's f1score: 0.648944\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008715 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.784233:  20%|##########6                                          | 2/10 [00:22<01:24, 10.58s/it][I 2024-02-08 16:41:48,048] Trial 28 finished with value: 0.781496385033511 and parameters: {'bagging_fraction': 0.9751151329699577, 'bagging_freq': 1}. Best is trial 28 with value: 0.781496385033511.\n",
      "bagging, val_score: 0.784233:  20%|##########6                                          | 2/10 [00:22<01:24, 10.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.900334\tvalid_0's f1score: 0.677067\tvalid_1's auc: 0.781496\tvalid_1's f1score: 0.649196\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009286 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  30%|###############9                                     | 3/10 [00:37<01:30, 12.99s/it][I 2024-02-08 16:42:03,906] Trial 29 finished with value: 0.7870368415806169 and parameters: {'bagging_fraction': 0.723416066250707, 'bagging_freq': 7}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  30%|###############9                                     | 3/10 [00:37<01:30, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  40%|#####################2                               | 4/10 [00:47<01:10, 11.77s/it][I 2024-02-08 16:42:13,805] Trial 30 finished with value: 0.7841714015984426 and parameters: {'bagging_fraction': 0.739446330354914, 'bagging_freq': 7}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  40%|#####################2                               | 4/10 [00:47<01:10, 11.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's auc: 0.924106\tvalid_0's f1score: 0.687496\tvalid_1's auc: 0.784171\tvalid_1's f1score: 0.648129\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008846 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  50%|##########################5                          | 5/10 [00:58<00:56, 11.30s/it][I 2024-02-08 16:42:24,275] Trial 31 finished with value: 0.779937375763013 and parameters: {'bagging_fraction': 0.7268977285793045, 'bagging_freq': 7}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  50%|##########################5                          | 5/10 [00:58<00:56, 11.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's auc: 0.934165\tvalid_0's f1score: 0.692305\tvalid_1's auc: 0.779937\tvalid_1's f1score: 0.651242\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  60%|###############################8                     | 6/10 [01:08<00:43, 10.84s/it][I 2024-02-08 16:42:34,227] Trial 32 finished with value: 0.7834964905799778 and parameters: {'bagging_fraction': 0.7312237874573977, 'bagging_freq': 7}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  60%|###############################8                     | 6/10 [01:08<00:43, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's auc: 0.926292\tvalid_0's f1score: 0.691381\tvalid_1's auc: 0.783496\tvalid_1's f1score: 0.650723\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  70%|#####################################                | 7/10 [01:18<00:31, 10.53s/it][I 2024-02-08 16:42:44,117] Trial 33 finished with value: 0.7842276930474197 and parameters: {'bagging_fraction': 0.7367577486449124, 'bagging_freq': 7}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  70%|#####################################                | 7/10 [01:18<00:31, 10.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's auc: 0.923123\tvalid_0's f1score: 0.68747\tvalid_1's auc: 0.784228\tvalid_1's f1score: 0.649437\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008066 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  80%|##########################################4          | 8/10 [01:25<00:19,  9.64s/it][I 2024-02-08 16:42:51,841] Trial 34 finished with value: 0.7832291061973368 and parameters: {'bagging_fraction': 0.7451938152080848, 'bagging_freq': 7}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  80%|##########################################4          | 8/10 [01:25<00:19,  9.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.874162\tvalid_0's f1score: 0.659109\tvalid_1's auc: 0.783229\tvalid_1's f1score: 0.642286\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007618 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037:  90%|###############################################7     | 9/10 [01:34<00:09,  9.44s/it][I 2024-02-08 16:43:00,837] Trial 35 finished with value: 0.7796160454084355 and parameters: {'bagging_fraction': 0.8294093966516651, 'bagging_freq': 5}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037:  90%|###############################################7     | 9/10 [01:34<00:09,  9.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.911628\tvalid_0's f1score: 0.681512\tvalid_1's auc: 0.779616\tvalid_1's f1score: 0.653792\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787037: 100%|####################################################| 10/10 [01:44<00:00,  9.43s/it][I 2024-02-08 16:43:10,256] Trial 36 finished with value: 0.7806943784779027 and parameters: {'bagging_fraction': 0.5390339726978717, 'bagging_freq': 5}. Best is trial 29 with value: 0.7870368415806169.\n",
      "bagging, val_score: 0.787037: 100%|####################################################| 10/10 [01:44<00:00, 10.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's auc: 0.916629\tvalid_0's f1score: 0.683206\tvalid_1's auc: 0.780694\tvalid_1's f1score: 0.652008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037:  17%|######3                               | 1/6 [00:10<00:51, 10.34s/it][I 2024-02-08 16:43:20,618] Trial 37 finished with value: 0.7839641200649697 and parameters: {'feature_fraction': 0.516}. Best is trial 37 with value: 0.7839641200649697.\n",
      "feature_fraction_stage2, val_score: 0.787037:  17%|######3                               | 1/6 [00:10<00:51, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's auc: 0.930616\tvalid_0's f1score: 0.692353\tvalid_1's auc: 0.783964\tvalid_1's f1score: 0.651497\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009380 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037:  33%|############6                         | 2/6 [00:19<00:39,  9.87s/it][I 2024-02-08 16:43:30,160] Trial 38 finished with value: 0.7842870629350127 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.7842870629350127.\n",
      "feature_fraction_stage2, val_score: 0.787037:  33%|############6                         | 2/6 [00:19<00:39,  9.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.89929\tvalid_0's f1score: 0.677771\tvalid_1's auc: 0.784287\tvalid_1's f1score: 0.648404\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011889 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037:  50%|###################                   | 3/6 [00:30<00:30, 10.22s/it][I 2024-02-08 16:43:40,771] Trial 39 finished with value: 0.7852684984842354 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 39 with value: 0.7852684984842354.\n",
      "feature_fraction_stage2, val_score: 0.787037:  50%|###################                   | 3/6 [00:30<00:30, 10.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.899247\tvalid_0's f1score: 0.675311\tvalid_1's auc: 0.785268\tvalid_1's f1score: 0.649167\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011982 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037:  67%|#########################3            | 4/6 [00:42<00:22, 11.04s/it][I 2024-02-08 16:43:53,069] Trial 40 finished with value: 0.7837920206871075 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.7852684984842354.\n",
      "feature_fraction_stage2, val_score: 0.787037:  67%|#########################3            | 4/6 [00:42<00:22, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's auc: 0.925472\tvalid_0's f1score: 0.687042\tvalid_1's auc: 0.783792\tvalid_1's f1score: 0.651497\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037:  83%|###############################6      | 5/6 [00:55<00:11, 11.71s/it][I 2024-02-08 16:44:05,993] Trial 41 finished with value: 0.7805598067326919 and parameters: {'feature_fraction': 0.42}. Best is trial 39 with value: 0.7852684984842354.\n",
      "feature_fraction_stage2, val_score: 0.787037:  83%|###############################6      | 5/6 [00:55<00:11, 11.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.928687\tvalid_0's f1score: 0.690597\tvalid_1's auc: 0.78056\tvalid_1's f1score: 0.657388\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012884 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.787037: 100%|######################################| 6/6 [01:08<00:00, 12.10s/it][I 2024-02-08 16:44:18,827] Trial 42 finished with value: 0.7835672946681443 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 39 with value: 0.7852684984842354.\n",
      "feature_fraction_stage2, val_score: 0.787037: 100%|######################################| 6/6 [01:08<00:00, 11.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.93271\tvalid_0's f1score: 0.692212\tvalid_1's auc: 0.783567\tvalid_1's f1score: 0.652522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:   5%|#9                                    | 1/20 [00:13<04:20, 13.73s/it][I 2024-02-08 16:44:32,586] Trial 43 finished with value: 0.7869617863153142 and parameters: {'lambda_l1': 2.7159403205480724e-05, 'lambda_l2': 8.198859061031024}. Best is trial 43 with value: 0.7869617863153142.\n",
      "regularization_factors, val_score: 0.787037:   5%|#9                                    | 1/20 [00:13<04:20, 13.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's auc: 0.897418\tvalid_0's f1score: 0.678554\tvalid_1's auc: 0.786962\tvalid_1's f1score: 0.65175\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010464 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  10%|###8                                  | 2/20 [00:27<04:11, 13.95s/it][I 2024-02-08 16:44:46,678] Trial 44 finished with value: 0.7841821028374408 and parameters: {'lambda_l1': 1.6858045636644403e-05, 'lambda_l2': 9.651709110325132}. Best is trial 43 with value: 0.7869617863153142.\n",
      "regularization_factors, val_score: 0.787037:  10%|###8                                  | 2/20 [00:27<04:11, 13.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's auc: 0.892681\tvalid_0's f1score: 0.675265\tvalid_1's auc: 0.784182\tvalid_1's f1score: 0.647116\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007491 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  15%|#####7                                | 3/20 [00:38<03:34, 12.63s/it][I 2024-02-08 16:44:57,758] Trial 45 finished with value: 0.7842320908168711 and parameters: {'lambda_l1': 0.6417185455012087, 'lambda_l2': 0.11975335717655125}. Best is trial 43 with value: 0.7869617863153142.\n",
      "regularization_factors, val_score: 0.787037:  15%|#####7                                | 3/20 [00:38<03:34, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.900693\tvalid_0's f1score: 0.676883\tvalid_1's auc: 0.784232\tvalid_1's f1score: 0.654308\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  20%|#######6                              | 4/20 [00:51<03:23, 12.72s/it][I 2024-02-08 16:45:10,595] Trial 46 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 2.305388224280722e-08, 'lambda_l2': 1.0705853133447937e-07}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  20%|#######6                              | 4/20 [00:51<03:23, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  25%|#########5                            | 5/20 [01:04<03:10, 12.70s/it][I 2024-02-08 16:45:23,271] Trial 47 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.0180694345011637e-08, 'lambda_l2': 1.0239554519908707e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  25%|#########5                            | 5/20 [01:04<03:10, 12.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008564 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  30%|###########4                          | 6/20 [01:16<02:55, 12.57s/it][I 2024-02-08 16:45:35,580] Trial 48 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.989988913867577e-08, 'lambda_l2': 1.1154182929926532e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  30%|###########4                          | 6/20 [01:16<02:55, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  35%|#############3                        | 7/20 [01:29<02:45, 12.69s/it][I 2024-02-08 16:45:48,526] Trial 49 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 2.265021174162139e-08, 'lambda_l2': 1.1622822649172822e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  35%|#############3                        | 7/20 [01:29<02:45, 12.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003200 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  40%|###############2                      | 8/20 [01:42<02:34, 12.84s/it][I 2024-02-08 16:46:01,694] Trial 50 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.0472018215367241e-08, 'lambda_l2': 1.1966957846447054e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  40%|###############2                      | 8/20 [01:42<02:34, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  45%|#################1                    | 9/20 [01:55<02:20, 12.77s/it][I 2024-02-08 16:46:14,312] Trial 51 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.6550609115269635e-08, 'lambda_l2': 1.0561895548153125e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  45%|#################1                    | 9/20 [01:55<02:20, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011844 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  50%|##################5                  | 10/20 [02:09<02:10, 13.03s/it][I 2024-02-08 16:46:27,933] Trial 52 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.185410401105235e-08, 'lambda_l2': 1.0989206763027253e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  50%|##################5                  | 10/20 [02:09<02:10, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012015 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  55%|####################3                | 11/20 [02:22<01:57, 13.11s/it][I 2024-02-08 16:46:41,199] Trial 53 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.2287173783774111e-08, 'lambda_l2': 1.2272018965966767e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  55%|####################3                | 11/20 [02:22<01:57, 13.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009986 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  60%|######################2              | 12/20 [02:34<01:43, 12.89s/it][I 2024-02-08 16:46:53,588] Trial 54 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 9.014098641306218e-08, 'lambda_l2': 2.898327380161226e-07}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  60%|######################2              | 12/20 [02:34<01:43, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006401 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  65%|########################             | 13/20 [02:47<01:29, 12.77s/it][I 2024-02-08 16:47:06,080] Trial 55 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 3.4335220295557086e-07, 'lambda_l2': 1.2176486575775706e-06}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  65%|########################             | 13/20 [02:47<01:29, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003934 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  70%|#########################9           | 14/20 [03:00<01:17, 12.87s/it][I 2024-02-08 16:47:19,181] Trial 56 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 5.444163211102414e-07, 'lambda_l2': 3.862654435776382e-07}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  70%|#########################9           | 14/20 [03:00<01:17, 12.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  75%|###########################7         | 15/20 [03:13<01:04, 12.94s/it][I 2024-02-08 16:47:32,281] Trial 57 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.0171803968286897e-08, 'lambda_l2': 1.0747530713575783e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  75%|###########################7         | 15/20 [03:13<01:04, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006689 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  80%|#############################6       | 16/20 [03:27<00:52, 13.16s/it][I 2024-02-08 16:47:45,963] Trial 58 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 5.146510021385956e-07, 'lambda_l2': 2.437206684837922e-07}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  80%|#############################6       | 16/20 [03:27<00:52, 13.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010576 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  85%|###############################4     | 17/20 [03:40<00:39, 13.10s/it][I 2024-02-08 16:47:58,918] Trial 59 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.432290190177153e-07, 'lambda_l2': 1.1229545727134164e-07}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  85%|###############################4     | 17/20 [03:40<00:39, 13.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  90%|#################################3   | 18/20 [03:51<00:25, 12.63s/it][I 2024-02-08 16:48:10,467] Trial 60 finished with value: 0.7845112025847157 and parameters: {'lambda_l1': 0.015679385178003758, 'lambda_l2': 2.9498344819606884e-06}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  90%|#################################3   | 18/20 [03:51<00:25, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.881163\tvalid_0's f1score: 0.665665\tvalid_1's auc: 0.784511\tvalid_1's f1score: 0.644704\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007959 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037:  95%|###################################1 | 19/20 [04:03<00:12, 12.39s/it][I 2024-02-08 16:48:22,294] Trial 61 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 1.0398640667661803e-08, 'lambda_l2': 1.777927727249958e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037:  95%|###################################1 | 19/20 [04:03<00:12, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008165 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.787037: 100%|#####################################| 20/20 [04:12<00:00, 11.35s/it][I 2024-02-08 16:48:31,230] Trial 62 finished with value: 0.7870368415806169 and parameters: {'lambda_l1': 8.181318385218018e-08, 'lambda_l2': 1.1100227311306033e-08}. Best is trial 46 with value: 0.7870368415806169.\n",
      "regularization_factors, val_score: 0.787037: 100%|#####################################| 20/20 [04:12<00:00, 12.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's auc: 0.927443\tvalid_0's f1score: 0.688471\tvalid_1's auc: 0.787037\tvalid_1's f1score: 0.651236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.787037:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.787037:  20%|########8                                   | 1/5 [00:06<00:26,  6.67s/it][I 2024-02-08 16:48:37,902] Trial 63 finished with value: 0.7853205387560762 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.7853205387560762.\n",
      "min_child_samples, val_score: 0.787037:  20%|########8                                   | 1/5 [00:06<00:26,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's auc: 0.887801\tvalid_0's f1score: 0.671976\tvalid_1's auc: 0.785321\tvalid_1's f1score: 0.647142\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.787037:  40%|#################6                          | 2/5 [00:12<00:18,  6.19s/it][I 2024-02-08 16:48:43,755] Trial 64 finished with value: 0.7818939433919116 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.7853205387560762.\n",
      "min_child_samples, val_score: 0.787037:  40%|#################6                          | 2/5 [00:12<00:18,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's auc: 0.903549\tvalid_0's f1score: 0.670128\tvalid_1's auc: 0.781894\tvalid_1's f1score: 0.648912\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003049 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.787037:  60%|##########################4                 | 3/5 [00:19<00:13,  6.71s/it][I 2024-02-08 16:48:51,081] Trial 65 finished with value: 0.7809281932203986 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.7853205387560762.\n",
      "min_child_samples, val_score: 0.787037:  60%|##########################4                 | 3/5 [00:19<00:13,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.923073\tvalid_0's f1score: 0.68789\tvalid_1's auc: 0.780928\tvalid_1's f1score: 0.650474\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006769 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.787037:  80%|###################################2        | 4/5 [00:26<00:06,  6.59s/it][I 2024-02-08 16:48:57,499] Trial 66 finished with value: 0.7846781712315514 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.7853205387560762.\n",
      "min_child_samples, val_score: 0.787037:  80%|###################################2        | 4/5 [00:26<00:06,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.878757\tvalid_0's f1score: 0.668671\tvalid_1's auc: 0.784678\tvalid_1's f1score: 0.645578\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5139\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.787037: 100%|############################################| 5/5 [00:34<00:00,  7.05s/it][I 2024-02-08 16:49:05,350] Trial 67 finished with value: 0.7854576025706428 and parameters: {'min_child_samples': 10}. Best is trial 67 with value: 0.7854576025706428.\n",
      "min_child_samples, val_score: 0.787037: 100%|############################################| 5/5 [00:34<00:00,  6.82s/it]\n",
      "[I 2024-02-08 16:49:05,491] A new study created in memory with name: no-name-5b8802ad-514c-49c1-bd56-32be4ed52380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's auc: 0.944345\tvalid_0's f1score: 0.696964\tvalid_1's auc: 0.785458\tvalid_1's f1score: 0.652773\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005284 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.785365:  14%|######4                                      | 1/7 [00:06<00:37,  6.27s/it][I 2024-02-08 16:49:11,760] Trial 0 finished with value: 0.7853654411084382 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.7853654411084382.\n",
      "feature_fraction, val_score: 0.785365:  14%|######4                                      | 1/7 [00:06<00:37,  6.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.895321\tvalid_0's f1score: 0.675265\tvalid_1's auc: 0.785365\tvalid_1's f1score: 0.646141\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.789890:  29%|############8                                | 2/7 [00:13<00:34,  6.82s/it][I 2024-02-08 16:49:18,972] Trial 1 finished with value: 0.7898898674592895 and parameters: {'feature_fraction': 0.5}. Best is trial 1 with value: 0.7898898674592895.\n",
      "feature_fraction, val_score: 0.789890:  29%|############8                                | 2/7 [00:13<00:34,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's auc: 0.896969\tvalid_0's f1score: 0.674651\tvalid_1's auc: 0.78989\tvalid_1's f1score: 0.649966\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008724 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.789890:  43%|###################2                         | 3/7 [00:19<00:26,  6.55s/it][I 2024-02-08 16:49:25,210] Trial 2 finished with value: 0.7861625936806069 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.7898898674592895.\n",
      "feature_fraction, val_score: 0.789890:  43%|###################2                         | 3/7 [00:19<00:26,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.887166\tvalid_0's f1score: 0.669321\tvalid_1's auc: 0.786163\tvalid_1's f1score: 0.641227\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005210 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.789890:  57%|#########################7                   | 4/7 [00:30<00:24,  8.07s/it][I 2024-02-08 16:49:35,598] Trial 3 finished with value: 0.7853008188378978 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7898898674592895.\n",
      "feature_fraction, val_score: 0.789890:  57%|#########################7                   | 4/7 [00:30<00:24,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's auc: 0.875778\tvalid_0's f1score: 0.666102\tvalid_1's auc: 0.785301\tvalid_1's f1score: 0.642511\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008432 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.789890:  71%|################################1            | 5/7 [00:41<00:18,  9.18s/it][I 2024-02-08 16:49:46,761] Trial 4 finished with value: 0.7822462238619541 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.7898898674592895.\n",
      "feature_fraction, val_score: 0.789890:  71%|################################1            | 5/7 [00:41<00:18,  9.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.885849\tvalid_0's f1score: 0.671481\tvalid_1's auc: 0.782246\tvalid_1's f1score: 0.643794\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008410 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.789890:  86%|######################################5      | 6/7 [00:48<00:08,  8.39s/it][I 2024-02-08 16:49:53,585] Trial 5 finished with value: 0.7890626445688379 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.7898898674592895.\n",
      "feature_fraction, val_score: 0.789890:  86%|######################################5      | 6/7 [00:48<00:08,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's auc: 0.888353\tvalid_0's f1score: 0.666987\tvalid_1's auc: 0.789063\tvalid_1's f1score: 0.643053\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.790862: 100%|#############################################| 7/7 [00:58<00:00,  9.21s/it][I 2024-02-08 16:50:04,493] Trial 6 finished with value: 0.7908622374629903 and parameters: {'feature_fraction': 0.4}. Best is trial 6 with value: 0.7908622374629903.\n",
      "feature_fraction, val_score: 0.790862: 100%|#############################################| 7/7 [00:59<00:00,  8.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.871752\tvalid_0's f1score: 0.662678\tvalid_1's auc: 0.790862\tvalid_1's f1score: 0.630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.790862:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006507 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:   5%|##5                                               | 1/20 [00:06<02:07,  6.74s/it][I 2024-02-08 16:50:11,250] Trial 7 finished with value: 0.7912625485751296 and parameters: {'num_leaves': 209}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:   5%|##5                                               | 1/20 [00:06<02:07,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.986576\tvalid_0's f1score: 0.775592\tvalid_1's auc: 0.791263\tvalid_1's f1score: 0.631429\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:  10%|#####                                             | 2/20 [00:13<02:01,  6.75s/it][I 2024-02-08 16:50:17,992] Trial 8 finished with value: 0.788424228580681 and parameters: {'num_leaves': 167}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:  10%|#####                                             | 2/20 [00:13<02:01,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.965324\tvalid_0's f1score: 0.71227\tvalid_1's auc: 0.788424\tvalid_1's f1score: 0.630235\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005813 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:  15%|#######5                                          | 3/20 [00:19<01:52,  6.59s/it][I 2024-02-08 16:50:24,399] Trial 9 finished with value: 0.7905029839008142 and parameters: {'num_leaves': 189}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:  15%|#######5                                          | 3/20 [00:19<01:52,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's auc: 0.982807\tvalid_0's f1score: 0.760645\tvalid_1's auc: 0.790503\tvalid_1's f1score: 0.635672\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:  20%|##########                                        | 4/20 [00:25<01:37,  6.11s/it][I 2024-02-08 16:50:29,776] Trial 10 finished with value: 0.7898511230107328 and parameters: {'num_leaves': 51}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:  20%|##########                                        | 4/20 [00:25<01:37,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's auc: 0.880148\tvalid_0's f1score: 0.664427\tvalid_1's auc: 0.789851\tvalid_1's f1score: 0.633556\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:  25%|############5                                     | 5/20 [00:31<01:31,  6.07s/it][I 2024-02-08 16:50:35,779] Trial 11 finished with value: 0.7851216980477425 and parameters: {'num_leaves': 225}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:  25%|############5                                     | 5/20 [00:31<01:31,  6.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's auc: 0.966841\tvalid_0's f1score: 0.716205\tvalid_1's auc: 0.785122\tvalid_1's f1score: 0.621369\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:  30%|###############                                   | 6/20 [00:37<01:24,  6.06s/it][I 2024-02-08 16:50:41,796] Trial 12 finished with value: 0.7875296366117691 and parameters: {'num_leaves': 92}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:  30%|###############                                   | 6/20 [00:37<01:24,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.931891\tvalid_0's f1score: 0.689115\tvalid_1's auc: 0.78753\tvalid_1's f1score: 0.632731\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005871 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.791263:  35%|#################5                                | 7/20 [00:43<01:17,  5.99s/it][I 2024-02-08 16:50:47,642] Trial 13 finished with value: 0.7824009125185049 and parameters: {'num_leaves': 255}. Best is trial 7 with value: 0.7912625485751296.\n",
      "num_leaves, val_score: 0.791263:  35%|#################5                                | 7/20 [00:43<01:17,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.962363\tvalid_0's f1score: 0.700401\tvalid_1's auc: 0.782401\tvalid_1's f1score: 0.600235\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005848 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.792176:  40%|####################                              | 8/20 [00:48<01:10,  5.87s/it][I 2024-02-08 16:50:53,267] Trial 14 finished with value: 0.7921757899241303 and parameters: {'num_leaves': 136}. Best is trial 14 with value: 0.7921757899241303.\n",
      "num_leaves, val_score: 0.792176:  40%|####################                              | 8/20 [00:48<01:10,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.946781\tvalid_0's f1score: 0.695114\tvalid_1's auc: 0.792176\tvalid_1's f1score: 0.621554\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007115 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  45%|######################5                           | 9/20 [00:54<01:05,  5.94s/it][I 2024-02-08 16:50:59,363] Trial 15 finished with value: 0.7932418405347891 and parameters: {'num_leaves': 125}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  45%|######################5                           | 9/20 [00:54<01:05,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  50%|########################5                        | 10/20 [01:00<00:57,  5.72s/it][I 2024-02-08 16:51:04,586] Trial 16 finished with value: 0.7903912321891192 and parameters: {'num_leaves': 108}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  50%|########################5                        | 10/20 [01:00<00:57,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.927026\tvalid_0's f1score: 0.684894\tvalid_1's auc: 0.790391\tvalid_1's f1score: 0.629763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  55%|##########################9                      | 11/20 [01:05<00:51,  5.72s/it][I 2024-02-08 16:51:10,299] Trial 17 finished with value: 0.7898942045244264 and parameters: {'num_leaves': 142}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  55%|##########################9                      | 11/20 [01:05<00:51,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.955381\tvalid_0's f1score: 0.705352\tvalid_1's auc: 0.789894\tvalid_1's f1score: 0.630362\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002269 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  60%|#############################4                   | 12/20 [01:11<00:46,  5.85s/it][I 2024-02-08 16:51:16,444] Trial 18 finished with value: 0.7926470843356773 and parameters: {'num_leaves': 69}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  60%|#############################4                   | 12/20 [01:11<00:46,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.905447\tvalid_0's f1score: 0.675334\tvalid_1's auc: 0.792647\tvalid_1's f1score: 0.634615\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  65%|###############################8                 | 13/20 [01:18<00:42,  6.06s/it][I 2024-02-08 16:51:22,989] Trial 19 finished with value: 0.7881917618893413 and parameters: {'num_leaves': 5}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  65%|###############################8                 | 13/20 [01:18<00:42,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[196]\tvalid_0's auc: 0.796676\tvalid_0's f1score: 0.628546\tvalid_1's auc: 0.788192\tvalid_1's f1score: 0.62247\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006875 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  70%|##################################3              | 14/20 [01:24<00:36,  6.08s/it][I 2024-02-08 16:51:29,103] Trial 20 finished with value: 0.7915905752683198 and parameters: {'num_leaves': 66}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  70%|##################################3              | 14/20 [01:24<00:36,  6.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.91169\tvalid_0's f1score: 0.677263\tvalid_1's auc: 0.791591\tvalid_1's f1score: 0.632256\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006857 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  75%|####################################7            | 15/20 [01:30<00:30,  6.11s/it][I 2024-02-08 16:51:35,305] Trial 21 finished with value: 0.7901998230477424 and parameters: {'num_leaves': 137}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  75%|####################################7            | 15/20 [01:30<00:30,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's auc: 0.943643\tvalid_0's f1score: 0.693051\tvalid_1's auc: 0.7902\tvalid_1's f1score: 0.621963\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  80%|#######################################2         | 16/20 [01:36<00:23,  5.95s/it][I 2024-02-08 16:51:40,866] Trial 22 finished with value: 0.7925534037287195 and parameters: {'num_leaves': 107}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  80%|#######################################2         | 16/20 [01:36<00:23,  5.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.942306\tvalid_0's f1score: 0.696194\tvalid_1's auc: 0.792553\tvalid_1's f1score: 0.635819\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  85%|#########################################6       | 17/20 [01:42<00:18,  6.15s/it][I 2024-02-08 16:51:47,508] Trial 23 finished with value: 0.7929911581698742 and parameters: {'num_leaves': 70}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  85%|#########################################6       | 17/20 [01:43<00:18,  6.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's auc: 0.956095\tvalid_0's f1score: 0.718076\tvalid_1's auc: 0.792991\tvalid_1's f1score: 0.639877\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  90%|############################################1    | 18/20 [01:47<00:11,  5.72s/it][I 2024-02-08 16:51:52,222] Trial 24 finished with value: 0.789635715442265 and parameters: {'num_leaves': 49}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  90%|############################################1    | 18/20 [01:47<00:11,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.874204\tvalid_0's f1score: 0.663515\tvalid_1's auc: 0.789636\tvalid_1's f1score: 0.62522\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242:  95%|##############################################5  | 19/20 [01:54<00:06,  6.00s/it][I 2024-02-08 16:51:58,906] Trial 25 finished with value: 0.791326881707994 and parameters: {'num_leaves': 16}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242:  95%|##############################################5  | 19/20 [01:54<00:06,  6.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's auc: 0.864983\tvalid_0's f1score: 0.663766\tvalid_1's auc: 0.791327\tvalid_1's f1score: 0.638343\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007342 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.793242: 100%|#################################################| 20/20 [02:00<00:00,  5.97s/it][I 2024-02-08 16:52:04,770] Trial 26 finished with value: 0.7891807573094004 and parameters: {'num_leaves': 75}. Best is trial 15 with value: 0.7932418405347891.\n",
      "num_leaves, val_score: 0.793242: 100%|#################################################| 20/20 [02:00<00:00,  6.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.944026\tvalid_0's f1score: 0.701004\tvalid_1's auc: 0.789181\tvalid_1's f1score: 0.637136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  10%|#####3                                               | 1/10 [00:04<00:43,  4.87s/it][I 2024-02-08 16:52:09,653] Trial 27 finished with value: 0.7881559088175426 and parameters: {'bagging_fraction': 0.7272120492905768, 'bagging_freq': 4}. Best is trial 27 with value: 0.7881559088175426.\n",
      "bagging, val_score: 0.793242:  10%|#####3                                               | 1/10 [00:04<00:43,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's auc: 0.895074\tvalid_0's f1score: 0.649684\tvalid_1's auc: 0.788156\tvalid_1's f1score: 0.60573\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005799 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  20%|##########6                                          | 2/10 [00:10<00:40,  5.08s/it][I 2024-02-08 16:52:14,878] Trial 28 finished with value: 0.7889390382124353 and parameters: {'bagging_fraction': 0.4184158703341265, 'bagging_freq': 1}. Best is trial 28 with value: 0.7889390382124353.\n",
      "bagging, val_score: 0.793242:  20%|##########6                                          | 2/10 [00:10<00:40,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's auc: 0.914697\tvalid_0's f1score: 0.670264\tvalid_1's auc: 0.788939\tvalid_1's f1score: 0.614708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  30%|###############9                                     | 3/10 [00:15<00:37,  5.33s/it][I 2024-02-08 16:52:20,509] Trial 29 finished with value: 0.7868140208641747 and parameters: {'bagging_fraction': 0.9899382008340483, 'bagging_freq': 7}. Best is trial 28 with value: 0.7889390382124353.\n",
      "bagging, val_score: 0.793242:  30%|###############9                                     | 3/10 [00:15<00:37,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.952727\tvalid_0's f1score: 0.701306\tvalid_1's auc: 0.786814\tvalid_1's f1score: 0.631429\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004452 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  40%|#####################2                               | 4/10 [00:20<00:31,  5.21s/it][I 2024-02-08 16:52:25,532] Trial 30 finished with value: 0.7829841032105848 and parameters: {'bagging_fraction': 0.4105644169330055, 'bagging_freq': 7}. Best is trial 28 with value: 0.7889390382124353.\n",
      "bagging, val_score: 0.793242:  40%|#####################2                               | 4/10 [00:20<00:31,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's auc: 0.907708\tvalid_0's f1score: 0.676231\tvalid_1's auc: 0.782984\tvalid_1's f1score: 0.628785\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  50%|##########################5                          | 5/10 [00:26<00:26,  5.34s/it][I 2024-02-08 16:52:31,122] Trial 31 finished with value: 0.784532146326795 and parameters: {'bagging_fraction': 0.9872412604872166, 'bagging_freq': 1}. Best is trial 28 with value: 0.7889390382124353.\n",
      "bagging, val_score: 0.793242:  50%|##########################5                          | 5/10 [00:26<00:26,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.953498\tvalid_0's f1score: 0.706221\tvalid_1's auc: 0.784532\tvalid_1's f1score: 0.63297\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  60%|###############################8                     | 6/10 [00:32<00:23,  5.76s/it][I 2024-02-08 16:52:37,694] Trial 32 finished with value: 0.7902981298575129 and parameters: {'bagging_fraction': 0.7171304062793953, 'bagging_freq': 4}. Best is trial 32 with value: 0.7902981298575129.\n",
      "bagging, val_score: 0.793242:  60%|###############################8                     | 6/10 [00:32<00:23,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.972288\tvalid_0's f1score: 0.740825\tvalid_1's auc: 0.790298\tvalid_1's f1score: 0.631661\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005473 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  70%|#####################################                | 7/10 [00:37<00:16,  5.54s/it][I 2024-02-08 16:52:42,759] Trial 33 finished with value: 0.7872945676813472 and parameters: {'bagging_fraction': 0.5647673983050681, 'bagging_freq': 3}. Best is trial 32 with value: 0.7902981298575129.\n",
      "bagging, val_score: 0.793242:  70%|#####################################                | 7/10 [00:37<00:16,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's auc: 0.900109\tvalid_0's f1score: 0.659315\tvalid_1's auc: 0.787295\tvalid_1's f1score: 0.600235\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  80%|##########################################4          | 8/10 [00:44<00:11,  5.94s/it][I 2024-02-08 16:52:49,547] Trial 34 finished with value: 0.7920313656550703 and parameters: {'bagging_fraction': 0.843652989071868, 'bagging_freq': 6}. Best is trial 34 with value: 0.7920313656550703.\n",
      "bagging, val_score: 0.793242:  80%|##########################################4          | 8/10 [00:44<00:11,  5.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.966593\tvalid_0's f1score: 0.726606\tvalid_1's auc: 0.792031\tvalid_1's f1score: 0.644866\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002900 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242:  90%|###############################################7     | 9/10 [00:51<00:06,  6.26s/it][I 2024-02-08 16:52:56,516] Trial 35 finished with value: 0.7885005609270911 and parameters: {'bagging_fraction': 0.5806192923031483, 'bagging_freq': 2}. Best is trial 34 with value: 0.7920313656550703.\n",
      "bagging, val_score: 0.793242:  90%|###############################################7     | 9/10 [00:51<00:06,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's auc: 0.949128\tvalid_0's f1score: 0.705715\tvalid_1's auc: 0.788501\tvalid_1's f1score: 0.643547\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004143 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.793242: 100%|####################################################| 10/10 [00:58<00:00,  6.37s/it][I 2024-02-08 16:53:03,121] Trial 36 finished with value: 0.7926485300240562 and parameters: {'bagging_fraction': 0.8450969697844265, 'bagging_freq': 5}. Best is trial 36 with value: 0.7926485300240562.\n",
      "bagging, val_score: 0.793242: 100%|####################################################| 10/10 [00:58<00:00,  5.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's auc: 0.953294\tvalid_0's f1score: 0.703461\tvalid_1's auc: 0.792649\tvalid_1's f1score: 0.629527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.793242:   0%|                                              | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.793242:  33%|############6                         | 1/3 [00:06<00:12,  6.12s/it][I 2024-02-08 16:53:09,259] Trial 37 finished with value: 0.7856513982698001 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.7856513982698001.\n",
      "feature_fraction_stage2, val_score: 0.793242:  33%|############6                         | 1/3 [00:06<00:12,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.951838\tvalid_0's f1score: 0.705864\tvalid_1's auc: 0.785651\tvalid_1's f1score: 0.627146\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.793242:  67%|#########################3            | 2/3 [00:11<00:05,  5.96s/it][I 2024-02-08 16:53:15,101] Trial 38 finished with value: 0.7870321752405626 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 38 with value: 0.7870321752405626.\n",
      "feature_fraction_stage2, val_score: 0.793242:  67%|#########################3            | 2/3 [00:11<00:05,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's auc: 0.92484\tvalid_0's f1score: 0.68102\tvalid_1's auc: 0.787032\tvalid_1's f1score: 0.625524\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.793242: 100%|######################################| 3/3 [00:17<00:00,  5.94s/it][I 2024-02-08 16:53:21,030] Trial 39 finished with value: 0.7861805202165063 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 38 with value: 0.7870321752405626.\n",
      "feature_fraction_stage2, val_score: 0.793242: 100%|######################################| 3/3 [00:17<00:00,  5.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.952565\tvalid_0's f1score: 0.708148\tvalid_1's auc: 0.786181\tvalid_1's f1score: 0.638022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007315 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:   5%|#9                                    | 1/20 [00:05<01:36,  5.06s/it][I 2024-02-08 16:53:26,095] Trial 40 finished with value: 0.791495448972983 and parameters: {'lambda_l1': 0.0054487380769418945, 'lambda_l2': 0.04144522135997417}. Best is trial 40 with value: 0.791495448972983.\n",
      "regularization_factors, val_score: 0.793242:   5%|#9                                    | 1/20 [00:05<01:36,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's auc: 0.911363\tvalid_0's f1score: 0.667817\tvalid_1's auc: 0.791495\tvalid_1's f1score: 0.613127\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006954 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  10%|###8                                  | 2/20 [00:11<01:45,  5.88s/it][I 2024-02-08 16:53:32,551] Trial 41 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.2181736308816296e-08, 'lambda_l2': 1.4587832294247673e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  10%|###8                                  | 2/20 [00:11<01:45,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  15%|#####7                                | 3/20 [00:18<01:46,  6.26s/it][I 2024-02-08 16:53:39,258] Trial 42 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.3898341685071799e-07, 'lambda_l2': 1.2078253341968053e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  15%|#####7                                | 3/20 [00:18<01:46,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  20%|#######6                              | 4/20 [00:24<01:42,  6.43s/it][I 2024-02-08 16:53:45,944] Trial 43 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.8987090819080425e-08, 'lambda_l2': 5.803197458106437e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  20%|#######6                              | 4/20 [00:24<01:42,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  25%|#########5                            | 5/20 [00:31<01:34,  6.32s/it][I 2024-02-08 16:53:52,071] Trial 44 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.106581744294899e-08, 'lambda_l2': 1.2787528459716753e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  25%|#########5                            | 5/20 [00:31<01:34,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004063 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  30%|###########4                          | 6/20 [00:37<01:27,  6.28s/it][I 2024-02-08 16:53:58,287] Trial 45 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.2564590063320417e-08, 'lambda_l2': 1.3583250365119149e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  30%|###########4                          | 6/20 [00:37<01:27,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007341 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  35%|#############3                        | 7/20 [00:43<01:21,  6.25s/it][I 2024-02-08 16:54:04,467] Trial 46 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.2170426380996107e-08, 'lambda_l2': 1.740358772837612e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  35%|#############3                        | 7/20 [00:43<01:21,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007495 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  40%|###############2                      | 8/20 [00:49<01:15,  6.29s/it][I 2024-02-08 16:54:10,826] Trial 47 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.5157553664708936e-08, 'lambda_l2': 1.1275101928853252e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  40%|###############2                      | 8/20 [00:49<01:15,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006781 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  45%|#################1                    | 9/20 [00:56<01:09,  6.32s/it][I 2024-02-08 16:54:17,238] Trial 48 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 8.047132363781629e-08, 'lambda_l2': 3.025545234370112e-08}. Best is trial 41 with value: 0.7932418405347891.\n",
      "regularization_factors, val_score: 0.793242:  45%|#################1                    | 9/20 [00:56<01:09,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006797 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  50%|##################5                  | 10/20 [01:02<01:04,  6.41s/it][I 2024-02-08 16:54:23,839] Trial 49 finished with value: 0.7932421296724649 and parameters: {'lambda_l1': 4.882286226935187e-06, 'lambda_l2': 2.017091561384744e-06}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  50%|##################5                  | 10/20 [01:02<01:04,  6.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959691\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007096 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  55%|####################3                | 11/20 [01:07<00:54,  6.01s/it][I 2024-02-08 16:54:28,922] Trial 50 finished with value: 0.788855911130644 and parameters: {'lambda_l1': 5.2508798850047127e-05, 'lambda_l2': 1.2510608460357235e-05}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  55%|####################3                | 11/20 [01:07<00:54,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[33]\tvalid_0's auc: 0.894155\tvalid_0's f1score: 0.641001\tvalid_1's auc: 0.788856\tvalid_1's f1score: 0.587596\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  60%|######################2              | 12/20 [01:13<00:47,  5.91s/it][I 2024-02-08 16:54:34,613] Trial 51 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 3.4991326128925044e-06, 'lambda_l2': 1.3561195814219493e-06}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  60%|######################2              | 12/20 [01:13<00:47,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959691\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002322 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  65%|########################             | 13/20 [01:19<00:41,  5.92s/it][I 2024-02-08 16:54:40,565] Trial 52 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 8.016251576301627e-07, 'lambda_l2': 3.5579583308679723e-07}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  65%|########################             | 13/20 [01:19<00:41,  5.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006411 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  70%|#########################9           | 14/20 [01:25<00:35,  5.86s/it][I 2024-02-08 16:54:46,276] Trial 53 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 5.337758528563186e-07, 'lambda_l2': 3.6129100282340794e-07}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  70%|#########################9           | 14/20 [01:25<00:35,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  75%|###########################7         | 15/20 [01:32<00:30,  6.16s/it][I 2024-02-08 16:54:53,124] Trial 54 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 2.2176200958925968e-07, 'lambda_l2': 1.0964200543767613e-08}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  75%|###########################7         | 15/20 [01:32<00:30,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007071 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  80%|#############################6       | 16/20 [01:38<00:25,  6.32s/it][I 2024-02-08 16:54:59,836] Trial 55 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.0177426447387784e-08, 'lambda_l2': 3.8897595658828056e-07}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  80%|#############################6       | 16/20 [01:38<00:25,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959692\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004557 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  85%|###############################4     | 17/20 [01:45<00:18,  6.33s/it][I 2024-02-08 16:55:06,175] Trial 56 finished with value: 0.7925429947723909 and parameters: {'lambda_l1': 2.4744944831875424, 'lambda_l2': 0.00022991265972747667}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  85%|###############################4     | 17/20 [01:45<00:18,  6.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's auc: 0.912171\tvalid_0's f1score: 0.674776\tvalid_1's auc: 0.792543\tvalid_1's f1score: 0.624201\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006734 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  90%|#################################3   | 18/20 [01:51<00:12,  6.29s/it][I 2024-02-08 16:55:12,361] Trial 57 finished with value: 0.7932421296724649 and parameters: {'lambda_l1': 1.1158677504170498e-05, 'lambda_l2': 1.6536086500830072e-07}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  90%|#################################3   | 18/20 [01:51<00:12,  6.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959691\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007017 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242:  95%|###################################1 | 19/20 [01:57<00:06,  6.35s/it][I 2024-02-08 16:55:18,865] Trial 58 finished with value: 0.7932418405347891 and parameters: {'lambda_l1': 1.630509738919265e-05, 'lambda_l2': 5.7346912771113695e-06}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242:  95%|###################################1 | 19/20 [01:57<00:06,  6.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.959691\tvalid_0's f1score: 0.713577\tvalid_1's auc: 0.793242\tvalid_1's f1score: 0.631666\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.793242: 100%|#####################################| 20/20 [02:04<00:00,  6.34s/it][I 2024-02-08 16:55:25,192] Trial 59 finished with value: 0.7896160540803109 and parameters: {'lambda_l1': 0.00024203188627821643, 'lambda_l2': 3.0179628388018977e-07}. Best is trial 49 with value: 0.7932421296724649.\n",
      "regularization_factors, val_score: 0.793242: 100%|#####################################| 20/20 [02:04<00:00,  6.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's auc: 0.948789\tvalid_0's f1score: 0.69925\tvalid_1's auc: 0.789616\tvalid_1's f1score: 0.627612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.793242:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.793242:  20%|########8                                   | 1/5 [00:06<00:26,  6.62s/it][I 2024-02-08 16:55:31,825] Trial 60 finished with value: 0.788939471918949 and parameters: {'min_child_samples': 5}. Best is trial 60 with value: 0.788939471918949.\n",
      "min_child_samples, val_score: 0.793242:  20%|########8                                   | 1/5 [00:06<00:26,  6.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.972045\tvalid_0's f1score: 0.718525\tvalid_1's auc: 0.788939\tvalid_1's f1score: 0.628957\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006858 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.793242:  40%|#################6                          | 2/5 [00:13<00:19,  6.49s/it][I 2024-02-08 16:55:38,224] Trial 61 finished with value: 0.7913988769892673 and parameters: {'min_child_samples': 50}. Best is trial 61 with value: 0.7913988769892673.\n",
      "min_child_samples, val_score: 0.793242:  40%|#################6                          | 2/5 [00:13<00:19,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.948068\tvalid_0's f1score: 0.700095\tvalid_1's auc: 0.791399\tvalid_1's f1score: 0.640612\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.793242:  60%|##########################4                 | 3/5 [00:19<00:13,  6.53s/it][I 2024-02-08 16:55:44,781] Trial 62 finished with value: 0.7885213788397484 and parameters: {'min_child_samples': 10}. Best is trial 61 with value: 0.7913988769892673.\n",
      "min_child_samples, val_score: 0.793242:  60%|##########################4                 | 3/5 [00:19<00:13,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.971376\tvalid_0's f1score: 0.730818\tvalid_1's auc: 0.788521\tvalid_1's f1score: 0.633898\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.793242:  80%|###################################2        | 4/5 [00:26<00:06,  6.52s/it][I 2024-02-08 16:55:51,295] Trial 63 finished with value: 0.7906769002128053 and parameters: {'min_child_samples': 25}. Best is trial 61 with value: 0.7913988769892673.\n",
      "min_child_samples, val_score: 0.793242:  80%|###################################2        | 4/5 [00:26<00:06,  6.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.955306\tvalid_0's f1score: 0.7081\tvalid_1's auc: 0.790677\tvalid_1's f1score: 0.633317\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006541 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5135\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.793242: 100%|############################################| 5/5 [00:32<00:00,  6.39s/it][I 2024-02-08 16:55:57,452] Trial 64 finished with value: 0.789515289600296 and parameters: {'min_child_samples': 100}. Best is trial 61 with value: 0.7913988769892673.\n",
      "min_child_samples, val_score: 0.793242: 100%|############################################| 5/5 [00:32<00:00,  6.45s/it]\n",
      "[I 2024-02-08 16:55:57,593] A new study created in memory with name: no-name-222ec5fc-cc29-4ab8-a15b-ecf744070ca0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.917192\tvalid_0's f1score: 0.671635\tvalid_1's auc: 0.789515\tvalid_1's f1score: 0.625757\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007657 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.780599:  14%|######4                                      | 1/7 [00:07<00:47,  7.94s/it][I 2024-02-08 16:56:05,549] Trial 0 finished with value: 0.7805986687339607 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.7805986687339607.\n",
      "feature_fraction, val_score: 0.780599:  14%|######4                                      | 1/7 [00:07<00:47,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's auc: 0.918755\tvalid_0's f1score: 0.683661\tvalid_1's auc: 0.780599\tvalid_1's f1score: 0.640049\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008477 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.780787:  29%|############8                                | 2/7 [00:18<00:46,  9.39s/it][I 2024-02-08 16:56:15,941] Trial 1 finished with value: 0.7807872647562019 and parameters: {'feature_fraction': 0.8}. Best is trial 1 with value: 0.7807872647562019.\n",
      "feature_fraction, val_score: 0.780787:  29%|############8                                | 2/7 [00:18<00:46,  9.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's auc: 0.887031\tvalid_0's f1score: 0.669262\tvalid_1's auc: 0.780787\tvalid_1's f1score: 0.639306\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007674 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783649:  43%|###################2                         | 3/7 [00:26<00:35,  8.85s/it][I 2024-02-08 16:56:24,142] Trial 2 finished with value: 0.7836489520958084 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.7836489520958084.\n",
      "feature_fraction, val_score: 0.783649:  43%|###################2                         | 3/7 [00:26<00:35,  8.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's auc: 0.919061\tvalid_0's f1score: 0.685849\tvalid_1's auc: 0.783649\tvalid_1's f1score: 0.643788\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008218 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.783649:  57%|#########################7                   | 4/7 [00:32<00:23,  7.72s/it][I 2024-02-08 16:56:30,151] Trial 3 finished with value: 0.7793045605218135 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.7836489520958084.\n",
      "feature_fraction, val_score: 0.783649:  57%|#########################7                   | 4/7 [00:32<00:23,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.868618\tvalid_0's f1score: 0.661755\tvalid_1's auc: 0.779305\tvalid_1's f1score: 0.641168\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.785358:  71%|################################1            | 5/7 [00:38<00:13,  6.99s/it][I 2024-02-08 16:56:35,843] Trial 4 finished with value: 0.7853575438408896 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.7853575438408896.\n",
      "feature_fraction, val_score: 0.785358:  71%|################################1            | 5/7 [00:38<00:13,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.848163\tvalid_0's f1score: 0.651022\tvalid_1's auc: 0.785358\tvalid_1's f1score: 0.633468\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006578 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.785358:  86%|######################################5      | 6/7 [00:43<00:06,  6.47s/it][I 2024-02-08 16:56:41,309] Trial 5 finished with value: 0.7845426112061591 and parameters: {'feature_fraction': 0.6}. Best is trial 4 with value: 0.7853575438408896.\n",
      "feature_fraction, val_score: 0.785358:  86%|######################################5      | 6/7 [00:43<00:06,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's auc: 0.853483\tvalid_0's f1score: 0.657224\tvalid_1's auc: 0.784543\tvalid_1's f1score: 0.642593\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.786082: 100%|#############################################| 7/7 [00:52<00:00,  7.24s/it][I 2024-02-08 16:56:50,138] Trial 6 finished with value: 0.786082121471343 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.786082121471343.\n",
      "feature_fraction, val_score: 0.786082: 100%|#############################################| 7/7 [00:52<00:00,  7.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's auc: 0.929471\tvalid_0's f1score: 0.694073\tvalid_1's auc: 0.786082\tvalid_1's f1score: 0.638851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786082:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786082:   5%|##5                                               | 1/20 [00:05<01:41,  5.36s/it][I 2024-02-08 16:56:55,518] Trial 7 finished with value: 0.7806747219846022 and parameters: {'num_leaves': 149}. Best is trial 7 with value: 0.7806747219846022.\n",
      "num_leaves, val_score: 0.786082:   5%|##5                                               | 1/20 [00:05<01:41,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.900031\tvalid_0's f1score: 0.635409\tvalid_1's auc: 0.780675\tvalid_1's f1score: 0.588263\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008322 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  10%|#####                                             | 2/20 [00:10<01:35,  5.29s/it][I 2024-02-08 16:57:00,765] Trial 8 finished with value: 0.7862434505988024 and parameters: {'num_leaves': 102}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  10%|#####                                             | 2/20 [00:10<01:35,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's auc: 0.873151\tvalid_0's f1score: 0.618946\tvalid_1's auc: 0.786243\tvalid_1's f1score: 0.588639\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007756 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  15%|#######5                                          | 3/20 [00:16<01:31,  5.40s/it][I 2024-02-08 16:57:06,296] Trial 9 finished with value: 0.7844781864841746 and parameters: {'num_leaves': 70}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  15%|#######5                                          | 3/20 [00:16<01:31,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.908119\tvalid_0's f1score: 0.673449\tvalid_1's auc: 0.784478\tvalid_1's f1score: 0.638093\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007583 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  20%|##########                                        | 4/20 [00:21<01:28,  5.53s/it][I 2024-02-08 16:57:12,027] Trial 10 finished with value: 0.7775117621899059 and parameters: {'num_leaves': 250}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  20%|##########                                        | 4/20 [00:21<01:28,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.9168\tvalid_0's f1score: 0.565452\tvalid_1's auc: 0.777512\tvalid_1's f1score: 0.52485\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007208 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  25%|############5                                     | 5/20 [00:31<01:42,  6.84s/it][I 2024-02-08 16:57:21,204] Trial 11 finished with value: 0.78410874679213 and parameters: {'num_leaves': 8}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  25%|############5                                     | 5/20 [00:31<01:42,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.871103\tvalid_0's f1score: 0.662378\tvalid_1's auc: 0.784109\tvalid_1's f1score: 0.644708\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007540 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  30%|###############                                   | 6/20 [00:36<01:28,  6.32s/it][I 2024-02-08 16:57:26,487] Trial 12 finished with value: 0.7816369493156544 and parameters: {'num_leaves': 155}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  30%|###############                                   | 6/20 [00:36<01:28,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.869704\tvalid_0's f1score: 0.476836\tvalid_1's auc: 0.781637\tvalid_1's f1score: 0.472197\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  35%|#################5                                | 7/20 [00:40<01:14,  5.73s/it][I 2024-02-08 16:57:31,023] Trial 13 finished with value: 0.7839708083832335 and parameters: {'num_leaves': 86}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  35%|#################5                                | 7/20 [00:40<01:14,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.84763\tvalid_0's f1score: 0.57019\tvalid_1's auc: 0.783971\tvalid_1's f1score: 0.538515\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006252 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  40%|####################                              | 8/20 [00:48<01:14,  6.19s/it][I 2024-02-08 16:57:38,174] Trial 14 finished with value: 0.7811665953806672 and parameters: {'num_leaves': 211}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  40%|####################                              | 8/20 [00:48<01:14,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.982524\tvalid_0's f1score: 0.756831\tvalid_1's auc: 0.781167\tvalid_1's f1score: 0.640708\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007549 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  45%|######################5                           | 9/20 [00:57<01:18,  7.18s/it][I 2024-02-08 16:57:47,531] Trial 15 finished with value: 0.7822963002566296 and parameters: {'num_leaves': 6}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  45%|######################5                           | 9/20 [00:57<01:18,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.847042\tvalid_0's f1score: 0.653066\tvalid_1's auc: 0.782296\tvalid_1's f1score: 0.644937\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004267 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  50%|########################5                        | 10/20 [01:02<01:04,  6.49s/it][I 2024-02-08 16:57:52,485] Trial 16 finished with value: 0.7846420551753636 and parameters: {'num_leaves': 80}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  50%|########################5                        | 10/20 [01:02<01:04,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's auc: 0.861269\tvalid_0's f1score: 0.621454\tvalid_1's auc: 0.784642\tvalid_1's f1score: 0.597387\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008134 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  55%|##########################9                      | 11/20 [01:07<00:54,  6.11s/it][I 2024-02-08 16:57:57,713] Trial 17 finished with value: 0.7779684826775022 and parameters: {'num_leaves': 192}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  55%|##########################9                      | 11/20 [01:07<00:54,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's auc: 0.89792\tvalid_0's f1score: 0.552651\tvalid_1's auc: 0.777968\tvalid_1's f1score: 0.518433\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004588 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786243:  60%|#############################4                   | 12/20 [01:12<00:46,  5.77s/it][I 2024-02-08 16:58:02,714] Trial 18 finished with value: 0.7811163387510693 and parameters: {'num_leaves': 111}. Best is trial 8 with value: 0.7862434505988024.\n",
      "num_leaves, val_score: 0.786243:  60%|#############################4                   | 12/20 [01:12<00:46,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.842681\tvalid_0's f1score: 0.472581\tvalid_1's auc: 0.781116\tvalid_1's f1score: 0.470734\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007105 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786681:  65%|###############################8                 | 13/20 [01:18<00:40,  5.77s/it][I 2024-02-08 16:58:08,501] Trial 19 finished with value: 0.7866811911890504 and parameters: {'num_leaves': 41}. Best is trial 19 with value: 0.7866811911890504.\n",
      "num_leaves, val_score: 0.786681:  65%|###############################8                 | 13/20 [01:18<00:40,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.870635\tvalid_0's f1score: 0.661829\tvalid_1's auc: 0.786681\tvalid_1's f1score: 0.641399\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007582 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786681:  70%|##################################3              | 14/20 [01:23<00:34,  5.73s/it][I 2024-02-08 16:58:14,127] Trial 20 finished with value: 0.7857839232249786 and parameters: {'num_leaves': 45}. Best is trial 19 with value: 0.7866811911890504.\n",
      "num_leaves, val_score: 0.786681:  70%|##################################3              | 14/20 [01:23<00:34,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.883083\tvalid_0's f1score: 0.667034\tvalid_1's auc: 0.785784\tvalid_1's f1score: 0.639272\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006117 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786681:  75%|####################################7            | 15/20 [01:29<00:28,  5.75s/it][I 2024-02-08 16:58:19,936] Trial 21 finished with value: 0.7864806993156545 and parameters: {'num_leaves': 36}. Best is trial 19 with value: 0.7866811911890504.\n",
      "num_leaves, val_score: 0.786681:  75%|####################################7            | 15/20 [01:29<00:28,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's auc: 0.868633\tvalid_0's f1score: 0.660311\tvalid_1's auc: 0.786481\tvalid_1's f1score: 0.643998\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007725 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786681:  80%|#######################################2         | 16/20 [01:35<00:23,  5.83s/it][I 2024-02-08 16:58:25,923] Trial 22 finished with value: 0.7854720915312232 and parameters: {'num_leaves': 35}. Best is trial 19 with value: 0.7866811911890504.\n",
      "num_leaves, val_score: 0.786681:  80%|#######################################2         | 16/20 [01:35<00:23,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's auc: 0.871681\tvalid_0's f1score: 0.660955\tvalid_1's auc: 0.785472\tvalid_1's f1score: 0.644704\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007449 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.786681:  85%|#########################################6       | 17/20 [01:41<00:17,  5.80s/it][I 2024-02-08 16:58:31,646] Trial 23 finished with value: 0.7865635692899915 and parameters: {'num_leaves': 43}. Best is trial 19 with value: 0.7866811911890504.\n",
      "num_leaves, val_score: 0.786681:  85%|#########################################6       | 17/20 [01:41<00:17,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's auc: 0.868718\tvalid_0's f1score: 0.65858\tvalid_1's auc: 0.786564\tvalid_1's f1score: 0.636588\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004268 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.787011:  90%|############################################1    | 18/20 [01:47<00:11,  5.96s/it][I 2024-02-08 16:58:37,997] Trial 24 finished with value: 0.7870113344739094 and parameters: {'num_leaves': 44}. Best is trial 24 with value: 0.7870113344739094.\n",
      "num_leaves, val_score: 0.787011:  90%|############################################1    | 18/20 [01:47<00:11,  5.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's auc: 0.91854\tvalid_0's f1score: 0.685977\tvalid_1's auc: 0.787011\tvalid_1's f1score: 0.644941\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004493 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.787011:  95%|##############################################5  | 19/20 [01:52<00:05,  5.70s/it][I 2024-02-08 16:58:43,102] Trial 25 finished with value: 0.7844616124893071 and parameters: {'num_leaves': 56}. Best is trial 24 with value: 0.7870113344739094.\n",
      "num_leaves, val_score: 0.787011:  95%|##############################################5  | 19/20 [01:52<00:05,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.892944\tvalid_0's f1score: 0.669481\tvalid_1's auc: 0.784462\tvalid_1's f1score: 0.637823\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004816 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.787011: 100%|#################################################| 20/20 [01:57<00:00,  5.48s/it][I 2024-02-08 16:58:48,051] Trial 26 finished with value: 0.7844473107356715 and parameters: {'num_leaves': 25}. Best is trial 24 with value: 0.7870113344739094.\n",
      "num_leaves, val_score: 0.787011: 100%|#################################################| 20/20 [01:57<00:00,  5.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.850133\tvalid_0's f1score: 0.65877\tvalid_1's auc: 0.784447\tvalid_1's f1score: 0.643301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787011:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787011:  10%|#####3                                               | 1/10 [00:04<00:42,  4.77s/it][I 2024-02-08 16:58:52,824] Trial 27 finished with value: 0.781336879811805 and parameters: {'bagging_fraction': 0.6123317821035567, 'bagging_freq': 2}. Best is trial 27 with value: 0.781336879811805.\n",
      "bagging, val_score: 0.787011:  10%|#####3                                               | 1/10 [00:04<00:42,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's auc: 0.862232\tvalid_0's f1score: 0.654557\tvalid_1's auc: 0.781337\tvalid_1's f1score: 0.627946\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787011:  20%|##########6                                          | 2/10 [00:09<00:39,  4.92s/it][I 2024-02-08 16:58:57,839] Trial 28 finished with value: 0.7855143284858854 and parameters: {'bagging_fraction': 0.9342705241751211, 'bagging_freq': 7}. Best is trial 28 with value: 0.7855143284858854.\n",
      "bagging, val_score: 0.787011:  20%|##########6                                          | 2/10 [00:09<00:39,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.876384\tvalid_0's f1score: 0.662327\tvalid_1's auc: 0.785514\tvalid_1's f1score: 0.640221\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004765 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787011:  30%|###############9                                     | 3/10 [00:13<00:31,  4.50s/it][I 2024-02-08 16:59:01,851] Trial 29 finished with value: 0.777268365055603 and parameters: {'bagging_fraction': 0.44117363039147234, 'bagging_freq': 6}. Best is trial 28 with value: 0.7855143284858854.\n",
      "bagging, val_score: 0.787011:  30%|###############9                                     | 3/10 [00:13<00:31,  4.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[22]\tvalid_0's auc: 0.810444\tvalid_0's f1score: 0.539511\tvalid_1's auc: 0.777268\tvalid_1's f1score: 0.53398\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787011:  40%|#####################2                               | 4/10 [00:18<00:28,  4.73s/it][I 2024-02-08 16:59:06,930] Trial 30 finished with value: 0.7835666167664671 and parameters: {'bagging_fraction': 0.9866514744850011, 'bagging_freq': 1}. Best is trial 28 with value: 0.7855143284858854.\n",
      "bagging, val_score: 0.787011:  40%|#####################2                               | 4/10 [00:18<00:28,  4.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's auc: 0.882059\tvalid_0's f1score: 0.664214\tvalid_1's auc: 0.783567\tvalid_1's f1score: 0.640962\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005824 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.787011:  50%|##########################5                          | 5/10 [00:24<00:25,  5.01s/it][I 2024-02-08 16:59:12,429] Trial 31 finished with value: 0.7866119546621043 and parameters: {'bagging_fraction': 0.7450300649527196, 'bagging_freq': 4}. Best is trial 31 with value: 0.7866119546621043.\n",
      "bagging, val_score: 0.787011:  50%|##########################5                          | 5/10 [00:24<00:25,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's auc: 0.900636\tvalid_0's f1score: 0.673976\tvalid_1's auc: 0.786612\tvalid_1's f1score: 0.644013\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006271 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.789023:  60%|###############################8                     | 6/10 [00:30<00:20,  5.24s/it][I 2024-02-08 16:59:18,103] Trial 32 finished with value: 0.7890229362703165 and parameters: {'bagging_fraction': 0.7428640866412556, 'bagging_freq': 4}. Best is trial 32 with value: 0.7890229362703165.\n",
      "bagging, val_score: 0.789023:  60%|###############################8                     | 6/10 [00:30<00:20,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's auc: 0.905686\tvalid_0's f1score: 0.676442\tvalid_1's auc: 0.789023\tvalid_1's f1score: 0.638093\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007396 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.789023:  70%|#####################################                | 7/10 [00:35<00:16,  5.44s/it][I 2024-02-08 16:59:23,975] Trial 33 finished with value: 0.7862898310521813 and parameters: {'bagging_fraction': 0.7436231831363792, 'bagging_freq': 4}. Best is trial 32 with value: 0.7890229362703165.\n",
      "bagging, val_score: 0.789023:  70%|#####################################                | 7/10 [00:35<00:16,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's auc: 0.894389\tvalid_0's f1score: 0.670605\tvalid_1's auc: 0.78629\tvalid_1's f1score: 0.640681\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.789023:  80%|##########################################4          | 8/10 [00:40<00:10,  5.32s/it][I 2024-02-08 16:59:29,041] Trial 34 finished with value: 0.784714499572284 and parameters: {'bagging_fraction': 0.74863871294872, 'bagging_freq': 4}. Best is trial 32 with value: 0.7890229362703165.\n",
      "bagging, val_score: 0.789023:  80%|##########################################4          | 8/10 [00:40<00:10,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's auc: 0.874105\tvalid_0's f1score: 0.662851\tvalid_1's auc: 0.784714\tvalid_1's f1score: 0.63183\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004237 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.789023:  90%|###############################################7     | 9/10 [00:45<00:05,  5.21s/it][I 2024-02-08 16:59:33,989] Trial 35 finished with value: 0.7861548331907613 and parameters: {'bagging_fraction': 0.8209291330675947, 'bagging_freq': 5}. Best is trial 32 with value: 0.7890229362703165.\n",
      "bagging, val_score: 0.789023:  90%|###############################################7     | 9/10 [00:45<00:05,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.872435\tvalid_0's f1score: 0.660465\tvalid_1's auc: 0.786155\tvalid_1's f1score: 0.63551\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004323 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.789023: 100%|####################################################| 10/10 [00:51<00:00,  5.43s/it][I 2024-02-08 16:59:39,945] Trial 36 finished with value: 0.7861981394354148 and parameters: {'bagging_fraction': 0.6011882357215356, 'bagging_freq': 3}. Best is trial 32 with value: 0.7890229362703165.\n",
      "bagging, val_score: 0.789023: 100%|####################################################| 10/10 [00:51<00:00,  5.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.905689\tvalid_0's f1score: 0.672958\tvalid_1's auc: 0.786198\tvalid_1's f1score: 0.644711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789023:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007928 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789023:  17%|######3                               | 1/6 [00:05<00:25,  5.17s/it][I 2024-02-08 16:59:45,117] Trial 37 finished with value: 0.7841940226689478 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.7841940226689478.\n",
      "feature_fraction_stage2, val_score: 0.789023:  17%|######3                               | 1/6 [00:05<00:25,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.87702\tvalid_0's f1score: 0.66417\tvalid_1's auc: 0.784194\tvalid_1's f1score: 0.641443\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007212 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789701:  33%|############6                         | 2/6 [00:10<00:20,  5.16s/it][I 2024-02-08 16:59:50,275] Trial 38 finished with value: 0.7897011334473909 and parameters: {'feature_fraction': 0.42}. Best is trial 38 with value: 0.7897011334473909.\n",
      "feature_fraction_stage2, val_score: 0.789701:  33%|############6                         | 2/6 [00:10<00:20,  5.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005123 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789701:  50%|###################                   | 3/6 [00:15<00:15,  5.01s/it][I 2024-02-08 16:59:55,094] Trial 39 finished with value: 0.789006495936698 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 38 with value: 0.7897011334473909.\n",
      "feature_fraction_stage2, val_score: 0.789701:  50%|###################                   | 3/6 [00:15<00:15,  5.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's auc: 0.860897\tvalid_0's f1score: 0.650798\tvalid_1's auc: 0.789006\tvalid_1's f1score: 0.631225\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005032 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789701:  67%|#########################3            | 4/6 [00:20<00:10,  5.30s/it][I 2024-02-08 17:00:00,845] Trial 40 finished with value: 0.7810954875962361 and parameters: {'feature_fraction': 0.58}. Best is trial 38 with value: 0.7897011334473909.\n",
      "feature_fraction_stage2, val_score: 0.789701:  67%|#########################3            | 4/6 [00:20<00:10,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.889697\tvalid_0's f1score: 0.670597\tvalid_1's auc: 0.781095\tvalid_1's f1score: 0.644941\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005891 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789701:  83%|###############################6      | 5/6 [00:25<00:05,  5.08s/it][I 2024-02-08 17:00:05,524] Trial 41 finished with value: 0.7856942365269461 and parameters: {'feature_fraction': 0.484}. Best is trial 38 with value: 0.7897011334473909.\n",
      "feature_fraction_stage2, val_score: 0.789701:  83%|###############################6      | 5/6 [00:25<00:05,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's auc: 0.83605\tvalid_0's f1score: 0.624819\tvalid_1's auc: 0.785694\tvalid_1's f1score: 0.61256\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.789701: 100%|######################################| 6/6 [00:31<00:00,  5.50s/it][I 2024-02-08 17:00:11,855] Trial 42 finished with value: 0.7862681779298546 and parameters: {'feature_fraction': 0.516}. Best is trial 38 with value: 0.7897011334473909.\n",
      "feature_fraction_stage2, val_score: 0.789701: 100%|######################################| 6/6 [00:31<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's auc: 0.884614\tvalid_0's f1score: 0.664203\tvalid_1's auc: 0.786268\tvalid_1's f1score: 0.645171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789701:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005030 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.789701:   5%|#9                                    | 1/20 [00:05<01:42,  5.37s/it][I 2024-02-08 17:00:17,241] Trial 43 finished with value: 0.7879597946963216 and parameters: {'lambda_l1': 0.014740199561462464, 'lambda_l2': 6.498736527406643e-08}. Best is trial 43 with value: 0.7879597946963216.\n",
      "regularization_factors, val_score: 0.789701:   5%|#9                                    | 1/20 [00:05<01:42,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.873741\tvalid_0's f1score: 0.660909\tvalid_1's auc: 0.78796\tvalid_1's f1score: 0.636134\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.005998 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  10%|###8                                  | 2/20 [00:11<01:41,  5.65s/it][I 2024-02-08 17:00:23,063] Trial 44 finished with value: 0.7908444717707442 and parameters: {'lambda_l1': 0.020821057783219802, 'lambda_l2': 1.5465682526877924e-08}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  10%|###8                                  | 2/20 [00:11<01:41,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's auc: 0.871935\tvalid_0's f1score: 0.661363\tvalid_1's auc: 0.790844\tvalid_1's f1score: 0.634722\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007604 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  15%|#####7                                | 3/20 [00:16<01:36,  5.69s/it][I 2024-02-08 17:00:28,816] Trial 45 finished with value: 0.7881669696321643 and parameters: {'lambda_l1': 0.025139273945402222, 'lambda_l2': 1.194232141606517e-08}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  15%|#####7                                | 3/20 [00:16<01:36,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.872216\tvalid_0's f1score: 0.66195\tvalid_1's auc: 0.788167\tvalid_1's f1score: 0.642576\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006910 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  20%|#######6                              | 4/20 [00:22<01:32,  5.79s/it][I 2024-02-08 17:00:34,743] Trial 46 finished with value: 0.7858917878528657 and parameters: {'lambda_l1': 0.050031145011558614, 'lambda_l2': 3.214605008883854e-08}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  20%|#######6                              | 4/20 [00:22<01:32,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's auc: 0.861841\tvalid_0's f1score: 0.655574\tvalid_1's auc: 0.785892\tvalid_1's f1score: 0.631897\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008402 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  25%|#########5                            | 5/20 [00:31<01:41,  6.79s/it][I 2024-02-08 17:00:43,316] Trial 47 finished with value: 0.7897011334473909 and parameters: {'lambda_l1': 2.3815564310351707e-05, 'lambda_l2': 1.0302181469031461e-08}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  25%|#########5                            | 5/20 [00:31<01:41,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  30%|###########4                          | 6/20 [00:39<01:41,  7.23s/it][I 2024-02-08 17:00:51,389] Trial 48 finished with value: 0.7879883982035928 and parameters: {'lambda_l1': 8.529352683789756e-07, 'lambda_l2': 0.3494524900562266}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  30%|###########4                          | 6/20 [00:39<01:41,  7.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's auc: 0.863377\tvalid_0's f1score: 0.65548\tvalid_1's auc: 0.787988\tvalid_1's f1score: 0.638508\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007530 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  35%|#############3                        | 7/20 [00:47<01:38,  7.61s/it][I 2024-02-08 17:00:59,785] Trial 49 finished with value: 0.7897008661248931 and parameters: {'lambda_l1': 1.137886553492953e-05, 'lambda_l2': 4.6601304253607954e-05}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  35%|#############3                        | 7/20 [00:47<01:38,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880911\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009014 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  40%|###############2                      | 8/20 [00:56<01:35,  7.92s/it][I 2024-02-08 17:01:08,389] Trial 50 finished with value: 0.7897008661248931 and parameters: {'lambda_l1': 8.290252347458996e-06, 'lambda_l2': 1.9701248585852013e-05}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  40%|###############2                      | 8/20 [00:56<01:35,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008349 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  45%|#################1                    | 9/20 [01:03<01:23,  7.62s/it][I 2024-02-08 17:01:15,318] Trial 51 finished with value: 0.7897000641573995 and parameters: {'lambda_l1': 5.7227467491072695e-06, 'lambda_l2': 0.0001222825988603413}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  45%|#################1                    | 9/20 [01:03<01:23,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.88091\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.7897\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007233 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  50%|##################5                  | 10/20 [01:09<01:10,  7.02s/it][I 2024-02-08 17:01:21,007] Trial 52 finished with value: 0.7897005988023952 and parameters: {'lambda_l1': 7.96724691046281e-06, 'lambda_l2': 8.472825982848031e-05}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  50%|##################5                  | 10/20 [01:09<01:10,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880911\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006770 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  55%|####################3                | 11/20 [01:14<00:59,  6.57s/it][I 2024-02-08 17:01:26,545] Trial 53 finished with value: 0.7897008661248931 and parameters: {'lambda_l1': 1.4540096665340808e-05, 'lambda_l2': 5.577658638551168e-05}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  55%|####################3                | 11/20 [01:14<00:59,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880911\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006973 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  60%|######################2              | 12/20 [01:22<00:55,  6.91s/it][I 2024-02-08 17:01:34,254] Trial 54 finished with value: 0.789849497433704 and parameters: {'lambda_l1': 7.382258959755338e-05, 'lambda_l2': 1.822410780959377e-05}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  60%|######################2              | 12/20 [01:22<00:55,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's auc: 0.894103\tvalid_0's f1score: 0.670549\tvalid_1's auc: 0.789849\tvalid_1's f1score: 0.642839\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  65%|########################             | 13/20 [01:30<00:51,  7.38s/it][I 2024-02-08 17:01:42,718] Trial 55 finished with value: 0.7882938141573995 and parameters: {'lambda_l1': 0.00021181384364425711, 'lambda_l2': 2.8452342308484184e-06}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  65%|########################             | 13/20 [01:30<00:51,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.8396\tvalid_0's f1score: 0.630789\tvalid_1's auc: 0.788294\tvalid_1's f1score: 0.624844\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008364 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  70%|#########################9           | 14/20 [01:39<00:46,  7.75s/it][I 2024-02-08 17:01:51,324] Trial 56 finished with value: 0.7882938141573995 and parameters: {'lambda_l1': 0.00023501858133613204, 'lambda_l2': 2.332215633360015e-06}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  70%|#########################9           | 14/20 [01:39<00:46,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.8396\tvalid_0's f1score: 0.630789\tvalid_1's auc: 0.788294\tvalid_1's f1score: 0.624844\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008838 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  75%|###########################7         | 15/20 [01:48<00:41,  8.28s/it][I 2024-02-08 17:02:00,821] Trial 57 finished with value: 0.7865443220701455 and parameters: {'lambda_l1': 2.6219194082741808e-08, 'lambda_l2': 0.0039977474423545985}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  75%|###########################7         | 15/20 [01:48<00:41,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.874715\tvalid_0's f1score: 0.661523\tvalid_1's auc: 0.786544\tvalid_1's f1score: 0.638549\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.007643 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  80%|#############################6       | 16/20 [01:58<00:34,  8.75s/it][I 2024-02-08 17:02:10,656] Trial 58 finished with value: 0.7897005988023952 and parameters: {'lambda_l1': 9.193194492197324e-05, 'lambda_l2': 1.3129896720219792e-06}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  80%|#############################6       | 16/20 [01:58<00:34,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  85%|###############################4     | 17/20 [02:09<00:28,  9.35s/it][I 2024-02-08 17:02:21,398] Trial 59 finished with value: 0.7888817899914456 and parameters: {'lambda_l1': 6.953119055793895, 'lambda_l2': 0.0029148165651182957}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  85%|###############################4     | 17/20 [02:09<00:28,  9.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.84456\tvalid_0's f1score: 0.653931\tvalid_1's auc: 0.788882\tvalid_1's f1score: 0.63376\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  90%|#################################3   | 18/20 [02:18<00:18,  9.33s/it][I 2024-02-08 17:02:30,699] Trial 60 finished with value: 0.7897011334473909 and parameters: {'lambda_l1': 4.979521350025102e-07, 'lambda_l2': 5.444109511580568e-07}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  90%|#################################3   | 18/20 [02:18<00:18,  9.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006381 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844:  95%|###################################1 | 19/20 [02:25<00:08,  8.61s/it][I 2024-02-08 17:02:37,610] Trial 61 finished with value: 0.7897011334473909 and parameters: {'lambda_l1': 6.208539460262756e-07, 'lambda_l2': 4.4934771293502447e-07}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844:  95%|###################################1 | 19/20 [02:25<00:08,  8.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010313 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.790844: 100%|#####################################| 20/20 [02:35<00:00,  9.08s/it][I 2024-02-08 17:02:47,783] Trial 62 finished with value: 0.7897011334473909 and parameters: {'lambda_l1': 3.5326671988531105e-07, 'lambda_l2': 2.7327679623759935e-07}. Best is trial 44 with value: 0.7908444717707442.\n",
      "regularization_factors, val_score: 0.790844: 100%|#####################################| 20/20 [02:35<00:00,  7.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.880912\tvalid_0's f1score: 0.66501\tvalid_1's auc: 0.789701\tvalid_1's f1score: 0.639763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.790844:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012231 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.790844:  20%|########8                                   | 1/5 [00:10<00:42, 10.57s/it][I 2024-02-08 17:02:58,359] Trial 63 finished with value: 0.7906701775021385 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.7906701775021385.\n",
      "min_child_samples, val_score: 0.790844:  20%|########8                                   | 1/5 [00:10<00:42, 10.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.893366\tvalid_0's f1score: 0.672043\tvalid_1's auc: 0.79067\tvalid_1's f1score: 0.636554\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.790844:  40%|#################6                          | 2/5 [00:21<00:31, 10.55s/it][I 2024-02-08 17:03:08,901] Trial 64 finished with value: 0.7852173331907614 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.7906701775021385.\n",
      "min_child_samples, val_score: 0.790844:  40%|#################6                          | 2/5 [00:21<00:31, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's auc: 0.909605\tvalid_0's f1score: 0.668875\tvalid_1's auc: 0.785217\tvalid_1's f1score: 0.645174\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011049 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.790844:  60%|##########################4                 | 3/5 [00:31<00:20, 10.34s/it][I 2024-02-08 17:03:18,997] Trial 65 finished with value: 0.7870864520958084 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.7906701775021385.\n",
      "min_child_samples, val_score: 0.790844:  60%|##########################4                 | 3/5 [00:31<00:20, 10.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.897716\tvalid_0's f1score: 0.669704\tvalid_1's auc: 0.787086\tvalid_1's f1score: 0.635961\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003136 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.790844:  80%|###################################2        | 4/5 [00:39<00:09,  9.67s/it][I 2024-02-08 17:03:27,613] Trial 66 finished with value: 0.7863086772882806 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.7906701775021385.\n",
      "min_child_samples, val_score: 0.790844:  80%|###################################2        | 4/5 [00:39<00:09,  9.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's auc: 0.833678\tvalid_0's f1score: 0.62786\tvalid_1's auc: 0.786309\tvalid_1's f1score: 0.616044\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.006434 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5128\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.790844: 100%|############################################| 5/5 [00:48<00:00,  9.38s/it][I 2024-02-08 17:03:36,487] Trial 67 finished with value: 0.7871531490590248 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.7906701775021385.\n",
      "min_child_samples, val_score: 0.790844: 100%|############################################| 5/5 [00:48<00:00,  9.74s/it]\n",
      "[I 2024-02-08 17:03:36,655] A new study created in memory with name: no-name-4d9484b2-6486-4db3-b2f0-d52b3341e882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[41]\tvalid_0's auc: 0.828133\tvalid_0's f1score: 0.616723\tvalid_1's auc: 0.787153\tvalid_1's f1score: 0.611718\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: -inf:   0%|                                                         | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010597 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779614:  14%|######4                                      | 1/7 [00:16<01:37, 16.18s/it][I 2024-02-08 17:03:52,838] Trial 0 finished with value: 0.7796142137800899 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.7796142137800899.\n",
      "feature_fraction, val_score: 0.779614:  14%|######4                                      | 1/7 [00:16<01:37, 16.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.971657\tvalid_0's f1score: 0.773969\tvalid_1's auc: 0.779614\tvalid_1's f1score: 0.640233\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779614:  29%|############8                                | 2/7 [00:31<01:18, 15.77s/it][I 2024-02-08 17:04:08,317] Trial 1 finished with value: 0.7782344614607623 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.7796142137800899.\n",
      "feature_fraction, val_score: 0.779614:  29%|############8                                | 2/7 [00:31<01:18, 15.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's auc: 0.94013\tvalid_0's f1score: 0.712724\tvalid_1's auc: 0.778234\tvalid_1's f1score: 0.636693\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003808 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.779614:  43%|###################2                         | 3/7 [00:46<01:01, 15.26s/it][I 2024-02-08 17:04:22,978] Trial 2 finished with value: 0.7796033541490741 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.7796142137800899.\n",
      "feature_fraction, val_score: 0.779614:  43%|###################2                         | 3/7 [00:46<01:01, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's auc: 0.926951\tvalid_0's f1score: 0.697884\tvalid_1's auc: 0.779603\tvalid_1's f1score: 0.640145\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013130 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.781272:  57%|#########################7                   | 4/7 [01:00<00:44, 14.95s/it][I 2024-02-08 17:04:37,452] Trial 3 finished with value: 0.7812721174485022 and parameters: {'feature_fraction': 0.8}. Best is trial 3 with value: 0.7812721174485022.\n",
      "feature_fraction, val_score: 0.781272:  57%|#########################7                   | 4/7 [01:00<00:44, 14.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's auc: 0.936095\tvalid_0's f1score: 0.700819\tvalid_1's auc: 0.781272\tvalid_1's f1score: 0.637514\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007075 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.781272:  71%|################################1            | 5/7 [01:19<00:32, 16.44s/it][I 2024-02-08 17:04:56,535] Trial 4 finished with value: 0.7767032534875343 and parameters: {'feature_fraction': 0.7}. Best is trial 3 with value: 0.7812721174485022.\n",
      "feature_fraction, val_score: 0.781272:  71%|################################1            | 5/7 [01:19<00:32, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.972251\tvalid_0's f1score: 0.782857\tvalid_1's auc: 0.776703\tvalid_1's f1score: 0.64332\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009775 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.781272:  86%|######################################5      | 6/7 [01:37<00:16, 16.85s/it][I 2024-02-08 17:05:14,184] Trial 5 finished with value: 0.780705679094718 and parameters: {'feature_fraction': 0.4}. Best is trial 3 with value: 0.7812721174485022.\n",
      "feature_fraction, val_score: 0.781272:  86%|######################################5      | 6/7 [01:37<00:16, 16.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.966752\tvalid_0's f1score: 0.759702\tvalid_1's auc: 0.780706\tvalid_1's f1score: 0.642634\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012601 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.781272: 100%|#############################################| 7/7 [01:51<00:00, 15.99s/it][I 2024-02-08 17:05:28,397] Trial 6 finished with value: 0.7791526070643782 and parameters: {'feature_fraction': 1.0}. Best is trial 3 with value: 0.7812721174485022.\n",
      "feature_fraction, val_score: 0.781272: 100%|#############################################| 7/7 [01:51<00:00, 15.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[178]\tvalid_0's auc: 0.921608\tvalid_0's f1score: 0.689975\tvalid_1's auc: 0.779153\tvalid_1's f1score: 0.642902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781272:   0%|                                                          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009409 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781272:   5%|##5                                               | 1/20 [00:14<04:37, 14.60s/it][I 2024-02-08 17:05:43,024] Trial 7 finished with value: 0.7765506394729922 and parameters: {'num_leaves': 127}. Best is trial 7 with value: 0.7765506394729922.\n",
      "num_leaves, val_score: 0.781272:   5%|##5                                               | 1/20 [00:14<04:37, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.988769\tvalid_0's f1score: 0.822259\tvalid_1's auc: 0.776551\tvalid_1's f1score: 0.641922\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011940 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  10%|#####                                             | 2/20 [00:28<04:14, 14.12s/it][I 2024-02-08 17:05:56,796] Trial 8 finished with value: 0.7819083470309479 and parameters: {'num_leaves': 79}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  10%|#####                                             | 2/20 [00:28<04:14, 14.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966047\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781908\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010737 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  15%|#######5                                          | 3/20 [00:43<04:04, 14.39s/it][I 2024-02-08 17:06:11,497] Trial 9 finished with value: 0.7765506394729922 and parameters: {'num_leaves': 127}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  15%|#######5                                          | 3/20 [00:43<04:04, 14.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's auc: 0.988769\tvalid_0's f1score: 0.822259\tvalid_1's auc: 0.776551\tvalid_1's f1score: 0.641922\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011944 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  20%|##########                                        | 4/20 [00:57<03:52, 14.52s/it][I 2024-02-08 17:06:26,242] Trial 10 finished with value: 0.7736537243032171 and parameters: {'num_leaves': 3}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  20%|##########                                        | 4/20 [00:57<03:52, 14.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.803503\tvalid_0's f1score: 0.635579\tvalid_1's auc: 0.773654\tvalid_1's f1score: 0.621521\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013246 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  25%|############5                                     | 5/20 [01:08<03:19, 13.29s/it][I 2024-02-08 17:06:37,333] Trial 11 finished with value: 0.7778928898665453 and parameters: {'num_leaves': 35}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  25%|############5                                     | 5/20 [01:08<03:19, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's auc: 0.889368\tvalid_0's f1score: 0.673102\tvalid_1's auc: 0.777893\tvalid_1's f1score: 0.64359\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010743 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  30%|###############                                   | 6/20 [01:25<03:24, 14.58s/it][I 2024-02-08 17:06:54,405] Trial 12 finished with value: 0.7744068035153929 and parameters: {'num_leaves': 242}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  30%|###############                                   | 6/20 [01:25<03:24, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.997923\tvalid_0's f1score: 0.921365\tvalid_1's auc: 0.774407\tvalid_1's f1score: 0.634541\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009952 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  35%|#################5                                | 7/20 [01:40<03:09, 14.58s/it][I 2024-02-08 17:07:09,007] Trial 13 finished with value: 0.7790487889918671 and parameters: {'num_leaves': 75}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  35%|#################5                                | 7/20 [01:40<03:09, 14.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's auc: 0.964266\tvalid_0's f1score: 0.733957\tvalid_1's auc: 0.779049\tvalid_1's f1score: 0.645095\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.005572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  40%|####################                              | 8/20 [01:58<03:08, 15.67s/it][I 2024-02-08 17:07:27,001] Trial 14 finished with value: 0.7744068035153929 and parameters: {'num_leaves': 242}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  40%|####################                              | 8/20 [01:58<03:08, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's auc: 0.997923\tvalid_0's f1score: 0.921365\tvalid_1's auc: 0.774407\tvalid_1's f1score: 0.634541\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010667 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  45%|######################5                           | 9/20 [02:12<02:46, 15.15s/it][I 2024-02-08 17:07:40,990] Trial 15 finished with value: 0.7709789247864852 and parameters: {'num_leaves': 163}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  45%|######################5                           | 9/20 [02:12<02:46, 15.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's auc: 0.988909\tvalid_0's f1score: 0.80624\tvalid_1's auc: 0.770979\tvalid_1's f1score: 0.640939\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011217 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  50%|########################5                        | 10/20 [02:25<02:24, 14.49s/it][I 2024-02-08 17:07:54,018] Trial 16 finished with value: 0.7750534583436138 and parameters: {'num_leaves': 80}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  50%|########################5                        | 10/20 [02:25<02:24, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's auc: 0.949718\tvalid_0's f1score: 0.708389\tvalid_1's auc: 0.775053\tvalid_1's f1score: 0.644095\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012292 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  55%|##########################9                      | 11/20 [02:39<02:08, 14.32s/it][I 2024-02-08 17:08:07,959] Trial 17 finished with value: 0.7739324548326226 and parameters: {'num_leaves': 175}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  55%|##########################9                      | 11/20 [02:39<02:08, 14.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's auc: 0.987898\tvalid_0's f1score: 0.802458\tvalid_1's auc: 0.773932\tvalid_1's f1score: 0.641332\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013118 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  60%|#############################4                   | 12/20 [02:52<01:52, 14.02s/it][I 2024-02-08 17:08:21,282] Trial 18 finished with value: 0.7769412965994007 and parameters: {'num_leaves': 73}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  60%|#############################4                   | 12/20 [02:52<01:52, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's auc: 0.951003\tvalid_0's f1score: 0.711349\tvalid_1's auc: 0.776941\tvalid_1's f1score: 0.641611\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  65%|###############################8                 | 13/20 [03:08<01:40, 14.36s/it][I 2024-02-08 17:08:36,441] Trial 19 finished with value: 0.780214968567884 and parameters: {'num_leaves': 184}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  65%|###############################8                 | 13/20 [03:08<01:40, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.99463\tvalid_0's f1score: 0.860836\tvalid_1's auc: 0.780215\tvalid_1's f1score: 0.63716\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013353 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  70%|##################################3              | 14/20 [03:26<01:33, 15.57s/it][I 2024-02-08 17:08:54,794] Trial 20 finished with value: 0.7743109491722934 and parameters: {'num_leaves': 32}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  70%|##################################3              | 14/20 [03:26<01:33, 15.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\tvalid_0's auc: 0.975514\tvalid_0's f1score: 0.790394\tvalid_1's auc: 0.774311\tvalid_1's f1score: 0.642159\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013899 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  75%|####################################7            | 15/20 [03:42<01:18, 15.69s/it][I 2024-02-08 17:09:10,758] Trial 21 finished with value: 0.7776108290502949 and parameters: {'num_leaves': 95}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  75%|####################################7            | 15/20 [03:42<01:18, 15.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's auc: 0.983845\tvalid_0's f1score: 0.793741\tvalid_1's auc: 0.777611\tvalid_1's f1score: 0.634771\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012462 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  80%|#######################################2         | 16/20 [03:57<01:02, 15.67s/it][I 2024-02-08 17:09:26,374] Trial 22 finished with value: 0.777479644707624 and parameters: {'num_leaves': 206}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  80%|#######################################2         | 16/20 [03:57<01:02, 15.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.996512\tvalid_0's f1score: 0.883923\tvalid_1's auc: 0.77748\tvalid_1's f1score: 0.637222\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009784 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  85%|#########################################6       | 17/20 [04:09<00:43, 14.50s/it][I 2024-02-08 17:09:38,163] Trial 23 finished with value: 0.772619308250192 and parameters: {'num_leaves': 102}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  85%|#########################################6       | 17/20 [04:09<00:43, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's auc: 0.935819\tvalid_0's f1score: 0.698772\tvalid_1's auc: 0.772619\tvalid_1's f1score: 0.63986\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012558 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  90%|############################################1    | 18/20 [04:23<00:28, 14.16s/it][I 2024-02-08 17:09:51,524] Trial 24 finished with value: 0.7782450315016176 and parameters: {'num_leaves': 28}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  90%|############################################1    | 18/20 [04:23<00:28, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's auc: 0.905987\tvalid_0's f1score: 0.683363\tvalid_1's auc: 0.778245\tvalid_1's f1score: 0.638969\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008879 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908:  95%|##############################################5  | 19/20 [04:39<00:14, 14.78s/it][I 2024-02-08 17:10:07,771] Trial 25 finished with value: 0.7773617815123325 and parameters: {'num_leaves': 59}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908:  95%|##############################################5  | 19/20 [04:39<00:14, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's auc: 0.965193\tvalid_0's f1score: 0.749496\tvalid_1's auc: 0.777362\tvalid_1's f1score: 0.641649\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009693 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.781908: 100%|#################################################| 20/20 [04:54<00:00, 14.94s/it][I 2024-02-08 17:10:23,061] Trial 26 finished with value: 0.7752067963335569 and parameters: {'num_leaves': 156}. Best is trial 8 with value: 0.7819083470309479.\n",
      "num_leaves, val_score: 0.781908: 100%|#################################################| 20/20 [04:54<00:00, 14.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's auc: 0.992688\tvalid_0's f1score: 0.845234\tvalid_1's auc: 0.775207\tvalid_1's f1score: 0.639438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:   0%|                                                             | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011666 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  10%|#####3                                               | 1/10 [00:12<01:55, 12.82s/it][I 2024-02-08 17:10:35,898] Trial 27 finished with value: 0.7767629090605811 and parameters: {'bagging_fraction': 0.6669033120864303, 'bagging_freq': 6}. Best is trial 27 with value: 0.7767629090605811.\n",
      "bagging, val_score: 0.781908:  10%|#####3                                               | 1/10 [00:12<01:55, 12.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.938626\tvalid_0's f1score: 0.696754\tvalid_1's auc: 0.776763\tvalid_1's f1score: 0.640097\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012132 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  20%|##########6                                          | 2/10 [00:29<02:00, 15.04s/it][I 2024-02-08 17:10:52,517] Trial 28 finished with value: 0.7764180071795193 and parameters: {'bagging_fraction': 0.9768811786368599, 'bagging_freq': 1}. Best is trial 27 with value: 0.7767629090605811.\n",
      "bagging, val_score: 0.781908:  20%|##########6                                          | 2/10 [00:29<02:00, 15.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's auc: 0.978374\tvalid_0's f1score: 0.770273\tvalid_1's auc: 0.776418\tvalid_1's f1score: 0.642954\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012240 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  30%|###############9                                     | 3/10 [00:43<01:43, 14.78s/it][I 2024-02-08 17:11:06,957] Trial 29 finished with value: 0.7735021238542366 and parameters: {'bagging_fraction': 0.4436942809247401, 'bagging_freq': 2}. Best is trial 27 with value: 0.7767629090605811.\n",
      "bagging, val_score: 0.781908:  30%|###############9                                     | 3/10 [00:43<01:43, 14.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.960683\tvalid_0's f1score: 0.719353\tvalid_1's auc: 0.773502\tvalid_1's f1score: 0.636693\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007448 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  40%|#####################2                               | 4/10 [00:57<01:24, 14.16s/it][I 2024-02-08 17:11:20,161] Trial 30 finished with value: 0.7760383544792069 and parameters: {'bagging_fraction': 0.9933535024343183, 'bagging_freq': 7}. Best is trial 27 with value: 0.7767629090605811.\n",
      "bagging, val_score: 0.781908:  40%|#####################2                               | 4/10 [00:57<01:24, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's auc: 0.945209\tvalid_0's f1score: 0.703142\tvalid_1's auc: 0.776038\tvalid_1's f1score: 0.631548\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011024 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  50%|##########################5                          | 5/10 [01:09<01:08, 13.65s/it][I 2024-02-08 17:11:32,912] Trial 31 finished with value: 0.7762068959525721 and parameters: {'bagging_fraction': 0.4655022941019493, 'bagging_freq': 4}. Best is trial 27 with value: 0.7767629090605811.\n",
      "bagging, val_score: 0.781908:  50%|##########################5                          | 5/10 [01:09<01:08, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's auc: 0.932941\tvalid_0's f1score: 0.692589\tvalid_1's auc: 0.776207\tvalid_1's f1score: 0.633756\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015686 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  60%|###############################8                     | 6/10 [01:22<00:52, 13.21s/it][I 2024-02-08 17:11:45,251] Trial 32 finished with value: 0.77692710668154 and parameters: {'bagging_fraction': 0.7383420097729773, 'bagging_freq': 4}. Best is trial 32 with value: 0.77692710668154.\n",
      "bagging, val_score: 0.781908:  60%|###############################8                     | 6/10 [01:22<00:52, 13.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's auc: 0.923192\tvalid_0's f1score: 0.685309\tvalid_1's auc: 0.776927\tvalid_1's f1score: 0.63609\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.019388 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  70%|#####################################                | 7/10 [01:37<00:42, 14.01s/it][I 2024-02-08 17:12:00,912] Trial 33 finished with value: 0.7732701621357391 and parameters: {'bagging_fraction': 0.7758600535550815, 'bagging_freq': 3}. Best is trial 32 with value: 0.77692710668154.\n",
      "bagging, val_score: 0.781908:  70%|#####################################                | 7/10 [01:37<00:42, 14.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's auc: 0.973503\tvalid_0's f1score: 0.747666\tvalid_1's auc: 0.77327\tvalid_1's f1score: 0.641094\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010368 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  80%|##########################################4          | 8/10 [01:51<00:27, 14.00s/it][I 2024-02-08 17:12:14,883] Trial 34 finished with value: 0.780442441638895 and parameters: {'bagging_fraction': 0.5876515357599262, 'bagging_freq': 6}. Best is trial 34 with value: 0.780442441638895.\n",
      "bagging, val_score: 0.781908:  80%|##########################################4          | 8/10 [01:51<00:27, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's auc: 0.958115\tvalid_0's f1score: 0.722724\tvalid_1's auc: 0.780442\tvalid_1's f1score: 0.640145\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.009950 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908:  90%|###############################################7     | 9/10 [02:05<00:13, 13.99s/it][I 2024-02-08 17:12:28,856] Trial 35 finished with value: 0.7768623832806858 and parameters: {'bagging_fraction': 0.6011915043114148, 'bagging_freq': 6}. Best is trial 34 with value: 0.780442441638895.\n",
      "bagging, val_score: 0.781908:  90%|###############################################7     | 9/10 [02:05<00:13, 13.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.958324\tvalid_0's f1score: 0.719188\tvalid_1's auc: 0.776862\tvalid_1's f1score: 0.643641\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008385 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.781908: 100%|####################################################| 10/10 [02:18<00:00, 13.63s/it][I 2024-02-08 17:12:41,666] Trial 36 finished with value: 0.7731218919736033 and parameters: {'bagging_fraction': 0.5664109340759327, 'bagging_freq': 6}. Best is trial 34 with value: 0.780442441638895.\n",
      "bagging, val_score: 0.781908: 100%|####################################################| 10/10 [02:18<00:00, 13.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's auc: 0.932945\tvalid_0's f1score: 0.688822\tvalid_1's auc: 0.773122\tvalid_1's f1score: 0.640713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908:   0%|                                              | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013300 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908:  17%|######3                               | 1/6 [00:16<01:22, 16.40s/it][I 2024-02-08 17:12:58,077] Trial 37 finished with value: 0.7785858791204336 and parameters: {'feature_fraction': 0.88}. Best is trial 37 with value: 0.7785858791204336.\n",
      "feature_fraction_stage2, val_score: 0.781908:  17%|######3                               | 1/6 [00:16<01:22, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's auc: 0.974978\tvalid_0's f1score: 0.772859\tvalid_1's auc: 0.778586\tvalid_1's f1score: 0.635695\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908:  33%|############6                         | 2/6 [00:30<00:59, 14.75s/it][I 2024-02-08 17:13:11,667] Trial 38 finished with value: 0.7758822653827397 and parameters: {'feature_fraction': 0.8160000000000001}. Best is trial 37 with value: 0.7785858791204336.\n",
      "feature_fraction_stage2, val_score: 0.781908:  33%|############6                         | 2/6 [00:30<00:59, 14.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[109]\tvalid_0's auc: 0.95626\tvalid_0's f1score: 0.715405\tvalid_1's auc: 0.775882\tvalid_1's f1score: 0.642124\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011805 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908:  50%|###################                   | 3/6 [00:44<00:43, 14.60s/it][I 2024-02-08 17:13:26,089] Trial 39 finished with value: 0.7749150342469324 and parameters: {'feature_fraction': 0.7520000000000001}. Best is trial 37 with value: 0.7785858791204336.\n",
      "feature_fraction_stage2, val_score: 0.781908:  50%|###################                   | 3/6 [00:44<00:43, 14.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's auc: 0.965219\tvalid_0's f1score: 0.73692\tvalid_1's auc: 0.774915\tvalid_1's f1score: 0.636393\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013104 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908:  67%|#########################3            | 4/6 [01:00<00:30, 15.02s/it][I 2024-02-08 17:13:41,742] Trial 40 finished with value: 0.7774835541747896 and parameters: {'feature_fraction': 0.8480000000000001}. Best is trial 37 with value: 0.7785858791204336.\n",
      "feature_fraction_stage2, val_score: 0.781908:  67%|#########################3            | 4/6 [01:00<00:30, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's auc: 0.972998\tvalid_0's f1score: 0.756628\tvalid_1's auc: 0.777484\tvalid_1's f1score: 0.642396\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011159 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908:  83%|###############################6      | 5/6 [01:16<00:15, 15.43s/it][I 2024-02-08 17:13:57,916] Trial 41 finished with value: 0.778021178307612 and parameters: {'feature_fraction': 0.784}. Best is trial 37 with value: 0.7785858791204336.\n",
      "feature_fraction_stage2, val_score: 0.781908:  83%|###############################6      | 5/6 [01:16<00:15, 15.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's auc: 0.974491\tvalid_0's f1score: 0.759233\tvalid_1's auc: 0.778021\tvalid_1's f1score: 0.643829\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013741 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.781908: 100%|######################################| 6/6 [01:31<00:00, 15.37s/it][I 2024-02-08 17:14:13,169] Trial 42 finished with value: 0.7718225009237926 and parameters: {'feature_fraction': 0.7200000000000001}. Best is trial 37 with value: 0.7785858791204336.\n",
      "feature_fraction_stage2, val_score: 0.781908: 100%|######################################| 6/6 [01:31<00:00, 15.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's auc: 0.970369\tvalid_0's f1score: 0.745015\tvalid_1's auc: 0.771823\tvalid_1's f1score: 0.646541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781908:   0%|                                              | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010826 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:   5%|#9                                    | 1/20 [00:14<04:38, 14.65s/it][I 2024-02-08 17:14:27,818] Trial 43 finished with value: 0.7819089262112687 and parameters: {'lambda_l1': 3.330048262115388e-06, 'lambda_l2': 0.00010318849891206893}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:   5%|#9                                    | 1/20 [00:14<04:38, 14.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011242 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  10%|###8                                  | 2/20 [00:29<04:26, 14.81s/it][I 2024-02-08 17:14:42,734] Trial 44 finished with value: 0.7819089262112687 and parameters: {'lambda_l1': 4.991853486414514e-06, 'lambda_l2': 0.00010682958461918897}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  10%|###8                                  | 2/20 [00:29<04:26, 14.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  15%|#####7                                | 3/20 [00:43<04:01, 14.20s/it][I 2024-02-08 17:14:56,207] Trial 45 finished with value: 0.7777966011382051 and parameters: {'lambda_l1': 4.5338682599621965e-06, 'lambda_l2': 0.0001755519093457976}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  15%|#####7                                | 3/20 [00:43<04:01, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's auc: 0.941234\tvalid_0's f1score: 0.702065\tvalid_1's auc: 0.777797\tvalid_1's f1score: 0.641373\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013645 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  20%|#######6                              | 4/20 [00:58<03:54, 14.69s/it][I 2024-02-08 17:15:11,646] Trial 46 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 4.969162656614964e-06, 'lambda_l2': 6.905535529809835e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  20%|#######6                              | 4/20 [00:58<03:54, 14.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013611 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  25%|#########5                            | 5/20 [01:13<03:42, 14.86s/it][I 2024-02-08 17:15:26,803] Trial 47 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 3.7465463991889797e-06, 'lambda_l2': 6.987719348380009e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  25%|#########5                            | 5/20 [01:13<03:42, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  30%|###########4                          | 6/20 [01:29<03:32, 15.17s/it][I 2024-02-08 17:15:42,572] Trial 48 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 3.956799372578004e-06, 'lambda_l2': 7.712882658832652e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  30%|###########4                          | 6/20 [01:29<03:32, 15.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.007957 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  35%|#############3                        | 7/20 [01:45<03:20, 15.41s/it][I 2024-02-08 17:15:58,475] Trial 49 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 3.385700687628099e-06, 'lambda_l2': 7.448662913698764e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  35%|#############3                        | 7/20 [01:45<03:20, 15.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018794 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  40%|###############2                      | 8/20 [02:03<03:14, 16.19s/it][I 2024-02-08 17:16:16,334] Trial 50 finished with value: 0.7819089262112687 and parameters: {'lambda_l1': 2.4051760247553443e-06, 'lambda_l2': 9.917837642433756e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  40%|###############2                      | 8/20 [02:03<03:14, 16.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010761 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  45%|#################1                    | 9/20 [02:20<03:00, 16.42s/it][I 2024-02-08 17:16:33,270] Trial 51 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 3.4113123502769446e-06, 'lambda_l2': 5.783422494807119e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  45%|#################1                    | 9/20 [02:20<03:00, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.011496 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  50%|##################5                  | 10/20 [02:36<02:45, 16.53s/it][I 2024-02-08 17:16:50,061] Trial 52 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 3.302567475099847e-06, 'lambda_l2': 6.966264931982108e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  50%|##################5                  | 10/20 [02:36<02:45, 16.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013560 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  55%|####################3                | 11/20 [02:53<02:29, 16.56s/it][I 2024-02-08 17:17:06,683] Trial 53 finished with value: 0.7819086366211083 and parameters: {'lambda_l1': 3.493275396782661e-06, 'lambda_l2': 7.895268123899153e-05}. Best is trial 43 with value: 0.7819089262112687.\n",
      "regularization_factors, val_score: 0.781909:  55%|####################3                | 11/20 [02:53<02:29, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.012443 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  60%|######################2              | 12/20 [03:10<02:12, 16.59s/it][I 2024-02-08 17:17:23,323] Trial 54 finished with value: 0.7819092158014291 and parameters: {'lambda_l1': 4.452779208790112e-06, 'lambda_l2': 0.00010920566414952067}. Best is trial 54 with value: 0.7819092158014291.\n",
      "regularization_factors, val_score: 0.781909:  60%|######################2              | 12/20 [03:10<02:12, 16.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966046\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781909\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013658 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  65%|########################             | 13/20 [03:27<01:57, 16.73s/it][I 2024-02-08 17:17:40,367] Trial 55 finished with value: 0.7798493609903521 and parameters: {'lambda_l1': 0.0003028855405052765, 'lambda_l2': 0.006701623996072308}. Best is trial 54 with value: 0.7819092158014291.\n",
      "regularization_factors, val_score: 0.781909:  65%|########################             | 13/20 [03:27<01:57, 16.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's auc: 0.96866\tvalid_0's f1score: 0.74287\tvalid_1's auc: 0.779849\tvalid_1's f1score: 0.638969\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  70%|#########################9           | 14/20 [03:43<01:40, 16.69s/it][I 2024-02-08 17:17:56,983] Trial 56 finished with value: 0.7819083470309479 and parameters: {'lambda_l1': 5.672700500193675e-08, 'lambda_l2': 1.1984308259783647e-06}. Best is trial 54 with value: 0.7819092158014291.\n",
      "regularization_factors, val_score: 0.781909:  70%|#########################9           | 14/20 [03:43<01:40, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's auc: 0.966047\tvalid_0's f1score: 0.73679\tvalid_1's auc: 0.781908\tvalid_1's f1score: 0.644335\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010867 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  75%|###########################7         | 15/20 [04:01<01:24, 16.97s/it][I 2024-02-08 17:18:14,606] Trial 57 finished with value: 0.7802531944690596 and parameters: {'lambda_l1': 9.273567278665837, 'lambda_l2': 0.0014855205871852006}. Best is trial 54 with value: 0.7819092158014291.\n",
      "regularization_factors, val_score: 0.781909:  75%|###########################7         | 15/20 [04:01<01:24, 16.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's auc: 0.910315\tvalid_0's f1score: 0.692925\tvalid_1's auc: 0.780253\tvalid_1's f1score: 0.642088\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017437 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  80%|#############################6       | 16/20 [04:17<01:06, 16.55s/it][I 2024-02-08 17:18:30,185] Trial 58 finished with value: 0.7754232649784719 and parameters: {'lambda_l1': 9.27387235269106e-05, 'lambda_l2': 2.8172514963043863e-06}. Best is trial 54 with value: 0.7819092158014291.\n",
      "regularization_factors, val_score: 0.781909:  80%|#############################6       | 16/20 [04:17<01:06, 16.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's auc: 0.958916\tvalid_0's f1score: 0.721623\tvalid_1's auc: 0.775423\tvalid_1's f1score: 0.637747\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.015417 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.781909:  85%|###############################4     | 17/20 [04:32<00:48, 16.21s/it][I 2024-02-08 17:18:45,589] Trial 59 finished with value: 0.7772256741369344 and parameters: {'lambda_l1': 9.349068429674353e-08, 'lambda_l2': 0.5099381429858177}. Best is trial 54 with value: 0.7819092158014291.\n",
      "regularization_factors, val_score: 0.781909:  85%|###############################4     | 17/20 [04:32<00:48, 16.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's auc: 0.941315\tvalid_0's f1score: 0.700864\tvalid_1's auc: 0.777226\tvalid_1's f1score: 0.642902\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016193 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.782006:  90%|#################################3   | 18/20 [04:53<00:35, 17.70s/it][I 2024-02-08 17:19:06,764] Trial 60 finished with value: 0.7820059389150099 and parameters: {'lambda_l1': 2.9225262155746125e-05, 'lambda_l2': 6.432268948847906e-06}. Best is trial 60 with value: 0.7820059389150099.\n",
      "regularization_factors, val_score: 0.782006:  90%|#################################3   | 18/20 [04:53<00:35, 17.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's auc: 0.972597\tvalid_0's f1score: 0.75733\tvalid_1's auc: 0.782006\tvalid_1's f1score: 0.645077\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.782006:  95%|###################################1 | 19/20 [05:15<00:18, 18.94s/it][I 2024-02-08 17:19:28,596] Trial 61 finished with value: 0.7820059389150099 and parameters: {'lambda_l1': 3.127025317403685e-05, 'lambda_l2': 6.641073274490716e-06}. Best is trial 60 with value: 0.7820059389150099.\n",
      "regularization_factors, val_score: 0.782006:  95%|###################################1 | 19/20 [05:15<00:18, 18.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's auc: 0.972597\tvalid_0's f1score: 0.75733\tvalid_1's auc: 0.782006\tvalid_1's f1score: 0.645077\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.021113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.782006: 100%|#####################################| 20/20 [05:34<00:00, 18.92s/it][I 2024-02-08 17:19:47,480] Trial 62 finished with value: 0.7768987268458187 and parameters: {'lambda_l1': 4.859875091626554e-05, 'lambda_l2': 5.45708006616368e-06}. Best is trial 60 with value: 0.7820059389150099.\n",
      "regularization_factors, val_score: 0.782006: 100%|#####################################| 20/20 [05:34<00:00, 16.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's auc: 0.960384\tvalid_0's f1score: 0.725051\tvalid_1's auc: 0.776899\tvalid_1's f1score: 0.642664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.782006:   0%|                                                    | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010384 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.782006:  20%|########8                                   | 1/5 [00:18<01:13, 18.29s/it][I 2024-02-08 17:20:05,804] Trial 63 finished with value: 0.7763198361151364 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.7763198361151364.\n",
      "min_child_samples, val_score: 0.782006:  20%|########8                                   | 1/5 [00:18<01:13, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's auc: 0.912914\tvalid_0's f1score: 0.677922\tvalid_1's auc: 0.77632\tvalid_1's f1score: 0.645058\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.016103 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.782006:  40%|#################6                          | 2/5 [00:37<00:57, 19.10s/it][I 2024-02-08 17:20:25,449] Trial 64 finished with value: 0.7785360696128412 and parameters: {'min_child_samples': 25}. Best is trial 64 with value: 0.7785360696128412.\n",
      "min_child_samples, val_score: 0.782006:  40%|#################6                          | 2/5 [00:37<00:57, 19.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's auc: 0.949574\tvalid_0's f1score: 0.709688\tvalid_1's auc: 0.778536\tvalid_1's f1score: 0.643378\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.018587 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.782006:  60%|##########################4                 | 3/5 [00:58<00:39, 19.95s/it][I 2024-02-08 17:20:46,419] Trial 65 finished with value: 0.7814913371999411 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.7814913371999411.\n",
      "min_child_samples, val_score: 0.782006:  60%|##########################4                 | 3/5 [00:58<00:39, 19.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's auc: 0.970792\tvalid_0's f1score: 0.727377\tvalid_1's auc: 0.781491\tvalid_1's f1score: 0.64388\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.782006:  80%|###################################2        | 4/5 [01:18<00:19, 19.91s/it][I 2024-02-08 17:21:06,282] Trial 66 finished with value: 0.7761788057070113 and parameters: {'min_child_samples': 10}. Best is trial 65 with value: 0.7814913371999411.\n",
      "min_child_samples, val_score: 0.782006:  80%|###################################2        | 4/5 [01:18<00:19, 19.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's auc: 0.950466\tvalid_0's f1score: 0.710744\tvalid_1's auc: 0.776179\tvalid_1's f1score: 0.640468\n",
      "[LightGBM] [Warning] Met categorical feature which contains sparse values. Consider renumbering to consecutive integers started from zero\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.036834 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 5124\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 63\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_child_samples, val_score: 0.782006: 100%|############################################| 5/5 [01:37<00:00, 19.49s/it][I 2024-02-08 17:21:25,018] Trial 67 finished with value: 0.7755666121078805 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.7814913371999411.\n",
      "min_child_samples, val_score: 0.782006: 100%|############################################| 5/5 [01:37<00:00, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's auc: 0.934727\tvalid_0's f1score: 0.698148\tvalid_1's auc: 0.775567\tvalid_1's f1score: 0.643856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lightgbm our out of folds CV f1score is 0.6371000033921015\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1\n",
      "[0]\ttrain-logloss:0.65990\ttrain-f1score:0.09771\teval-logloss:0.65991\teval-f1score:0.09208\n",
      "[25]\ttrain-logloss:0.33453\ttrain-f1score:0.67453\teval-logloss:0.33704\teval-f1score:0.64129\n",
      "[50]\ttrain-logloss:0.27755\ttrain-f1score:0.67064\teval-logloss:0.28654\teval-f1score:0.63481\n",
      "[75]\ttrain-logloss:0.25977\ttrain-f1score:0.68020\teval-logloss:0.27734\teval-f1score:0.64236\n",
      "[100]\ttrain-logloss:0.24999\ttrain-f1score:0.68765\teval-logloss:0.27553\teval-f1score:0.64371\n",
      "[125]\ttrain-logloss:0.24230\ttrain-f1score:0.69477\teval-logloss:0.27526\teval-f1score:0.64601\n",
      "[150]\ttrain-logloss:0.23701\ttrain-f1score:0.70069\teval-logloss:0.27540\teval-f1score:0.64924\n",
      "[175]\ttrain-logloss:0.23231\ttrain-f1score:0.70406\teval-logloss:0.27566\teval-f1score:0.64752\n",
      "[200]\ttrain-logloss:0.22736\ttrain-f1score:0.71113\teval-logloss:0.27597\teval-f1score:0.65264\n",
      "[225]\ttrain-logloss:0.22372\ttrain-f1score:0.71774\teval-logloss:0.27614\teval-f1score:0.65286\n",
      "[250]\ttrain-logloss:0.22093\ttrain-f1score:0.72293\teval-logloss:0.27636\teval-f1score:0.65550\n",
      "[275]\ttrain-logloss:0.21690\ttrain-f1score:0.73001\teval-logloss:0.27698\teval-f1score:0.65696\n",
      "[300]\ttrain-logloss:0.21380\ttrain-f1score:0.73373\teval-logloss:0.27716\teval-f1score:0.65696\n",
      "[325]\ttrain-logloss:0.21005\ttrain-f1score:0.73984\teval-logloss:0.27707\teval-f1score:0.65670\n",
      "[350]\ttrain-logloss:0.20650\ttrain-f1score:0.74728\teval-logloss:0.27736\teval-f1score:0.65670\n",
      "[375]\ttrain-logloss:0.20275\ttrain-f1score:0.75199\teval-logloss:0.27770\teval-f1score:0.65621\n",
      "[400]\ttrain-logloss:0.19943\ttrain-f1score:0.75824\teval-logloss:0.27800\teval-f1score:0.65596\n",
      "[425]\ttrain-logloss:0.19700\ttrain-f1score:0.76369\teval-logloss:0.27852\teval-f1score:0.65621\n",
      "[450]\ttrain-logloss:0.19347\ttrain-f1score:0.77061\teval-logloss:0.27866\teval-f1score:0.65596\n",
      "[475]\ttrain-logloss:0.19039\ttrain-f1score:0.77688\teval-logloss:0.27916\teval-f1score:0.65377\n",
      "[499]\ttrain-logloss:0.18747\ttrain-f1score:0.78324\teval-logloss:0.27969\teval-f1score:0.65327\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2\n",
      "[0]\ttrain-logloss:0.65982\ttrain-f1score:0.09652\teval-logloss:0.66030\teval-f1score:0.09925\n",
      "[25]\ttrain-logloss:0.33383\ttrain-f1score:0.66202\teval-logloss:0.34247\teval-f1score:0.65995\n",
      "[50]\ttrain-logloss:0.27700\ttrain-f1score:0.67100\teval-logloss:0.29440\teval-f1score:0.65918\n",
      "[75]\ttrain-logloss:0.25864\ttrain-f1score:0.68091\teval-logloss:0.28524\teval-f1score:0.66702\n",
      "[100]\ttrain-logloss:0.24885\ttrain-f1score:0.68915\teval-logloss:0.28332\teval-f1score:0.66617\n",
      "[125]\ttrain-logloss:0.24137\ttrain-f1score:0.69424\teval-logloss:0.28286\teval-f1score:0.66808\n",
      "[150]\ttrain-logloss:0.23538\ttrain-f1score:0.69913\teval-logloss:0.28320\teval-f1score:0.66542\n",
      "[175]\ttrain-logloss:0.23149\ttrain-f1score:0.70364\teval-logloss:0.28330\teval-f1score:0.66556\n",
      "[200]\ttrain-logloss:0.22823\ttrain-f1score:0.70909\teval-logloss:0.28333\teval-f1score:0.66909\n",
      "[213]\ttrain-logloss:0.22659\ttrain-f1score:0.71125\teval-logloss:0.28360\teval-f1score:0.66771\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3\n",
      "[0]\ttrain-logloss:0.65989\ttrain-f1score:0.09683\teval-logloss:0.66007\teval-f1score:0.09737\n",
      "[25]\ttrain-logloss:0.33416\ttrain-f1score:0.66776\teval-logloss:0.34030\teval-f1score:0.65985\n",
      "[50]\ttrain-logloss:0.27702\ttrain-f1score:0.66766\teval-logloss:0.29106\teval-f1score:0.65114\n",
      "[75]\ttrain-logloss:0.25930\ttrain-f1score:0.67883\teval-logloss:0.28180\teval-f1score:0.65484\n",
      "[100]\ttrain-logloss:0.24911\ttrain-f1score:0.68748\teval-logloss:0.27962\teval-f1score:0.66077\n",
      "[125]\ttrain-logloss:0.24192\ttrain-f1score:0.69534\teval-logloss:0.27849\teval-f1score:0.66587\n",
      "[150]\ttrain-logloss:0.23642\ttrain-f1score:0.70167\teval-logloss:0.27865\teval-f1score:0.66806\n",
      "[175]\ttrain-logloss:0.23155\ttrain-f1score:0.70797\teval-logloss:0.27890\teval-f1score:0.66681\n",
      "[200]\ttrain-logloss:0.22698\ttrain-f1score:0.71474\teval-logloss:0.27891\teval-f1score:0.67010\n",
      "[225]\ttrain-logloss:0.22277\ttrain-f1score:0.72088\teval-logloss:0.27907\teval-f1score:0.66947\n",
      "[250]\ttrain-logloss:0.21886\ttrain-f1score:0.72620\teval-logloss:0.27939\teval-f1score:0.66771\n",
      "[275]\ttrain-logloss:0.21428\ttrain-f1score:0.73476\teval-logloss:0.27979\teval-f1score:0.67133\n",
      "[300]\ttrain-logloss:0.21082\ttrain-f1score:0.74030\teval-logloss:0.28037\teval-f1score:0.67181\n",
      "[325]\ttrain-logloss:0.20762\ttrain-f1score:0.74617\teval-logloss:0.28091\teval-f1score:0.67045\n",
      "[350]\ttrain-logloss:0.20424\ttrain-f1score:0.75147\teval-logloss:0.28121\teval-f1score:0.67106\n",
      "[375]\ttrain-logloss:0.20150\ttrain-f1score:0.75741\teval-logloss:0.28161\teval-f1score:0.67242\n",
      "[400]\ttrain-logloss:0.19826\ttrain-f1score:0.76264\teval-logloss:0.28205\teval-f1score:0.67106\n",
      "[425]\ttrain-logloss:0.19488\ttrain-f1score:0.77023\teval-logloss:0.28272\teval-f1score:0.67142\n",
      "[450]\ttrain-logloss:0.19184\ttrain-f1score:0.77434\teval-logloss:0.28331\teval-f1score:0.67093\n",
      "[475]\ttrain-logloss:0.18819\ttrain-f1score:0.78158\teval-logloss:0.28378\teval-f1score:0.67043\n",
      "[499]\ttrain-logloss:0.18512\ttrain-f1score:0.78664\teval-logloss:0.28418\teval-f1score:0.66982\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4\n",
      "[0]\ttrain-logloss:0.65994\ttrain-f1score:0.09733\teval-logloss:0.65977\teval-f1score:0.09440\n",
      "[25]\ttrain-logloss:0.33494\ttrain-f1score:0.67047\teval-logloss:0.33434\teval-f1score:0.66506\n",
      "[50]\ttrain-logloss:0.27806\ttrain-f1score:0.67059\teval-logloss:0.28382\teval-f1score:0.65862\n",
      "[75]\ttrain-logloss:0.25987\ttrain-f1score:0.67865\teval-logloss:0.27464\teval-f1score:0.66489\n",
      "[100]\ttrain-logloss:0.25034\ttrain-f1score:0.68515\teval-logloss:0.27286\teval-f1score:0.67077\n",
      "[125]\ttrain-logloss:0.24385\ttrain-f1score:0.69233\teval-logloss:0.27240\teval-f1score:0.67347\n",
      "[150]\ttrain-logloss:0.23859\ttrain-f1score:0.69819\teval-logloss:0.27225\teval-f1score:0.67768\n",
      "[175]\ttrain-logloss:0.23270\ttrain-f1score:0.70482\teval-logloss:0.27246\teval-f1score:0.67505\n",
      "[200]\ttrain-logloss:0.22804\ttrain-f1score:0.71323\teval-logloss:0.27259\teval-f1score:0.67425\n",
      "[225]\ttrain-logloss:0.22438\ttrain-f1score:0.72038\teval-logloss:0.27256\teval-f1score:0.67711\n",
      "[250]\ttrain-logloss:0.22116\ttrain-f1score:0.72425\teval-logloss:0.27264\teval-f1score:0.67567\n",
      "[275]\ttrain-logloss:0.21749\ttrain-f1score:0.72983\teval-logloss:0.27274\teval-f1score:0.67423\n",
      "[300]\ttrain-logloss:0.21399\ttrain-f1score:0.73445\teval-logloss:0.27296\teval-f1score:0.67124\n",
      "[325]\ttrain-logloss:0.21054\ttrain-f1score:0.73838\teval-logloss:0.27344\teval-f1score:0.67150\n",
      "[346]\ttrain-logloss:0.20789\ttrain-f1score:0.74163\teval-logloss:0.27362\teval-f1score:0.67150\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5\n",
      "[0]\ttrain-logloss:0.65985\ttrain-f1score:0.09710\teval-logloss:0.66002\teval-f1score:0.09575\n",
      "[25]\ttrain-logloss:0.33442\ttrain-f1score:0.67079\teval-logloss:0.33748\teval-f1score:0.66319\n",
      "[50]\ttrain-logloss:0.27779\ttrain-f1score:0.66980\teval-logloss:0.28686\teval-f1score:0.65146\n",
      "[75]\ttrain-logloss:0.26005\ttrain-f1score:0.67996\teval-logloss:0.27703\teval-f1score:0.65974\n",
      "[100]\ttrain-logloss:0.25044\ttrain-f1score:0.68814\teval-logloss:0.27439\teval-f1score:0.66058\n",
      "[125]\ttrain-logloss:0.24289\ttrain-f1score:0.69525\teval-logloss:0.27392\teval-f1score:0.66429\n",
      "[150]\ttrain-logloss:0.23753\ttrain-f1score:0.70019\teval-logloss:0.27334\teval-f1score:0.66778\n",
      "[175]\ttrain-logloss:0.23228\ttrain-f1score:0.70673\teval-logloss:0.27326\teval-f1score:0.66726\n",
      "[200]\ttrain-logloss:0.22826\ttrain-f1score:0.71216\teval-logloss:0.27328\teval-f1score:0.66700\n",
      "[225]\ttrain-logloss:0.22419\ttrain-f1score:0.71724\teval-logloss:0.27303\teval-f1score:0.66874\n",
      "[250]\ttrain-logloss:0.22092\ttrain-f1score:0.72387\teval-logloss:0.27325\teval-f1score:0.66900\n",
      "[275]\ttrain-logloss:0.21750\ttrain-f1score:0.72900\teval-logloss:0.27349\teval-f1score:0.67044\n",
      "[300]\ttrain-logloss:0.21403\ttrain-f1score:0.73498\teval-logloss:0.27401\teval-f1score:0.67215\n",
      "[325]\ttrain-logloss:0.21120\ttrain-f1score:0.73957\teval-logloss:0.27434\teval-f1score:0.67397\n",
      "[350]\ttrain-logloss:0.20850\ttrain-f1score:0.74436\teval-logloss:0.27449\teval-f1score:0.67488\n",
      "[375]\ttrain-logloss:0.20519\ttrain-f1score:0.75035\teval-logloss:0.27486\teval-f1score:0.67526\n",
      "[400]\ttrain-logloss:0.20176\ttrain-f1score:0.75563\teval-logloss:0.27511\teval-f1score:0.67578\n",
      "[425]\ttrain-logloss:0.19839\ttrain-f1score:0.76251\teval-logloss:0.27524\teval-f1score:0.67371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[450]\ttrain-logloss:0.19528\ttrain-f1score:0.76863\teval-logloss:0.27544\teval-f1score:0.67500\n",
      "[475]\ttrain-logloss:0.19261\ttrain-f1score:0.77498\teval-logloss:0.27590\teval-f1score:0.67189\n",
      "[499]\ttrain-logloss:0.18841\ttrain-f1score:0.78268\teval-logloss:0.27615\teval-f1score:0.67006\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6\n",
      "[0]\ttrain-logloss:0.65976\ttrain-f1score:0.09575\teval-logloss:0.66044\teval-f1score:0.10380\n",
      "[25]\ttrain-logloss:0.33313\ttrain-f1score:0.66029\teval-logloss:0.34500\teval-f1score:0.66320\n",
      "[50]\ttrain-logloss:0.27622\ttrain-f1score:0.66274\teval-logloss:0.29736\teval-f1score:0.66046\n",
      "[75]\ttrain-logloss:0.25812\ttrain-f1score:0.67489\teval-logloss:0.28904\teval-f1score:0.66995\n",
      "[100]\ttrain-logloss:0.24831\ttrain-f1score:0.68264\teval-logloss:0.28730\teval-f1score:0.67672\n",
      "[125]\ttrain-logloss:0.24207\ttrain-f1score:0.68900\teval-logloss:0.28721\teval-f1score:0.67555\n",
      "[150]\ttrain-logloss:0.23672\ttrain-f1score:0.69489\teval-logloss:0.28713\teval-f1score:0.67780\n",
      "[175]\ttrain-logloss:0.23271\ttrain-f1score:0.70126\teval-logloss:0.28728\teval-f1score:0.67928\n",
      "[200]\ttrain-logloss:0.22876\ttrain-f1score:0.70615\teval-logloss:0.28777\teval-f1score:0.67820\n",
      "[208]\ttrain-logloss:0.22769\ttrain-f1score:0.70788\teval-logloss:0.28785\teval-f1score:0.67795\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7\n",
      "[0]\ttrain-logloss:0.65984\ttrain-f1score:0.09712\teval-logloss:0.66015\teval-f1score:0.09563\n",
      "[25]\ttrain-logloss:0.33406\ttrain-f1score:0.67024\teval-logloss:0.34096\teval-f1score:0.65924\n",
      "[50]\ttrain-logloss:0.27726\ttrain-f1score:0.67029\teval-logloss:0.29166\teval-f1score:0.65451\n",
      "[75]\ttrain-logloss:0.25922\ttrain-f1score:0.67793\teval-logloss:0.28271\teval-f1score:0.65635\n",
      "[100]\ttrain-logloss:0.24860\ttrain-f1score:0.68969\teval-logloss:0.28026\teval-f1score:0.65806\n",
      "[125]\ttrain-logloss:0.24166\ttrain-f1score:0.69524\teval-logloss:0.28003\teval-f1score:0.66004\n",
      "[150]\ttrain-logloss:0.23560\ttrain-f1score:0.70220\teval-logloss:0.28008\teval-f1score:0.66200\n",
      "[175]\ttrain-logloss:0.23080\ttrain-f1score:0.70872\teval-logloss:0.28061\teval-f1score:0.66304\n",
      "[200]\ttrain-logloss:0.22642\ttrain-f1score:0.71478\teval-logloss:0.28114\teval-f1score:0.66295\n",
      "[225]\ttrain-logloss:0.22253\ttrain-f1score:0.71895\teval-logloss:0.28112\teval-f1score:0.66496\n",
      "[250]\ttrain-logloss:0.22005\ttrain-f1score:0.72175\teval-logloss:0.28117\teval-f1score:0.66471\n",
      "[275]\ttrain-logloss:0.21684\ttrain-f1score:0.72623\teval-logloss:0.28122\teval-f1score:0.66310\n",
      "[300]\ttrain-logloss:0.21283\ttrain-f1score:0.73212\teval-logloss:0.28143\teval-f1score:0.66359\n",
      "[325]\ttrain-logloss:0.20954\ttrain-f1score:0.73677\teval-logloss:0.28175\teval-f1score:0.66173\n",
      "[350]\ttrain-logloss:0.20612\ttrain-f1score:0.74252\teval-logloss:0.28208\teval-f1score:0.66398\n",
      "[375]\ttrain-logloss:0.20249\ttrain-f1score:0.74977\teval-logloss:0.28216\teval-f1score:0.66085\n",
      "[400]\ttrain-logloss:0.19882\ttrain-f1score:0.75573\teval-logloss:0.28247\teval-f1score:0.66246\n",
      "[412]\ttrain-logloss:0.19725\ttrain-f1score:0.75767\teval-logloss:0.28255\teval-f1score:0.66173\n",
      "xgboost our out of folds CV f1score is 0.63801327722384\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "0:\tlearn: 0.6454802\ttest: 0.6449976\tbest: 0.6449976 (0)\ttotal: 279ms\tremaining: 2m 18s\n",
      "25:\tlearn: 0.3087555\ttest: 0.3051899\tbest: 0.3051899 (25)\ttotal: 3.28s\tremaining: 59.7s\n",
      "50:\tlearn: 0.2817684\ttest: 0.2791099\tbest: 0.2791099 (50)\ttotal: 6.33s\tremaining: 55.7s\n",
      "75:\tlearn: 0.2757197\ttest: 0.2747829\tbest: 0.2747829 (75)\ttotal: 9.35s\tremaining: 52.1s\n",
      "100:\tlearn: 0.2727189\ttest: 0.2737709\tbest: 0.2737709 (100)\ttotal: 12.3s\tremaining: 48.6s\n",
      "125:\tlearn: 0.2704658\ttest: 0.2733502\tbest: 0.2733376 (124)\ttotal: 15s\tremaining: 44.6s\n",
      "150:\tlearn: 0.2684597\ttest: 0.2732265\tbest: 0.2732265 (150)\ttotal: 17.7s\tremaining: 41s\n",
      "175:\tlearn: 0.2669001\ttest: 0.2732618\tbest: 0.2731754 (161)\ttotal: 20.3s\tremaining: 37.5s\n",
      "200:\tlearn: 0.2653921\ttest: 0.2731973\tbest: 0.2731754 (161)\ttotal: 23s\tremaining: 34.2s\n",
      "225:\tlearn: 0.2637479\ttest: 0.2730399\tbest: 0.2730281 (224)\ttotal: 25.6s\tremaining: 31.1s\n",
      "250:\tlearn: 0.2620941\ttest: 0.2728987\tbest: 0.2728950 (239)\ttotal: 28.2s\tremaining: 28s\n",
      "275:\tlearn: 0.2605245\ttest: 0.2730125\tbest: 0.2728608 (264)\ttotal: 30.8s\tremaining: 25s\n",
      "300:\tlearn: 0.2591360\ttest: 0.2730666\tbest: 0.2728608 (264)\ttotal: 33.4s\tremaining: 22.1s\n",
      "325:\tlearn: 0.2576930\ttest: 0.2731301\tbest: 0.2728608 (264)\ttotal: 35.8s\tremaining: 19.1s\n",
      "350:\tlearn: 0.2563491\ttest: 0.2732653\tbest: 0.2728608 (264)\ttotal: 38.2s\tremaining: 16.2s\n",
      "375:\tlearn: 0.2551111\ttest: 0.2733005\tbest: 0.2728608 (264)\ttotal: 40.6s\tremaining: 13.4s\n",
      "400:\tlearn: 0.2537632\ttest: 0.2734076\tbest: 0.2728608 (264)\ttotal: 43s\tremaining: 10.6s\n",
      "425:\tlearn: 0.2525537\ttest: 0.2734094\tbest: 0.2728608 (264)\ttotal: 45.4s\tremaining: 7.88s\n",
      "450:\tlearn: 0.2513020\ttest: 0.2735582\tbest: 0.2728608 (264)\ttotal: 47.7s\tremaining: 5.18s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2728607927\n",
      "bestIteration = 264\n",
      "\n",
      "Shrink model to first 265 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "0:\tlearn: 0.6454527\ttest: 0.6458499\tbest: 0.6458499 (0)\ttotal: 85.5ms\tremaining: 42.7s\n",
      "25:\tlearn: 0.3090843\ttest: 0.3143989\tbest: 0.3143989 (25)\ttotal: 2.2s\tremaining: 40.1s\n",
      "50:\tlearn: 0.2802510\ttest: 0.2881951\tbest: 0.2881951 (50)\ttotal: 4.42s\tremaining: 38.9s\n",
      "75:\tlearn: 0.2739334\ttest: 0.2837899\tbest: 0.2837899 (75)\ttotal: 6.7s\tremaining: 37.4s\n",
      "100:\tlearn: 0.2709943\ttest: 0.2824348\tbest: 0.2824348 (100)\ttotal: 9.01s\tremaining: 35.6s\n",
      "125:\tlearn: 0.2692511\ttest: 0.2818912\tbest: 0.2818651 (120)\ttotal: 11.3s\tremaining: 33.6s\n",
      "150:\tlearn: 0.2675811\ttest: 0.2814362\tbest: 0.2814362 (150)\ttotal: 13.5s\tremaining: 31.3s\n",
      "175:\tlearn: 0.2660324\ttest: 0.2810103\tbest: 0.2810103 (175)\ttotal: 15.8s\tremaining: 29.1s\n",
      "200:\tlearn: 0.2644399\ttest: 0.2807605\tbest: 0.2807605 (200)\ttotal: 18.2s\tremaining: 27s\n",
      "225:\tlearn: 0.2627889\ttest: 0.2802975\tbest: 0.2802975 (225)\ttotal: 20.5s\tremaining: 24.9s\n",
      "250:\tlearn: 0.2611228\ttest: 0.2800372\tbest: 0.2800372 (250)\ttotal: 22.9s\tremaining: 22.7s\n",
      "275:\tlearn: 0.2596802\ttest: 0.2797328\tbest: 0.2797328 (275)\ttotal: 25.4s\tremaining: 20.6s\n",
      "300:\tlearn: 0.2583429\ttest: 0.2796311\tbest: 0.2796005 (288)\ttotal: 27.8s\tremaining: 18.4s\n",
      "325:\tlearn: 0.2567257\ttest: 0.2797054\tbest: 0.2795668 (302)\ttotal: 30.3s\tremaining: 16.2s\n",
      "350:\tlearn: 0.2553856\ttest: 0.2796434\tbest: 0.2795668 (302)\ttotal: 32.8s\tremaining: 13.9s\n",
      "375:\tlearn: 0.2542665\ttest: 0.2795430\tbest: 0.2795137 (362)\ttotal: 35.3s\tremaining: 11.6s\n",
      "400:\tlearn: 0.2529049\ttest: 0.2795362\tbest: 0.2794723 (383)\ttotal: 37.7s\tremaining: 9.31s\n",
      "425:\tlearn: 0.2517469\ttest: 0.2796499\tbest: 0.2794723 (383)\ttotal: 40.3s\tremaining: 7s\n",
      "450:\tlearn: 0.2503315\ttest: 0.2795770\tbest: 0.2794723 (383)\ttotal: 42.6s\tremaining: 4.63s\n",
      "475:\tlearn: 0.2489149\ttest: 0.2795873\tbest: 0.2794723 (383)\ttotal: 45.1s\tremaining: 2.27s\n",
      "499:\tlearn: 0.2478685\ttest: 0.2797224\tbest: 0.2794723 (383)\ttotal: 47.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2794722724\n",
      "bestIteration = 383\n",
      "\n",
      "Shrink model to first 384 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "0:\tlearn: 0.6451767\ttest: 0.6455721\tbest: 0.6455721 (0)\ttotal: 89.4ms\tremaining: 44.6s\n",
      "25:\tlearn: 0.3101012\ttest: 0.3128497\tbest: 0.3128497 (25)\ttotal: 2.17s\tremaining: 39.6s\n",
      "50:\tlearn: 0.2805374\ttest: 0.2840234\tbest: 0.2840234 (50)\ttotal: 4.33s\tremaining: 38.1s\n",
      "75:\tlearn: 0.2746361\ttest: 0.2797837\tbest: 0.2797837 (75)\ttotal: 6.62s\tremaining: 36.9s\n",
      "100:\tlearn: 0.2715160\ttest: 0.2777825\tbest: 0.2777825 (100)\ttotal: 9.05s\tremaining: 35.8s\n",
      "125:\tlearn: 0.2693803\ttest: 0.2769896\tbest: 0.2769896 (125)\ttotal: 11.5s\tremaining: 34s\n",
      "150:\tlearn: 0.2679612\ttest: 0.2766380\tbest: 0.2766380 (150)\ttotal: 13.8s\tremaining: 31.9s\n",
      "175:\tlearn: 0.2663297\ttest: 0.2764098\tbest: 0.2764067 (173)\ttotal: 16.1s\tremaining: 29.7s\n",
      "200:\tlearn: 0.2650839\ttest: 0.2759145\tbest: 0.2759145 (200)\ttotal: 18.5s\tremaining: 27.6s\n",
      "225:\tlearn: 0.2635047\ttest: 0.2756890\tbest: 0.2756890 (225)\ttotal: 20.8s\tremaining: 25.3s\n",
      "250:\tlearn: 0.2622368\ttest: 0.2756090\tbest: 0.2756090 (250)\ttotal: 23.3s\tremaining: 23.1s\n",
      "275:\tlearn: 0.2607219\ttest: 0.2754349\tbest: 0.2754309 (274)\ttotal: 25.8s\tremaining: 20.9s\n",
      "300:\tlearn: 0.2590432\ttest: 0.2754141\tbest: 0.2753633 (290)\ttotal: 28.1s\tremaining: 18.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325:\tlearn: 0.2575422\ttest: 0.2753398\tbest: 0.2753183 (315)\ttotal: 30.6s\tremaining: 16.3s\n",
      "350:\tlearn: 0.2561949\ttest: 0.2752824\tbest: 0.2752623 (346)\ttotal: 33s\tremaining: 14s\n",
      "375:\tlearn: 0.2546850\ttest: 0.2751707\tbest: 0.2751043 (372)\ttotal: 35.4s\tremaining: 11.7s\n",
      "400:\tlearn: 0.2532164\ttest: 0.2751125\tbest: 0.2751034 (396)\ttotal: 37.9s\tremaining: 9.35s\n",
      "425:\tlearn: 0.2516511\ttest: 0.2749291\tbest: 0.2749291 (425)\ttotal: 40.3s\tremaining: 7s\n",
      "450:\tlearn: 0.2505892\ttest: 0.2747473\tbest: 0.2747324 (444)\ttotal: 42.7s\tremaining: 4.64s\n",
      "475:\tlearn: 0.2494744\ttest: 0.2747472\tbest: 0.2746401 (455)\ttotal: 45.2s\tremaining: 2.28s\n",
      "499:\tlearn: 0.2483044\ttest: 0.2749072\tbest: 0.2746401 (455)\ttotal: 47.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2746401408\n",
      "bestIteration = 455\n",
      "\n",
      "Shrink model to first 456 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4\n",
      "0:\tlearn: 0.6453655\ttest: 0.6446511\tbest: 0.6446511 (0)\ttotal: 91.6ms\tremaining: 45.7s\n",
      "25:\tlearn: 0.3095927\ttest: 0.3033003\tbest: 0.3033003 (25)\ttotal: 2.31s\tremaining: 42.2s\n",
      "50:\tlearn: 0.2827263\ttest: 0.2761511\tbest: 0.2761511 (50)\ttotal: 4.34s\tremaining: 38.2s\n",
      "75:\tlearn: 0.2767345\ttest: 0.2712089\tbest: 0.2712089 (75)\ttotal: 6.66s\tremaining: 37.2s\n",
      "100:\tlearn: 0.2739282\ttest: 0.2699789\tbest: 0.2699789 (100)\ttotal: 8.91s\tremaining: 35.2s\n",
      "125:\tlearn: 0.2717374\ttest: 0.2690882\tbest: 0.2690832 (124)\ttotal: 11.3s\tremaining: 33.6s\n",
      "150:\tlearn: 0.2700132\ttest: 0.2684997\tbest: 0.2684997 (150)\ttotal: 13.5s\tremaining: 31.3s\n",
      "175:\tlearn: 0.2682686\ttest: 0.2679908\tbest: 0.2679689 (173)\ttotal: 16s\tremaining: 29.4s\n",
      "200:\tlearn: 0.2666979\ttest: 0.2677550\tbest: 0.2677550 (200)\ttotal: 18.3s\tremaining: 27.3s\n",
      "225:\tlearn: 0.2653856\ttest: 0.2674768\tbest: 0.2674768 (225)\ttotal: 20.6s\tremaining: 25s\n",
      "250:\tlearn: 0.2639580\ttest: 0.2671259\tbest: 0.2671251 (249)\ttotal: 23s\tremaining: 22.8s\n",
      "275:\tlearn: 0.2628745\ttest: 0.2668704\tbest: 0.2668686 (274)\ttotal: 25.5s\tremaining: 20.7s\n",
      "300:\tlearn: 0.2617029\ttest: 0.2670417\tbest: 0.2668686 (274)\ttotal: 27.8s\tremaining: 18.4s\n",
      "325:\tlearn: 0.2601934\ttest: 0.2670020\tbest: 0.2668686 (274)\ttotal: 30.2s\tremaining: 16.1s\n",
      "350:\tlearn: 0.2591597\ttest: 0.2671047\tbest: 0.2668686 (274)\ttotal: 32.6s\tremaining: 13.8s\n",
      "375:\tlearn: 0.2576979\ttest: 0.2669407\tbest: 0.2668686 (274)\ttotal: 35s\tremaining: 11.6s\n",
      "400:\tlearn: 0.2564490\ttest: 0.2669556\tbest: 0.2668686 (274)\ttotal: 37.5s\tremaining: 9.26s\n",
      "425:\tlearn: 0.2552663\ttest: 0.2671907\tbest: 0.2668686 (274)\ttotal: 40s\tremaining: 6.95s\n",
      "450:\tlearn: 0.2540968\ttest: 0.2670202\tbest: 0.2668686 (274)\ttotal: 42.5s\tremaining: 4.61s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2668686243\n",
      "bestIteration = 274\n",
      "\n",
      "Shrink model to first 275 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5\n",
      "0:\tlearn: 0.6456354\ttest: 0.6457651\tbest: 0.6457651 (0)\ttotal: 92.7ms\tremaining: 46.2s\n",
      "25:\tlearn: 0.3084404\ttest: 0.3062415\tbest: 0.3062415 (25)\ttotal: 2.38s\tremaining: 43.5s\n",
      "50:\tlearn: 0.2813245\ttest: 0.2792238\tbest: 0.2792238 (50)\ttotal: 4.56s\tremaining: 40.1s\n",
      "75:\tlearn: 0.2757354\ttest: 0.2746069\tbest: 0.2746069 (75)\ttotal: 6.83s\tremaining: 38.1s\n",
      "100:\tlearn: 0.2727646\ttest: 0.2729726\tbest: 0.2729726 (100)\ttotal: 9.14s\tremaining: 36.1s\n",
      "125:\tlearn: 0.2706892\ttest: 0.2720865\tbest: 0.2720865 (125)\ttotal: 11.4s\tremaining: 34s\n",
      "150:\tlearn: 0.2687299\ttest: 0.2712971\tbest: 0.2712971 (150)\ttotal: 13.9s\tremaining: 32s\n",
      "175:\tlearn: 0.2670949\ttest: 0.2710146\tbest: 0.2709357 (169)\ttotal: 16.3s\tremaining: 30.1s\n",
      "200:\tlearn: 0.2654413\ttest: 0.2704595\tbest: 0.2704497 (199)\ttotal: 18.8s\tremaining: 28s\n",
      "225:\tlearn: 0.2640166\ttest: 0.2702068\tbest: 0.2702068 (225)\ttotal: 21.2s\tremaining: 25.7s\n",
      "250:\tlearn: 0.2626038\ttest: 0.2700214\tbest: 0.2700214 (250)\ttotal: 23.7s\tremaining: 23.5s\n",
      "275:\tlearn: 0.2610508\ttest: 0.2697873\tbest: 0.2697873 (275)\ttotal: 26.1s\tremaining: 21.2s\n",
      "300:\tlearn: 0.2593185\ttest: 0.2695915\tbest: 0.2695915 (300)\ttotal: 28.7s\tremaining: 19s\n",
      "325:\tlearn: 0.2577505\ttest: 0.2694274\tbest: 0.2694022 (323)\ttotal: 31.5s\tremaining: 16.8s\n",
      "350:\tlearn: 0.2560106\ttest: 0.2694188\tbest: 0.2693401 (330)\ttotal: 34.1s\tremaining: 14.5s\n",
      "375:\tlearn: 0.2546787\ttest: 0.2692418\tbest: 0.2692372 (374)\ttotal: 36.5s\tremaining: 12s\n",
      "400:\tlearn: 0.2533848\ttest: 0.2692765\tbest: 0.2692306 (383)\ttotal: 39s\tremaining: 9.63s\n",
      "425:\tlearn: 0.2522312\ttest: 0.2693330\tbest: 0.2692306 (383)\ttotal: 41.5s\tremaining: 7.2s\n",
      "450:\tlearn: 0.2509182\ttest: 0.2693828\tbest: 0.2692306 (383)\ttotal: 43.9s\tremaining: 4.77s\n",
      "475:\tlearn: 0.2496453\ttest: 0.2694581\tbest: 0.2692306 (383)\ttotal: 46.5s\tremaining: 2.34s\n",
      "499:\tlearn: 0.2482333\ttest: 0.2695860\tbest: 0.2692306 (383)\ttotal: 49.1s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2692306012\n",
      "bestIteration = 383\n",
      "\n",
      "Shrink model to first 384 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6\n",
      "0:\tlearn: 0.6450561\ttest: 0.6457277\tbest: 0.6457277 (0)\ttotal: 89.7ms\tremaining: 44.8s\n",
      "25:\tlearn: 0.3075649\ttest: 0.3155591\tbest: 0.3155591 (25)\ttotal: 2.44s\tremaining: 44.5s\n",
      "50:\tlearn: 0.2801232\ttest: 0.2889721\tbest: 0.2889721 (50)\ttotal: 4.71s\tremaining: 41.4s\n",
      "75:\tlearn: 0.2740150\ttest: 0.2843858\tbest: 0.2843858 (75)\ttotal: 7.2s\tremaining: 40.2s\n",
      "100:\tlearn: 0.2708347\ttest: 0.2831452\tbest: 0.2831452 (100)\ttotal: 9.74s\tremaining: 38.5s\n",
      "125:\tlearn: 0.2687823\ttest: 0.2824516\tbest: 0.2824516 (125)\ttotal: 12.2s\tremaining: 36.3s\n",
      "150:\tlearn: 0.2668843\ttest: 0.2821000\tbest: 0.2821000 (150)\ttotal: 14.5s\tremaining: 33.5s\n",
      "175:\tlearn: 0.2655978\ttest: 0.2819596\tbest: 0.2819324 (172)\ttotal: 16.8s\tremaining: 30.9s\n",
      "200:\tlearn: 0.2639454\ttest: 0.2817961\tbest: 0.2817401 (195)\ttotal: 19.3s\tremaining: 28.8s\n",
      "225:\tlearn: 0.2625474\ttest: 0.2817939\tbest: 0.2817401 (195)\ttotal: 21.9s\tremaining: 26.5s\n",
      "250:\tlearn: 0.2607321\ttest: 0.2817278\tbest: 0.2816081 (244)\ttotal: 24.3s\tremaining: 24.2s\n",
      "275:\tlearn: 0.2595472\ttest: 0.2816751\tbest: 0.2816081 (244)\ttotal: 26.9s\tremaining: 21.9s\n",
      "300:\tlearn: 0.2580796\ttest: 0.2817840\tbest: 0.2816081 (244)\ttotal: 29.6s\tremaining: 19.5s\n",
      "325:\tlearn: 0.2567249\ttest: 0.2818178\tbest: 0.2816081 (244)\ttotal: 32.2s\tremaining: 17.2s\n",
      "350:\tlearn: 0.2553665\ttest: 0.2816604\tbest: 0.2816081 (244)\ttotal: 34.8s\tremaining: 14.8s\n",
      "375:\tlearn: 0.2541400\ttest: 0.2816157\tbest: 0.2815304 (365)\ttotal: 37.5s\tremaining: 12.4s\n",
      "400:\tlearn: 0.2528099\ttest: 0.2817553\tbest: 0.2815304 (365)\ttotal: 40.3s\tremaining: 9.95s\n",
      "425:\tlearn: 0.2513449\ttest: 0.2815846\tbest: 0.2815304 (365)\ttotal: 43s\tremaining: 7.47s\n",
      "450:\tlearn: 0.2502028\ttest: 0.2815515\tbest: 0.2815131 (446)\ttotal: 45.7s\tremaining: 4.96s\n",
      "475:\tlearn: 0.2488935\ttest: 0.2817067\tbest: 0.2815131 (446)\ttotal: 48.2s\tremaining: 2.43s\n",
      "499:\tlearn: 0.2475596\ttest: 0.2817667\tbest: 0.2815131 (446)\ttotal: 50.9s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2815130584\n",
      "bestIteration = 446\n",
      "\n",
      "Shrink model to first 447 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 7\n",
      "0:\tlearn: 0.6477380\ttest: 0.6479876\tbest: 0.6479876 (0)\ttotal: 69ms\tremaining: 34.4s\n",
      "25:\tlearn: 0.3093706\ttest: 0.3095643\tbest: 0.3095643 (25)\ttotal: 2.44s\tremaining: 44.5s\n",
      "50:\tlearn: 0.2807764\ttest: 0.2824905\tbest: 0.2824905 (50)\ttotal: 4.78s\tremaining: 42.1s\n",
      "75:\tlearn: 0.2746069\ttest: 0.2787821\tbest: 0.2787821 (75)\ttotal: 7.17s\tremaining: 40s\n",
      "100:\tlearn: 0.2717528\ttest: 0.2777841\tbest: 0.2777783 (99)\ttotal: 9.72s\tremaining: 38.4s\n",
      "125:\tlearn: 0.2697464\ttest: 0.2772847\tbest: 0.2772732 (123)\ttotal: 12.2s\tremaining: 36.1s\n",
      "150:\tlearn: 0.2680085\ttest: 0.2769720\tbest: 0.2769647 (149)\ttotal: 14.7s\tremaining: 33.9s\n",
      "175:\tlearn: 0.2666515\ttest: 0.2766921\tbest: 0.2766883 (167)\ttotal: 17s\tremaining: 31.3s\n",
      "200:\tlearn: 0.2652289\ttest: 0.2765672\tbest: 0.2765645 (190)\ttotal: 19.3s\tremaining: 28.8s\n",
      "225:\tlearn: 0.2637556\ttest: 0.2765324\tbest: 0.2764867 (213)\ttotal: 21.8s\tremaining: 26.5s\n",
      "250:\tlearn: 0.2626751\ttest: 0.2765945\tbest: 0.2764830 (233)\ttotal: 24.6s\tremaining: 24.4s\n",
      "275:\tlearn: 0.2615681\ttest: 0.2767070\tbest: 0.2764830 (233)\ttotal: 27.2s\tremaining: 22.1s\n",
      "300:\tlearn: 0.2601703\ttest: 0.2769711\tbest: 0.2764830 (233)\ttotal: 29.8s\tremaining: 19.7s\n",
      "325:\tlearn: 0.2585541\ttest: 0.2770148\tbest: 0.2764830 (233)\ttotal: 32.5s\tremaining: 17.3s\n",
      "350:\tlearn: 0.2570169\ttest: 0.2769687\tbest: 0.2764830 (233)\ttotal: 35.2s\tremaining: 14.9s\n",
      "375:\tlearn: 0.2557421\ttest: 0.2768597\tbest: 0.2764830 (233)\ttotal: 37.9s\tremaining: 12.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400:\tlearn: 0.2545533\ttest: 0.2767349\tbest: 0.2764830 (233)\ttotal: 40.4s\tremaining: 9.97s\n",
      "425:\tlearn: 0.2532389\ttest: 0.2767797\tbest: 0.2764830 (233)\ttotal: 43s\tremaining: 7.47s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.2764830279\n",
      "bestIteration = 233\n",
      "\n",
      "Shrink model to first 234 iterations.\n",
      "catboost our out of folds CV f1score is 0.6440738667508445\n"
     ]
    }
   ],
   "source": [
    "Learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PcFYu2WqOzxS"
   },
   "outputs": [],
   "source": [
    "def lightgbm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "def xgboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(xgb.DMatrix(x_test))\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def gradient_boosting_model_inference(method: str):\n",
    "    x_test_lgb = test_df_lgb[features_lgb]\n",
    "    x_test_ctb = test_df_ctb[features_ctb]\n",
    "    if method == 'lightgbm':\n",
    "        test_pred = lightgbm_inference(x_test_lgb)\n",
    "    if method == 'xgboost':\n",
    "        test_pred = xgboost_inference(x_test_ctb)\n",
    "    if method == 'catboost':\n",
    "        test_pred = catboost_inference(x_test_ctb)\n",
    "    return test_pred\n",
    "\n",
    "def Predicting():\n",
    "    output_df = test_df_lgb.copy()\n",
    "    output_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method)\n",
    "        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mGMj6OftPMpC"
   },
   "outputs": [],
   "source": [
    "test_df_lgb = Predicting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "k11-nGPEZS1h"
   },
   "outputs": [],
   "source": [
    "#後処理の定義\n",
    "def Postprocessing():\n",
    "    train_df_lgb['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "        train_df_lgb['pred_prob'] += CFG.model_weight_dict[method] * oof_df[f'{method}_prediction']\n",
    "    best_score = 0\n",
    "    best_v = 0\n",
    "    for v in tqdm(np.arange(1000) / 1000):\n",
    "        score = f1_score(oof_df[CFG.target_col], train_df_lgb[f'pred_prob'] >= v, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_v = v\n",
    "    print(best_score, best_v)\n",
    "    test_df_lgb['target'] = np.where(test_df_lgb['pred_prob'] >= best_v, 1, 0)\n",
    "    return train_df_lgb, test_df_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "ef58b4abcf0f43cd90a523a3875a2f28",
      "6f14799525cf44158bbffc0e9a08891b",
      "d239d2ff297a4c00aa350f8699ca6bb1",
      "76ddf1599bb144b2a6b4573027c6f662",
      "6762ef5aab7e4d18b98e7d837dedc03f",
      "b7dceec9910a46cea90915015ca58358",
      "573ab758539147f1a2bc21ac9f0347ce",
      "5de7c5cebd814e1caa8437775031ea12",
      "b0ab4a4e03b242e2ae3610b6a52b5c14",
      "4074a8c3b85548ed9424375a19416c7d",
      "13858cd0c554419bb867071b5c810b30"
     ]
    },
    "id": "q3P87swwPqf2",
    "outputId": "8d624fd1-4808-44f9-d59b-982a93d06ad5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d390dfd33a641d9b26f2d1b5166f8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.686757845822522 0.758\n"
     ]
    }
   ],
   "source": [
    "#後処理\n",
    "train_df, test_df = Postprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "hK_3WqNDT0yj"
   },
   "outputs": [],
   "source": [
    "test_df[['target']].to_csv(f'seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13858cd0c554419bb867071b5c810b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4074a8c3b85548ed9424375a19416c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573ab758539147f1a2bc21ac9f0347ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5de7c5cebd814e1caa8437775031ea12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6762ef5aab7e4d18b98e7d837dedc03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f14799525cf44158bbffc0e9a08891b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7dceec9910a46cea90915015ca58358",
      "placeholder": "​",
      "style": "IPY_MODEL_573ab758539147f1a2bc21ac9f0347ce",
      "value": "100%"
     }
    },
    "76ddf1599bb144b2a6b4573027c6f662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4074a8c3b85548ed9424375a19416c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_13858cd0c554419bb867071b5c810b30",
      "value": " 1000/1000 [00:19&lt;00:00, 37.91it/s]"
     }
    },
    "b0ab4a4e03b242e2ae3610b6a52b5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7dceec9910a46cea90915015ca58358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d239d2ff297a4c00aa350f8699ca6bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de7c5cebd814e1caa8437775031ea12",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0ab4a4e03b242e2ae3610b6a52b5c14",
      "value": 1000
     }
    },
    "ef58b4abcf0f43cd90a523a3875a2f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f14799525cf44158bbffc0e9a08891b",
       "IPY_MODEL_d239d2ff297a4c00aa350f8699ca6bb1",
       "IPY_MODEL_76ddf1599bb144b2a6b4573027c6f662"
      ],
      "layout": "IPY_MODEL_6762ef5aab7e4d18b98e7d837dedc03f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
