{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "実際に動いたコードしか突っ込まないこと！！！\n",
    "（ここでエラーが出ると調整が大変です。)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "B3WEPx1JJqlG"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "#import optuna.integration.lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import clone_model\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 5.2\n",
    "    AUTHOR = 'naokisusami'\n",
    "    COMPETITION = 'FDUA2'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = [ 'neuralnetwork', 'adaboost','lightgbm', 'xgboost', 'catboost']\n",
    "    seed = 42\n",
    "    n_folds = 7\n",
    "    target_col = 'MIS_Status'\n",
    "    metric = 'f1_score'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 500\n",
    "    early_stopping_round = 200\n",
    "    verbose = 25\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        'depth':7,\n",
    "        'learning_rate': 0.01,\n",
    "        'iterations': 1200,\n",
    "        'l2_leaf_reg': 7,\n",
    "        'random_seed': seed,\n",
    "    }\n",
    "    classification_adaboost_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 1.0,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "    nn_params = {\n",
    "        'input_size': 62,  # 特徴量の数に応じて変更してください\n",
    "        'hidden_size': [64, 32],  # 隠れ層のユニット数\n",
    "        'output_size': 1,  # 出力層のユニット数\n",
    "        'dropout_rate': 0.1,\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 10,\n",
    "    }\n",
    "\n",
    "    model_weight_dict = {'lightgbm': 0.30, 'xgboost': 0.10, 'catboost': 0.30, 'adaboost': 0.10, 'neuralnetwork': 0.15}\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# f1_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro'), CFG.metric_maximize_flag\n",
    "\n",
    "# ====================================================\n",
    "# XGBoost Metric\n",
    "# ====================================================\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro')\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(cfg['input_size'], cfg['hidden_size'][0])\n",
    "        self.dropout = nn.Dropout(cfg['dropout_rate'])\n",
    "        self.fc2 = nn.Linear(cfg['hidden_size'][0], cfg['hidden_size'][1])\n",
    "        self.fc3 = nn.Linear(cfg['hidden_size'][1], cfg['output_size'])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "    \n",
    "def f1_score_nn(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.round(K.flatten(y_pred))\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    fn = K.sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return f1\n",
    "\n",
    "def macro_f1_score_nn(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.round(K.flatten(y_pred))\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    fn = K.sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    \n",
    "    # Calculate F1 score for each class\n",
    "    f1_per_class = []\n",
    "    for c in range(tf.shape(y_true)[-1]):\n",
    "        true_positives = K.sum(K.cast(y_true[:, c] * K.round(y_pred[:, c]), 'float'), axis=0)\n",
    "        possible_positives = K.sum(K.cast(y_true[:, c], 'float'), axis=0)\n",
    "        predicted_positives = K.sum(K.cast(K.round(y_pred[:, c]), 'float'), axis=0)\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        f1_per_class.append(2 * precision * recall / (precision + recall + K.epsilon()))\n",
    "        \n",
    "class MacroF1ScoreCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(MacroF1ScoreCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        print(f'Epoch {epoch+1}: val_macro_f1: {_val_f1}')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "id": "g6R4KoxhL91E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n",
      "City\n",
      "BankState\n",
      "UrbanRural_Sector_interaction\n",
      "Sector_RevLineCr\n",
      "Sector_LowDoc\n",
      "       Term  NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
      "0       163     21         1          0            0              1   \n",
      "1        84      6         1          4            0              0   \n",
      "2       242     45         1          4           90              0   \n",
      "3       237      4         1          0            0              0   \n",
      "4       184      0         1          0            0              0   \n",
      "...     ...    ...       ...        ...          ...            ...   \n",
      "42302   283     14         1          0            0              1   \n",
      "42303    53      2         1          0            0              0   \n",
      "42304    59      6         0          0            0              1   \n",
      "42305   295     18         1          0            8              0   \n",
      "42306    84      4         1          0            8              0   \n",
      "\n",
      "       RevLineCr_1.0  RevLineCr_0.0  RevLineCr_4.0  RevLineCr_3.0  \\\n",
      "0                  1              0              0              0   \n",
      "1                  0              1              0              0   \n",
      "2                  1              0              0              0   \n",
      "3                  1              0              0              0   \n",
      "4                  1              0              0              0   \n",
      "...              ...            ...            ...            ...   \n",
      "42302              1              0              0              0   \n",
      "42303              0              0              1              0   \n",
      "42304              1              0              0              0   \n",
      "42305              1              0              0              0   \n",
      "42306              1              0              0              0   \n",
      "\n",
      "       RevLineCr_2.0  LowDoc_3.0  LowDoc_2.0  LowDoc_5.0  LowDoc_6.0  \\\n",
      "0                  0           1           0           0           0   \n",
      "1                  0           1           0           0           0   \n",
      "2                  0           1           0           0           0   \n",
      "3                  0           1           0           0           0   \n",
      "4                  0           1           0           0           0   \n",
      "...              ...         ...         ...         ...         ...   \n",
      "42302              0           1           0           0           0   \n",
      "42303              0           1           0           0           0   \n",
      "42304              0           1           0           0           0   \n",
      "42305              0           1           0           0           0   \n",
      "42306              0           1           0           0           0   \n",
      "\n",
      "       LowDoc_0.0  LowDoc_4.0  LowDoc_1.0  DisbursementDate  Sector  \\\n",
      "0               0           0           0               847       0   \n",
      "1               0           0           0               638      20   \n",
      "2               0           0           0               232       8   \n",
      "3               0           0           0               386       7   \n",
      "4               0           0           0               427       0   \n",
      "...           ...         ...         ...               ...     ...   \n",
      "42302           0           0           0               847       0   \n",
      "42303           0           0           0               605       8   \n",
      "42304           0           0           0               270       8   \n",
      "42305           0           0           0               800       8   \n",
      "42306           0           0           0               534      22   \n",
      "\n",
      "       ApprovalDate  ApprovalFY          City  State BankState  \\\n",
      "0              2084        2006       PHOENIX      3        SD   \n",
      "1              3265        1992     MCALESTER     36        OK   \n",
      "2              1232        2001     HAWTHORNE     31        NJ   \n",
      "3              3793        2004     NASHVILLE     42        SD   \n",
      "4              1126        2000        POMONA      4        CA   \n",
      "...             ...         ...           ...    ...       ...   \n",
      "42302          1603        1995  PHILADELPHIA     38        PA   \n",
      "42303          3756        2007   LOS ANGELES      4        SD   \n",
      "42304           747        2003      COLUMBUS     35        OH   \n",
      "42305          2117        1989       CLOQUET     23        MN   \n",
      "42306           379        2011   SAN GABRIEL      4        NC   \n",
      "\n",
      "       DisbursementGross    GrAppv  SBA_Appv  UrbanRural  DisbursementDay  \\\n",
      "0                80000.0   80000.0   68000.0           0               31   \n",
      "1               287000.0  287000.0  229600.0           0               31   \n",
      "2                31983.0   30000.0   15000.0           1               31   \n",
      "3               229000.0  229000.0  229000.0           0               31   \n",
      "4               525000.0  525000.0  393750.0           0                8   \n",
      "...                  ...       ...       ...         ...              ...   \n",
      "42302            80000.0   80000.0   68000.0           0               31   \n",
      "42303             5000.0    5000.0    4250.0           1                3   \n",
      "42304            60000.0   60000.0   51000.0           0               28   \n",
      "42305           294000.0  294000.0  220500.0           0               10   \n",
      "42306            67500.0   67500.0   50625.0           0               31   \n",
      "\n",
      "       DisbursementMonth  DisbursementYear  ApprovalDay  ApprovalMonth  \\\n",
      "0                      1                -2           22              9   \n",
      "1                     10                -7           30              6   \n",
      "2                      8                 1           18              4   \n",
      "3                      8                 7            6             10   \n",
      "4                      6               -17           17             12   \n",
      "...                  ...               ...          ...            ...   \n",
      "42302                  1                -2            2              3   \n",
      "42303                  4                -9            6              6   \n",
      "42304                  2                 3           14              3   \n",
      "42305                 12                -3           23              8   \n",
      "42306                 10               -11           12              4   \n",
      "\n",
      "       ApprovalYear  CompanyLong  ApprovalTerm  DisbursementTerm  \\\n",
      "0                 6           -8         -1991                17   \n",
      "1                -8            1         -1977                22   \n",
      "2                 1            0         -1986                14   \n",
      "3                 3            4         -1989                 8   \n",
      "4                -1          -16         -1985                32   \n",
      "...             ...          ...           ...               ...   \n",
      "42302            -5            3         -1980                17   \n",
      "42303             7          -16         -1992                24   \n",
      "42304             3            0         -1988                12   \n",
      "42305           -11            8         -1974                18   \n",
      "42306            11          -22         -1996                26   \n",
      "\n",
      "       Bankraptcy_By_Year  Cor_State  Unemployment_By_State  GDP_By_State  \\\n",
      "0                 38377.0          0                    4.0         33655   \n",
      "1                 53300.0          1                    3.2         29470   \n",
      "2                 36284.4          1                    3.3         45052   \n",
      "3                 48317.0          0                    3.5         33742   \n",
      "4                 72700.0          1                    4.1         42376   \n",
      "...                   ...        ...                    ...           ...   \n",
      "42302             38377.0          1                    4.3         35153   \n",
      "42303             59900.0          0                    4.1         42376   \n",
      "42304             31346.0          1                    4.1         34040   \n",
      "42305             41067.4          1                    2.9         41353   \n",
      "42306             65600.0          0                    4.1         42376   \n",
      "\n",
      "       GDPperPerson_By_State  AveSalary_By_State  BCI           TI  \\\n",
      "0                      48148               45.40 -336    22.172949   \n",
      "1                      40376               40.75   12   306.951872   \n",
      "2                      55320               56.72    0     2.632346   \n",
      "3                      42865               41.88   32   192.436975   \n",
      "4                      53525               56.10    0  2837.837838   \n",
      "...                      ...                 ...  ...          ...   \n",
      "42302                  43246               46.10   84    18.779343   \n",
      "42303                  53525               56.10  -64    30.864198   \n",
      "42304                  41073               43.45    0   142.857143   \n",
      "42305                  51829               46.99  288    52.275960   \n",
      "42306                  53525               56.10 -176   158.823529   \n",
      "\n",
      "               TI2  GrAppv_SBA_Appv_ratio  DisbursementGross_GrAppv_ratio  \\\n",
      "0        18.847007               0.849989                        0.999988   \n",
      "1       245.561497               0.799997                        0.999997   \n",
      "2         1.234568               0.499983                        1.066064   \n",
      "3       192.436975               0.999996                        0.999996   \n",
      "4      2128.378378               0.749999                        0.999998   \n",
      "...            ...                    ...                             ...   \n",
      "42302    15.962441               0.849989                        0.999988   \n",
      "42303    26.234568               0.849830                        0.999800   \n",
      "42304   121.428571               0.849986                        0.999983   \n",
      "42305    39.206970               0.749997                        0.999997   \n",
      "42306   119.117647               0.749989                        0.999985   \n",
      "\n",
      "       NewExist_NoEmp_interaction UrbanRural_Sector_interaction  \\\n",
      "0                              21                           0_0   \n",
      "1                               6                          0_62   \n",
      "2                              45                          1_42   \n",
      "3                               4                          0_33   \n",
      "4                               0                           0_0   \n",
      "...                           ...                           ...   \n",
      "42302                          14                           0_0   \n",
      "42303                           2                          1_42   \n",
      "42304                           0                          0_42   \n",
      "42305                          18                          0_42   \n",
      "42306                           4                          0_72   \n",
      "\n",
      "       RevLineCr_LowDoc_risk_indicator  Franchise_risk_factor  \\\n",
      "0                                    0                      0   \n",
      "1                                    0                      0   \n",
      "2                                    0                      0   \n",
      "3                                    0                      0   \n",
      "4                                    0                      0   \n",
      "...                                ...                    ...   \n",
      "42302                                0                      0   \n",
      "42303                                1                      0   \n",
      "42304                                0                      0   \n",
      "42305                                0                      0   \n",
      "42306                                0                      0   \n",
      "\n",
      "       Emp_to_Loan_Ratio  JobImpactScore  Employment_creation_ratio  \\\n",
      "0               0.000262               0                   0.000000   \n",
      "1               0.000021               4                   0.571429   \n",
      "2               0.001407              94                   0.086957   \n",
      "3               0.000017               0                   0.000000   \n",
      "4               0.000000               0                   0.000000   \n",
      "...                  ...             ...                        ...   \n",
      "42302           0.000175               0                   0.000000   \n",
      "42303           0.000400               0                   0.000000   \n",
      "42304           0.000100               0                   0.000000   \n",
      "42305           0.000061               8                   0.000000   \n",
      "42306           0.000059               8                   0.000000   \n",
      "\n",
      "       Disbursement_per_Term Sector_RevLineCr Sector_LowDoc  \\\n",
      "0                 487.804878              0_N           0_N   \n",
      "1                3376.470588             62_0          62_N   \n",
      "2                 131.617284             42_N          42_N   \n",
      "3                 962.184874             33_N          33_N   \n",
      "4                2837.837838              0_N           0_N   \n",
      "...                      ...              ...           ...   \n",
      "42302             281.690141              0_N           0_N   \n",
      "42303              92.592593             42_Y          42_N   \n",
      "42304            1000.000000             42_N          42_N   \n",
      "42305             993.243243             42_N          42_N   \n",
      "42306             794.117647             72_N          72_N   \n",
      "\n",
      "       FranchiseCode_count_encoding  UrbanRural_count_encoding  \\\n",
      "0                             14033                      24037   \n",
      "1                             26392                      24037   \n",
      "2                             26392                      11759   \n",
      "3                             26392                      24037   \n",
      "4                             26392                      24037   \n",
      "...                             ...                        ...   \n",
      "42302                         14033                      24037   \n",
      "42303                         26392                      11759   \n",
      "42304                         14033                      24037   \n",
      "42305                         26392                      24037   \n",
      "42306                         26392                      24037   \n",
      "\n",
      "       State_count_encoding  City_count_encoding  Sector_count_encoding  \\\n",
      "0                       768                  324                   9798   \n",
      "1                       527                    8                   1191   \n",
      "2                       488                    6                   7337   \n",
      "3                      1147                  599                   5050   \n",
      "4                      6893                  584                   9798   \n",
      "...                     ...                  ...                    ...   \n",
      "42302                  2849                  612                   9798   \n",
      "42303                  6893                  348                   7337   \n",
      "42304                  1229                  124                   7337   \n",
      "42305                  1004                    2                   7337   \n",
      "42306                  6893                   69                   2478   \n",
      "\n",
      "       UrbanRural_Sector_interaction_count_encoding  \\\n",
      "0                                              9046   \n",
      "1                                               562   \n",
      "2                                              2515   \n",
      "3                                              2402   \n",
      "4                                              9046   \n",
      "...                                             ...   \n",
      "42302                                          9046   \n",
      "42303                                          2515   \n",
      "42304                                          3737   \n",
      "42305                                          3737   \n",
      "42306                                          1365   \n",
      "\n",
      "       Sector_RevLineCr_count_encoding  Sector_LowDoc_count_encoding  \\\n",
      "0                                 8323                          6308   \n",
      "1                                  290                           800   \n",
      "2                                 4688                          6720   \n",
      "3                                 3204                          4781   \n",
      "4                                 8323                          6308   \n",
      "...                                ...                           ...   \n",
      "42302                             8323                          6308   \n",
      "42303                             1578                          6720   \n",
      "42304                             4688                          6720   \n",
      "42305                             4688                          6720   \n",
      "42306                             1576                          2085   \n",
      "\n",
      "       MIS_Status  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "...           ...  \n",
      "42302           1  \n",
      "42303           1  \n",
      "42304           1  \n",
      "42305           1  \n",
      "42306           1  \n",
      "\n",
      "[42307 rows x 68 columns]\n"
     ]
    }
   ],
   "source": [
    "#LGB用データ作成\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector','DisbursementDate','ApprovalDate']\n",
    "\n",
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "        df['ApprovalTerm'] = 15 - df['ApprovalFY']\n",
    "        df['DisbursementTerm'] = 15 - df['DisbursementYear']\n",
    "\n",
    "    \n",
    "        #Bankraptdataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "        \n",
    "\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = sum(k.values()) / len(k)\n",
    "        \n",
    "            \n",
    "        \n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "        \n",
    "        \n",
    "        #State関係の特徴量作成\n",
    "        df['Cor_State'] = (df['State']==df['BankState']).astype(int)\n",
    "        StateList = ['AL','AK','AZ','AR','CA','CO','CT','DE','DC','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA',\n",
    "                      'MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX',\n",
    "                      'UT','VT','VA','WA','WV','WI','WY']\n",
    "        \n",
    "        UnemploymentList = [2.6,3.7,4.0,3.4,4.1,2.8,4.0,4.6,4.2,2.7,3.1,3.7,2.8,4.6,3.1,3.0,2.9,3.9,3.5,3.1,3.0,3.7,4.3,2.9,4.0,\n",
    "                          2.7,2.6,2.7,5.5,2.9,3.3,3.5,4.1,3.8,2.1,4.1,3.2,4.8,4.3,3.2,3.3,2.2,3.5,3.8,2.4,3.0,3.1\n",
    "                            ,4.5,4.1,3.0,3.9]\n",
    "\n",
    "        GDPList = [29603,44807,33655,27781,42376,40805,51911,56496,126421,33417,35265,38850,29843,39568,32724,35814,34770,30364,35181,\n",
    "                   30282,39596,47351,32846,41353,24477,32590,28201,37075,40210,37375,45052,30943,49038,37053,34694,34040,29470,\n",
    "                   38339,35153,36543,28894,35596,33742,37793,32774,34197,41617,40361,24929,34890,40303]\n",
    "        \n",
    "        GDPperPersonList = [37282,71008,48148,35674,53525,54943,63504,76720,164002,45958,48434,50788,39529,49083,40529,44091,43633,\n",
    "                       38148,48366,37734,50729,55364,38433,51829,31127,41012,37966,46803,63662,46400,55320,41878,58126,49625,43172,\n",
    "                       41073,40376,46248,43246,44738,38093,44955,42865,54766,47313,40312,54102,52810,31914,43309,63822]\n",
    "        \n",
    "        AveSalaryList = [40.46,50.81,45.40,37.79,56.10,49.79,60.14,49.66,79.85,43.66,46.17,44.09,36.45,51.71,40.97,38.39,40.96,\n",
    "                        39.54,43.15,39.06,54.28,58.62,45.19,46.99,35.95,42.58,35.81,39.87,44.38,46.38,56.72,40.91,61.04,43.11,41.12,\n",
    "                        43.45,40.75,43.46,46.10,46.38,39.63,35.00,41.88,48.35,41.11,39.54,52.07,51.04,38.48,41.46,44.03]\n",
    "        \n",
    "        Unemploymentdict = dict(zip(StateList,UnemploymentList))\n",
    "        GDPdict = dict(zip(StateList,GDPList))\n",
    "        GDPperPersondict = dict(zip(StateList,GDPperPersonList))\n",
    "        AveSalarydict = dict(zip(StateList,AveSalaryList))\n",
    "        \n",
    "        df['Unemployment_By_State'] = df['State'].map(Unemploymentdict)\n",
    "        df['GDP_By_State'] = df['State'].map(GDPdict)\n",
    "        df['GDPperPerson_By_State'] = df['State'].map(GDPperPersondict)\n",
    "        df['AveSalary_By_State'] = df['State'].map(AveSalarydict)\n",
    "        \n",
    "        \n",
    "        #現状グループ分けされない特徴量の作成\n",
    "        #企業の安定さ、デカさ\n",
    "        df['BCI'] = df['CompanyLong']*(df['NoEmp'])*(df['NewExist']+1)\n",
    "        df['BCI'] = df['BCI'].fillna(df['BCI'].mean)\n",
    "        #しんどさ指数\n",
    "        df['TI'] = (df['DisbursementGross']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "        #しんどさ指数2\n",
    "        df['TI2'] = (df['SBA_Appv']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "        \n",
    "        #派生特徴量\n",
    "        # Employee to Loan Size Ratio\n",
    "        # 財務関連の派生特徴量\n",
    "        df['GrAppv_SBA_Appv_ratio'] = df['SBA_Appv'] / (df['GrAppv'] + 1) \n",
    "        df['DisbursementGross_GrAppv_ratio'] = df['DisbursementGross'] / (df['GrAppv'] + 1)\n",
    "        # ビジネスの条件関連\n",
    "        df['NewExist_NoEmp_interaction'] = df['NewExist'] * df['NoEmp']\n",
    "        df['UrbanRural_Sector_interaction'] = df['UrbanRural'].astype(str) + '_' + df['Sector'].astype(str)\n",
    "        # リスク関連の派生特徴量\n",
    "        df['RevLineCr_LowDoc_risk_indicator'] = (df['RevLineCr'] == 'Y').astype(int) + (df['LowDoc'] == 'Y').astype(int)\n",
    "        # FranchiseCodeのリスク要因\n",
    "        df['Franchise_risk_factor'] = df['FranchiseCode'].apply(lambda x: 0 if x in [0, 1] else 1)\n",
    "        # 経済的特徴の組み合わせ\n",
    "        df['Emp_to_Loan_Ratio'] = df['NoEmp'] / (df['DisbursementGross'] + 1)\n",
    "        df['JobImpactScore'] = df['CreateJob'] + df['RetainedJob']\n",
    "        df['Employment_creation_ratio'] = df['CreateJob'] / (df['NoEmp'] + 1)\n",
    "        df['Disbursement_per_Term'] = df['DisbursementGross'] / (df['Term']+1)\n",
    "        # 業種と金融条件の組み合わせ\n",
    "        df['Sector_RevLineCr'] = df['Sector'].astype(str) + '_' + df['RevLineCr']\n",
    "        df['Sector_LowDoc'] = df['Sector'].astype(str) + '_' + df['LowDoc']\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df\n",
    "\n",
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)\n",
    "\n",
    "#カウントエンコーディング\n",
    "for col in ['FranchiseCode','UrbanRural', 'State','City', 'Sector', \n",
    "            'UrbanRural_Sector_interaction', 'Sector_RevLineCr', 'Sector_LowDoc']:\n",
    "    count_dict = dict(train_df[col].value_counts())\n",
    "    train_df[f'{col}_count_encoding'] = train_df[col].map(count_dict).astype(int)\n",
    "    test_df[f'{col}_count_encoding'] = test_df[col].map(count_dict).fillna(1).astype(int)\n",
    "\n",
    "#ラベルエンコーディング\n",
    "for col in categorical_features:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "    \n",
    "#OneHotEncoding\n",
    "train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "OneHotList = ['RevLineCr', 'LowDoc']\n",
    "ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "train_df2 = ohe.fit_transform(train_df2)\n",
    "test_df = ohe.transform(test_df)\n",
    "train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "\n",
    "#featuresの作成\n",
    "categorical_features =['UrbanRural', 'State', 'Sector','RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0',\n",
    "                       'LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0','FranchiseCode']\n",
    "\n",
    "RemoveList=['MIS_Status','City','BankState','UrbanRural_Sector_interaction',\n",
    "            'Sector_RevLineCr', 'Sector_LowDoc']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "    \n",
    "print(train_df)\n",
    "#専用変数として保存\n",
    "train_df_lgb = train_df\n",
    "test_df_lgb = test_df\n",
    "categorical_features_lgb = categorical_features\n",
    "features_lgb = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n",
      "ApprovalDay\n",
      "ApprovalMonth\n",
      "ApprovalFY\n",
      "ApprovalYear\n",
      "DisbursementDay\n",
      "DisbursementMonth\n",
      "DisbursementYear\n"
     ]
    }
   ],
   "source": [
    "#CTB用データ作成\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "default_numerical_features = ['Term', 'NoEmp', 'CreateJob', 'RetainedJob', 'DisbursementGross', 'GrAppv', 'SBA_Appv', 'ApprovalFY']\n",
    "default_categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector','FranchiseCode','City','ApprovalDate',\n",
    "                                'DisbursementDate','BankState','NewExist']\n",
    "new_categorical_features = []\n",
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        \n",
    "        #Bankraptcydataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [Bankraptcydata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = k[-26]*2\n",
    "        \n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "\n",
    "        '''\n",
    "        #組み合わせ特徴量\n",
    "        CList = ['Term','NoEmp','CreateJob','RetainedJob','FranchiseCode','RevLineCr','LowDoc','DisbursementDate','ApprovalDate','City',\n",
    "                'State','BankState','DisbursementGross','GrAppv','SBA_Appv','UrbanRural','NewExist']\n",
    "        for i in range(len(CList)-2):\n",
    "            for j in range(i+1,len(CList)):\n",
    "                a,b = CList[i],CList[j]\n",
    "                df[f'{a}_{b}'] = df[a].astype(str) + '_' + df[b].astype(str)\n",
    "        '''\n",
    "        #組み合わせ特徴量\n",
    "        df['State_Sector'] = df['State'].astype(str) + '_' + df['Sector'].astype(str)\n",
    "         # 地理的特徴の組み合わせ\n",
    "        df['City_State'] = df['City'] + '_' + df['State']\n",
    "        # 時間的特徴の組み合わせ\n",
    "        df['ApprovalFY_Term'] = df['ApprovalFY'].astype(str) + '_' + df['Term'].astype(str)\n",
    "        \n",
    "        df['FranchiseCode_ApprovalDate'] = df['FranchiseCode'].astype(str) + '_' + df['ApprovalDate'].astype(str)\n",
    "        \n",
    "        df['Term_NoEmp'] = df['Term'].astype(str) + '_' + df['NoEmp'].astype(str)\n",
    "        \n",
    "        df['City_BankState'] = df['City'].astype(str) + '_' + df['BankState'].astype(str)\n",
    "        \n",
    "        df['NoEmp_SBA_Appv'] = df['NoEmp'].astype(str) + '_' + df['SBA_Appv'].astype(str)\n",
    "        \n",
    "        df['DisbursementDate_UrbanRural'] = df['DisbursementDate'].astype(str) + '_' + df['UrbanRural'].astype(str)\n",
    "        \n",
    "    \n",
    "    \n",
    "        \n",
    "        \n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df\n",
    "\n",
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)\n",
    "\n",
    "'''\n",
    "#カウントエンコーディング\n",
    "for col in categorical_features:\n",
    "    count_dict = dict(train_df[col].value_counts())\n",
    "    train_df[f'{col}_count_encoding'] = train_df[col].map(count_dict).astype(int)\n",
    "    test_df[f'{col}_count_encoding'] = test_df[col].map(count_dict).fillna(1).astype(int)\n",
    "'''\n",
    "\n",
    "#ラベルエンコーディング\n",
    "new_categorical_features = ['State_Sector','City_State','ApprovalFY_Term','FranchiseCode_ApprovalDate','Term_NoEmp',\n",
    "                           'City_BankState','NoEmp_SBA_Appv','DisbursementDate_UrbanRural']\n",
    "categorical_features = default_categorical_features + new_categorical_features\n",
    "for col in categorical_features:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "    \n",
    "\n",
    "#featuresの作成\n",
    "numerical_features = default_numerical_features + ['Bankraptcy_By_Year']\n",
    "features = numerical_features + categorical_features \n",
    "\n",
    "RemoveList=['MIS_Status','ApprovalDay','ApprovalMonth','ApprovalFY','ApprovalYear','DisbursementDay','DisbursementMonth',\n",
    "           'DisbursementYear']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "    \n",
    "#専用変数の作成\n",
    "train_df_ctb = train_df\n",
    "test_df_ctb = test_df\n",
    "categorical_features_ctb = categorical_features\n",
    "features_ctb = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n",
      "City\n",
      "ApprovalDate\n",
      "BankState\n",
      "DisbursementDate\n",
      "ApprovalDay\n",
      "ApprovalMonth\n",
      "ApprovalFY\n",
      "ApprovalYear\n",
      "DisbursementDay\n",
      "DisbursementMonth\n",
      "MIS_Status\n",
      "City\n",
      "ApprovalDate\n",
      "BankState\n",
      "DisbursementDate\n",
      "ApprovalDay\n",
      "ApprovalMonth\n",
      "ApprovalFY\n",
      "ApprovalYear\n",
      "DisbursementDay\n",
      "DisbursementMonth\n",
      "           Term     NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
      "0      0.643243  0.645918  0.516224  -0.428693    -0.428684      -0.185372   \n",
      "1     -0.290907 -0.211822  0.516224   0.356557    -0.428684      -0.185467   \n",
      "2      1.577393  2.018302  0.516224   0.356557    10.663868      -0.185467   \n",
      "3      1.518270 -0.326187  0.516224  -0.428693    -0.428684      -0.185467   \n",
      "4      0.891561 -0.554918  0.516224  -0.428693    -0.428684      -0.185467   \n",
      "...         ...       ...       ...        ...          ...            ...   \n",
      "42302  2.062205  0.245639  0.516224  -0.428693    -0.428684      -0.185372   \n",
      "42303 -0.657472 -0.440553  0.516224  -0.428693    -0.428684      -0.185467   \n",
      "42304 -0.586524 -0.211822 -1.937144  -0.428693    -0.428684      -0.185372   \n",
      "42305  2.204102  0.474370  0.516224  -0.428693     0.557321      -0.185467   \n",
      "42306 -0.290907 -0.326187  0.516224  -0.428693     0.557321      -0.185467   \n",
      "\n",
      "       RevLineCr_1.0  RevLineCr_0.0  RevLineCr_4.0  RevLineCr_3.0  \\\n",
      "0                  1              0              0              0   \n",
      "1                  0              1              0              0   \n",
      "2                  1              0              0              0   \n",
      "3                  1              0              0              0   \n",
      "4                  1              0              0              0   \n",
      "...              ...            ...            ...            ...   \n",
      "42302              1              0              0              0   \n",
      "42303              0              0              1              0   \n",
      "42304              1              0              0              0   \n",
      "42305              1              0              0              0   \n",
      "42306              1              0              0              0   \n",
      "\n",
      "       RevLineCr_2.0  LowDoc_3.0  LowDoc_2.0  LowDoc_5.0  LowDoc_6.0  \\\n",
      "0                  0           1           0           0           0   \n",
      "1                  0           1           0           0           0   \n",
      "2                  0           1           0           0           0   \n",
      "3                  0           1           0           0           0   \n",
      "4                  0           1           0           0           0   \n",
      "...              ...         ...         ...         ...         ...   \n",
      "42302              0           1           0           0           0   \n",
      "42303              0           1           0           0           0   \n",
      "42304              0           1           0           0           0   \n",
      "42305              0           1           0           0           0   \n",
      "42306              0           1           0           0           0   \n",
      "\n",
      "       LowDoc_0.0  LowDoc_4.0  LowDoc_1.0  DisbursementDate    Sector  \\\n",
      "0               0           0           0               847 -1.158439   \n",
      "1               0           0           0               638  1.785958   \n",
      "2               0           0           0               232  0.019320   \n",
      "3               0           0           0               386 -0.127900   \n",
      "4               0           0           0               427 -1.158439   \n",
      "...           ...         ...         ...               ...       ...   \n",
      "42302           0           0           0               847 -1.158439   \n",
      "42303           0           0           0               605  0.019320   \n",
      "42304           0           0           0               270  0.019320   \n",
      "42305           0           0           0               800  0.019320   \n",
      "42306           0           0           0               534  2.080397   \n",
      "\n",
      "       ApprovalDate  ApprovalFY  City     State  BankState  DisbursementGross  \\\n",
      "0              2084        2006  2208 -1.423718         42          -0.399474   \n",
      "1              3265        1992  1723  0.698629         36           0.432786   \n",
      "2              1232        2001  1214  0.377061         31          -0.592531   \n",
      "3              3793        2004  1906  1.084510         42           0.199592   \n",
      "4              1126        2000  2246 -1.359404          4           1.389684   \n",
      "...             ...         ...   ...       ...        ...                ...   \n",
      "42302          1603        1995  2207  0.827256         38          -0.399474   \n",
      "42303          3756        2007  1594 -1.359404         42          -0.701018   \n",
      "42304           747        2003   580  0.634315         35          -0.479886   \n",
      "42305          2117        1989   547 -0.137447         23           0.460930   \n",
      "42306           379        2011  2489 -1.359404         27          -0.449732   \n",
      "\n",
      "         GrAppv  SBA_Appv  UrbanRural  DisbursementDay  DisbursementMonth  \\\n",
      "0     -0.379998 -0.338594   -0.789495               31                  1   \n",
      "1      0.457168  0.447553   -0.789495               31                 10   \n",
      "2     -0.582212 -0.596427    0.558359               31                  8   \n",
      "3      0.222600  0.444634   -0.789495               31                  8   \n",
      "4      1.419706  1.246104   -0.789495                8                  6   \n",
      "...         ...       ...         ...              ...                ...   \n",
      "42302 -0.379998 -0.338594   -0.789495               31                  1   \n",
      "42303 -0.683319 -0.648723    0.558359                3                  4   \n",
      "42304 -0.460884 -0.421295   -0.789495               28                  2   \n",
      "42305  0.485478  0.403283   -0.789495               10                 12   \n",
      "42306 -0.430552 -0.423119   -0.789495               31                 10   \n",
      "\n",
      "       DisbursementYear  ApprovalDay  ApprovalMonth  ApprovalYear  \\\n",
      "0             -0.467855           22              9             6   \n",
      "1             -1.196781           30              6            -8   \n",
      "2             -0.030500           18              4             1   \n",
      "3              0.844211            6             10             3   \n",
      "4             -2.654632           17             12            -1   \n",
      "...                 ...          ...            ...           ...   \n",
      "42302         -0.467855            2              3            -5   \n",
      "42303         -1.488351            6              6             7   \n",
      "42304          0.261071           14              3             3   \n",
      "42305         -0.613640           23              8           -11   \n",
      "42306         -1.779921           12              4            11   \n",
      "\n",
      "       CompanyLong  ApprovalTerm  DisbursementTerm  EconomyGrowth_By_Year  \\\n",
      "0        -0.888012     -0.761411          0.467855               0.434452   \n",
      "1         0.116853      1.627481          1.196781               1.293286   \n",
      "2         0.005202      0.091765          0.030500               0.484761   \n",
      "3         0.451809     -0.420141         -0.844211              -1.410783   \n",
      "4        -1.781226      0.262400          2.654632               1.904172   \n",
      "...            ...           ...               ...                    ...   \n",
      "42302     0.340157      1.115576          0.467855               0.434452   \n",
      "42303    -1.781226     -0.932046          1.488351               0.869260   \n",
      "42304     0.005202     -0.249506         -0.261071               0.058937   \n",
      "42305     0.898416      2.139386          0.613640               0.682400   \n",
      "42306    -2.451137     -1.614587          1.779921               0.030190   \n",
      "\n",
      "       Bankraptcy_By_Year  Unemploymentrate_By_Year  Interestrate_By_Year  \\\n",
      "0               -0.456812                 -0.835666              0.287011   \n",
      "1                1.184805                 -0.567823              1.168808   \n",
      "2               -0.687010                 -0.465412             -0.239917   \n",
      "3                0.636646                  1.834890             -1.358294   \n",
      "4                3.318918                  0.503551              2.620548   \n",
      "...                   ...                       ...                   ...   \n",
      "42302           -0.456812                 -0.835666              0.287011   \n",
      "42303            1.910843                  0.259340              0.684895   \n",
      "42304           -1.230262                 -0.733256              0.200982   \n",
      "42305           -0.160852                 -1.111387              0.738663   \n",
      "42306            2.537876                  0.440529              0.792431   \n",
      "\n",
      "       Inflationrate_By_Year  Unemployment_By_State  GDP_By_State  \\\n",
      "0                  -0.020816               0.530831     -0.636054   \n",
      "1                  -0.035181              -0.707438     -1.192072   \n",
      "2                   0.295214              -0.552655      0.878150   \n",
      "3                  -0.713928              -0.243087     -0.624495   \n",
      "4                   1.728124               0.685615      0.522617   \n",
      "...                      ...                    ...           ...   \n",
      "42302              -0.020816               0.995182     -0.437030   \n",
      "42303               0.726165               0.685615      0.522617   \n",
      "42304               1.297174               0.685615     -0.584903   \n",
      "42305              -0.290160              -1.171789      0.386701   \n",
      "42306               2.123162               0.685615      0.522617   \n",
      "\n",
      "       GDPperPerson_By_State  AveSalary_By_State       BCI  \\\n",
      "0                  -0.156982           -0.416051 -0.946043   \n",
      "1                  -0.963001           -1.075428  0.053940   \n",
      "2                   0.586813            1.189141  0.019457   \n",
      "3                  -0.704872           -0.915192  0.111410   \n",
      "4                   0.400657            1.101224  0.019457   \n",
      "...                      ...                 ...       ...   \n",
      "42302              -0.665359           -0.316790  0.260832   \n",
      "42303               0.400657            1.101224 -0.164447   \n",
      "42304              -0.890716           -0.692564  0.019457   \n",
      "42305               0.224768           -0.190587  0.847029   \n",
      "42306               0.400657            1.101224 -0.486281   \n",
      "\n",
      "       DisbursementGrossPerMonth  SBA_Appv-DisbursementGross  \\\n",
      "0                      -0.150790                    0.348687   \n",
      "1                      -0.035776                   -0.183318   \n",
      "2                      -0.164972                    0.290295   \n",
      "3                      -0.131902                    0.489305   \n",
      "4                      -0.057222                   -1.048705   \n",
      "...                          ...                         ...   \n",
      "42302                  -0.158996                    0.348687   \n",
      "42303                  -0.166525                    0.480516   \n",
      "42304                  -0.130396                    0.383841   \n",
      "42305                  -0.130665                   -0.371980   \n",
      "42306                  -0.138594                    0.291561   \n",
      "\n",
      "       DisbursementGrossPerNoEmp  DisbursementGrossPerEmp        TI       TI2  \\\n",
      "0                      -0.467973                -0.439885 -0.111339 -0.106998   \n",
      "1                       0.013984                -0.118164 -0.079156 -0.076365   \n",
      "2                      -0.505910                -0.482821 -0.113547 -0.109378   \n",
      "3                       0.075900                 0.164221 -0.092098 -0.083543   \n",
      "4                       6.257150                 7.030033  0.206855  0.178032   \n",
      "...                          ...                      ...       ...       ...   \n",
      "42302                  -0.446084                -0.415571 -0.111722 -0.107388   \n",
      "42303                  -0.493380                -0.468106 -0.110357 -0.106000   \n",
      "42304                  -0.404315                -0.369177 -0.097700 -0.093138   \n",
      "42305                  -0.315282                -0.270284 -0.107937 -0.104247   \n",
      "42306                  -0.340741                -0.298562 -0.095896 -0.093450   \n",
      "\n",
      "       MIS_Status  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "...           ...  \n",
      "42302           1  \n",
      "42303           1  \n",
      "42304           1  \n",
      "42305           1  \n",
      "42306           1  \n",
      "\n",
      "[42307 rows x 55 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42307 entries, 0 to 42306\n",
      "Data columns (total 55 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Term                        42307 non-null  float64\n",
      " 1   NoEmp                       42307 non-null  float64\n",
      " 2   NewExist                    42307 non-null  float64\n",
      " 3   CreateJob                   42307 non-null  float64\n",
      " 4   RetainedJob                 42307 non-null  float64\n",
      " 5   FranchiseCode               42307 non-null  float64\n",
      " 6   RevLineCr_1.0               42307 non-null  int64  \n",
      " 7   RevLineCr_0.0               42307 non-null  int64  \n",
      " 8   RevLineCr_4.0               42307 non-null  int64  \n",
      " 9   RevLineCr_3.0               42307 non-null  int64  \n",
      " 10  RevLineCr_2.0               42307 non-null  int64  \n",
      " 11  LowDoc_3.0                  42307 non-null  int64  \n",
      " 12  LowDoc_2.0                  42307 non-null  int64  \n",
      " 13  LowDoc_5.0                  42307 non-null  int64  \n",
      " 14  LowDoc_6.0                  42307 non-null  int64  \n",
      " 15  LowDoc_0.0                  42307 non-null  int64  \n",
      " 16  LowDoc_4.0                  42307 non-null  int64  \n",
      " 17  LowDoc_1.0                  42307 non-null  int64  \n",
      " 18  DisbursementDate            42307 non-null  int32  \n",
      " 19  Sector                      42307 non-null  float64\n",
      " 20  ApprovalDate                42307 non-null  int32  \n",
      " 21  ApprovalFY                  42307 non-null  int64  \n",
      " 22  City                        42307 non-null  int32  \n",
      " 23  State                       42307 non-null  float64\n",
      " 24  BankState                   42307 non-null  int32  \n",
      " 25  DisbursementGross           42307 non-null  float64\n",
      " 26  GrAppv                      42307 non-null  float64\n",
      " 27  SBA_Appv                    42307 non-null  float64\n",
      " 28  UrbanRural                  42307 non-null  float64\n",
      " 29  DisbursementDay             42307 non-null  int32  \n",
      " 30  DisbursementMonth           42307 non-null  int64  \n",
      " 31  DisbursementYear            42307 non-null  float64\n",
      " 32  ApprovalDay                 42307 non-null  int32  \n",
      " 33  ApprovalMonth               42307 non-null  int64  \n",
      " 34  ApprovalYear                42307 non-null  int64  \n",
      " 35  CompanyLong                 42307 non-null  float64\n",
      " 36  ApprovalTerm                42307 non-null  float64\n",
      " 37  DisbursementTerm            42307 non-null  float64\n",
      " 38  EconomyGrowth_By_Year       42307 non-null  float64\n",
      " 39  Bankraptcy_By_Year          42307 non-null  float64\n",
      " 40  Unemploymentrate_By_Year    42307 non-null  float64\n",
      " 41  Interestrate_By_Year        42307 non-null  float64\n",
      " 42  Inflationrate_By_Year       42307 non-null  float64\n",
      " 43  Unemployment_By_State       42307 non-null  float64\n",
      " 44  GDP_By_State                42307 non-null  float64\n",
      " 45  GDPperPerson_By_State       42307 non-null  float64\n",
      " 46  AveSalary_By_State          42307 non-null  float64\n",
      " 47  BCI                         42307 non-null  float64\n",
      " 48  DisbursementGrossPerMonth   42307 non-null  float64\n",
      " 49  SBA_Appv-DisbursementGross  42307 non-null  float64\n",
      " 50  DisbursementGrossPerNoEmp   42307 non-null  float64\n",
      " 51  DisbursementGrossPerEmp     42307 non-null  float64\n",
      " 52  TI                          42307 non-null  float64\n",
      " 53  TI2                         42307 non-null  float64\n",
      " 54  MIS_Status                  42307 non-null  int64  \n",
      "dtypes: float64(32), int32(6), int64(17)\n",
      "memory usage: 17.1 MB\n",
      "['Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'RevLineCr_1.0', 'RevLineCr_0.0', 'RevLineCr_4.0', 'RevLineCr_3.0', 'RevLineCr_2.0', 'LowDoc_3.0', 'LowDoc_2.0', 'LowDoc_5.0', 'LowDoc_6.0', 'LowDoc_0.0', 'LowDoc_4.0', 'LowDoc_1.0', 'Sector', 'State', 'DisbursementGross', 'GrAppv', 'SBA_Appv', 'UrbanRural', 'DisbursementYear', 'CompanyLong', 'ApprovalTerm', 'DisbursementTerm', 'EconomyGrowth_By_Year', 'Bankraptcy_By_Year', 'Unemploymentrate_By_Year', 'Interestrate_By_Year', 'Inflationrate_By_Year', 'Unemployment_By_State', 'GDP_By_State', 'GDPperPerson_By_State', 'AveSalary_By_State', 'BCI', 'DisbursementGrossPerMonth', 'SBA_Appv-DisbursementGross', 'DisbursementGrossPerNoEmp', 'DisbursementGrossPerEmp', 'TI', 'TI2']\n"
     ]
    }
   ],
   "source": [
    "#NN用データ作成\n",
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector']\n",
    "#前処理メソッドの定義\n",
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "        df['ApprovalTerm'] = 15 - df['ApprovalFY']\n",
    "        df['DisbursementTerm'] = 15 - df['DisbursementYear']\n",
    "\n",
    "\n",
    "        #経済成長率\n",
    "        EconomyGrowthdata={-26:-0.6,-25:-0.4,-24:5.6,-23:4.6,-22:5.5,-21:3.2,-20:-0.26,-19:2.54,-18:-1.8,-17:4.58,-16:7.24,-15:4.17,\n",
    "                           -14:3.46,-13:3.46,-12:4.18,-11:3.67,-10:1.89,-9:-0.11,-8:3.52,-7:2.75,-6:4.03,-5:2.68,-4:3.77,-3:4.45,\n",
    "                           -2:4.18,-1:4.8,0:4.08,1:0.95,2:1.7,3:2.8,4:3.85,5:3.48,6:2.78,7: 2.01,8:0.12,9:-2.6,10:2.71,11:1.55,12:2.28,\n",
    "                           13:1.84,14:2.29,15:2.71,16:1.67,17:2.24,18:2.95,19:2.30}\n",
    "        #Bankraptdataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "        #失業率\n",
    "        Unemploymentratedata={-26:5.45,-25:8.7,-24:7.7,-23:7.05,-22:6.05,-21:5.7,-20:7.7,-19:7.35,-18:9.7,-17:9.75,-16:7.35,-15:7.4,\n",
    "                              -14:7.1,-13:6.15,-12:5.4,-11:5.25,-10:5.35,-9:6.85,-8:7.75,-7:6.95,-6:6.1,-5:5.65,-4:5.4,-3:4.95,-2:4.5,\n",
    "                              -1:4.3,0:4.0,1:4.55,2:5.8,3:6.25,4:5.55,5:5.0,6:4.65,7:4.65,8:5.7,9:9.5,10:9.4,11:9.05,12:8.2,13:7.4,\n",
    "                              14:6.15,15:5.25,16:4.9,17:4.3,18:3.9,19:3.6}\n",
    "        #金利\n",
    "        Interestratedata={-26:10,-25:7,-24:5,-23:7,-22:8.5,-21:12,-20:15,-19:15,-18:14,-17:9,-16:10,-15:8.5,\n",
    "                              -14:7,-13:6.5,-12:8,-11:9,-10:7,-9:5.5,-8:3.5,-7:3,-6:4,-5:6,-4:5.5,-3:5.7,-2:5.3,\n",
    "                              -1:5,0:6.1,1:4.3,2:1.8,3:1.1,4:1.8,5:3.5,6:5.2,7:5,8:2,9:0.25,10:0.25,11:0.25,12:0.25,13:0.25,\n",
    "                              14:0.25,15:0.25,16:0.5,17:1,18:2,19:2.2}\n",
    "        #インフレ率\n",
    "        Inflationratedata={-26:11,-25:9,-24:5,-23:7,-22:8,-21:12,-20:13.5,-19:10.38,-18:6.16,-17:3.16,-16:4.37,-15:3.16,\n",
    "                           -14:1.94,-13:3.58,-12:4.1,-11:4.79,-10:5.42,-9:4.22,-8:3.04,-7:2.97,-6:2.6,-5:2.81,-4:2.94,-3:2.34,\n",
    "                           -2:1.55,-1:2.19,0:3.37,1:2.82,2:1.6,3:2.3,4:2.67,5:3.37,6:3.22,7:2.87,8:3.82,9:-0.32,10:1.64,11:3.14,12:2.07,\n",
    "                           13:1.47,14:1.62,15:0.12,16:1.27,17:2.13,18:2.44,19:1.81}\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [EconomyGrowthdata,Bankraptcydata,Unemploymentratedata,Interestratedata,Inflationratedata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = sum(k.values()) / len(k)\n",
    "        \n",
    "        df['EconomyGrowth_By_Year'] = df['DisbursementYear'].map(EconomyGrowthdata)\n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "        df['Unemploymentrate_By_Year'] = df['DisbursementYear'].map(Unemploymentratedata)\n",
    "        df['Interestrate_By_Year'] = df['DisbursementYear'].map(Interestratedata)\n",
    "        df['Inflationrate_By_Year'] = df['DisbursementYear'].map(Inflationratedata)\n",
    "        \n",
    "        #State関係の特徴量作成\n",
    "        StateList = ['AL','AK','AZ','AR','CA','CO','CT','DE','DC','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA',\n",
    "                      'MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX',\n",
    "                      'UT','VT','VA','WA','WV','WI','WY']\n",
    "        \n",
    "        UnemploymentList = [2.6,3.7,4.0,3.4,4.1,2.8,4.0,4.6,4.2,2.7,3.1,3.7,2.8,4.6,3.1,3.0,2.9,3.9,3.5,3.1,3.0,3.7,4.3,2.9,4.0,\n",
    "                          2.7,2.6,2.7,5.5,2.9,3.3,3.5,4.1,3.8,2.1,4.1,3.2,4.8,4.3,3.2,3.3,2.2,3.5,3.8,2.4,3.0,3.1\n",
    "                            ,4.5,4.1,3.0,3.9]\n",
    "        \n",
    "        GDPList = [29603,44807,33655,27781,42376,40805,51911,56496,126421,33417,35265,38850,29843,39568,32724,35814,34770,30364,35181,\n",
    "                   30282,39596,47351,32846,41353,24477,32590,28201,37075,40210,37375,45052,30943,49038,37053,34694,34040,29470,\n",
    "                   38339,35153,36543,28894,35596,33742,37793,32774,34197,41617,40361,24929,34890,40303]\n",
    "        \n",
    "        GDPperPersonList = [37282,71008,48148,35674,53525,54943,63504,76720,164002,45958,48434,50788,39529,49083,40529,44091,43633,\n",
    "                       38148,48366,37734,50729,55364,38433,51829,31127,41012,37966,46803,63662,46400,55320,41878,58126,49625,43172,\n",
    "                       41073,40376,46248,43246,44738,38093,44955,42865,54766,47313,40312,54102,52810,31914,43309,63822]\n",
    "        \n",
    "        AveSalaryList = [40.46,50.81,45.40,37.79,56.10,49.79,60.14,49.66,79.85,43.66,46.17,44.09,36.45,51.71,40.97,38.39,40.96,\n",
    "                        39.54,43.15,39.06,54.28,58.62,45.19,46.99,35.95,42.58,35.81,39.87,44.38,46.38,56.72,40.91,61.04,43.11,41.12,\n",
    "                        43.45,40.75,43.46,46.10,46.38,39.63,35.00,41.88,48.35,41.11,39.54,52.07,51.04,38.48,41.46,44.03]\n",
    "        \n",
    "        Unemploymentdict = dict(zip(StateList,UnemploymentList))\n",
    "        GDPdict = dict(zip(StateList,GDPList))\n",
    "        GDPperPersondict = dict(zip(StateList,GDPperPersonList))\n",
    "        AveSalarydict = dict(zip(StateList,AveSalaryList))\n",
    "        \n",
    "        df['Unemployment_By_State'] = df['State'].map(Unemploymentdict)\n",
    "        df['GDP_By_State'] = df['State'].map(GDPdict)\n",
    "        df['GDPperPerson_By_State'] = df['State'].map(GDPperPersondict)\n",
    "        df['AveSalary_By_State'] = df['State'].map(AveSalarydict)\n",
    "        \n",
    "        #現状グループ分けされない特徴量の作成\n",
    "        #企業の安定さ、デカさ\n",
    "        df['BCI'] = df['CompanyLong']*(df['NoEmp'])*(df['NewExist']+1)\n",
    "        df['BCI'] = df['BCI'].fillna(df['BCI'].mean)\n",
    "        #一か月あたりの返済必要量\n",
    "        df['DisbursementGrossPerMonth'] = df['DisbursementGross']/(df['Term']+1)\n",
    "        #SBA承認より減らした額\n",
    "        df['SBA_Appv-DisbursementGross'] = df['SBA_Appv']-df['DisbursementGross']\n",
    "        #本来の従業員一人当たりの返済必要量\n",
    "        df['DisbursementGrossPerNoEmp'] = df['DisbursementGross']/(df['NoEmp']+1)\n",
    "        #雇用創出後の従業員一人当たりの返済必要量\n",
    "        df['DisbursementGrossPerEmp'] = df['DisbursementGross']/(df['NoEmp']+df['CreateJob']+1)\n",
    "        #しんどさ指数\n",
    "        df['TI'] = (df['DisbursementGross']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "        #しんどさ指数2\n",
    "        df['TI2'] = (df['SBA_Appv']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df\n",
    "\n",
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)\n",
    "\n",
    "#ラベルエンコーディング\n",
    "for col in categorical_features :\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "categorical_features_unlabelable = ['City','ApprovalDate','BankState','DisbursementDate']\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    le = LabelEncoder()   \n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else len(le.classes_))\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "    \n",
    "#OneHotEncoding\n",
    "train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "OneHotList = ['RevLineCr', 'LowDoc']\n",
    "ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "train_df2 = ohe.fit_transform(train_df2)\n",
    "test_df = ohe.transform(test_df)\n",
    "train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "\n",
    "#featuresの作成\n",
    "categorical_features = ['State', 'Sector','RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0',\n",
    "                       'LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0','UrbanRural']\n",
    "\n",
    "\n",
    "RemoveList=['MIS_Status','City','ApprovalDate','BankState','DisbursementDate','ApprovalDay','ApprovalMonth','ApprovalFY','ApprovalYear',\n",
    "           'DisbursementDay','DisbursementMonth']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "OneHotedList = ['RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0','LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0']\n",
    "\n",
    "scalelist = features\n",
    "for i in OneHotedList:\n",
    "    scalelist.remove(i)\n",
    "    \n",
    "stdscl = StandardScaler()\n",
    "train_df[scalelist] = stdscl.fit_transform(train_df[scalelist])\n",
    "test_df[scalelist] = stdscl.fit_transform(test_df[scalelist])\n",
    "\n",
    "RemoveList=['MIS_Status','City','ApprovalDate','BankState','DisbursementDate','ApprovalDay','ApprovalMonth','ApprovalFY','ApprovalYear',\n",
    "           'DisbursementDay','DisbursementMonth']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "\n",
    "    \n",
    "print(train_df)\n",
    "train_df.info()\n",
    "print(features)\n",
    "\n",
    "train_df_nn = train_df\n",
    "test_df_nn = test_df\n",
    "features_nn = features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "quaQcTgQOjyJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# AdaBoost training\n",
    "def adaboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = AdaBoostClassifier(**CFG.classification_adaboost_params)\n",
    "    model.fit(x_train, y_train)\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(Dropout(0.1))  # Dropout層を追加\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.1))  \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# モデルの学習と評価\n",
    "def nn_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = build_model(x_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=[MacroF1ScoreCallback(validation_data=(x_valid, y_valid)), early_stopping])\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    valid_pred = valid_pred.flatten()  # 1 次元の配列に変換する\n",
    "    return  model, valid_pred\n",
    "\n",
    "#lightgbmでの学習メソッドの定義\n",
    "def lightgbm_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    lgb_train = lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
    "    lgb_valid = lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
    "    model = lgb.train(\n",
    "                params = CFG.classification_lgb_params,\n",
    "                train_set = lgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                valid_sets = [lgb_train, lgb_valid],\n",
    "                feval = lgb_metric,\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=CFG.early_stopping_round,\n",
    "                                              verbose=CFG.verbose)]\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    return model, valid_pred\n",
    "\n",
    "#xgboostでの学習メソッドの定義\n",
    "def xgboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    xgb_train = xgb.DMatrix(data=x_train, label=y_train)\n",
    "    xgb_valid = xgb.DMatrix(data=x_valid, label=y_valid)\n",
    "    model = xgb.train(\n",
    "                CFG.classification_xgb_params,\n",
    "                dtrain = xgb_train,\n",
    "                num_boost_round = CFG.num_boost_round,\n",
    "                evals = [(xgb_train, 'train'), (xgb_valid, 'eval')],\n",
    "                early_stopping_rounds = CFG.early_stopping_round,\n",
    "                verbose_eval = CFG.verbose,\n",
    "                feval = xgb_metric,\n",
    "                maximize = CFG.metric_maximize_flag,\n",
    "            )\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict(xgb.DMatrix(x_valid))\n",
    "    return model, valid_pred\n",
    "\n",
    "#catboostでの学習メソッドの定義\n",
    "def catboost_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    cat_train = Pool(data=x_train, label=y_train, cat_features=categorical_features)\n",
    "    cat_valid = Pool(data=x_valid, label=y_valid, cat_features=categorical_features)\n",
    "    model = CatBoostClassifier(**CFG.classification_cat_params)\n",
    "    model.fit(cat_train,\n",
    "              eval_set = [cat_valid],\n",
    "              early_stopping_rounds = CFG.early_stopping_round,\n",
    "              verbose = CFG.verbose,\n",
    "              use_best_model = True)\n",
    "    # Predict validation\n",
    "    valid_pred = model.predict_proba(x_valid)[:, 1]\n",
    "    return model, valid_pred\n",
    "#任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    kfold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df)):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "\n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        \n",
    "        model = None  # モデル変数を初期化する\n",
    "        valid_pred = None\n",
    "        \n",
    "        if method == 'adaboost':\n",
    "            model, valid_pred = adaboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        if method == 'neuralnetwork':\n",
    "            model, valid_pred = nn_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            model.save(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.h5')\n",
    "        if method == 'lightgbm':\n",
    "            model, valid_pred = lightgbm_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        if method == 'xgboost':\n",
    "            model, valid_pred = xgboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        if method == 'catboost':\n",
    "            model, valid_pred = catboost_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "    \n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "    print(f'{method} our out of folds CV f1score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "#学習メソッドの定義\n",
    "def Learning():\n",
    "    gradient_boosting_model_cv_training('neuralnetwork', train_df_nn, features_nn, categorical_features_lgb)\n",
    "    gradient_boosting_model_cv_training('adaboost', train_df_ctb, features_ctb, categorical_features_ctb)\n",
    "    gradient_boosting_model_cv_training('lightgbm', train_df_ctb, features_ctb, categorical_features_ctb)\n",
    "    gradient_boosting_model_cv_training('xgboost',train_df_ctb, features_ctb, categorical_features_ctb)\n",
    "    gradient_boosting_model_cv_training('catboost',train_df_ctb, features_ctb, categorical_features_ctb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb入力をctb入力に変えた"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWzQv798OiQ-",
    "outputId": "57cabf2c-5c42-4084-e263-e00eaeb695ec",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "neuralnetwork training fold 1\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.3150 -\n",
      "Epoch 1: val_macro_f1: 0.593023186847424\n",
      "1134/1134 [==============================] - 8s 6ms/step - loss: 0.3151 - accuracy: 0.8922 - val_loss: 0.2873 - val_accuracy: 0.9042\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2938 -\n",
      "Epoch 2: val_macro_f1: 0.6110033575448729\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2943 - accuracy: 0.9012 - val_loss: 0.2851 - val_accuracy: 0.9062\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2914 - a\n",
      "Epoch 3: val_macro_f1: 0.6144611652666098\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2915 - accuracy: 0.9024 - val_loss: 0.2820 - val_accuracy: 0.9060\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2884 - a\n",
      "Epoch 4: val_macro_f1: 0.6107340428884842\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2886 - accuracy: 0.9031 - val_loss: 0.2817 - val_accuracy: 0.9067\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2862 - acc\n",
      "Epoch 5: val_macro_f1: 0.6160480962617038\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2861 - accuracy: 0.9040 - val_loss: 0.2823 - val_accuracy: 0.9052\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2868 - a\n",
      "Epoch 6: val_macro_f1: 0.6034062905554178\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2859 - accuracy: 0.9044 - val_loss: 0.2830 - val_accuracy: 0.9047\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2846 - a\n",
      "Epoch 7: val_macro_f1: 0.6153758519839723\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2847 - accuracy: 0.9038 - val_loss: 0.2828 - val_accuracy: 0.9054\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2823 - \n",
      "Epoch 8: val_macro_f1: 0.6173763310163204\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2823 - accuracy: 0.9045 - val_loss: 0.2842 - val_accuracy: 0.9049\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2817 - acc\n",
      "Epoch 9: val_macro_f1: 0.6178393268441893\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2816 - accuracy: 0.9042 - val_loss: 0.2850 - val_accuracy: 0.9059\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2802 - a\n",
      "Epoch 10: val_macro_f1: 0.6283143555452275\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2804 - accuracy: 0.9045 - val_loss: 0.2848 - val_accuracy: 0.9065\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2799 - a\n",
      "Epoch 11: val_macro_f1: 0.6173972458212548\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2802 - accuracy: 0.9046 - val_loss: 0.2833 - val_accuracy: 0.9062\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2779\n",
      "Epoch 12: val_macro_f1: 0.6112246822999416\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2779 - accuracy: 0.9051 - val_loss: 0.2862 - val_accuracy: 0.9064\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2779 - a\n",
      "Epoch 13: val_macro_f1: 0.61672069166235\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2778 - accuracy: 0.9055 - val_loss: 0.2844 - val_accuracy: 0.9057\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2764 -\n",
      "Epoch 14: val_macro_f1: 0.6268779634049324\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2770 - accuracy: 0.9056 - val_loss: 0.2848 - val_accuracy: 0.9037\n",
      "189/189 [==============================] - 1s 3ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 2\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.3088 - a\n",
      "Epoch 1: val_macro_f1: 0.599874356818185\n",
      "1134/1134 [==============================] - 7s 5ms/step - loss: 0.3088 - accuracy: 0.8963 - val_loss: 0.2997 - val_accuracy: 0.8989\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2914 - a\n",
      "Epoch 2: val_macro_f1: 0.6246088766534613\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2915 - accuracy: 0.9020 - val_loss: 0.2940 - val_accuracy: 0.9021\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2891 -\n",
      "Epoch 3: val_macro_f1: 0.6151220328312059\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2888 - accuracy: 0.9034 - val_loss: 0.2959 - val_accuracy: 0.9006\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2873 \n",
      "Epoch 4: val_macro_f1: 0.6321453821137213\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2874 - accuracy: 0.9034 - val_loss: 0.2930 - val_accuracy: 0.9017\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2859 - \n",
      "Epoch 5: val_macro_f1: 0.6165950961102372\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2852 - accuracy: 0.9039 - val_loss: 0.2966 - val_accuracy: 0.9004\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2838 - a\n",
      "Epoch 6: val_macro_f1: 0.6266223931134232\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2841 - accuracy: 0.9039 - val_loss: 0.2915 - val_accuracy: 0.9006\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2830 - a\n",
      "Epoch 7: val_macro_f1: 0.639959710575247\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2829 - accuracy: 0.9043 - val_loss: 0.2915 - val_accuracy: 0.9024\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2815 -\n",
      "Epoch 8: val_macro_f1: 0.6067319196844225\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2815 - accuracy: 0.9048 - val_loss: 0.2942 - val_accuracy: 0.8994\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2799 - a\n",
      "Epoch 9: val_macro_f1: 0.6346225175877029\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2798 - accuracy: 0.9053 - val_loss: 0.2941 - val_accuracy: 0.9024\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2801 - a\n",
      "Epoch 10: val_macro_f1: 0.6272738798272648\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2800 - accuracy: 0.9051 - val_loss: 0.2953 - val_accuracy: 0.9022\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2790 -\n",
      "Epoch 11: val_macro_f1: 0.6186620136148564\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2790 - accuracy: 0.9046 - val_loss: 0.2930 - val_accuracy: 0.9001\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2779 - a\n",
      "Epoch 12: val_macro_f1: 0.6170293116623572\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2776 - accuracy: 0.9053 - val_loss: 0.2915 - val_accuracy: 0.9007\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2765 \n",
      "Epoch 13: val_macro_f1: 0.6336718787297594\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2768 - accuracy: 0.9056 - val_loss: 0.2925 - val_accuracy: 0.9034\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2760 - a\n",
      "Epoch 14: val_macro_f1: 0.6319163333250427\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2760 - accuracy: 0.9060 - val_loss: 0.2944 - val_accuracy: 0.9016\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2759 - a\n",
      "Epoch 15: val_macro_f1: 0.6307031424760359\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2761 - accuracy: 0.9055 - val_loss: 0.2924 - val_accuracy: 0.9024\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2749 - \n",
      "Epoch 16: val_macro_f1: 0.6282045652577322\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2746 - accuracy: 0.9063 - val_loss: 0.2943 - val_accuracy: 0.9006\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 3\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 2ms/step loss: 0.3111 - a\n",
      "Epoch 1: val_macro_f1: 0.6096453490790549\n",
      "1134/1134 [==============================] - 8s 6ms/step - loss: 0.3111 - accuracy: 0.8939 - val_loss: 0.2933 - val_accuracy: 0.9024\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2924 - acc\n",
      "Epoch 2: val_macro_f1: 0.6325124713861369\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2927 - accuracy: 0.9017 - val_loss: 0.2907 - val_accuracy: 0.9025\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2902 - a\n",
      "Epoch 3: val_macro_f1: 0.6253378198471656\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2904 - accuracy: 0.9030 - val_loss: 0.2906 - val_accuracy: 0.9014\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2875 - a\n",
      "Epoch 4: val_macro_f1: 0.6267390830165919\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2880 - accuracy: 0.9042 - val_loss: 0.2890 - val_accuracy: 0.9042\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2856 - \n",
      "Epoch 5: val_macro_f1: 0.6240875761595972\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2855 - accuracy: 0.9047 - val_loss: 0.2894 - val_accuracy: 0.9029\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2842 - a\n",
      "Epoch 6: val_macro_f1: 0.6304873171906242\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2842 - accuracy: 0.9046 - val_loss: 0.2878 - val_accuracy: 0.9034\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2837 - acc\n",
      "Epoch 7: val_macro_f1: 0.63571055749331\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2837 - accuracy: 0.9038 - val_loss: 0.2865 - val_accuracy: 0.9037\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2822 - acc\n",
      "Epoch 8: val_macro_f1: 0.6339926827141005\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2818 - accuracy: 0.9049 - val_loss: 0.2879 - val_accuracy: 0.9030\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2816 - a\n",
      "Epoch 9: val_macro_f1: 0.6276013244827002\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2814 - accuracy: 0.9056 - val_loss: 0.2871 - val_accuracy: 0.9030\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2803 - a\n",
      "Epoch 10: val_macro_f1: 0.6101085361330172\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2803 - accuracy: 0.9063 - val_loss: 0.2874 - val_accuracy: 0.9021\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2795 - a\n",
      "Epoch 11: val_macro_f1: 0.6202452004474295\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2798 - accuracy: 0.9057 - val_loss: 0.2869 - val_accuracy: 0.9019\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2791 - a\n",
      "Epoch 12: val_macro_f1: 0.6304739476666039\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2790 - accuracy: 0.9060 - val_loss: 0.2883 - val_accuracy: 0.9022\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2778 - a\n",
      "Epoch 13: val_macro_f1: 0.6232563211957158\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2777 - accuracy: 0.9063 - val_loss: 0.2883 - val_accuracy: 0.9029\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2755 - \n",
      "Epoch 14: val_macro_f1: 0.6183415346043745\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2758 - accuracy: 0.9066 - val_loss: 0.2888 - val_accuracy: 0.9017\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2757 - a\n",
      "Epoch 15: val_macro_f1: 0.6133837362095341\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2760 - accuracy: 0.9066 - val_loss: 0.2872 - val_accuracy: 0.9039\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2747 -\n",
      "Epoch 16: val_macro_f1: 0.6191847255369929\n",
      "1134/1134 [==============================] - 6s 6ms/step - loss: 0.2745 - accuracy: 0.9076 - val_loss: 0.2886 - val_accuracy: 0.9017\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2735 - \n",
      "Epoch 17: val_macro_f1: 0.5872915682182532\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2734 - accuracy: 0.9070 - val_loss: 0.2896 - val_accuracy: 0.9002\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 4\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.3138 - a\n",
      "Epoch 1: val_macro_f1: 0.6262237379317814\n",
      "1134/1134 [==============================] - 7s 5ms/step - loss: 0.3138 - accuracy: 0.8915 - val_loss: 0.2888 - val_accuracy: 0.9068\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2942 - a\n",
      "Epoch 2: val_macro_f1: 0.6227955210124891\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2942 - accuracy: 0.9017 - val_loss: 0.2833 - val_accuracy: 0.9075\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2902 - a\n",
      "Epoch 3: val_macro_f1: 0.6295922020524812\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2902 - accuracy: 0.9026 - val_loss: 0.2808 - val_accuracy: 0.9080\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2893 - \n",
      "Epoch 4: val_macro_f1: 0.6468639899619583\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2893 - accuracy: 0.9031 - val_loss: 0.2829 - val_accuracy: 0.9092\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2879 - a\n",
      "Epoch 5: val_macro_f1: 0.6332222312975779\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2875 - accuracy: 0.9033 - val_loss: 0.2811 - val_accuracy: 0.9082\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2856 - a\n",
      "Epoch 6: val_macro_f1: 0.6369689637123415\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2857 - accuracy: 0.9034 - val_loss: 0.2824 - val_accuracy: 0.9073\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2848 - a\n",
      "Epoch 7: val_macro_f1: 0.63047115532578\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2847 - accuracy: 0.9027 - val_loss: 0.2822 - val_accuracy: 0.9068\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2840 - acc\n",
      "Epoch 8: val_macro_f1: 0.6319005096085601\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2840 - accuracy: 0.9037 - val_loss: 0.2815 - val_accuracy: 0.9078\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2827 - a\n",
      "Epoch 9: val_macro_f1: 0.6386748966806904\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2829 - accuracy: 0.9049 - val_loss: 0.2821 - val_accuracy: 0.9085\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2817 - a\n",
      "Epoch 10: val_macro_f1: 0.6287847969388786\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2818 - accuracy: 0.9045 - val_loss: 0.2825 - val_accuracy: 0.9068\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2806 - \n",
      "Epoch 11: val_macro_f1: 0.6224698382060094\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2809 - accuracy: 0.9052 - val_loss: 0.2834 - val_accuracy: 0.9060\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2792 - a\n",
      "Epoch 12: val_macro_f1: 0.6376122323523554\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2795 - accuracy: 0.9051 - val_loss: 0.2834 - val_accuracy: 0.9083\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2790 - a\n",
      "Epoch 13: val_macro_f1: 0.6291584418455874\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2790 - accuracy: 0.9052 - val_loss: 0.2834 - val_accuracy: 0.9065\n",
      "189/189 [==============================] - 1s 2ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 5\n",
      "Epoch 1/100\n",
      "   1/1134 [..............................] - ETA: 27:01 - loss: 0.6835 - accuracy: 0.6250WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0032s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 2ms/step loss: 0.3104 - a\n",
      "Epoch 1: val_macro_f1: 0.609083354483935\n",
      "1134/1134 [==============================] - 8s 6ms/step - loss: 0.3105 - accuracy: 0.8956 - val_loss: 0.2899 - val_accuracy: 0.9040\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2934 - a\n",
      "Epoch 2: val_macro_f1: 0.6037177744583229\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2937 - accuracy: 0.9018 - val_loss: 0.2870 - val_accuracy: 0.9042\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2902 \n",
      "Epoch 3: val_macro_f1: 0.6223671907372494\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2899 - accuracy: 0.9027 - val_loss: 0.2876 - val_accuracy: 0.9047\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2878 - a\n",
      "Epoch 4: val_macro_f1: 0.6055975218799361\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2878 - accuracy: 0.9037 - val_loss: 0.2860 - val_accuracy: 0.9042\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2863 \n",
      "Epoch 5: val_macro_f1: 0.610905030512508\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2864 - accuracy: 0.9030 - val_loss: 0.2854 - val_accuracy: 0.9040\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2860 \n",
      "Epoch 6: val_macro_f1: 0.6099964932704615\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2857 - accuracy: 0.9046 - val_loss: 0.2849 - val_accuracy: 0.9040\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2845 - a\n",
      "Epoch 7: val_macro_f1: 0.6189329848453584\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2847 - accuracy: 0.9040 - val_loss: 0.2831 - val_accuracy: 0.9054\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2835 - \n",
      "Epoch 8: val_macro_f1: 0.6129457179648821\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2835 - accuracy: 0.9048 - val_loss: 0.2860 - val_accuracy: 0.9035\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2830 - a\n",
      "Epoch 9: val_macro_f1: 0.6227070301438979\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2828 - accuracy: 0.9049 - val_loss: 0.2846 - val_accuracy: 0.9037\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2815 - a\n",
      "Epoch 10: val_macro_f1: 0.6111555525882946\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2813 - accuracy: 0.9049 - val_loss: 0.2859 - val_accuracy: 0.9035\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2795 - a\n",
      "Epoch 11: val_macro_f1: 0.595100891738022\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2797 - accuracy: 0.9054 - val_loss: 0.2864 - val_accuracy: 0.9019\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2786 - \n",
      "Epoch 12: val_macro_f1: 0.6032722948785728\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2788 - accuracy: 0.9058 - val_loss: 0.2858 - val_accuracy: 0.9024\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2789 - \n",
      "Epoch 13: val_macro_f1: 0.6188803768491072\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2793 - accuracy: 0.9056 - val_loss: 0.2877 - val_accuracy: 0.9040\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2775 - a\n",
      "Epoch 14: val_macro_f1: 0.6184335156407625\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2774 - accuracy: 0.9059 - val_loss: 0.2855 - val_accuracy: 0.9037\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2767 - \n",
      "Epoch 15: val_macro_f1: 0.6035685436617005\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2764 - accuracy: 0.9061 - val_loss: 0.2883 - val_accuracy: 0.9019\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2763 - a\n",
      "Epoch 16: val_macro_f1: 0.6142809252069662\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2758 - accuracy: 0.9062 - val_loss: 0.2870 - val_accuracy: 0.9019\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2744 - a\n",
      "Epoch 17: val_macro_f1: 0.6027609666065756\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2744 - accuracy: 0.9061 - val_loss: 0.2881 - val_accuracy: 0.9027\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 6\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.3107 - acc\n",
      "Epoch 1: val_macro_f1: 0.6123282983218676\n",
      "1134/1134 [==============================] - 8s 5ms/step - loss: 0.3108 - accuracy: 0.8931 - val_loss: 0.3015 - val_accuracy: 0.8964\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2925 - \n",
      "Epoch 2: val_macro_f1: 0.6187862818623593\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2919 - accuracy: 0.9019 - val_loss: 0.3036 - val_accuracy: 0.8989\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2881 -\n",
      "Epoch 3: val_macro_f1: 0.6290962145334766\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2885 - accuracy: 0.9036 - val_loss: 0.2960 - val_accuracy: 0.9001\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2854 - a\n",
      "Epoch 4: val_macro_f1: 0.6528625972589222\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2858 - accuracy: 0.9036 - val_loss: 0.2957 - val_accuracy: 0.9014\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2850 -\n",
      "Epoch 5: val_macro_f1: 0.6311903944211876\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2851 - accuracy: 0.9040 - val_loss: 0.2961 - val_accuracy: 0.8999\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2832 \n",
      "Epoch 6: val_macro_f1: 0.6461048734804602\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2832 - accuracy: 0.9050 - val_loss: 0.2956 - val_accuracy: 0.9016\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2827 - \n",
      "Epoch 7: val_macro_f1: 0.6364795354089523\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2827 - accuracy: 0.9047 - val_loss: 0.3006 - val_accuracy: 0.8999\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2814\n",
      "Epoch 8: val_macro_f1: 0.6509531777371949\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2817 - accuracy: 0.9048 - val_loss: 0.2953 - val_accuracy: 0.9001\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2803 - a\n",
      "Epoch 9: val_macro_f1: 0.6338497596631312\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2804 - accuracy: 0.9061 - val_loss: 0.2980 - val_accuracy: 0.8991\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2796 -\n",
      "Epoch 10: val_macro_f1: 0.6123378144716349\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2795 - accuracy: 0.9061 - val_loss: 0.2987 - val_accuracy: 0.8971\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2788 - a\n",
      "Epoch 11: val_macro_f1: 0.6395340208092198\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2790 - accuracy: 0.9051 - val_loss: 0.2974 - val_accuracy: 0.8984\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2773 \n",
      "Epoch 12: val_macro_f1: 0.6333982571657715\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2772 - accuracy: 0.9053 - val_loss: 0.2982 - val_accuracy: 0.8987\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2760 -\n",
      "Epoch 13: val_macro_f1: 0.6202175466519007\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2760 - accuracy: 0.9061 - val_loss: 0.3000 - val_accuracy: 0.8969\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2763 - a\n",
      "Epoch 14: val_macro_f1: 0.6313653735100798\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2762 - accuracy: 0.9068 - val_loss: 0.2989 - val_accuracy: 0.8989\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 1s 3ms/step loss: 0.2743 -\n",
      "Epoch 15: val_macro_f1: 0.642113264740894\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2743 - accuracy: 0.9068 - val_loss: 0.2993 - val_accuracy: 0.8992\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2740 -\n",
      "Epoch 16: val_macro_f1: 0.631896917188629\n",
      "1134/1134 [==============================] - 6s 6ms/step - loss: 0.2739 - accuracy: 0.9069 - val_loss: 0.2975 - val_accuracy: 0.8987\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2731 - a\n",
      "Epoch 17: val_macro_f1: 0.6353395178953499\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2731 - accuracy: 0.9070 - val_loss: 0.2994 - val_accuracy: 0.8991\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2735 -\n",
      "Epoch 18: val_macro_f1: 0.6363070821289023\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2733 - accuracy: 0.9068 - val_loss: 0.2993 - val_accuracy: 0.8992\n",
      "189/189 [==============================] - 1s 3ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 7\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.3088 - a\n",
      "Epoch 1: val_macro_f1: 0.6015866797193762\n",
      "1134/1134 [==============================] - 8s 6ms/step - loss: 0.3087 - accuracy: 0.8960 - val_loss: 0.2920 - val_accuracy: 0.8996\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2917 - a\n",
      "Epoch 2: val_macro_f1: 0.6185202671659065\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2918 - accuracy: 0.9030 - val_loss: 0.2885 - val_accuracy: 0.9012\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2893 - a\n",
      "Epoch 3: val_macro_f1: 0.6280790971360716\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2894 - accuracy: 0.9037 - val_loss: 0.2930 - val_accuracy: 0.8987\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2869 - a\n",
      "Epoch 4: val_macro_f1: 0.6237728369639859\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2869 - accuracy: 0.9040 - val_loss: 0.2890 - val_accuracy: 0.9002\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2856 - a\n",
      "Epoch 5: val_macro_f1: 0.6262934613208633\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2855 - accuracy: 0.9045 - val_loss: 0.2882 - val_accuracy: 0.8997\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2848 - a\n",
      "Epoch 6: val_macro_f1: 0.6199199529262693\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2850 - accuracy: 0.9040 - val_loss: 0.2886 - val_accuracy: 0.9004\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2835 - a\n",
      "Epoch 7: val_macro_f1: 0.6192644523486319\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2835 - accuracy: 0.9047 - val_loss: 0.2874 - val_accuracy: 0.8999\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2823 - a\n",
      "Epoch 8: val_macro_f1: 0.6237403257994906\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2824 - accuracy: 0.9048 - val_loss: 0.2896 - val_accuracy: 0.8984\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2807 -\n",
      "Epoch 9: val_macro_f1: 0.5991624910833899\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2806 - accuracy: 0.9058 - val_loss: 0.2879 - val_accuracy: 0.8991\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2798 - a\n",
      "Epoch 10: val_macro_f1: 0.6194825590317394\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2797 - accuracy: 0.9052 - val_loss: 0.2929 - val_accuracy: 0.9000\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2783 - \n",
      "Epoch 11: val_macro_f1: 0.6131901281702579\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2786 - accuracy: 0.9057 - val_loss: 0.2887 - val_accuracy: 0.8991\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2779 - a\n",
      "Epoch 12: val_macro_f1: 0.6175734961971799\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2778 - accuracy: 0.9064 - val_loss: 0.2904 - val_accuracy: 0.8992\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 1s 3ms/step loss: 0.2766 - a\n",
      "Epoch 13: val_macro_f1: 0.6044056230264562\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2767 - accuracy: 0.9055 - val_loss: 0.2891 - val_accuracy: 0.8982\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 1s 2ms/step loss: 0.2771 \n",
      "Epoch 14: val_macro_f1: 0.6071437766638088\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2771 - accuracy: 0.9069 - val_loss: 0.2902 - val_accuracy: 0.8997\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2751 - a\n",
      "Epoch 15: val_macro_f1: 0.6106264752791069\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2751 - accuracy: 0.9069 - val_loss: 0.2888 - val_accuracy: 0.8997\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2745 - acc\n",
      "Epoch 16: val_macro_f1: 0.6240886202447689\n",
      "1134/1134 [==============================] - 5s 5ms/step - loss: 0.2752 - accuracy: 0.9070 - val_loss: 0.2951 - val_accuracy: 0.8981\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2741 \n",
      "Epoch 17: val_macro_f1: 0.6193121683970788\n",
      "1134/1134 [==============================] - 6s 5ms/step - loss: 0.2742 - accuracy: 0.9068 - val_loss: 0.2914 - val_accuracy: 0.9005\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "neuralnetwork our out of folds CV f1score is 0.6280729108349614\n",
      "--------------------------------------------------\n",
      "adaboost training fold 1\n",
      "--------------------------------------------------\n",
      "adaboost training fold 2\n",
      "--------------------------------------------------\n",
      "adaboost training fold 3\n",
      "--------------------------------------------------\n",
      "adaboost training fold 4\n",
      "--------------------------------------------------\n",
      "adaboost training fold 5\n",
      "--------------------------------------------------\n",
      "adaboost training fold 6\n",
      "--------------------------------------------------\n",
      "adaboost training fold 7\n",
      "adaboost our out of folds CV f1score is 0.596536850586954\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 1\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32336, number of negative: 3927\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013948 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 20987\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.891708 -> initscore=2.108305\n",
      "[LightGBM] [Info] Start training from score 2.108305\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's auc: 0.884909\ttraining's f1score: 0.471377\tvalid_1's auc: 0.749782\tvalid_1's f1score: 0.47329\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 2\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32389, number of negative: 3874\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014298 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21101\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.893169 -> initscore=2.123531\n",
      "[LightGBM] [Info] Start training from score 2.123531\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.905332\ttraining's f1score: 0.57013\tvalid_1's auc: 0.764999\tvalid_1's f1score: 0.529222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "lightgbm training fold 3\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32375, number of negative: 3888\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013070 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21060\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892783 -> initscore=2.119492\n",
      "[LightGBM] [Info] Start training from score 2.119492\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's auc: 0.888175\ttraining's f1score: 0.471677\tvalid_1's auc: 0.763122\tvalid_1's f1score: 0.471494\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 4\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32353, number of negative: 3910\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.014160 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21049\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892177 -> initscore=2.113169\n",
      "[LightGBM] [Info] Start training from score 2.113169\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's auc: 0.925408\ttraining's f1score: 0.66073\tvalid_1's auc: 0.778584\tvalid_1's f1score: 0.598437\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 5\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3900\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013585 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21089\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892452 -> initscore=2.116039\n",
      "[LightGBM] [Info] Start training from score 2.116039\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.936066\ttraining's f1score: 0.689108\tvalid_1's auc: 0.763471\tvalid_1's f1score: 0.609685\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 6\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32423, number of negative: 3840\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21041\n",
      "[LightGBM] [Info] Number of data points in the train set: 36263, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.894107 -> initscore=2.133396\n",
      "[LightGBM] [Info] Start training from score 2.133396\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's auc: 0.906696\ttraining's f1score: 0.540971\tvalid_1's auc: 0.777794\tvalid_1's f1score: 0.526387\n",
      "--------------------------------------------------\n",
      "lightgbm training fold 7\n",
      "[LightGBM] [Warning] Categorical features with more bins than the configured maximum bin number found.\n",
      "[LightGBM] [Warning] For categorical features, max_bin and max_bin_by_feature may be ignored with a large number of categories.\n",
      "[LightGBM] [Info] Number of positive: 32363, number of negative: 3901\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.013581 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 21065\n",
      "[LightGBM] [Info] Number of data points in the train set: 36264, number of used features: 27\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.892428 -> initscore=2.115783\n",
      "[LightGBM] [Info] Start training from score 2.115783\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's auc: 0.905258\ttraining's f1score: 0.584372\tvalid_1's auc: 0.774517\tvalid_1's f1score: 0.550349\n",
      "lightgbm our out of folds CV f1score is 0.5405767753725311\n",
      "--------------------------------------------------\n",
      "xgboost training fold 1\n",
      "[0]\ttrain-logloss:0.66010\ttrain-f1score:0.09771\teval-logloss:0.66005\teval-f1score:0.09208\n",
      "[25]\ttrain-logloss:0.33619\ttrain-f1score:0.66470\teval-logloss:0.33786\teval-f1score:0.63634\n",
      "[50]\ttrain-logloss:0.27890\ttrain-f1score:0.66805\teval-logloss:0.28804\teval-f1score:0.63602\n",
      "[75]\ttrain-logloss:0.26107\ttrain-f1score:0.67724\teval-logloss:0.27973\teval-f1score:0.63959\n",
      "[100]\ttrain-logloss:0.25112\ttrain-f1score:0.68746\teval-logloss:0.27817\teval-f1score:0.64624\n",
      "[125]\ttrain-logloss:0.24420\ttrain-f1score:0.69541\teval-logloss:0.27745\teval-f1score:0.64553\n",
      "[150]\ttrain-logloss:0.23903\ttrain-f1score:0.70222\teval-logloss:0.27725\teval-f1score:0.64458\n",
      "[175]\ttrain-logloss:0.23537\ttrain-f1score:0.70611\teval-logloss:0.27741\teval-f1score:0.64680\n",
      "[200]\ttrain-logloss:0.23251\ttrain-f1score:0.70858\teval-logloss:0.27756\teval-f1score:0.64923\n",
      "[209]\ttrain-logloss:0.23122\ttrain-f1score:0.70983\teval-logloss:0.27766\teval-f1score:0.64995\n",
      "--------------------------------------------------\n",
      "xgboost training fold 2\n",
      "[0]\ttrain-logloss:0.65993\ttrain-f1score:0.09652\teval-logloss:0.66039\teval-f1score:0.09925\n",
      "[25]\ttrain-logloss:0.33430\ttrain-f1score:0.66286\teval-logloss:0.34394\teval-f1score:0.65310\n",
      "[50]\ttrain-logloss:0.27752\ttrain-f1score:0.66676\teval-logloss:0.29559\teval-f1score:0.65471\n",
      "[75]\ttrain-logloss:0.25987\ttrain-f1score:0.67473\teval-logloss:0.28712\teval-f1score:0.65813\n",
      "[100]\ttrain-logloss:0.25020\ttrain-f1score:0.68243\teval-logloss:0.28461\teval-f1score:0.66308\n",
      "[125]\ttrain-logloss:0.24388\ttrain-f1score:0.69187\teval-logloss:0.28371\teval-f1score:0.66795\n",
      "[150]\ttrain-logloss:0.23863\ttrain-f1score:0.69880\teval-logloss:0.28326\teval-f1score:0.66581\n",
      "[175]\ttrain-logloss:0.23497\ttrain-f1score:0.70230\teval-logloss:0.28340\teval-f1score:0.66369\n",
      "[200]\ttrain-logloss:0.23238\ttrain-f1score:0.70492\teval-logloss:0.28342\teval-f1score:0.66369\n",
      "[225]\ttrain-logloss:0.22901\ttrain-f1score:0.70980\teval-logloss:0.28363\teval-f1score:0.65989\n",
      "[250]\ttrain-logloss:0.22622\ttrain-f1score:0.71379\teval-logloss:0.28405\teval-f1score:0.66030\n",
      "[275]\ttrain-logloss:0.22330\ttrain-f1score:0.71943\teval-logloss:0.28411\teval-f1score:0.66158\n",
      "[300]\ttrain-logloss:0.22042\ttrain-f1score:0.72469\teval-logloss:0.28438\teval-f1score:0.66030\n",
      "[325]\ttrain-logloss:0.21667\ttrain-f1score:0.73162\teval-logloss:0.28460\teval-f1score:0.66110\n",
      "--------------------------------------------------\n",
      "xgboost training fold 3\n",
      "[0]\ttrain-logloss:0.66003\ttrain-f1score:0.09683\teval-logloss:0.66040\teval-f1score:0.09737\n",
      "[25]\ttrain-logloss:0.33463\ttrain-f1score:0.66090\teval-logloss:0.34195\teval-f1score:0.65245\n",
      "[50]\ttrain-logloss:0.27807\ttrain-f1score:0.66295\teval-logloss:0.29324\teval-f1score:0.64706\n",
      "[75]\ttrain-logloss:0.26010\ttrain-f1score:0.67359\teval-logloss:0.28338\teval-f1score:0.65248\n",
      "[100]\ttrain-logloss:0.25024\ttrain-f1score:0.68453\teval-logloss:0.28116\teval-f1score:0.65851\n",
      "[125]\ttrain-logloss:0.24412\ttrain-f1score:0.69194\teval-logloss:0.28010\teval-f1score:0.65904\n",
      "[150]\ttrain-logloss:0.23914\ttrain-f1score:0.69598\teval-logloss:0.27953\teval-f1score:0.66185\n",
      "[175]\ttrain-logloss:0.23470\ttrain-f1score:0.70312\teval-logloss:0.27922\teval-f1score:0.66871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200]\ttrain-logloss:0.23038\ttrain-f1score:0.70859\teval-logloss:0.27888\teval-f1score:0.66934\n",
      "[225]\ttrain-logloss:0.22606\ttrain-f1score:0.71308\teval-logloss:0.27908\teval-f1score:0.66947\n",
      "[250]\ttrain-logloss:0.22159\ttrain-f1score:0.72172\teval-logloss:0.27941\teval-f1score:0.67120\n",
      "[275]\ttrain-logloss:0.21903\ttrain-f1score:0.72662\teval-logloss:0.27957\teval-f1score:0.67095\n",
      "[300]\ttrain-logloss:0.21661\ttrain-f1score:0.73045\teval-logloss:0.27976\teval-f1score:0.66983\n",
      "[325]\ttrain-logloss:0.21324\ttrain-f1score:0.73559\teval-logloss:0.28011\teval-f1score:0.66983\n",
      "[350]\ttrain-logloss:0.20979\ttrain-f1score:0.74221\teval-logloss:0.28048\teval-f1score:0.66983\n",
      "[375]\ttrain-logloss:0.20759\ttrain-f1score:0.74597\teval-logloss:0.28071\teval-f1score:0.66810\n",
      "[400]\ttrain-logloss:0.20498\ttrain-f1score:0.75125\teval-logloss:0.28116\teval-f1score:0.66785\n",
      "[425]\ttrain-logloss:0.20154\ttrain-f1score:0.75767\teval-logloss:0.28174\teval-f1score:0.66835\n",
      "[445]\ttrain-logloss:0.19936\ttrain-f1score:0.76163\teval-logloss:0.28188\teval-f1score:0.66872\n",
      "--------------------------------------------------\n",
      "xgboost training fold 4\n",
      "[0]\ttrain-logloss:0.66007\ttrain-f1score:0.09733\teval-logloss:0.65991\teval-f1score:0.09440\n",
      "[25]\ttrain-logloss:0.33592\ttrain-f1score:0.66162\teval-logloss:0.33774\teval-f1score:0.65144\n",
      "[50]\ttrain-logloss:0.27942\ttrain-f1score:0.66549\teval-logloss:0.28724\teval-f1score:0.64924\n",
      "[75]\ttrain-logloss:0.26130\ttrain-f1score:0.67522\teval-logloss:0.27791\teval-f1score:0.65363\n",
      "[100]\ttrain-logloss:0.25174\ttrain-f1score:0.68503\teval-logloss:0.27567\teval-f1score:0.65725\n",
      "[125]\ttrain-logloss:0.24489\ttrain-f1score:0.69214\teval-logloss:0.27504\teval-f1score:0.66172\n",
      "[150]\ttrain-logloss:0.24007\ttrain-f1score:0.69870\teval-logloss:0.27456\teval-f1score:0.66472\n",
      "[175]\ttrain-logloss:0.23521\ttrain-f1score:0.70457\teval-logloss:0.27470\teval-f1score:0.66607\n",
      "[200]\ttrain-logloss:0.23113\ttrain-f1score:0.70880\teval-logloss:0.27487\teval-f1score:0.66572\n",
      "[225]\ttrain-logloss:0.22709\ttrain-f1score:0.71601\teval-logloss:0.27495\teval-f1score:0.66926\n",
      "[250]\ttrain-logloss:0.22339\ttrain-f1score:0.72016\teval-logloss:0.27529\teval-f1score:0.66731\n",
      "[275]\ttrain-logloss:0.22016\ttrain-f1score:0.72464\teval-logloss:0.27526\teval-f1score:0.66731\n",
      "[300]\ttrain-logloss:0.21665\ttrain-f1score:0.72887\teval-logloss:0.27564\teval-f1score:0.67020\n",
      "[325]\ttrain-logloss:0.21318\ttrain-f1score:0.73453\teval-logloss:0.27571\teval-f1score:0.66968\n",
      "[350]\ttrain-logloss:0.21030\ttrain-f1score:0.73940\teval-logloss:0.27604\teval-f1score:0.66903\n",
      "[375]\ttrain-logloss:0.20764\ttrain-f1score:0.74495\teval-logloss:0.27639\teval-f1score:0.66917\n",
      "[400]\ttrain-logloss:0.20458\ttrain-f1score:0.74922\teval-logloss:0.27688\teval-f1score:0.66866\n",
      "[425]\ttrain-logloss:0.20108\ttrain-f1score:0.75694\teval-logloss:0.27726\teval-f1score:0.66633\n",
      "[450]\ttrain-logloss:0.19836\ttrain-f1score:0.76228\teval-logloss:0.27776\teval-f1score:0.66558\n",
      "[475]\ttrain-logloss:0.19510\ttrain-f1score:0.76758\teval-logloss:0.27811\teval-f1score:0.66583\n",
      "[499]\ttrain-logloss:0.19189\ttrain-f1score:0.77371\teval-logloss:0.27865\teval-f1score:0.66351\n",
      "--------------------------------------------------\n",
      "xgboost training fold 5\n",
      "[0]\ttrain-logloss:0.66006\ttrain-f1score:0.09710\teval-logloss:0.66004\teval-f1score:0.09575\n",
      "[25]\ttrain-logloss:0.33572\ttrain-f1score:0.66245\teval-logloss:0.33844\teval-f1score:0.65144\n",
      "[50]\ttrain-logloss:0.27903\ttrain-f1score:0.66533\teval-logloss:0.28726\teval-f1score:0.65561\n",
      "[75]\ttrain-logloss:0.26139\ttrain-f1score:0.67672\teval-logloss:0.27767\teval-f1score:0.65898\n",
      "[100]\ttrain-logloss:0.25145\ttrain-f1score:0.68515\teval-logloss:0.27513\teval-f1score:0.66274\n",
      "[125]\ttrain-logloss:0.24449\ttrain-f1score:0.69425\teval-logloss:0.27429\teval-f1score:0.66668\n",
      "[150]\ttrain-logloss:0.23915\ttrain-f1score:0.70250\teval-logloss:0.27388\teval-f1score:0.67135\n",
      "[175]\ttrain-logloss:0.23478\ttrain-f1score:0.70722\teval-logloss:0.27375\teval-f1score:0.67241\n",
      "[200]\ttrain-logloss:0.23059\ttrain-f1score:0.71237\teval-logloss:0.27349\teval-f1score:0.67372\n",
      "[225]\ttrain-logloss:0.22758\ttrain-f1score:0.71683\teval-logloss:0.27357\teval-f1score:0.67215\n",
      "[250]\ttrain-logloss:0.22416\ttrain-f1score:0.72269\teval-logloss:0.27359\teval-f1score:0.67372\n",
      "[275]\ttrain-logloss:0.22153\ttrain-f1score:0.72567\teval-logloss:0.27371\teval-f1score:0.67254\n",
      "[300]\ttrain-logloss:0.21836\ttrain-f1score:0.72988\teval-logloss:0.27398\teval-f1score:0.66992\n",
      "[325]\ttrain-logloss:0.21502\ttrain-f1score:0.73450\teval-logloss:0.27419\teval-f1score:0.67423\n",
      "[350]\ttrain-logloss:0.21128\ttrain-f1score:0.73985\teval-logloss:0.27436\teval-f1score:0.67215\n",
      "[375]\ttrain-logloss:0.20639\ttrain-f1score:0.74885\teval-logloss:0.27499\teval-f1score:0.67006\n",
      "[400]\ttrain-logloss:0.20314\ttrain-f1score:0.75494\teval-logloss:0.27540\teval-f1score:0.67215\n",
      "[425]\ttrain-logloss:0.20040\ttrain-f1score:0.76072\teval-logloss:0.27557\teval-f1score:0.67202\n",
      "[450]\ttrain-logloss:0.19687\ttrain-f1score:0.76636\teval-logloss:0.27607\teval-f1score:0.67044\n",
      "[475]\ttrain-logloss:0.19383\ttrain-f1score:0.77239\teval-logloss:0.27669\teval-f1score:0.66731\n",
      "[499]\ttrain-logloss:0.19045\ttrain-f1score:0.77798\teval-logloss:0.27686\teval-f1score:0.66980\n",
      "--------------------------------------------------\n",
      "xgboost training fold 6\n",
      "[0]\ttrain-logloss:0.65991\ttrain-f1score:0.09575\teval-logloss:0.66044\teval-f1score:0.10380\n",
      "[25]\ttrain-logloss:0.33427\ttrain-f1score:0.65652\teval-logloss:0.34573\teval-f1score:0.67181\n",
      "[50]\ttrain-logloss:0.27753\ttrain-f1score:0.66265\teval-logloss:0.29889\teval-f1score:0.67120\n",
      "[75]\ttrain-logloss:0.25950\ttrain-f1score:0.67075\teval-logloss:0.29020\teval-f1score:0.67020\n",
      "[100]\ttrain-logloss:0.24955\ttrain-f1score:0.68125\teval-logloss:0.28797\teval-f1score:0.67781\n",
      "[125]\ttrain-logloss:0.24298\ttrain-f1score:0.68995\teval-logloss:0.28785\teval-f1score:0.67772\n",
      "[150]\ttrain-logloss:0.23763\ttrain-f1score:0.69943\teval-logloss:0.28739\teval-f1score:0.67863\n",
      "[175]\ttrain-logloss:0.23327\ttrain-f1score:0.70373\teval-logloss:0.28773\teval-f1score:0.67985\n",
      "[200]\ttrain-logloss:0.22953\ttrain-f1score:0.70775\teval-logloss:0.28786\teval-f1score:0.67992\n",
      "[210]\ttrain-logloss:0.22810\ttrain-f1score:0.70885\teval-logloss:0.28779\teval-f1score:0.68073\n",
      "--------------------------------------------------\n",
      "xgboost training fold 7\n",
      "[0]\ttrain-logloss:0.65997\ttrain-f1score:0.09712\teval-logloss:0.66031\teval-f1score:0.09563\n",
      "[25]\ttrain-logloss:0.33461\ttrain-f1score:0.66280\teval-logloss:0.34169\teval-f1score:0.64681\n",
      "[50]\ttrain-logloss:0.27799\ttrain-f1score:0.66416\teval-logloss:0.29227\teval-f1score:0.64799\n",
      "[75]\ttrain-logloss:0.25971\ttrain-f1score:0.67562\teval-logloss:0.28326\teval-f1score:0.65334\n",
      "[100]\ttrain-logloss:0.24972\ttrain-f1score:0.68729\teval-logloss:0.28096\teval-f1score:0.65514\n",
      "[125]\ttrain-logloss:0.24351\ttrain-f1score:0.69362\teval-logloss:0.28030\teval-f1score:0.65667\n",
      "[150]\ttrain-logloss:0.23887\ttrain-f1score:0.70054\teval-logloss:0.28022\teval-f1score:0.65800\n",
      "[175]\ttrain-logloss:0.23436\ttrain-f1score:0.70502\teval-logloss:0.28044\teval-f1score:0.65727\n",
      "[200]\ttrain-logloss:0.23077\ttrain-f1score:0.70931\teval-logloss:0.28056\teval-f1score:0.65499\n",
      "[225]\ttrain-logloss:0.22653\ttrain-f1score:0.71459\teval-logloss:0.28093\teval-f1score:0.65493\n",
      "[250]\ttrain-logloss:0.22365\ttrain-f1score:0.72028\teval-logloss:0.28110\teval-f1score:0.65488\n",
      "[275]\ttrain-logloss:0.22045\ttrain-f1score:0.72462\teval-logloss:0.28117\teval-f1score:0.65607\n",
      "[300]\ttrain-logloss:0.21744\ttrain-f1score:0.72959\teval-logloss:0.28135\teval-f1score:0.65607\n",
      "[325]\ttrain-logloss:0.21485\ttrain-f1score:0.73440\teval-logloss:0.28142\teval-f1score:0.66013\n",
      "[350]\ttrain-logloss:0.21069\ttrain-f1score:0.74174\teval-logloss:0.28173\teval-f1score:0.65941\n",
      "[375]\ttrain-logloss:0.20859\ttrain-f1score:0.74532\teval-logloss:0.28201\teval-f1score:0.66029\n",
      "[400]\ttrain-logloss:0.20541\ttrain-f1score:0.75090\teval-logloss:0.28220\teval-f1score:0.66295\n",
      "[425]\ttrain-logloss:0.20273\ttrain-f1score:0.75435\teval-logloss:0.28233\teval-f1score:0.66246\n",
      "[450]\ttrain-logloss:0.20069\ttrain-f1score:0.75784\teval-logloss:0.28254\teval-f1score:0.66398\n",
      "[475]\ttrain-logloss:0.19766\ttrain-f1score:0.76425\teval-logloss:0.28261\teval-f1score:0.66461\n",
      "[499]\ttrain-logloss:0.19437\ttrain-f1score:0.77163\teval-logloss:0.28268\teval-f1score:0.66461\n",
      "xgboost our out of folds CV f1score is 0.6369446817322499\n",
      "--------------------------------------------------\n",
      "catboost training fold 1\n",
      "0:\tlearn: 0.6831341\ttest: 0.6830488\tbest: 0.6830488 (0)\ttotal: 281ms\tremaining: 5m 36s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25:\tlearn: 0.5038325\ttest: 0.5024687\tbest: 0.5024687 (25)\ttotal: 6.31s\tremaining: 4m 44s\n",
      "50:\tlearn: 0.4095408\ttest: 0.4074300\tbest: 0.4074300 (50)\ttotal: 12.7s\tremaining: 4m 47s\n",
      "75:\tlearn: 0.3574025\ttest: 0.3550017\tbest: 0.3550017 (75)\ttotal: 19.2s\tremaining: 4m 44s\n",
      "100:\tlearn: 0.3285133\ttest: 0.3261818\tbest: 0.3261818 (100)\ttotal: 26s\tremaining: 4m 42s\n",
      "125:\tlearn: 0.3106320\ttest: 0.3086515\tbest: 0.3086515 (125)\ttotal: 32.7s\tremaining: 4m 38s\n",
      "150:\tlearn: 0.2986332\ttest: 0.2970670\tbest: 0.2970670 (150)\ttotal: 40.4s\tremaining: 4m 40s\n",
      "175:\tlearn: 0.2907224\ttest: 0.2894520\tbest: 0.2894520 (175)\ttotal: 48.2s\tremaining: 4m 40s\n",
      "200:\tlearn: 0.2854808\ttest: 0.2847415\tbest: 0.2847415 (200)\ttotal: 56.5s\tremaining: 4m 40s\n",
      "225:\tlearn: 0.2819504\ttest: 0.2815482\tbest: 0.2815482 (225)\ttotal: 1m 4s\tremaining: 4m 37s\n",
      "250:\tlearn: 0.2792877\ttest: 0.2793523\tbest: 0.2793523 (250)\ttotal: 1m 13s\tremaining: 4m 36s\n",
      "275:\tlearn: 0.2772961\ttest: 0.2778482\tbest: 0.2778482 (275)\ttotal: 1m 21s\tremaining: 4m 33s\n",
      "300:\tlearn: 0.2757512\ttest: 0.2767856\tbest: 0.2767856 (300)\ttotal: 1m 30s\tremaining: 4m 31s\n",
      "325:\tlearn: 0.2744833\ttest: 0.2759792\tbest: 0.2759792 (325)\ttotal: 1m 39s\tremaining: 4m 27s\n",
      "350:\tlearn: 0.2734580\ttest: 0.2755224\tbest: 0.2755224 (350)\ttotal: 1m 48s\tremaining: 4m 21s\n",
      "375:\tlearn: 0.2725664\ttest: 0.2751579\tbest: 0.2751579 (375)\ttotal: 1m 55s\tremaining: 4m 14s\n",
      "400:\tlearn: 0.2717248\ttest: 0.2748023\tbest: 0.2748023 (400)\ttotal: 2m 4s\tremaining: 4m 8s\n",
      "425:\tlearn: 0.2709672\ttest: 0.2745016\tbest: 0.2745016 (425)\ttotal: 2m 13s\tremaining: 4m 1s\n",
      "450:\tlearn: 0.2702649\ttest: 0.2743269\tbest: 0.2743269 (450)\ttotal: 2m 21s\tremaining: 3m 55s\n",
      "475:\tlearn: 0.2696272\ttest: 0.2742294\tbest: 0.2742208 (474)\ttotal: 2m 30s\tremaining: 3m 48s\n",
      "500:\tlearn: 0.2690831\ttest: 0.2741203\tbest: 0.2741203 (500)\ttotal: 2m 39s\tremaining: 3m 42s\n",
      "525:\tlearn: 0.2684668\ttest: 0.2740449\tbest: 0.2740449 (525)\ttotal: 2m 48s\tremaining: 3m 35s\n",
      "550:\tlearn: 0.2678765\ttest: 0.2739373\tbest: 0.2739373 (550)\ttotal: 2m 57s\tremaining: 3m 28s\n",
      "575:\tlearn: 0.2673481\ttest: 0.2738604\tbest: 0.2738574 (574)\ttotal: 3m 5s\tremaining: 3m 21s\n",
      "600:\tlearn: 0.2668531\ttest: 0.2738381\tbest: 0.2738381 (600)\ttotal: 3m 14s\tremaining: 3m 13s\n",
      "625:\tlearn: 0.2663856\ttest: 0.2738209\tbest: 0.2738077 (620)\ttotal: 3m 22s\tremaining: 3m 5s\n",
      "650:\tlearn: 0.2659073\ttest: 0.2737584\tbest: 0.2737584 (650)\ttotal: 3m 30s\tremaining: 2m 57s\n",
      "675:\tlearn: 0.2655038\ttest: 0.2737277\tbest: 0.2737277 (675)\ttotal: 3m 39s\tremaining: 2m 50s\n",
      "700:\tlearn: 0.2650964\ttest: 0.2736914\tbest: 0.2736902 (699)\ttotal: 3m 47s\tremaining: 2m 42s\n",
      "725:\tlearn: 0.2646436\ttest: 0.2736499\tbest: 0.2736494 (721)\ttotal: 3m 56s\tremaining: 2m 34s\n",
      "750:\tlearn: 0.2643020\ttest: 0.2736242\tbest: 0.2736071 (741)\ttotal: 4m 6s\tremaining: 2m 27s\n",
      "775:\tlearn: 0.2639122\ttest: 0.2735956\tbest: 0.2735834 (770)\ttotal: 4m 16s\tremaining: 2m 19s\n",
      "800:\tlearn: 0.2635049\ttest: 0.2735755\tbest: 0.2735755 (800)\ttotal: 4m 25s\tremaining: 2m 12s\n",
      "825:\tlearn: 0.2631213\ttest: 0.2735249\tbest: 0.2735238 (824)\ttotal: 4m 35s\tremaining: 2m 4s\n",
      "850:\tlearn: 0.2627790\ttest: 0.2734661\tbest: 0.2734661 (850)\ttotal: 4m 44s\tremaining: 1m 56s\n",
      "875:\tlearn: 0.2624656\ttest: 0.2734465\tbest: 0.2734413 (871)\ttotal: 4m 54s\tremaining: 1m 48s\n",
      "900:\tlearn: 0.2621065\ttest: 0.2734229\tbest: 0.2734213 (899)\ttotal: 5m 4s\tremaining: 1m 40s\n",
      "925:\tlearn: 0.2617736\ttest: 0.2734124\tbest: 0.2734062 (914)\ttotal: 5m 13s\tremaining: 1m 32s\n",
      "950:\tlearn: 0.2613979\ttest: 0.2733803\tbest: 0.2733718 (947)\ttotal: 5m 23s\tremaining: 1m 24s\n",
      "975:\tlearn: 0.2610907\ttest: 0.2733306\tbest: 0.2733299 (974)\ttotal: 5m 32s\tremaining: 1m 16s\n",
      "1000:\tlearn: 0.2607146\ttest: 0.2733189\tbest: 0.2733168 (986)\ttotal: 5m 40s\tremaining: 1m 7s\n",
      "1025:\tlearn: 0.2603814\ttest: 0.2733152\tbest: 0.2732999 (1015)\ttotal: 5m 49s\tremaining: 59.4s\n",
      "1050:\tlearn: 0.2601008\ttest: 0.2733201\tbest: 0.2732999 (1015)\ttotal: 5m 58s\tremaining: 50.8s\n",
      "1075:\tlearn: 0.2597766\ttest: 0.2733292\tbest: 0.2732999 (1015)\ttotal: 6m 7s\tremaining: 42.3s\n",
      "1100:\tlearn: 0.2594560\ttest: 0.2733127\tbest: 0.2732999 (1015)\ttotal: 6m 15s\tremaining: 33.8s\n",
      "1125:\tlearn: 0.2591698\ttest: 0.2733029\tbest: 0.2732999 (1015)\ttotal: 6m 24s\tremaining: 25.3s\n",
      "1150:\tlearn: 0.2589162\ttest: 0.2733277\tbest: 0.2732999 (1015)\ttotal: 6m 33s\tremaining: 16.8s\n",
      "1175:\tlearn: 0.2586144\ttest: 0.2733437\tbest: 0.2732999 (1015)\ttotal: 6m 43s\tremaining: 8.22s\n",
      "1199:\tlearn: 0.2583676\ttest: 0.2733533\tbest: 0.2732999 (1015)\ttotal: 6m 52s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2732998851\n",
      "bestIteration = 1015\n",
      "\n",
      "Shrink model to first 1016 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 2\n",
      "0:\tlearn: 0.6832254\ttest: 0.6832371\tbest: 0.6832371 (0)\ttotal: 310ms\tremaining: 6m 11s\n",
      "25:\tlearn: 0.5020838\ttest: 0.5029516\tbest: 0.5029516 (25)\ttotal: 7.14s\tremaining: 5m 22s\n",
      "50:\tlearn: 0.4067367\ttest: 0.4086131\tbest: 0.4086131 (50)\ttotal: 13.7s\tremaining: 5m 8s\n",
      "75:\tlearn: 0.3555457\ttest: 0.3583423\tbest: 0.3583423 (75)\ttotal: 20.7s\tremaining: 5m 5s\n",
      "100:\tlearn: 0.3257025\ttest: 0.3294044\tbest: 0.3294044 (100)\ttotal: 28.2s\tremaining: 5m 6s\n",
      "125:\tlearn: 0.3079724\ttest: 0.3127507\tbest: 0.3127507 (125)\ttotal: 35.3s\tremaining: 5m\n",
      "150:\tlearn: 0.2967124\ttest: 0.3023637\tbest: 0.3023637 (150)\ttotal: 42.9s\tremaining: 4m 57s\n",
      "175:\tlearn: 0.2892439\ttest: 0.2956370\tbest: 0.2956370 (175)\ttotal: 50.2s\tremaining: 4m 52s\n",
      "200:\tlearn: 0.2840077\ttest: 0.2910911\tbest: 0.2910911 (200)\ttotal: 58.5s\tremaining: 4m 50s\n",
      "225:\tlearn: 0.2805823\ttest: 0.2883094\tbest: 0.2883094 (225)\ttotal: 1m 6s\tremaining: 4m 46s\n",
      "250:\tlearn: 0.2780260\ttest: 0.2864120\tbest: 0.2864120 (250)\ttotal: 1m 14s\tremaining: 4m 43s\n",
      "275:\tlearn: 0.2760211\ttest: 0.2850807\tbest: 0.2850807 (275)\ttotal: 1m 23s\tremaining: 4m 38s\n",
      "300:\tlearn: 0.2744876\ttest: 0.2841519\tbest: 0.2841519 (300)\ttotal: 1m 31s\tremaining: 4m 34s\n",
      "325:\tlearn: 0.2731982\ttest: 0.2834437\tbest: 0.2834437 (325)\ttotal: 1m 41s\tremaining: 4m 30s\n",
      "350:\tlearn: 0.2720773\ttest: 0.2829498\tbest: 0.2829498 (350)\ttotal: 1m 50s\tremaining: 4m 26s\n",
      "375:\tlearn: 0.2712122\ttest: 0.2825660\tbest: 0.2825660 (375)\ttotal: 1m 58s\tremaining: 4m 20s\n",
      "400:\tlearn: 0.2703533\ttest: 0.2821663\tbest: 0.2821663 (400)\ttotal: 2m 7s\tremaining: 4m 14s\n",
      "425:\tlearn: 0.2696118\ttest: 0.2819030\tbest: 0.2819024 (424)\ttotal: 2m 17s\tremaining: 4m 9s\n",
      "450:\tlearn: 0.2689034\ttest: 0.2816767\tbest: 0.2816723 (449)\ttotal: 2m 25s\tremaining: 4m 2s\n",
      "475:\tlearn: 0.2682998\ttest: 0.2814818\tbest: 0.2814799 (474)\ttotal: 2m 34s\tremaining: 3m 55s\n",
      "500:\tlearn: 0.2676795\ttest: 0.2812667\tbest: 0.2812667 (500)\ttotal: 2m 43s\tremaining: 3m 47s\n",
      "525:\tlearn: 0.2672169\ttest: 0.2811422\tbest: 0.2811422 (525)\ttotal: 2m 52s\tremaining: 3m 40s\n",
      "550:\tlearn: 0.2667089\ttest: 0.2810039\tbest: 0.2810039 (550)\ttotal: 3m\tremaining: 3m 33s\n",
      "575:\tlearn: 0.2662234\ttest: 0.2808668\tbest: 0.2808668 (575)\ttotal: 3m 9s\tremaining: 3m 25s\n",
      "600:\tlearn: 0.2657081\ttest: 0.2807378\tbest: 0.2807378 (600)\ttotal: 3m 18s\tremaining: 3m 17s\n",
      "625:\tlearn: 0.2653084\ttest: 0.2806252\tbest: 0.2806252 (625)\ttotal: 3m 26s\tremaining: 3m 9s\n",
      "650:\tlearn: 0.2649172\ttest: 0.2805311\tbest: 0.2805311 (650)\ttotal: 3m 36s\tremaining: 3m 2s\n",
      "675:\tlearn: 0.2645276\ttest: 0.2804264\tbest: 0.2804264 (675)\ttotal: 3m 45s\tremaining: 2m 54s\n",
      "700:\tlearn: 0.2641384\ttest: 0.2803516\tbest: 0.2803505 (699)\ttotal: 3m 54s\tremaining: 2m 47s\n",
      "725:\tlearn: 0.2637758\ttest: 0.2802642\tbest: 0.2802642 (725)\ttotal: 4m 3s\tremaining: 2m 39s\n",
      "750:\tlearn: 0.2634235\ttest: 0.2801903\tbest: 0.2801892 (748)\ttotal: 4m 12s\tremaining: 2m 31s\n",
      "775:\tlearn: 0.2631152\ttest: 0.2801215\tbest: 0.2801105 (771)\ttotal: 4m 21s\tremaining: 2m 23s\n",
      "800:\tlearn: 0.2628199\ttest: 0.2800802\tbest: 0.2800796 (798)\ttotal: 4m 30s\tremaining: 2m 14s\n",
      "825:\tlearn: 0.2625177\ttest: 0.2800188\tbest: 0.2800173 (817)\ttotal: 4m 40s\tremaining: 2m 6s\n",
      "850:\tlearn: 0.2621255\ttest: 0.2799632\tbest: 0.2799625 (849)\ttotal: 4m 49s\tremaining: 1m 58s\n",
      "875:\tlearn: 0.2617547\ttest: 0.2798778\tbest: 0.2798778 (874)\ttotal: 4m 58s\tremaining: 1m 50s\n",
      "900:\tlearn: 0.2614204\ttest: 0.2798264\tbest: 0.2798264 (900)\ttotal: 5m 7s\tremaining: 1m 42s\n",
      "925:\tlearn: 0.2610651\ttest: 0.2797770\tbest: 0.2797755 (921)\ttotal: 5m 16s\tremaining: 1m 33s\n",
      "950:\tlearn: 0.2607836\ttest: 0.2797490\tbest: 0.2797490 (950)\ttotal: 5m 25s\tremaining: 1m 25s\n",
      "975:\tlearn: 0.2605157\ttest: 0.2797116\tbest: 0.2797017 (970)\ttotal: 5m 35s\tremaining: 1m 16s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000:\tlearn: 0.2601864\ttest: 0.2796788\tbest: 0.2796788 (1000)\ttotal: 5m 44s\tremaining: 1m 8s\n",
      "1025:\tlearn: 0.2599607\ttest: 0.2796315\tbest: 0.2796315 (1025)\ttotal: 5m 54s\tremaining: 1m\n",
      "1050:\tlearn: 0.2596457\ttest: 0.2795650\tbest: 0.2795650 (1050)\ttotal: 6m 5s\tremaining: 51.8s\n",
      "1075:\tlearn: 0.2593642\ttest: 0.2795469\tbest: 0.2795460 (1074)\ttotal: 6m 16s\tremaining: 43.3s\n",
      "1100:\tlearn: 0.2591185\ttest: 0.2795311\tbest: 0.2795267 (1096)\ttotal: 6m 27s\tremaining: 34.8s\n",
      "1125:\tlearn: 0.2588619\ttest: 0.2794750\tbest: 0.2794750 (1125)\ttotal: 6m 38s\tremaining: 26.2s\n",
      "1150:\tlearn: 0.2586009\ttest: 0.2794613\tbest: 0.2794573 (1147)\ttotal: 6m 49s\tremaining: 17.4s\n",
      "1175:\tlearn: 0.2583670\ttest: 0.2794342\tbest: 0.2794342 (1175)\ttotal: 7m\tremaining: 8.59s\n",
      "1199:\tlearn: 0.2582426\ttest: 0.2794328\tbest: 0.2794322 (1193)\ttotal: 7m 11s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.279432168\n",
      "bestIteration = 1193\n",
      "\n",
      "Shrink model to first 1194 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 3\n",
      "0:\tlearn: 0.6830514\ttest: 0.6831263\tbest: 0.6831263 (0)\ttotal: 369ms\tremaining: 7m 21s\n",
      "25:\tlearn: 0.5031353\ttest: 0.5043444\tbest: 0.5043444 (25)\ttotal: 8.5s\tremaining: 6m 24s\n",
      "50:\tlearn: 0.4075988\ttest: 0.4093459\tbest: 0.4093459 (50)\ttotal: 16.8s\tremaining: 6m 17s\n",
      "75:\tlearn: 0.3567913\ttest: 0.3588790\tbest: 0.3588790 (75)\ttotal: 24.8s\tremaining: 6m 7s\n",
      "100:\tlearn: 0.3277677\ttest: 0.3301579\tbest: 0.3301579 (100)\ttotal: 33.5s\tremaining: 6m 5s\n",
      "125:\tlearn: 0.3094923\ttest: 0.3125006\tbest: 0.3125006 (125)\ttotal: 42.6s\tremaining: 6m 2s\n",
      "150:\tlearn: 0.2976103\ttest: 0.3009859\tbest: 0.3009859 (150)\ttotal: 51.6s\tremaining: 5m 58s\n",
      "175:\tlearn: 0.2900155\ttest: 0.2936314\tbest: 0.2936314 (175)\ttotal: 1m 1s\tremaining: 5m 56s\n",
      "200:\tlearn: 0.2846038\ttest: 0.2886407\tbest: 0.2886407 (200)\ttotal: 1m 10s\tremaining: 5m 52s\n",
      "225:\tlearn: 0.2810426\ttest: 0.2854371\tbest: 0.2854371 (225)\ttotal: 1m 20s\tremaining: 5m 46s\n",
      "250:\tlearn: 0.2785202\ttest: 0.2833539\tbest: 0.2833539 (250)\ttotal: 1m 30s\tremaining: 5m 42s\n",
      "275:\tlearn: 0.2767070\ttest: 0.2817899\tbest: 0.2817899 (275)\ttotal: 1m 41s\tremaining: 5m 38s\n",
      "300:\tlearn: 0.2752291\ttest: 0.2806310\tbest: 0.2806310 (300)\ttotal: 1m 51s\tremaining: 5m 32s\n",
      "325:\tlearn: 0.2739383\ttest: 0.2797315\tbest: 0.2797315 (325)\ttotal: 2m 1s\tremaining: 5m 26s\n",
      "350:\tlearn: 0.2728388\ttest: 0.2789828\tbest: 0.2789828 (350)\ttotal: 2m 12s\tremaining: 5m 20s\n",
      "375:\tlearn: 0.2719224\ttest: 0.2784365\tbest: 0.2784365 (375)\ttotal: 2m 23s\tremaining: 5m 13s\n",
      "400:\tlearn: 0.2710549\ttest: 0.2779306\tbest: 0.2779306 (400)\ttotal: 2m 33s\tremaining: 5m 5s\n",
      "425:\tlearn: 0.2702773\ttest: 0.2775355\tbest: 0.2775355 (425)\ttotal: 2m 44s\tremaining: 4m 58s\n",
      "450:\tlearn: 0.2695619\ttest: 0.2772117\tbest: 0.2772117 (450)\ttotal: 2m 54s\tremaining: 4m 49s\n",
      "475:\tlearn: 0.2689287\ttest: 0.2769925\tbest: 0.2769925 (475)\ttotal: 3m 5s\tremaining: 4m 42s\n",
      "500:\tlearn: 0.2683164\ttest: 0.2767920\tbest: 0.2767920 (500)\ttotal: 3m 16s\tremaining: 4m 34s\n",
      "525:\tlearn: 0.2677708\ttest: 0.2766457\tbest: 0.2766452 (524)\ttotal: 3m 26s\tremaining: 4m 24s\n",
      "550:\tlearn: 0.2672709\ttest: 0.2764392\tbest: 0.2764392 (550)\ttotal: 3m 36s\tremaining: 4m 15s\n",
      "575:\tlearn: 0.2667953\ttest: 0.2762587\tbest: 0.2762587 (575)\ttotal: 3m 45s\tremaining: 4m 4s\n",
      "600:\tlearn: 0.2663327\ttest: 0.2761762\tbest: 0.2761747 (599)\ttotal: 3m 55s\tremaining: 3m 54s\n",
      "625:\tlearn: 0.2659328\ttest: 0.2760870\tbest: 0.2760870 (625)\ttotal: 4m 5s\tremaining: 3m 45s\n",
      "650:\tlearn: 0.2655081\ttest: 0.2760326\tbest: 0.2760326 (650)\ttotal: 4m 16s\tremaining: 3m 35s\n",
      "675:\tlearn: 0.2651586\ttest: 0.2760053\tbest: 0.2759993 (674)\ttotal: 4m 25s\tremaining: 3m 25s\n",
      "700:\tlearn: 0.2647871\ttest: 0.2759409\tbest: 0.2759363 (695)\ttotal: 4m 35s\tremaining: 3m 16s\n",
      "725:\tlearn: 0.2644052\ttest: 0.2758512\tbest: 0.2758512 (725)\ttotal: 4m 45s\tremaining: 3m 6s\n",
      "750:\tlearn: 0.2639521\ttest: 0.2757855\tbest: 0.2757855 (750)\ttotal: 4m 57s\tremaining: 2m 57s\n",
      "775:\tlearn: 0.2635979\ttest: 0.2757346\tbest: 0.2757346 (775)\ttotal: 5m 8s\tremaining: 2m 48s\n",
      "800:\tlearn: 0.2632729\ttest: 0.2756422\tbest: 0.2756377 (797)\ttotal: 5m 18s\tremaining: 2m 38s\n",
      "825:\tlearn: 0.2629972\ttest: 0.2756106\tbest: 0.2756093 (824)\ttotal: 5m 28s\tremaining: 2m 28s\n",
      "850:\tlearn: 0.2626738\ttest: 0.2755708\tbest: 0.2755704 (842)\ttotal: 5m 39s\tremaining: 2m 19s\n",
      "875:\tlearn: 0.2623439\ttest: 0.2755124\tbest: 0.2755082 (873)\ttotal: 5m 50s\tremaining: 2m 9s\n",
      "900:\tlearn: 0.2620387\ttest: 0.2754625\tbest: 0.2754538 (897)\ttotal: 6m 1s\tremaining: 1m 59s\n",
      "925:\tlearn: 0.2616688\ttest: 0.2754295\tbest: 0.2754198 (921)\ttotal: 6m 11s\tremaining: 1m 49s\n",
      "950:\tlearn: 0.2613389\ttest: 0.2753644\tbest: 0.2753636 (949)\ttotal: 6m 22s\tremaining: 1m 40s\n",
      "975:\tlearn: 0.2610465\ttest: 0.2753519\tbest: 0.2753480 (972)\ttotal: 6m 33s\tremaining: 1m 30s\n",
      "1000:\tlearn: 0.2607249\ttest: 0.2752959\tbest: 0.2752959 (1000)\ttotal: 6m 46s\tremaining: 1m 20s\n",
      "1025:\tlearn: 0.2603614\ttest: 0.2752151\tbest: 0.2752151 (1025)\ttotal: 7m\tremaining: 1m 11s\n",
      "1050:\tlearn: 0.2600192\ttest: 0.2751752\tbest: 0.2751714 (1049)\ttotal: 7m 16s\tremaining: 1m 1s\n",
      "1075:\tlearn: 0.2597635\ttest: 0.2751250\tbest: 0.2751242 (1074)\ttotal: 7m 31s\tremaining: 52s\n",
      "1100:\tlearn: 0.2593939\ttest: 0.2750511\tbest: 0.2750511 (1100)\ttotal: 7m 46s\tremaining: 42s\n",
      "1125:\tlearn: 0.2591235\ttest: 0.2749902\tbest: 0.2749896 (1121)\ttotal: 7m 59s\tremaining: 31.5s\n",
      "1150:\tlearn: 0.2587610\ttest: 0.2749445\tbest: 0.2749375 (1149)\ttotal: 8m 14s\tremaining: 21.1s\n",
      "1175:\tlearn: 0.2585266\ttest: 0.2749130\tbest: 0.2749114 (1170)\ttotal: 8m 30s\tremaining: 10.4s\n",
      "1199:\tlearn: 0.2582479\ttest: 0.2748848\tbest: 0.2748841 (1198)\ttotal: 8m 45s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.274884057\n",
      "bestIteration = 1198\n",
      "\n",
      "Shrink model to first 1199 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 4\n",
      "0:\tlearn: 0.6831752\ttest: 0.6830069\tbest: 0.6830069 (0)\ttotal: 536ms\tremaining: 10m 42s\n",
      "25:\tlearn: 0.5040598\ttest: 0.5002798\tbest: 0.5002798 (25)\ttotal: 13.7s\tremaining: 10m 17s\n",
      "50:\tlearn: 0.4085658\ttest: 0.4028152\tbest: 0.4028152 (50)\ttotal: 26.2s\tremaining: 9m 51s\n",
      "75:\tlearn: 0.3578233\ttest: 0.3507668\tbest: 0.3507668 (75)\ttotal: 38.6s\tremaining: 9m 31s\n",
      "100:\tlearn: 0.3291825\ttest: 0.3216017\tbest: 0.3216017 (100)\ttotal: 52.1s\tremaining: 9m 26s\n",
      "125:\tlearn: 0.3117979\ttest: 0.3038792\tbest: 0.3038792 (125)\ttotal: 1m 5s\tremaining: 9m 15s\n",
      "150:\tlearn: 0.2996160\ttest: 0.2916037\tbest: 0.2916037 (150)\ttotal: 1m 18s\tremaining: 9m 6s\n",
      "175:\tlearn: 0.2914729\ttest: 0.2836455\tbest: 0.2836455 (175)\ttotal: 1m 32s\tremaining: 8m 59s\n",
      "200:\tlearn: 0.2862433\ttest: 0.2788413\tbest: 0.2788413 (200)\ttotal: 1m 47s\tremaining: 8m 55s\n",
      "225:\tlearn: 0.2826984\ttest: 0.2756427\tbest: 0.2756427 (225)\ttotal: 2m 1s\tremaining: 8m 42s\n",
      "250:\tlearn: 0.2801786\ttest: 0.2734977\tbest: 0.2734977 (250)\ttotal: 2m 14s\tremaining: 8m 29s\n",
      "275:\tlearn: 0.2782125\ttest: 0.2718660\tbest: 0.2718660 (275)\ttotal: 2m 29s\tremaining: 8m 20s\n",
      "300:\tlearn: 0.2766349\ttest: 0.2708473\tbest: 0.2708473 (300)\ttotal: 2m 44s\tremaining: 8m 11s\n",
      "325:\tlearn: 0.2753445\ttest: 0.2699655\tbest: 0.2699655 (325)\ttotal: 2m 59s\tremaining: 8m\n",
      "350:\tlearn: 0.2742452\ttest: 0.2693565\tbest: 0.2693565 (350)\ttotal: 3m 14s\tremaining: 7m 49s\n",
      "375:\tlearn: 0.2733101\ttest: 0.2688805\tbest: 0.2688805 (375)\ttotal: 3m 29s\tremaining: 7m 38s\n",
      "400:\tlearn: 0.2725094\ttest: 0.2685055\tbest: 0.2685055 (400)\ttotal: 3m 44s\tremaining: 7m 27s\n",
      "425:\tlearn: 0.2716907\ttest: 0.2681900\tbest: 0.2681900 (425)\ttotal: 3m 59s\tremaining: 7m 15s\n",
      "450:\tlearn: 0.2709251\ttest: 0.2678231\tbest: 0.2678231 (450)\ttotal: 4m 14s\tremaining: 7m 3s\n",
      "475:\tlearn: 0.2702981\ttest: 0.2675851\tbest: 0.2675851 (475)\ttotal: 4m 30s\tremaining: 6m 50s\n",
      "500:\tlearn: 0.2697623\ttest: 0.2674206\tbest: 0.2674206 (500)\ttotal: 4m 46s\tremaining: 6m 39s\n",
      "525:\tlearn: 0.2692997\ttest: 0.2672827\tbest: 0.2672827 (525)\ttotal: 5m 1s\tremaining: 6m 25s\n",
      "550:\tlearn: 0.2687963\ttest: 0.2671385\tbest: 0.2671343 (548)\ttotal: 5m 17s\tremaining: 6m 13s\n",
      "575:\tlearn: 0.2683468\ttest: 0.2670572\tbest: 0.2670572 (575)\ttotal: 5m 34s\tremaining: 6m 2s\n",
      "600:\tlearn: 0.2678672\ttest: 0.2669173\tbest: 0.2669118 (599)\ttotal: 5m 51s\tremaining: 5m 50s\n",
      "625:\tlearn: 0.2674156\ttest: 0.2668004\tbest: 0.2668004 (625)\ttotal: 6m 7s\tremaining: 5m 37s\n",
      "650:\tlearn: 0.2669874\ttest: 0.2667078\tbest: 0.2667078 (650)\ttotal: 6m 23s\tremaining: 5m 23s\n",
      "675:\tlearn: 0.2665240\ttest: 0.2666281\tbest: 0.2666281 (675)\ttotal: 6m 38s\tremaining: 5m 9s\n",
      "700:\tlearn: 0.2661614\ttest: 0.2665805\tbest: 0.2665688 (698)\ttotal: 6m 54s\tremaining: 4m 54s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "725:\tlearn: 0.2657655\ttest: 0.2665035\tbest: 0.2665035 (725)\ttotal: 7m 10s\tremaining: 4m 40s\n",
      "750:\tlearn: 0.2653684\ttest: 0.2664256\tbest: 0.2664255 (748)\ttotal: 7m 25s\tremaining: 4m 26s\n",
      "775:\tlearn: 0.2650262\ttest: 0.2663993\tbest: 0.2663993 (775)\ttotal: 7m 40s\tremaining: 4m 11s\n",
      "800:\tlearn: 0.2646308\ttest: 0.2663184\tbest: 0.2663184 (800)\ttotal: 7m 55s\tremaining: 3m 56s\n",
      "825:\tlearn: 0.2642923\ttest: 0.2662432\tbest: 0.2662432 (825)\ttotal: 8m 10s\tremaining: 3m 42s\n",
      "850:\tlearn: 0.2639107\ttest: 0.2661918\tbest: 0.2661918 (850)\ttotal: 8m 23s\tremaining: 3m 26s\n",
      "875:\tlearn: 0.2635619\ttest: 0.2661091\tbest: 0.2661091 (875)\ttotal: 8m 37s\tremaining: 3m 11s\n",
      "900:\tlearn: 0.2632645\ttest: 0.2660675\tbest: 0.2660652 (899)\ttotal: 8m 50s\tremaining: 2m 55s\n",
      "925:\tlearn: 0.2630559\ttest: 0.2660480\tbest: 0.2660447 (924)\ttotal: 9m 2s\tremaining: 2m 40s\n",
      "950:\tlearn: 0.2626955\ttest: 0.2660255\tbest: 0.2660254 (949)\ttotal: 9m 16s\tremaining: 2m 25s\n",
      "975:\tlearn: 0.2624185\ttest: 0.2660037\tbest: 0.2659981 (972)\ttotal: 9m 30s\tremaining: 2m 10s\n",
      "1000:\tlearn: 0.2621796\ttest: 0.2659868\tbest: 0.2659868 (1000)\ttotal: 9m 42s\tremaining: 1m 55s\n",
      "1025:\tlearn: 0.2618955\ttest: 0.2659544\tbest: 0.2659544 (1025)\ttotal: 9m 55s\tremaining: 1m 41s\n",
      "1050:\tlearn: 0.2615580\ttest: 0.2659000\tbest: 0.2658977 (1049)\ttotal: 10m 9s\tremaining: 1m 26s\n",
      "1075:\tlearn: 0.2613192\ttest: 0.2658979\tbest: 0.2658977 (1049)\ttotal: 10m 20s\tremaining: 1m 11s\n",
      "1100:\tlearn: 0.2610157\ttest: 0.2658949\tbest: 0.2658916 (1076)\ttotal: 10m 33s\tremaining: 56.9s\n",
      "1125:\tlearn: 0.2607054\ttest: 0.2658699\tbest: 0.2658598 (1118)\ttotal: 10m 46s\tremaining: 42.5s\n",
      "1150:\tlearn: 0.2604166\ttest: 0.2658455\tbest: 0.2658371 (1139)\ttotal: 11m\tremaining: 28.1s\n",
      "1175:\tlearn: 0.2601933\ttest: 0.2658123\tbest: 0.2658123 (1175)\ttotal: 11m 13s\tremaining: 13.7s\n",
      "1199:\tlearn: 0.2598290\ttest: 0.2657811\tbest: 0.2657752 (1197)\ttotal: 11m 26s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2657752294\n",
      "bestIteration = 1197\n",
      "\n",
      "Shrink model to first 1198 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 5\n",
      "0:\tlearn: 0.6832899\ttest: 0.6832514\tbest: 0.6832514 (0)\ttotal: 477ms\tremaining: 9m 32s\n",
      "25:\tlearn: 0.5029933\ttest: 0.5016717\tbest: 0.5016717 (25)\ttotal: 10.9s\tremaining: 8m 11s\n",
      "50:\tlearn: 0.4088383\ttest: 0.4067515\tbest: 0.4067515 (50)\ttotal: 22.4s\tremaining: 8m 24s\n",
      "75:\tlearn: 0.3578336\ttest: 0.3553396\tbest: 0.3553396 (75)\ttotal: 34s\tremaining: 8m 22s\n",
      "100:\tlearn: 0.3290188\ttest: 0.3262671\tbest: 0.3262671 (100)\ttotal: 46.1s\tremaining: 8m 21s\n",
      "125:\tlearn: 0.3110217\ttest: 0.3082170\tbest: 0.3082170 (125)\ttotal: 58.4s\tremaining: 8m 18s\n",
      "150:\tlearn: 0.2988403\ttest: 0.2959846\tbest: 0.2959846 (150)\ttotal: 1m 11s\tremaining: 8m 20s\n",
      "175:\tlearn: 0.2908684\ttest: 0.2880289\tbest: 0.2880289 (175)\ttotal: 1m 25s\tremaining: 8m 19s\n",
      "200:\tlearn: 0.2857123\ttest: 0.2830374\tbest: 0.2830374 (200)\ttotal: 1m 39s\tremaining: 8m 13s\n",
      "225:\tlearn: 0.2821237\ttest: 0.2796436\tbest: 0.2796436 (225)\ttotal: 1m 53s\tremaining: 8m 7s\n",
      "250:\tlearn: 0.2795746\ttest: 0.2773241\tbest: 0.2773241 (250)\ttotal: 2m 7s\tremaining: 8m 1s\n",
      "275:\tlearn: 0.2777497\ttest: 0.2756818\tbest: 0.2756818 (275)\ttotal: 2m 21s\tremaining: 7m 52s\n",
      "300:\tlearn: 0.2764053\ttest: 0.2745404\tbest: 0.2745404 (300)\ttotal: 2m 34s\tremaining: 7m 40s\n",
      "325:\tlearn: 0.2750979\ttest: 0.2736941\tbest: 0.2736941 (325)\ttotal: 2m 49s\tremaining: 7m 33s\n",
      "350:\tlearn: 0.2740793\ttest: 0.2729915\tbest: 0.2729915 (350)\ttotal: 3m 2s\tremaining: 7m 22s\n",
      "375:\tlearn: 0.2730788\ttest: 0.2723891\tbest: 0.2723891 (375)\ttotal: 3m 17s\tremaining: 7m 13s\n",
      "400:\tlearn: 0.2722972\ttest: 0.2719423\tbest: 0.2719423 (400)\ttotal: 3m 32s\tremaining: 7m 2s\n",
      "425:\tlearn: 0.2715380\ttest: 0.2715577\tbest: 0.2715577 (425)\ttotal: 3m 46s\tremaining: 6m 50s\n",
      "450:\tlearn: 0.2708875\ttest: 0.2712773\tbest: 0.2712773 (450)\ttotal: 3m 57s\tremaining: 6m 34s\n",
      "475:\tlearn: 0.2702499\ttest: 0.2710134\tbest: 0.2710090 (474)\ttotal: 4m 10s\tremaining: 6m 20s\n",
      "500:\tlearn: 0.2696551\ttest: 0.2708129\tbest: 0.2708129 (500)\ttotal: 4m 21s\tremaining: 6m 4s\n",
      "525:\tlearn: 0.2690873\ttest: 0.2706608\tbest: 0.2706608 (525)\ttotal: 4m 34s\tremaining: 5m 51s\n",
      "550:\tlearn: 0.2685564\ttest: 0.2704716\tbest: 0.2704704 (548)\ttotal: 4m 45s\tremaining: 5m 36s\n",
      "575:\tlearn: 0.2680949\ttest: 0.2703037\tbest: 0.2703037 (575)\ttotal: 4m 56s\tremaining: 5m 21s\n",
      "600:\tlearn: 0.2675675\ttest: 0.2701620\tbest: 0.2701620 (599)\ttotal: 5m 8s\tremaining: 5m 7s\n",
      "625:\tlearn: 0.2671346\ttest: 0.2700772\tbest: 0.2700772 (625)\ttotal: 5m 18s\tremaining: 4m 52s\n",
      "650:\tlearn: 0.2667177\ttest: 0.2699439\tbest: 0.2699439 (650)\ttotal: 5m 30s\tremaining: 4m 38s\n",
      "675:\tlearn: 0.2662253\ttest: 0.2698368\tbest: 0.2698368 (675)\ttotal: 5m 42s\tremaining: 4m 25s\n",
      "700:\tlearn: 0.2658272\ttest: 0.2697491\tbest: 0.2697491 (700)\ttotal: 5m 53s\tremaining: 4m 11s\n",
      "725:\tlearn: 0.2654675\ttest: 0.2696361\tbest: 0.2696361 (725)\ttotal: 6m 5s\tremaining: 3m 58s\n",
      "750:\tlearn: 0.2650770\ttest: 0.2695796\tbest: 0.2695732 (748)\ttotal: 6m 18s\tremaining: 3m 46s\n",
      "775:\tlearn: 0.2647056\ttest: 0.2695391\tbest: 0.2695391 (775)\ttotal: 6m 29s\tremaining: 3m 32s\n",
      "800:\tlearn: 0.2643290\ttest: 0.2694914\tbest: 0.2694914 (800)\ttotal: 6m 40s\tremaining: 3m 19s\n",
      "825:\tlearn: 0.2639573\ttest: 0.2694626\tbest: 0.2694596 (816)\ttotal: 6m 51s\tremaining: 3m 6s\n",
      "850:\tlearn: 0.2636041\ttest: 0.2694216\tbest: 0.2694112 (847)\ttotal: 7m 2s\tremaining: 2m 53s\n",
      "875:\tlearn: 0.2632523\ttest: 0.2693888\tbest: 0.2693861 (869)\ttotal: 7m 13s\tremaining: 2m 40s\n",
      "900:\tlearn: 0.2629348\ttest: 0.2693789\tbest: 0.2693789 (900)\ttotal: 7m 22s\tremaining: 2m 26s\n",
      "925:\tlearn: 0.2626957\ttest: 0.2693830\tbest: 0.2693744 (905)\ttotal: 7m 32s\tremaining: 2m 13s\n",
      "950:\tlearn: 0.2623658\ttest: 0.2693298\tbest: 0.2693298 (950)\ttotal: 7m 42s\tremaining: 2m 1s\n",
      "975:\tlearn: 0.2620007\ttest: 0.2692505\tbest: 0.2692491 (974)\ttotal: 7m 52s\tremaining: 1m 48s\n",
      "1000:\tlearn: 0.2616685\ttest: 0.2692327\tbest: 0.2692215 (987)\ttotal: 8m 2s\tremaining: 1m 36s\n",
      "1025:\tlearn: 0.2612862\ttest: 0.2692039\tbest: 0.2692039 (1025)\ttotal: 8m 13s\tremaining: 1m 23s\n",
      "1050:\tlearn: 0.2609379\ttest: 0.2691597\tbest: 0.2691531 (1049)\ttotal: 8m 24s\tremaining: 1m 11s\n",
      "1075:\tlearn: 0.2606053\ttest: 0.2691367\tbest: 0.2691365 (1074)\ttotal: 8m 34s\tremaining: 59.3s\n",
      "1100:\tlearn: 0.2602777\ttest: 0.2691350\tbest: 0.2691238 (1090)\ttotal: 8m 45s\tremaining: 47.3s\n",
      "1125:\tlearn: 0.2600547\ttest: 0.2691254\tbest: 0.2691181 (1105)\ttotal: 8m 57s\tremaining: 35.3s\n",
      "1150:\tlearn: 0.2598085\ttest: 0.2690740\tbest: 0.2690740 (1150)\ttotal: 9m 9s\tremaining: 23.4s\n",
      "1175:\tlearn: 0.2595610\ttest: 0.2690781\tbest: 0.2690727 (1152)\ttotal: 9m 21s\tremaining: 11.5s\n",
      "1199:\tlearn: 0.2593045\ttest: 0.2690533\tbest: 0.2690417 (1194)\ttotal: 9m 33s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2690416756\n",
      "bestIteration = 1194\n",
      "\n",
      "Shrink model to first 1195 iterations.\n",
      "--------------------------------------------------\n",
      "catboost training fold 6\n",
      "0:\tlearn: 0.6830941\ttest: 0.6831389\tbest: 0.6831389 (0)\ttotal: 325ms\tremaining: 6m 29s\n",
      "25:\tlearn: 0.5035631\ttest: 0.5067408\tbest: 0.5067408 (25)\ttotal: 8.76s\tremaining: 6m 35s\n",
      "50:\tlearn: 0.4075724\ttest: 0.4121094\tbest: 0.4121094 (50)\ttotal: 17.7s\tremaining: 6m 37s\n",
      "75:\tlearn: 0.3557595\ttest: 0.3615731\tbest: 0.3615731 (75)\ttotal: 27.3s\tremaining: 6m 44s\n",
      "100:\tlearn: 0.3273543\ttest: 0.3342573\tbest: 0.3342573 (100)\ttotal: 35.3s\tremaining: 6m 24s\n",
      "125:\tlearn: 0.3089147\ttest: 0.3161933\tbest: 0.3161933 (125)\ttotal: 43.3s\tremaining: 6m 9s\n",
      "150:\tlearn: 0.2969211\ttest: 0.3044322\tbest: 0.3044322 (150)\ttotal: 52.4s\tremaining: 6m 4s\n",
      "175:\tlearn: 0.2892187\ttest: 0.2969307\tbest: 0.2969307 (175)\ttotal: 1m 2s\tremaining: 6m 5s\n",
      "200:\tlearn: 0.2842953\ttest: 0.2923195\tbest: 0.2923195 (200)\ttotal: 1m 12s\tremaining: 6m 1s\n",
      "225:\tlearn: 0.2808185\ttest: 0.2892198\tbest: 0.2892198 (225)\ttotal: 1m 23s\tremaining: 5m 58s\n",
      "250:\tlearn: 0.2782931\ttest: 0.2871784\tbest: 0.2871784 (250)\ttotal: 1m 34s\tremaining: 5m 58s\n",
      "275:\tlearn: 0.2763215\ttest: 0.2856462\tbest: 0.2856462 (275)\ttotal: 1m 45s\tremaining: 5m 54s\n",
      "300:\tlearn: 0.2747835\ttest: 0.2844480\tbest: 0.2844480 (300)\ttotal: 1m 57s\tremaining: 5m 50s\n",
      "325:\tlearn: 0.2735222\ttest: 0.2836065\tbest: 0.2836065 (325)\ttotal: 2m 8s\tremaining: 5m 45s\n",
      "350:\tlearn: 0.2724577\ttest: 0.2830064\tbest: 0.2830064 (350)\ttotal: 2m 19s\tremaining: 5m 37s\n",
      "375:\tlearn: 0.2714260\ttest: 0.2824632\tbest: 0.2824632 (375)\ttotal: 2m 29s\tremaining: 5m 28s\n",
      "400:\tlearn: 0.2706251\ttest: 0.2821007\tbest: 0.2821007 (400)\ttotal: 2m 40s\tremaining: 5m 18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "425:\tlearn: 0.2698182\ttest: 0.2817547\tbest: 0.2817547 (425)\ttotal: 2m 50s\tremaining: 5m 9s\n",
      "450:\tlearn: 0.2690873\ttest: 0.2814949\tbest: 0.2814949 (450)\ttotal: 3m\tremaining: 5m\n",
      "475:\tlearn: 0.2684703\ttest: 0.2812839\tbest: 0.2812839 (475)\ttotal: 3m 11s\tremaining: 4m 51s\n",
      "500:\tlearn: 0.2678677\ttest: 0.2811056\tbest: 0.2811056 (500)\ttotal: 3m 21s\tremaining: 4m 41s\n",
      "525:\tlearn: 0.2673000\ttest: 0.2810037\tbest: 0.2810026 (524)\ttotal: 3m 30s\tremaining: 4m 29s\n",
      "550:\tlearn: 0.2667437\ttest: 0.2808307\tbest: 0.2808307 (550)\ttotal: 3m 39s\tremaining: 4m 18s\n",
      "575:\tlearn: 0.2661682\ttest: 0.2806899\tbest: 0.2806899 (575)\ttotal: 3m 47s\tremaining: 4m 6s\n",
      "600:\tlearn: 0.2656278\ttest: 0.2806421\tbest: 0.2806421 (600)\ttotal: 3m 56s\tremaining: 3m 55s\n",
      "625:\tlearn: 0.2652042\ttest: 0.2805932\tbest: 0.2805888 (623)\ttotal: 4m 4s\tremaining: 3m 44s\n",
      "650:\tlearn: 0.2647815\ttest: 0.2805400\tbest: 0.2805384 (647)\ttotal: 4m 13s\tremaining: 3m 33s\n",
      "675:\tlearn: 0.2643910\ttest: 0.2805252\tbest: 0.2805252 (675)\ttotal: 4m 22s\tremaining: 3m 23s\n",
      "700:\tlearn: 0.2639984\ttest: 0.2804916\tbest: 0.2804906 (698)\ttotal: 4m 30s\tremaining: 3m 12s\n",
      "725:\tlearn: 0.2636385\ttest: 0.2804678\tbest: 0.2804678 (725)\ttotal: 4m 39s\tremaining: 3m 2s\n",
      "750:\tlearn: 0.2632341\ttest: 0.2804316\tbest: 0.2804316 (750)\ttotal: 4m 49s\tremaining: 2m 52s\n",
      "775:\tlearn: 0.2627823\ttest: 0.2804267\tbest: 0.2804152 (763)\ttotal: 4m 58s\tremaining: 2m 42s\n",
      "800:\tlearn: 0.2623836\ttest: 0.2803896\tbest: 0.2803849 (798)\ttotal: 5m 7s\tremaining: 2m 33s\n",
      "825:\tlearn: 0.2620788\ttest: 0.2803452\tbest: 0.2803413 (823)\ttotal: 5m 16s\tremaining: 2m 23s\n",
      "850:\tlearn: 0.2617318\ttest: 0.2802872\tbest: 0.2802829 (849)\ttotal: 5m 26s\tremaining: 2m 13s\n",
      "875:\tlearn: 0.2613338\ttest: 0.2802130\tbest: 0.2802119 (873)\ttotal: 5m 36s\tremaining: 2m 4s\n",
      "900:\tlearn: 0.2609863\ttest: 0.2802019\tbest: 0.2801998 (898)\ttotal: 5m 44s\tremaining: 1m 54s\n",
      "925:\tlearn: 0.2606672\ttest: 0.2801881\tbest: 0.2801881 (925)\ttotal: 5m 52s\tremaining: 1m 44s\n",
      "950:\tlearn: 0.2603304\ttest: 0.2802093\tbest: 0.2801881 (925)\ttotal: 6m 1s\tremaining: 1m 34s\n",
      "975:\tlearn: 0.2599654\ttest: 0.2802307\tbest: 0.2801881 (925)\ttotal: 6m 9s\tremaining: 1m 24s\n",
      "1000:\tlearn: 0.2596003\ttest: 0.2802176\tbest: 0.2801881 (925)\ttotal: 6m 18s\tremaining: 1m 15s\n",
      "1025:\tlearn: 0.2592665\ttest: 0.2802302\tbest: 0.2801881 (925)\ttotal: 6m 27s\tremaining: 1m 5s\n",
      "1050:\tlearn: 0.2589606\ttest: 0.2801846\tbest: 0.2801846 (1050)\ttotal: 6m 36s\tremaining: 56.3s\n",
      "1075:\tlearn: 0.2587364\ttest: 0.2801372\tbest: 0.2801372 (1075)\ttotal: 6m 45s\tremaining: 46.7s\n",
      "1100:\tlearn: 0.2584545\ttest: 0.2801258\tbest: 0.2801236 (1094)\ttotal: 6m 54s\tremaining: 37.3s\n",
      "1125:\tlearn: 0.2581027\ttest: 0.2800704\tbest: 0.2800650 (1124)\ttotal: 7m 3s\tremaining: 27.8s\n",
      "1150:\tlearn: 0.2578449\ttest: 0.2800424\tbest: 0.2800398 (1136)\ttotal: 7m 12s\tremaining: 18.4s\n",
      "1175:\tlearn: 0.2574787\ttest: 0.2799993\tbest: 0.2799960 (1174)\ttotal: 7m 21s\tremaining: 9.01s\n",
      "1199:\tlearn: 0.2572567\ttest: 0.2799834\tbest: 0.2799834 (1199)\ttotal: 7m 29s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2799834228\n",
      "bestIteration = 1199\n",
      "\n",
      "--------------------------------------------------\n",
      "catboost training fold 7\n",
      "0:\tlearn: 0.6830910\ttest: 0.6831737\tbest: 0.6831737 (0)\ttotal: 332ms\tremaining: 6m 37s\n",
      "25:\tlearn: 0.5035034\ttest: 0.5041039\tbest: 0.5041039 (25)\ttotal: 6.49s\tremaining: 4m 52s\n",
      "50:\tlearn: 0.4077605\ttest: 0.4089136\tbest: 0.4089136 (50)\ttotal: 13.8s\tremaining: 5m 11s\n",
      "75:\tlearn: 0.3573030\ttest: 0.3586723\tbest: 0.3586723 (75)\ttotal: 20.5s\tremaining: 5m 3s\n",
      "100:\tlearn: 0.3286120\ttest: 0.3302527\tbest: 0.3302527 (100)\ttotal: 29.2s\tremaining: 5m 18s\n",
      "125:\tlearn: 0.3099265\ttest: 0.3120580\tbest: 0.3120580 (125)\ttotal: 37s\tremaining: 5m 15s\n",
      "150:\tlearn: 0.2976470\ttest: 0.3002680\tbest: 0.3002680 (150)\ttotal: 45.3s\tremaining: 5m 14s\n",
      "175:\tlearn: 0.2899183\ttest: 0.2927888\tbest: 0.2927888 (175)\ttotal: 52.7s\tremaining: 5m 6s\n",
      "200:\tlearn: 0.2847470\ttest: 0.2881242\tbest: 0.2881242 (200)\ttotal: 1m 1s\tremaining: 5m 3s\n",
      "225:\tlearn: 0.2811771\ttest: 0.2850680\tbest: 0.2850680 (225)\ttotal: 1m 9s\tremaining: 5m\n",
      "250:\tlearn: 0.2786707\ttest: 0.2830920\tbest: 0.2830920 (250)\ttotal: 1m 18s\tremaining: 4m 58s\n",
      "275:\tlearn: 0.2768257\ttest: 0.2817506\tbest: 0.2817506 (275)\ttotal: 1m 28s\tremaining: 4m 56s\n",
      "300:\tlearn: 0.2752870\ttest: 0.2807389\tbest: 0.2807389 (300)\ttotal: 1m 38s\tremaining: 4m 54s\n",
      "325:\tlearn: 0.2740863\ttest: 0.2800793\tbest: 0.2800793 (325)\ttotal: 1m 47s\tremaining: 4m 48s\n",
      "350:\tlearn: 0.2730110\ttest: 0.2795268\tbest: 0.2795268 (350)\ttotal: 1m 56s\tremaining: 4m 42s\n",
      "375:\tlearn: 0.2721467\ttest: 0.2791661\tbest: 0.2791652 (374)\ttotal: 2m 5s\tremaining: 4m 34s\n",
      "400:\tlearn: 0.2713064\ttest: 0.2787716\tbest: 0.2787716 (400)\ttotal: 2m 14s\tremaining: 4m 28s\n",
      "425:\tlearn: 0.2706468\ttest: 0.2785239\tbest: 0.2785239 (425)\ttotal: 2m 24s\tremaining: 4m 22s\n",
      "450:\tlearn: 0.2699599\ttest: 0.2782889\tbest: 0.2782889 (450)\ttotal: 2m 33s\tremaining: 4m 15s\n",
      "475:\tlearn: 0.2694405\ttest: 0.2780879\tbest: 0.2780879 (475)\ttotal: 2m 42s\tremaining: 4m 7s\n",
      "500:\tlearn: 0.2689085\ttest: 0.2779555\tbest: 0.2779555 (500)\ttotal: 2m 52s\tremaining: 4m\n",
      "525:\tlearn: 0.2684141\ttest: 0.2778955\tbest: 0.2778955 (525)\ttotal: 3m 1s\tremaining: 3m 52s\n",
      "550:\tlearn: 0.2680593\ttest: 0.2778373\tbest: 0.2778348 (549)\ttotal: 3m 10s\tremaining: 3m 44s\n",
      "575:\tlearn: 0.2675967\ttest: 0.2776965\tbest: 0.2776965 (575)\ttotal: 3m 19s\tremaining: 3m 36s\n",
      "600:\tlearn: 0.2672314\ttest: 0.2776175\tbest: 0.2776137 (599)\ttotal: 3m 28s\tremaining: 3m 27s\n",
      "625:\tlearn: 0.2668286\ttest: 0.2775487\tbest: 0.2775425 (623)\ttotal: 3m 37s\tremaining: 3m 19s\n",
      "650:\tlearn: 0.2664374\ttest: 0.2775108\tbest: 0.2775086 (649)\ttotal: 3m 46s\tremaining: 3m 10s\n",
      "675:\tlearn: 0.2661216\ttest: 0.2774503\tbest: 0.2774493 (673)\ttotal: 3m 54s\tremaining: 3m 1s\n",
      "700:\tlearn: 0.2657546\ttest: 0.2773819\tbest: 0.2773819 (700)\ttotal: 4m 2s\tremaining: 2m 52s\n",
      "725:\tlearn: 0.2653603\ttest: 0.2772422\tbest: 0.2772422 (725)\ttotal: 4m 11s\tremaining: 2m 44s\n",
      "750:\tlearn: 0.2650501\ttest: 0.2772047\tbest: 0.2772033 (749)\ttotal: 4m 20s\tremaining: 2m 35s\n",
      "775:\tlearn: 0.2646746\ttest: 0.2771374\tbest: 0.2771374 (775)\ttotal: 4m 29s\tremaining: 2m 27s\n",
      "800:\tlearn: 0.2644041\ttest: 0.2771233\tbest: 0.2771187 (797)\ttotal: 4m 37s\tremaining: 2m 18s\n",
      "825:\tlearn: 0.2641188\ttest: 0.2770424\tbest: 0.2770424 (825)\ttotal: 4m 46s\tremaining: 2m 9s\n",
      "850:\tlearn: 0.2638457\ttest: 0.2769979\tbest: 0.2769920 (846)\ttotal: 4m 55s\tremaining: 2m\n",
      "875:\tlearn: 0.2634752\ttest: 0.2769776\tbest: 0.2769761 (863)\ttotal: 5m 5s\tremaining: 1m 52s\n",
      "900:\tlearn: 0.2630890\ttest: 0.2769538\tbest: 0.2769420 (899)\ttotal: 5m 16s\tremaining: 1m 44s\n",
      "925:\tlearn: 0.2628466\ttest: 0.2769539\tbest: 0.2769420 (899)\ttotal: 5m 27s\tremaining: 1m 37s\n",
      "950:\tlearn: 0.2625985\ttest: 0.2769222\tbest: 0.2769199 (948)\ttotal: 5m 40s\tremaining: 1m 29s\n",
      "975:\tlearn: 0.2623413\ttest: 0.2768920\tbest: 0.2768920 (975)\ttotal: 5m 53s\tremaining: 1m 21s\n",
      "1000:\tlearn: 0.2621318\ttest: 0.2769056\tbest: 0.2768809 (976)\ttotal: 6m 5s\tremaining: 1m 12s\n",
      "1025:\tlearn: 0.2618616\ttest: 0.2768902\tbest: 0.2768809 (976)\ttotal: 6m 19s\tremaining: 1m 4s\n",
      "1050:\tlearn: 0.2616019\ttest: 0.2768714\tbest: 0.2768617 (1049)\ttotal: 6m 33s\tremaining: 55.8s\n",
      "1075:\tlearn: 0.2613789\ttest: 0.2768468\tbest: 0.2768457 (1061)\ttotal: 6m 45s\tremaining: 46.8s\n",
      "1100:\tlearn: 0.2611722\ttest: 0.2768327\tbest: 0.2768322 (1096)\ttotal: 6m 56s\tremaining: 37.4s\n",
      "1125:\tlearn: 0.2609377\ttest: 0.2768062\tbest: 0.2768062 (1125)\ttotal: 7m 9s\tremaining: 28.2s\n",
      "1150:\tlearn: 0.2607798\ttest: 0.2767866\tbest: 0.2767832 (1132)\ttotal: 7m 23s\tremaining: 18.9s\n",
      "1175:\tlearn: 0.2605801\ttest: 0.2767759\tbest: 0.2767755 (1174)\ttotal: 7m 37s\tremaining: 9.33s\n",
      "1199:\tlearn: 0.2604104\ttest: 0.2767858\tbest: 0.2767735 (1176)\ttotal: 7m 50s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.2767735203\n",
      "bestIteration = 1176\n",
      "\n",
      "Shrink model to first 1177 iterations.\n",
      "catboost our out of folds CV f1score is 0.6517841174556253\n"
     ]
    }
   ],
   "source": [
    "Learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "PcFYu2WqOzxS"
   },
   "outputs": [],
   "source": [
    "def adaboost_inference(x_test):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'adaboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def nn_inference( x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros((x_test.shape[0],))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = load_model(f'neuralnetwork_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.h5')\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        pred = pred.flatten()  # 1 次元の配列に変換する\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def lightgbm_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'lightgbm_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "def xgboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'xgboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict(xgb.DMatrix(x_test))\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def catboost_inference(x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros(len(x_test))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = pickle.load(open(f'catboost_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'rb'))\n",
    "        # Predict\n",
    "        pred = model.predict_proba(x_test)[:, 1]\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def gradient_boosting_model_inference(method: str):\n",
    "    x_test_lgb = test_df_lgb[features_lgb]\n",
    "    x_test_ctb = test_df_ctb[features_ctb]\n",
    "    x_test_nn = test_df_nn[features_nn]\n",
    "    if method == 'adaboost':\n",
    "        test_pred = adaboost_inference(x_test_ctb)\n",
    "    if method == 'neuralnetwork':\n",
    "        test_pred = nn_inference(x_test_nn)\n",
    "    if method == 'lightgbm':\n",
    "        test_pred = lightgbm_inference(x_test_ctb)\n",
    "    if method == 'xgboost':\n",
    "        test_pred = xgboost_inference(x_test_ctb)\n",
    "    if method == 'catboost':\n",
    "        test_pred = catboost_inference(x_test_ctb)\n",
    "    return test_pred\n",
    "\n",
    "def Predicting():\n",
    "    output_df = test_df_lgb.copy()\n",
    "    output_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method)\n",
    "        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "id": "mGMj6OftPMpC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323/1323 [==============================] - 11s 8ms/step\n",
      "1323/1323 [==============================] - 10s 8ms/step\n",
      "1323/1323 [==============================] - 7s 5ms/step\n",
      "1323/1323 [==============================] - 10s 7ms/step\n",
      "1323/1323 [==============================] - 10s 7ms/step\n",
      "1323/1323 [==============================] - 10s 8ms/step\n",
      "1323/1323 [==============================] - 10s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "test_df_lgb = Predicting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "id": "k11-nGPEZS1h"
   },
   "outputs": [],
   "source": [
    "#後処理の定義\n",
    "def Postprocessing():\n",
    "    train_df_lgb['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "        train_df_lgb['pred_prob'] += CFG.model_weight_dict[method] * oof_df[f'{method}_prediction']\n",
    "    best_score = 0\n",
    "    best_v = 0\n",
    "    for v in tqdm(np.arange(1000) / 1000):\n",
    "        score = f1_score(oof_df[CFG.target_col], train_df_lgb[f'pred_prob'] >= v, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_v = v\n",
    "    print(best_score, best_v)\n",
    "    test_df_lgb['target'] = np.where(test_df_lgb['pred_prob'] >= best_v, 1, 0)\n",
    "    return train_df_lgb, test_df_lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "ef58b4abcf0f43cd90a523a3875a2f28",
      "6f14799525cf44158bbffc0e9a08891b",
      "d239d2ff297a4c00aa350f8699ca6bb1",
      "76ddf1599bb144b2a6b4573027c6f662",
      "6762ef5aab7e4d18b98e7d837dedc03f",
      "b7dceec9910a46cea90915015ca58358",
      "573ab758539147f1a2bc21ac9f0347ce",
      "5de7c5cebd814e1caa8437775031ea12",
      "b0ab4a4e03b242e2ae3610b6a52b5c14",
      "4074a8c3b85548ed9424375a19416c7d",
      "13858cd0c554419bb867071b5c810b30"
     ]
    },
    "id": "q3P87swwPqf2",
    "outputId": "8d624fd1-4808-44f9-d59b-982a93d06ad5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feae2ff6ef0e4471b3805013b727b8c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#後処理\n",
    "train_df, test_df = Postprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "hK_3WqNDT0yj"
   },
   "outputs": [],
   "source": [
    "test_df[['target']].to_csv(f'seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.799, Best F1 Score: 0.687874789833567\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# OOF予測を基に新たな特徴量を作成\n",
    "oof_features = np.zeros((train_df.shape[0], len(CFG.METHOD_LIST)))\n",
    "for i, method in enumerate(CFG.METHOD_LIST):\n",
    "    oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "    oof_features[:, i] = oof_df[f'{method}_prediction']\n",
    "\n",
    "# テストデータの予測を基に特徴量を作成\n",
    "test_features = np.zeros((test_df.shape[0], len(CFG.METHOD_LIST)))\n",
    "for i, method in enumerate(CFG.METHOD_LIST):\n",
    "    test_features[:, i] = test_df[f'{method}_pred_prob']\n",
    "\n",
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "oof_features_scaled = scaler.fit_transform(oof_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# ロジスティック回帰モデルを学習\n",
    "lr = LogisticRegression()\n",
    "lr.fit(oof_features_scaled, train_df[CFG.target_col])\n",
    "\n",
    "# 最適な閾値とその時のF1スコアを探索する関数\n",
    "def find_best_threshold_and_score(y_true, y_pred_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in np.linspace(0, 1, 1001):  # 0.001刻みで閾値を変更\n",
    "        score = f1_score(y_true, y_pred_proba >= threshold, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# 学習データに対する予測確率\n",
    "train_pred_proba = lr.predict_proba(oof_features_scaled)[:, 1]\n",
    "\n",
    "# 最適な閾値とスコアを求める\n",
    "best_threshold, best_score = find_best_threshold_and_score(train_df[CFG.target_col], train_pred_proba)\n",
    "print(f'Best Threshold: {best_threshold}, Best F1 Score: {best_score}')\n",
    "\n",
    "# テストデータに対する最終予測\n",
    "test_pred_proba = lr.predict_proba(test_features_scaled)[:, 1]\n",
    "test_final_predictions = (test_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# 最終予渲結果をコンペ提出用のフォーマットでCSVファイルに出力\n",
    "submission_df = pd.DataFrame({'Id': test_df.index, 'target': test_final_predictions}).reset_index(drop=True)\n",
    "# ここで、インデックスの開始が42307であるため、その値から始めるように調整\n",
    "submission_df['Id'] = submission_df.index + 42307\n",
    "\n",
    "submission_df.to_csv(f'stacking_lr_submission_best_score{best_score:.4f}_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13858cd0c554419bb867071b5c810b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4074a8c3b85548ed9424375a19416c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573ab758539147f1a2bc21ac9f0347ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5de7c5cebd814e1caa8437775031ea12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6762ef5aab7e4d18b98e7d837dedc03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f14799525cf44158bbffc0e9a08891b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7dceec9910a46cea90915015ca58358",
      "placeholder": "​",
      "style": "IPY_MODEL_573ab758539147f1a2bc21ac9f0347ce",
      "value": "100%"
     }
    },
    "76ddf1599bb144b2a6b4573027c6f662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4074a8c3b85548ed9424375a19416c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_13858cd0c554419bb867071b5c810b30",
      "value": " 1000/1000 [00:19&lt;00:00, 37.91it/s]"
     }
    },
    "b0ab4a4e03b242e2ae3610b6a52b5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7dceec9910a46cea90915015ca58358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d239d2ff297a4c00aa350f8699ca6bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de7c5cebd814e1caa8437775031ea12",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0ab4a4e03b242e2ae3610b6a52b5c14",
      "value": 1000
     }
    },
    "ef58b4abcf0f43cd90a523a3875a2f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f14799525cf44158bbffc0e9a08891b",
       "IPY_MODEL_d239d2ff297a4c00aa350f8699ca6bb1",
       "IPY_MODEL_76ddf1599bb144b2a6b4573027c6f662"
      ],
      "layout": "IPY_MODEL_6762ef5aab7e4d18b98e7d837dedc03f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
