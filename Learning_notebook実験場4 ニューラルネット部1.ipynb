{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# ====================================================\n",
    "# Library\n",
    "# ====================================================\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import pickle\n",
    "import itertools\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, GroupKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import category_encoders as ce\n",
    "import lightgbm as lgb\n",
    "#import optuna.integration.lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import Pool, CatBoostRegressor, CatBoostClassifier\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch.optim as optim\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import clone_model\n",
    "\n",
    "pd.set_option('display.max_columns',1000)\n",
    "pd.set_option('display.max_rows',100)\n",
    "\n",
    "# ====================================================\n",
    "# Configurations\n",
    "# ====================================================\n",
    "class CFG:\n",
    "    VER = 7.1\n",
    "    AUTHOR = 'naokisusami'\n",
    "    COMPETITION = 'FDUA2'\n",
    "    DATA_PATH = Path('/data')\n",
    "    OOF_DATA_PATH = Path('/oof')\n",
    "    MODEL_DATA_PATH = Path('/models')\n",
    "    SUB_DATA_PATH = Path('/submission')\n",
    "    METHOD_LIST = [ 'neuralnetwork']\n",
    "    seed = 42\n",
    "    n_folds = 7\n",
    "    target_col = 'MIS_Status'\n",
    "    metric = 'f1_score'\n",
    "    metric_maximize_flag = True\n",
    "    num_boost_round = 500\n",
    "    early_stopping_round = 200\n",
    "    verbose = 25\n",
    "    classification_lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'learning_rate': 0.05,\n",
    "        'seed': seed,\n",
    "    }\n",
    "    classification_xgb_params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'learning_rate': 0.05,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    classification_cat_params = {\n",
    "        'learning_rate': 0.05,\n",
    "        'iterations': num_boost_round,\n",
    "        'random_seed': seed,\n",
    "    }\n",
    "    classification_adaboost_params = {\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 1.0,\n",
    "        'random_state': seed,\n",
    "    }\n",
    "\n",
    "    model_weight_dict = {'lightgbm': 0.50, 'xgboost': 0.10, 'catboost': 0.40, 'adaboost': 0.10, 'neuralnetwork': 1.00}\n",
    "# ====================================================\n",
    "# Seed everything\n",
    "# ====================================================\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "seed_everything(CFG.seed)\n",
    "\n",
    "\n",
    "# ====================================================\n",
    "# Metric\n",
    "# ====================================================\n",
    "# f1_score\n",
    "\n",
    "# ====================================================\n",
    "# LightGBM Metric\n",
    "# ====================================================\n",
    "def lgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro'), CFG.metric_maximize_flag\n",
    "\n",
    "# ====================================================\n",
    "# XGBoost Metric\n",
    "# ====================================================\n",
    "def xgb_metric(y_pred, y_true):\n",
    "    y_true = y_true.get_label()\n",
    "    return 'f1score', f1_score(y_true, np.where(y_pred >= 0.5, 1, 0), average='macro')\n",
    "\n",
    "class MacroF1ScoreCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super(MacroF1ScoreCallback, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        print(f'Epoch {epoch+1}: val_macro_f1: {_val_f1}')\n",
    "    \n",
    "def f1_score_nn(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.round(K.flatten(y_pred))\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    fn = K.sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    return f1\n",
    "\n",
    "def macro_f1_score_nn(y_true, y_pred):\n",
    "    y_true = K.flatten(y_true)\n",
    "    y_pred = K.round(K.flatten(y_pred))\n",
    "    tp = K.sum(y_true * y_pred)\n",
    "    fp = K.sum((1 - y_true) * y_pred)\n",
    "    fn = K.sum(y_true * (1 - y_pred))\n",
    "    precision = tp / (tp + fp + K.epsilon())\n",
    "    recall = tp / (tp + fn + K.epsilon())\n",
    "    f1 = 2 * precision * recall / (precision + recall + K.epsilon())\n",
    "    \n",
    "    # Calculate F1 score for each class\n",
    "    f1_per_class = []\n",
    "    for c in range(tf.shape(y_true)[-1]):\n",
    "        true_positives = K.sum(K.cast(y_true[:, c] * K.round(y_pred[:, c]), 'float'), axis=0)\n",
    "        possible_positives = K.sum(K.cast(y_true[:, c], 'float'), axis=0)\n",
    "        predicted_positives = K.sum(K.cast(K.round(y_pred[:, c]), 'float'), axis=0)\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        f1_per_class.append(2 * precision * recall / (precision + recall + K.epsilon()))\n",
    "        \n",
    "class CustomEarlyStoppingAndRestoreBestWeights(Callback):\n",
    "    def __init__(self, validation_data, patience=10):\n",
    "        super(CustomEarlyStoppingAndRestoreBestWeights, self).__init__()\n",
    "        self.validation_data = validation_data\n",
    "        self.patience = patience\n",
    "        self.best_weights = None\n",
    "        self.best_epoch = 0\n",
    "        self.best_f1 = 0.0\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_predict = (np.asarray(self.model.predict(self.validation_data[0]))).round()\n",
    "        val_targ = self.validation_data[1]\n",
    "        _val_f1 = f1_score(val_targ, val_predict, average='macro')\n",
    "        print(f'Epoch {epoch+1}: val_macro_f1: {_val_f1}')\n",
    "        \n",
    "        if _val_f1 > self.best_f1:\n",
    "            self.best_f1 = _val_f1\n",
    "            self.best_epoch = epoch\n",
    "            self.wait = 0\n",
    "            self.best_weights = clone_model(self.model).get_weights()\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.model.stop_training = True\n",
    "                print(f\"Restoring model weights from the end of the best epoch: {self.best_epoch+1}.\")\n",
    "                self.model.set_weights(self.best_weights)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "id": "g6R4KoxhL91E",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIS_Status\n",
      "City\n",
      "ApprovalDate\n",
      "BankState\n",
      "DisbursementDate\n",
      "ApprovalDay\n",
      "ApprovalMonth\n",
      "ApprovalFY\n",
      "ApprovalYear\n",
      "DisbursementDay\n",
      "DisbursementMonth\n",
      "MIS_Status\n",
      "City\n",
      "ApprovalDate\n",
      "BankState\n",
      "DisbursementDate\n",
      "ApprovalDay\n",
      "ApprovalMonth\n",
      "ApprovalFY\n",
      "ApprovalYear\n",
      "DisbursementDay\n",
      "DisbursementMonth\n",
      "           Term     NoEmp  NewExist  CreateJob  RetainedJob  FranchiseCode  \\\n",
      "0      0.643243  0.645918  0.516224  -0.428693    -0.428684      -0.185372   \n",
      "1     -0.290907 -0.211822  0.516224   0.356557    -0.428684      -0.185467   \n",
      "2      1.577393  2.018302  0.516224   0.356557    10.663868      -0.185467   \n",
      "3      1.518270 -0.326187  0.516224  -0.428693    -0.428684      -0.185467   \n",
      "4      0.891561 -0.554918  0.516224  -0.428693    -0.428684      -0.185467   \n",
      "...         ...       ...       ...        ...          ...            ...   \n",
      "42302  2.062205  0.245639  0.516224  -0.428693    -0.428684      -0.185372   \n",
      "42303 -0.657472 -0.440553  0.516224  -0.428693    -0.428684      -0.185467   \n",
      "42304 -0.586524 -0.211822 -1.937144  -0.428693    -0.428684      -0.185372   \n",
      "42305  2.204102  0.474370  0.516224  -0.428693     0.557321      -0.185467   \n",
      "42306 -0.290907 -0.326187  0.516224  -0.428693     0.557321      -0.185467   \n",
      "\n",
      "       RevLineCr_1.0  RevLineCr_0.0  RevLineCr_4.0  RevLineCr_3.0  \\\n",
      "0                  1              0              0              0   \n",
      "1                  0              1              0              0   \n",
      "2                  1              0              0              0   \n",
      "3                  1              0              0              0   \n",
      "4                  1              0              0              0   \n",
      "...              ...            ...            ...            ...   \n",
      "42302              1              0              0              0   \n",
      "42303              0              0              1              0   \n",
      "42304              1              0              0              0   \n",
      "42305              1              0              0              0   \n",
      "42306              1              0              0              0   \n",
      "\n",
      "       RevLineCr_2.0  LowDoc_3.0  LowDoc_2.0  LowDoc_5.0  LowDoc_6.0  \\\n",
      "0                  0           1           0           0           0   \n",
      "1                  0           1           0           0           0   \n",
      "2                  0           1           0           0           0   \n",
      "3                  0           1           0           0           0   \n",
      "4                  0           1           0           0           0   \n",
      "...              ...         ...         ...         ...         ...   \n",
      "42302              0           1           0           0           0   \n",
      "42303              0           1           0           0           0   \n",
      "42304              0           1           0           0           0   \n",
      "42305              0           1           0           0           0   \n",
      "42306              0           1           0           0           0   \n",
      "\n",
      "       LowDoc_0.0  LowDoc_4.0  LowDoc_1.0  DisbursementDate    Sector  \\\n",
      "0               0           0           0               847 -1.158439   \n",
      "1               0           0           0               638  1.785958   \n",
      "2               0           0           0               232  0.019320   \n",
      "3               0           0           0               386 -0.127900   \n",
      "4               0           0           0               427 -1.158439   \n",
      "...           ...         ...         ...               ...       ...   \n",
      "42302           0           0           0               847 -1.158439   \n",
      "42303           0           0           0               605  0.019320   \n",
      "42304           0           0           0               270  0.019320   \n",
      "42305           0           0           0               800  0.019320   \n",
      "42306           0           0           0               534  2.080397   \n",
      "\n",
      "       ApprovalDate  ApprovalFY  City     State  BankState  DisbursementGross  \\\n",
      "0              2084        2006  2208 -1.423718         42          -0.399474   \n",
      "1              3265        1992  1723  0.698629         36           0.432786   \n",
      "2              1232        2001  1214  0.377061         31          -0.592531   \n",
      "3              3793        2004  1906  1.084510         42           0.199592   \n",
      "4              1126        2000  2246 -1.359404          4           1.389684   \n",
      "...             ...         ...   ...       ...        ...                ...   \n",
      "42302          1603        1995  2207  0.827256         38          -0.399474   \n",
      "42303          3756        2007  1594 -1.359404         42          -0.701018   \n",
      "42304           747        2003   580  0.634315         35          -0.479886   \n",
      "42305          2117        1989   547 -0.137447         23           0.460930   \n",
      "42306           379        2011  2489 -1.359404         27          -0.449732   \n",
      "\n",
      "         GrAppv  SBA_Appv  UrbanRural  DisbursementDay  DisbursementMonth  \\\n",
      "0     -0.379998 -0.338594   -0.789495               31                  1   \n",
      "1      0.457168  0.447553   -0.789495               31                 10   \n",
      "2     -0.582212 -0.596427    0.558359               31                  8   \n",
      "3      0.222600  0.444634   -0.789495               31                  8   \n",
      "4      1.419706  1.246104   -0.789495                8                  6   \n",
      "...         ...       ...         ...              ...                ...   \n",
      "42302 -0.379998 -0.338594   -0.789495               31                  1   \n",
      "42303 -0.683319 -0.648723    0.558359                3                  4   \n",
      "42304 -0.460884 -0.421295   -0.789495               28                  2   \n",
      "42305  0.485478  0.403283   -0.789495               10                 12   \n",
      "42306 -0.430552 -0.423119   -0.789495               31                 10   \n",
      "\n",
      "       DisbursementYear  ApprovalDay  ApprovalMonth  ApprovalYear  \\\n",
      "0             -0.467855           22              9             6   \n",
      "1             -1.196781           30              6            -8   \n",
      "2             -0.030500           18              4             1   \n",
      "3              0.844211            6             10             3   \n",
      "4             -2.654632           17             12            -1   \n",
      "...                 ...          ...            ...           ...   \n",
      "42302         -0.467855            2              3            -5   \n",
      "42303         -1.488351            6              6             7   \n",
      "42304          0.261071           14              3             3   \n",
      "42305         -0.613640           23              8           -11   \n",
      "42306         -1.779921           12              4            11   \n",
      "\n",
      "       CompanyLong  ApprovalTerm  DisbursementTerm  EconomyGrowth_By_Year  \\\n",
      "0        -0.888012     -0.761411          0.467855               0.434452   \n",
      "1         0.116853      1.627481          1.196781               1.293286   \n",
      "2         0.005202      0.091765          0.030500               0.484761   \n",
      "3         0.451809     -0.420141         -0.844211              -1.410783   \n",
      "4        -1.781226      0.262400          2.654632               1.904172   \n",
      "...            ...           ...               ...                    ...   \n",
      "42302     0.340157      1.115576          0.467855               0.434452   \n",
      "42303    -1.781226     -0.932046          1.488351               0.869260   \n",
      "42304     0.005202     -0.249506         -0.261071               0.058937   \n",
      "42305     0.898416      2.139386          0.613640               0.682400   \n",
      "42306    -2.451137     -1.614587          1.779921               0.030190   \n",
      "\n",
      "       Bankraptcy_By_Year  Unemploymentrate_By_Year  Interestrate_By_Year  \\\n",
      "0               -0.456812                 -0.835666              0.287011   \n",
      "1                1.184805                 -0.567823              1.168808   \n",
      "2               -0.687010                 -0.465412             -0.239917   \n",
      "3                0.636646                  1.834890             -1.358294   \n",
      "4                3.318918                  0.503551              2.620548   \n",
      "...                   ...                       ...                   ...   \n",
      "42302           -0.456812                 -0.835666              0.287011   \n",
      "42303            1.910843                  0.259340              0.684895   \n",
      "42304           -1.230262                 -0.733256              0.200982   \n",
      "42305           -0.160852                 -1.111387              0.738663   \n",
      "42306            2.537876                  0.440529              0.792431   \n",
      "\n",
      "       Inflationrate_By_Year  Unemployment_By_State  GDP_By_State  \\\n",
      "0                  -0.020816               0.530831     -0.636054   \n",
      "1                  -0.035181              -0.707438     -1.192072   \n",
      "2                   0.295214              -0.552655      0.878150   \n",
      "3                  -0.713928              -0.243087     -0.624495   \n",
      "4                   1.728124               0.685615      0.522617   \n",
      "...                      ...                    ...           ...   \n",
      "42302              -0.020816               0.995182     -0.437030   \n",
      "42303               0.726165               0.685615      0.522617   \n",
      "42304               1.297174               0.685615     -0.584903   \n",
      "42305              -0.290160              -1.171789      0.386701   \n",
      "42306               2.123162               0.685615      0.522617   \n",
      "\n",
      "       GDPperPerson_By_State  AveSalary_By_State       BCI  \\\n",
      "0                  -0.156982           -0.416051 -0.946043   \n",
      "1                  -0.963001           -1.075428  0.053940   \n",
      "2                   0.586813            1.189141  0.019457   \n",
      "3                  -0.704872           -0.915192  0.111410   \n",
      "4                   0.400657            1.101224  0.019457   \n",
      "...                      ...                 ...       ...   \n",
      "42302              -0.665359           -0.316790  0.260832   \n",
      "42303               0.400657            1.101224 -0.164447   \n",
      "42304              -0.890716           -0.692564  0.019457   \n",
      "42305               0.224768           -0.190587  0.847029   \n",
      "42306               0.400657            1.101224 -0.486281   \n",
      "\n",
      "       DisbursementGrossPerMonth  SBA_Appv-DisbursementGross  \\\n",
      "0                      -0.150790                    0.348687   \n",
      "1                      -0.035776                   -0.183318   \n",
      "2                      -0.164972                    0.290295   \n",
      "3                      -0.131902                    0.489305   \n",
      "4                      -0.057222                   -1.048705   \n",
      "...                          ...                         ...   \n",
      "42302                  -0.158996                    0.348687   \n",
      "42303                  -0.166525                    0.480516   \n",
      "42304                  -0.130396                    0.383841   \n",
      "42305                  -0.130665                   -0.371980   \n",
      "42306                  -0.138594                    0.291561   \n",
      "\n",
      "       DisbursementGrossPerNoEmp  DisbursementGrossPerEmp        TI       TI2  \\\n",
      "0                      -0.467973                -0.439885 -0.111339 -0.106998   \n",
      "1                       0.013984                -0.118164 -0.079156 -0.076365   \n",
      "2                      -0.505910                -0.482821 -0.113547 -0.109378   \n",
      "3                       0.075900                 0.164221 -0.092098 -0.083543   \n",
      "4                       6.257150                 7.030033  0.206855  0.178032   \n",
      "...                          ...                      ...       ...       ...   \n",
      "42302                  -0.446084                -0.415571 -0.111722 -0.107388   \n",
      "42303                  -0.493380                -0.468106 -0.110357 -0.106000   \n",
      "42304                  -0.404315                -0.369177 -0.097700 -0.093138   \n",
      "42305                  -0.315282                -0.270284 -0.107937 -0.104247   \n",
      "42306                  -0.340741                -0.298562 -0.095896 -0.093450   \n",
      "\n",
      "       MIS_Status  \n",
      "0               1  \n",
      "1               1  \n",
      "2               1  \n",
      "3               1  \n",
      "4               1  \n",
      "...           ...  \n",
      "42302           1  \n",
      "42303           1  \n",
      "42304           1  \n",
      "42305           1  \n",
      "42306           1  \n",
      "\n",
      "[42307 rows x 55 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42307 entries, 0 to 42306\n",
      "Data columns (total 55 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   Term                        42307 non-null  float64\n",
      " 1   NoEmp                       42307 non-null  float64\n",
      " 2   NewExist                    42307 non-null  float64\n",
      " 3   CreateJob                   42307 non-null  float64\n",
      " 4   RetainedJob                 42307 non-null  float64\n",
      " 5   FranchiseCode               42307 non-null  float64\n",
      " 6   RevLineCr_1.0               42307 non-null  int64  \n",
      " 7   RevLineCr_0.0               42307 non-null  int64  \n",
      " 8   RevLineCr_4.0               42307 non-null  int64  \n",
      " 9   RevLineCr_3.0               42307 non-null  int64  \n",
      " 10  RevLineCr_2.0               42307 non-null  int64  \n",
      " 11  LowDoc_3.0                  42307 non-null  int64  \n",
      " 12  LowDoc_2.0                  42307 non-null  int64  \n",
      " 13  LowDoc_5.0                  42307 non-null  int64  \n",
      " 14  LowDoc_6.0                  42307 non-null  int64  \n",
      " 15  LowDoc_0.0                  42307 non-null  int64  \n",
      " 16  LowDoc_4.0                  42307 non-null  int64  \n",
      " 17  LowDoc_1.0                  42307 non-null  int64  \n",
      " 18  DisbursementDate            42307 non-null  int32  \n",
      " 19  Sector                      42307 non-null  float64\n",
      " 20  ApprovalDate                42307 non-null  int32  \n",
      " 21  ApprovalFY                  42307 non-null  int64  \n",
      " 22  City                        42307 non-null  int32  \n",
      " 23  State                       42307 non-null  float64\n",
      " 24  BankState                   42307 non-null  int32  \n",
      " 25  DisbursementGross           42307 non-null  float64\n",
      " 26  GrAppv                      42307 non-null  float64\n",
      " 27  SBA_Appv                    42307 non-null  float64\n",
      " 28  UrbanRural                  42307 non-null  float64\n",
      " 29  DisbursementDay             42307 non-null  int32  \n",
      " 30  DisbursementMonth           42307 non-null  int64  \n",
      " 31  DisbursementYear            42307 non-null  float64\n",
      " 32  ApprovalDay                 42307 non-null  int32  \n",
      " 33  ApprovalMonth               42307 non-null  int64  \n",
      " 34  ApprovalYear                42307 non-null  int64  \n",
      " 35  CompanyLong                 42307 non-null  float64\n",
      " 36  ApprovalTerm                42307 non-null  float64\n",
      " 37  DisbursementTerm            42307 non-null  float64\n",
      " 38  EconomyGrowth_By_Year       42307 non-null  float64\n",
      " 39  Bankraptcy_By_Year          42307 non-null  float64\n",
      " 40  Unemploymentrate_By_Year    42307 non-null  float64\n",
      " 41  Interestrate_By_Year        42307 non-null  float64\n",
      " 42  Inflationrate_By_Year       42307 non-null  float64\n",
      " 43  Unemployment_By_State       42307 non-null  float64\n",
      " 44  GDP_By_State                42307 non-null  float64\n",
      " 45  GDPperPerson_By_State       42307 non-null  float64\n",
      " 46  AveSalary_By_State          42307 non-null  float64\n",
      " 47  BCI                         42307 non-null  float64\n",
      " 48  DisbursementGrossPerMonth   42307 non-null  float64\n",
      " 49  SBA_Appv-DisbursementGross  42307 non-null  float64\n",
      " 50  DisbursementGrossPerNoEmp   42307 non-null  float64\n",
      " 51  DisbursementGrossPerEmp     42307 non-null  float64\n",
      " 52  TI                          42307 non-null  float64\n",
      " 53  TI2                         42307 non-null  float64\n",
      " 54  MIS_Status                  42307 non-null  int64  \n",
      "dtypes: float64(32), int32(6), int64(17)\n",
      "memory usage: 17.1 MB\n",
      "['Term', 'NoEmp', 'NewExist', 'CreateJob', 'RetainedJob', 'FranchiseCode', 'RevLineCr_1.0', 'RevLineCr_0.0', 'RevLineCr_4.0', 'RevLineCr_3.0', 'RevLineCr_2.0', 'LowDoc_3.0', 'LowDoc_2.0', 'LowDoc_5.0', 'LowDoc_6.0', 'LowDoc_0.0', 'LowDoc_4.0', 'LowDoc_1.0', 'Sector', 'State', 'DisbursementGross', 'GrAppv', 'SBA_Appv', 'UrbanRural', 'DisbursementYear', 'CompanyLong', 'ApprovalTerm', 'DisbursementTerm', 'EconomyGrowth_By_Year', 'Bankraptcy_By_Year', 'Unemploymentrate_By_Year', 'Interestrate_By_Year', 'Inflationrate_By_Year', 'Unemployment_By_State', 'GDP_By_State', 'GDPperPerson_By_State', 'AveSalary_By_State', 'BCI', 'DisbursementGrossPerMonth', 'SBA_Appv-DisbursementGross', 'DisbursementGrossPerNoEmp', 'DisbursementGrossPerEmp', 'TI', 'TI2']\n"
     ]
    }
   ],
   "source": [
    "#データの読み込み\n",
    "train_df = pd.read_csv('train.csv', index_col=0)\n",
    "test_df = pd.read_csv('test.csv', index_col=0)\n",
    "categorical_features = ['RevLineCr', 'LowDoc', 'UrbanRural', 'State', 'Sector']\n",
    "#前処理メソッドの定義\n",
    "def Preprocessing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "    #欠損値に対する処理\n",
    "    def deal_missing(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['RevLineCr', 'LowDoc', 'BankState']:\n",
    "            df[col] = input_df[col].fillna('UNK')\n",
    "        for col in ['DisbursementDate','ApprovalDate']:\n",
    "            df[col] = input_df[col].fillna('50-NaN-50')\n",
    "        \n",
    "        return df\n",
    "    #金額に対する前処理\n",
    "    def clean_money(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        for col in ['DisbursementGross', 'GrAppv', 'SBA_Appv']:\n",
    "            df[col] = input_df[col].str[1:].str.replace(',', '').str.replace(' ', '').astype(float)\n",
    "        return df\n",
    "    df = deal_missing(input_df)\n",
    "    df = clean_money(df)\n",
    "    df['NewExist'] = np.where(input_df['NewExist'] == 1, 1, 0)\n",
    "    #特徴量作成\n",
    "    def make_features(input_df: pd.DataFrame()) -> pd.DataFrame():\n",
    "        df = input_df.copy()\n",
    "        #日付関係の特徴量作成\n",
    "        df[['DisbursementDay','DisbursementMonth','DisbursementYear']] = df['DisbursementDate'].str.split('-',expand=True)\n",
    "        df[['ApprovalDay','ApprovalMonth','ApprovalYear']] = df['ApprovalDate'].str.split('-',expand=True)\n",
    "        df['DisbursementDay'] = df['DisbursementDay'].astype(int)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].astype(int)\n",
    "        df['ApprovalDay'] = df['ApprovalDay'].astype(int)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].astype(int)\n",
    "        Month_dict = {'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12,'NaN':50}\n",
    "        df['DisbursementMonth'] = df['DisbursementMonth'].map(Month_dict)\n",
    "        df['ApprovalMonth'] = df['ApprovalMonth'].map(Month_dict)\n",
    "        df['DisbursementDate'] = df['DisbursementYear'].astype(str)+df['DisbursementMonth'].astype(str)+df['DisbursementDay'].astype(str)\n",
    "        df['DisbursementYear'] = df['DisbursementYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['ApprovalYear'] = df['ApprovalYear'].apply(lambda x:x - 100 if x >50 else x)\n",
    "        df['CompanyLong'] = df['DisbursementYear'] - df['ApprovalYear']\n",
    "        df['ApprovalTerm'] = 15 - df['ApprovalFY']\n",
    "        df['DisbursementTerm'] = 15 - df['DisbursementYear']\n",
    "\n",
    "\n",
    "        #経済成長率\n",
    "        EconomyGrowthdata={-26:-0.6,-25:-0.4,-24:5.6,-23:4.6,-22:5.5,-21:3.2,-20:-0.26,-19:2.54,-18:-1.8,-17:4.58,-16:7.24,-15:4.17,\n",
    "                           -14:3.46,-13:3.46,-12:4.18,-11:3.67,-10:1.89,-9:-0.11,-8:3.52,-7:2.75,-6:4.03,-5:2.68,-4:3.77,-3:4.45,\n",
    "                           -2:4.18,-1:4.8,0:4.08,1:0.95,2:1.7,3:2.8,4:3.85,5:3.48,6:2.78,7: 2.01,8:0.12,9:-2.6,10:2.71,11:1.55,12:2.28,\n",
    "                           13:1.84,14:2.29,15:2.71,16:1.67,17:2.24,18:2.95,19:2.30}\n",
    "        #Bankraptdataの74~80は生成したもので実際の数値ではない。(失業率から換算して生成)\n",
    "        Bankraptcydata={-26:32700,-25:52200,-24:46200,-23:42300,-22:36300,-21:34200,-20:46200,-19:44000,-18:48500,-17:69800,-16:62500,\n",
    "                      -15:64500,-14:72000,-13:81500,-12:83000,-11:64500,-10:65000,-9:67000,-8:71000,-7:67000,-6:58000,-5:51000,\n",
    "                        -4:52500,-3:54000,-2:51000,-1:41000,0:37500,1:35992,2:39845,3:37548,4:36785,5:31952,6:35292,7:21960,8:30741,\n",
    "                        9:49091,10:61148,11:54212,12:46393,13:37552,14:31671,15:26130,16:24797,17:23591,18:23106,19:22157}\n",
    "        #失業率\n",
    "        Unemploymentratedata={-26:5.45,-25:8.7,-24:7.7,-23:7.05,-22:6.05,-21:5.7,-20:7.7,-19:7.35,-18:9.7,-17:9.75,-16:7.35,-15:7.4,\n",
    "                              -14:7.1,-13:6.15,-12:5.4,-11:5.25,-10:5.35,-9:6.85,-8:7.75,-7:6.95,-6:6.1,-5:5.65,-4:5.4,-3:4.95,-2:4.5,\n",
    "                              -1:4.3,0:4.0,1:4.55,2:5.8,3:6.25,4:5.55,5:5.0,6:4.65,7:4.65,8:5.7,9:9.5,10:9.4,11:9.05,12:8.2,13:7.4,\n",
    "                              14:6.15,15:5.25,16:4.9,17:4.3,18:3.9,19:3.6}\n",
    "        #金利\n",
    "        Interestratedata={-26:10,-25:7,-24:5,-23:7,-22:8.5,-21:12,-20:15,-19:15,-18:14,-17:9,-16:10,-15:8.5,\n",
    "                              -14:7,-13:6.5,-12:8,-11:9,-10:7,-9:5.5,-8:3.5,-7:3,-6:4,-5:6,-4:5.5,-3:5.7,-2:5.3,\n",
    "                              -1:5,0:6.1,1:4.3,2:1.8,3:1.1,4:1.8,5:3.5,6:5.2,7:5,8:2,9:0.25,10:0.25,11:0.25,12:0.25,13:0.25,\n",
    "                              14:0.25,15:0.25,16:0.5,17:1,18:2,19:2.2}\n",
    "        #インフレ率\n",
    "        Inflationratedata={-26:11,-25:9,-24:5,-23:7,-22:8,-21:12,-20:13.5,-19:10.38,-18:6.16,-17:3.16,-16:4.37,-15:3.16,\n",
    "                           -14:1.94,-13:3.58,-12:4.1,-11:4.79,-10:5.42,-9:4.22,-8:3.04,-7:2.97,-6:2.6,-5:2.81,-4:2.94,-3:2.34,\n",
    "                           -2:1.55,-1:2.19,0:3.37,1:2.82,2:1.6,3:2.3,4:2.67,5:3.37,6:3.22,7:2.87,8:3.82,9:-0.32,10:1.64,11:3.14,12:2.07,\n",
    "                           13:1.47,14:1.62,15:0.12,16:1.27,17:2.13,18:2.44,19:1.81}\n",
    "        #年ごとのデータを、1-5年後の平均に変換\n",
    "        datalist = [EconomyGrowthdata,Bankraptcydata,Unemploymentratedata,Interestratedata,Inflationratedata]\n",
    "        for k in datalist:\n",
    "            for i in range(len(k)-5):\n",
    "                k[-27+i] = 0\n",
    "                for j in range(5):\n",
    "                    k[-27+i] += k[-26+i+j]\n",
    "                k[-27+i] = k[-27+i]/5\n",
    "            k[50] = sum(k.values()) / len(k)\n",
    "        \n",
    "        df['EconomyGrowth_By_Year'] = df['DisbursementYear'].map(EconomyGrowthdata)\n",
    "        df['Bankraptcy_By_Year'] = df['DisbursementYear'].map(Bankraptcydata)\n",
    "        df['Unemploymentrate_By_Year'] = df['DisbursementYear'].map(Unemploymentratedata)\n",
    "        df['Interestrate_By_Year'] = df['DisbursementYear'].map(Interestratedata)\n",
    "        df['Inflationrate_By_Year'] = df['DisbursementYear'].map(Inflationratedata)\n",
    "        \n",
    "        #State関係の特徴量作成\n",
    "        StateList = ['AL','AK','AZ','AR','CA','CO','CT','DE','DC','FL','GA','HI','ID','IL','IN','IA','KS','KY','LA','ME','MD','MA',\n",
    "                      'MI','MN','MS','MO','MT','NE','NV','NH','NJ','NM','NY','NC','ND','OH','OK','OR','PA','RI','SC','SD','TN','TX',\n",
    "                      'UT','VT','VA','WA','WV','WI','WY']\n",
    "        \n",
    "        UnemploymentList = [2.6,3.7,4.0,3.4,4.1,2.8,4.0,4.6,4.2,2.7,3.1,3.7,2.8,4.6,3.1,3.0,2.9,3.9,3.5,3.1,3.0,3.7,4.3,2.9,4.0,\n",
    "                          2.7,2.6,2.7,5.5,2.9,3.3,3.5,4.1,3.8,2.1,4.1,3.2,4.8,4.3,3.2,3.3,2.2,3.5,3.8,2.4,3.0,3.1\n",
    "                            ,4.5,4.1,3.0,3.9]\n",
    "        \n",
    "        GDPList = [29603,44807,33655,27781,42376,40805,51911,56496,126421,33417,35265,38850,29843,39568,32724,35814,34770,30364,35181,\n",
    "                   30282,39596,47351,32846,41353,24477,32590,28201,37075,40210,37375,45052,30943,49038,37053,34694,34040,29470,\n",
    "                   38339,35153,36543,28894,35596,33742,37793,32774,34197,41617,40361,24929,34890,40303]\n",
    "        \n",
    "        GDPperPersonList = [37282,71008,48148,35674,53525,54943,63504,76720,164002,45958,48434,50788,39529,49083,40529,44091,43633,\n",
    "                       38148,48366,37734,50729,55364,38433,51829,31127,41012,37966,46803,63662,46400,55320,41878,58126,49625,43172,\n",
    "                       41073,40376,46248,43246,44738,38093,44955,42865,54766,47313,40312,54102,52810,31914,43309,63822]\n",
    "        \n",
    "        AveSalaryList = [40.46,50.81,45.40,37.79,56.10,49.79,60.14,49.66,79.85,43.66,46.17,44.09,36.45,51.71,40.97,38.39,40.96,\n",
    "                        39.54,43.15,39.06,54.28,58.62,45.19,46.99,35.95,42.58,35.81,39.87,44.38,46.38,56.72,40.91,61.04,43.11,41.12,\n",
    "                        43.45,40.75,43.46,46.10,46.38,39.63,35.00,41.88,48.35,41.11,39.54,52.07,51.04,38.48,41.46,44.03]\n",
    "        \n",
    "        Unemploymentdict = dict(zip(StateList,UnemploymentList))\n",
    "        GDPdict = dict(zip(StateList,GDPList))\n",
    "        GDPperPersondict = dict(zip(StateList,GDPperPersonList))\n",
    "        AveSalarydict = dict(zip(StateList,AveSalaryList))\n",
    "        \n",
    "        df['Unemployment_By_State'] = df['State'].map(Unemploymentdict)\n",
    "        df['GDP_By_State'] = df['State'].map(GDPdict)\n",
    "        df['GDPperPerson_By_State'] = df['State'].map(GDPperPersondict)\n",
    "        df['AveSalary_By_State'] = df['State'].map(AveSalarydict)\n",
    "        \n",
    "        #現状グループ分けされない特徴量の作成\n",
    "        #企業の安定さ、デカさ\n",
    "        df['BCI'] = df['CompanyLong']*(df['NoEmp'])*(df['NewExist']+1)\n",
    "        df['BCI'] = df['BCI'].fillna(df['BCI'].mean)\n",
    "        #一か月あたりの返済必要量\n",
    "        df['DisbursementGrossPerMonth'] = df['DisbursementGross']/(df['Term']+1)\n",
    "        #SBA承認より減らした額\n",
    "        df['SBA_Appv-DisbursementGross'] = df['SBA_Appv']-df['DisbursementGross']\n",
    "        #本来の従業員一人当たりの返済必要量\n",
    "        df['DisbursementGrossPerNoEmp'] = df['DisbursementGross']/(df['NoEmp']+1)\n",
    "        #雇用創出後の従業員一人当たりの返済必要量\n",
    "        df['DisbursementGrossPerEmp'] = df['DisbursementGross']/(df['NoEmp']+df['CreateJob']+1)\n",
    "        #しんどさ指数\n",
    "        df['TI'] = (df['DisbursementGross']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "        #しんどさ指数2\n",
    "        df['TI2'] = (df['SBA_Appv']/(df['NoEmp']+df['CreateJob']+1))/(df['Term']+1)\n",
    "\n",
    "\n",
    "        \n",
    "        return df\n",
    "    df = make_features(df)\n",
    "    return df\n",
    "\n",
    "#前処理の実行\n",
    "train_df = Preprocessing(train_df)\n",
    "test_df = Preprocessing(test_df)\n",
    "\n",
    "#ラベルエンコーディング\n",
    "for col in categorical_features :\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    \n",
    "categorical_features_unlabelable = ['City','ApprovalDate','BankState','DisbursementDate']\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    le = LabelEncoder()   \n",
    "    le.fit(train_df[col])\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    test_df[col] = test_df[col].apply(lambda x: le.transform([x])[0] if x in le.classes_ else len(le.classes_))\n",
    "'''\n",
    "for col in categorical_features_unlabelable:\n",
    "    encoder = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col], test_df[col]], axis=0)\n",
    "    encoder.fit(combined)\n",
    "    train_df[col] = encoder.transform(train_df[col])\n",
    "    test_df[col] = encoder.transform(test_df[col])\n",
    "    \n",
    "#OneHotEncoding\n",
    "train_df2 = train_df.drop(['MIS_Status'],axis=1)\n",
    "OneHotList = ['RevLineCr', 'LowDoc','State']\n",
    "ohe = ce.OneHotEncoder(cols=OneHotList,use_cat_names=True)\n",
    "train_df2 = ohe.fit_transform(train_df2)\n",
    "test_df = ohe.transform(test_df)\n",
    "train_df = pd.concat([train_df2,train_df['MIS_Status']],axis=1)\n",
    "\n",
    "\n",
    "for i in range(51):\n",
    "    OneHotedList.append(f'State_{i}.0')\n",
    "    \n",
    "for i in range(25):\n",
    "    OneHotedList.append(f'Sector_{i}.0')\n",
    "\n",
    "\n",
    "RemoveList=['MIS_Status','City','ApprovalDate','BankState','DisbursementDate','ApprovalDay','ApprovalMonth','ApprovalFY','ApprovalYear',\n",
    "           'DisbursementDay','DisbursementMonth']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "OneHotedList = ['RevLineCr_0.0','RevLineCr_1.0','RevLineCr_2.0','RevLineCr_3.0','RevLineCr_4.0','LowDoc_0.0','LowDoc_1.0','LowDoc_2.0','LowDoc_3.0','LowDoc_4.0','LowDoc_5.0','LowDoc_6.0']\n",
    "\n",
    "scalelist = features\n",
    "for i in OneHotedList:\n",
    "    scalelist.remove(i)\n",
    "    \n",
    "stdscl = StandardScaler()\n",
    "train_df[scalelist] = stdscl.fit_transform(train_df[scalelist])\n",
    "test_df[scalelist] = stdscl.fit_transform(test_df[scalelist])\n",
    "\n",
    "RemoveList=['MIS_Status','City','ApprovalDate','BankState','DisbursementDate','ApprovalDay','ApprovalMonth','ApprovalFY','ApprovalYear',\n",
    "           'DisbursementDay','DisbursementMonth']\n",
    "features = train_df.columns.tolist()\n",
    "for i in RemoveList:\n",
    "    print(i)\n",
    "    features.remove(i)\n",
    "\n",
    "    \n",
    "print(train_df)\n",
    "train_df.info()\n",
    "print(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "neuralnetwork training fold 1\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3452 - accurac\n",
      "Epoch 1: val_macro_f1: 0.4831073751226477\n",
      "1134/1134 [==============================] - 6s 4ms/step - loss: 0.3452 - accuracy: 0.8874 - val_loss: 0.2925 - val_accuracy: 0.8992\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3141 - accura\n",
      "Epoch 2: val_macro_f1: 0.5626227640726005\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.3132 - accuracy: 0.8938 - val_loss: 0.2844 - val_accuracy: 0.9052\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3080 - accura\n",
      "Epoch 3: val_macro_f1: 0.5767053799904747\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.3079 - accuracy: 0.8963 - val_loss: 0.2830 - val_accuracy: 0.9055\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3001 - accu\n",
      "Epoch 4: val_macro_f1: 0.6005494208267184\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3004 - accuracy: 0.8995 - val_loss: 0.2823 - val_accuracy: 0.9070\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2978 - accura\n",
      "Epoch 5: val_macro_f1: 0.6121878043607765\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2980 - accuracy: 0.9005 - val_loss: 0.2827 - val_accuracy: 0.9057\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2974 - accura\n",
      "Epoch 6: val_macro_f1: 0.603078664297508\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2971 - accuracy: 0.9015 - val_loss: 0.2818 - val_accuracy: 0.9067\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2945 - accu\n",
      "Epoch 7: val_macro_f1: 0.613127319782377\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2945 - accuracy: 0.9007 - val_loss: 0.2833 - val_accuracy: 0.9050\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2960 - accura\n",
      "Epoch 8: val_macro_f1: 0.60200833817943\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2953 - accuracy: 0.9014 - val_loss: 0.2812 - val_accuracy: 0.9059\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2935 - accu\n",
      "Epoch 9: val_macro_f1: 0.6112672776116816\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2936 - accuracy: 0.9009 - val_loss: 0.2819 - val_accuracy: 0.9057\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2914 - accurac\n",
      "Epoch 10: val_macro_f1: 0.6033019463307501\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2920 - accuracy: 0.9020 - val_loss: 0.2822 - val_accuracy: 0.9054\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2917 - accura\n",
      "Epoch 11: val_macro_f1: 0.6028760231283322\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2919 - accuracy: 0.9017 - val_loss: 0.2816 - val_accuracy: 0.9050\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2914 - accu\n",
      "Epoch 12: val_macro_f1: 0.6089747968962003\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2914 - accuracy: 0.9020 - val_loss: 0.2807 - val_accuracy: 0.9054\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2923 - accu\n",
      "Epoch 13: val_macro_f1: 0.6078243260183401\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2921 - accuracy: 0.9010 - val_loss: 0.2804 - val_accuracy: 0.9052\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2903 - accu\n",
      "Epoch 14: val_macro_f1: 0.6146981082256375\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2901 - accuracy: 0.9024 - val_loss: 0.2804 - val_accuracy: 0.9055\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2897 - accu\n",
      "Epoch 15: val_macro_f1: 0.6193587177866723\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2898 - accuracy: 0.9018 - val_loss: 0.2814 - val_accuracy: 0.9050\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2885 - accura\n",
      "Epoch 16: val_macro_f1: 0.6084108520742788\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2884 - accuracy: 0.9020 - val_loss: 0.2805 - val_accuracy: 0.9064\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2902 - accura\n",
      "Epoch 17: val_macro_f1: 0.6122190388302287\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2902 - accuracy: 0.9014 - val_loss: 0.2814 - val_accuracy: 0.9050\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2895 - accu\n",
      "Epoch 18: val_macro_f1: 0.6064234245132214\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2894 - accuracy: 0.9018 - val_loss: 0.2816 - val_accuracy: 0.9070\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2889 - accurac\n",
      "Epoch 19: val_macro_f1: 0.6020988463628774\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2888 - accuracy: 0.9023 - val_loss: 0.2808 - val_accuracy: 0.9067\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2880 - accu\n",
      "Epoch 20: val_macro_f1: 0.6056434376013055\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2881 - accuracy: 0.9027 - val_loss: 0.2821 - val_accuracy: 0.9057\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2881 - accu\n",
      "Epoch 21: val_macro_f1: 0.5986463552502229\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2879 - accuracy: 0.9032 - val_loss: 0.2816 - val_accuracy: 0.9055\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2884 - accura\n",
      "Epoch 22: val_macro_f1: 0.6248429496989557\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2883 - accuracy: 0.9019 - val_loss: 0.2836 - val_accuracy: 0.9040\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2880 - accu\n",
      "Epoch 23: val_macro_f1: 0.6021268081988339\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2881 - accuracy: 0.9027 - val_loss: 0.2830 - val_accuracy: 0.9052\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2867 - accu\n",
      "Epoch 24: val_macro_f1: 0.6063764495883981\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2866 - accuracy: 0.9029 - val_loss: 0.2814 - val_accuracy: 0.9055\n",
      "189/189 [==============================] - 0s 1ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 2\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3376 - accur\n",
      "Epoch 1: val_macro_f1: 0.479605215684437\n",
      "1134/1134 [==============================] - 5s 4ms/step - loss: 0.3384 - accuracy: 0.8923 - val_loss: 0.3077 - val_accuracy: 0.8896\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3121 - accu\n",
      "Epoch 2: val_macro_f1: 0.513583738603571\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.3122 - accuracy: 0.8955 - val_loss: 0.3015 - val_accuracy: 0.8923\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3041 - accura\n",
      "Epoch 3: val_macro_f1: 0.5884790584164179\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3039 - accuracy: 0.8974 - val_loss: 0.2975 - val_accuracy: 0.8987\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2994 - accura\n",
      "Epoch 4: val_macro_f1: 0.6166628612020194\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2990 - accuracy: 0.8996 - val_loss: 0.2935 - val_accuracy: 0.9024\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2958 - accu\n",
      "Epoch 5: val_macro_f1: 0.6166429186485156\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2960 - accuracy: 0.9009 - val_loss: 0.2933 - val_accuracy: 0.9017\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2937 - accu\n",
      "Epoch 6: val_macro_f1: 0.6114650694895045\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2937 - accuracy: 0.9015 - val_loss: 0.2938 - val_accuracy: 0.9011\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 2ms/step loss: 0.2931 - accu\n",
      "Epoch 7: val_macro_f1: 0.6077327982554711\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2933 - accuracy: 0.9013 - val_loss: 0.2937 - val_accuracy: 0.9009\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2922 - accu\n",
      "Epoch 8: val_macro_f1: 0.6286536852877013\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2924 - accuracy: 0.9013 - val_loss: 0.2929 - val_accuracy: 0.9021\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2914 - accu\n",
      "Epoch 9: val_macro_f1: 0.6129851868076844\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2911 - accuracy: 0.9016 - val_loss: 0.2934 - val_accuracy: 0.9009\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2916 - accu\n",
      "Epoch 10: val_macro_f1: 0.6279564084042587\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2909 - accuracy: 0.9020 - val_loss: 0.2925 - val_accuracy: 0.9027\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2899 - accu\n",
      "Epoch 11: val_macro_f1: 0.6213032581453634\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2901 - accuracy: 0.9018 - val_loss: 0.2921 - val_accuracy: 0.9021\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2890 - accura\n",
      "Epoch 12: val_macro_f1: 0.6223589072821321\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2888 - accuracy: 0.9020 - val_loss: 0.2932 - val_accuracy: 0.9022\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2891 - accura\n",
      "Epoch 13: val_macro_f1: 0.6138474088535977\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2885 - accuracy: 0.9022 - val_loss: 0.2928 - val_accuracy: 0.9016\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2880 - accu\n",
      "Epoch 14: val_macro_f1: 0.6168120060741376\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2881 - accuracy: 0.9021 - val_loss: 0.2929 - val_accuracy: 0.9006\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2890 - accu\n",
      "Epoch 15: val_macro_f1: 0.6144761737401063\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2890 - accuracy: 0.9022 - val_loss: 0.2921 - val_accuracy: 0.9001\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2877 - accura\n",
      "Epoch 16: val_macro_f1: 0.6320516445635228\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2879 - accuracy: 0.9017 - val_loss: 0.2915 - val_accuracy: 0.9022\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2872 - accura\n",
      "Epoch 17: val_macro_f1: 0.6117037041284634\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2873 - accuracy: 0.9029 - val_loss: 0.2928 - val_accuracy: 0.8999\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2876 - accu\n",
      "Epoch 18: val_macro_f1: 0.614702240413867\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2876 - accuracy: 0.9023 - val_loss: 0.2913 - val_accuracy: 0.9009\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2876 - accura\n",
      "Epoch 19: val_macro_f1: 0.6149184792915623\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2874 - accuracy: 0.9028 - val_loss: 0.2924 - val_accuracy: 0.9011\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2861 - accu\n",
      "Epoch 20: val_macro_f1: 0.6081968742635039\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2864 - accuracy: 0.9025 - val_loss: 0.2931 - val_accuracy: 0.9006\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2869 - accurac\n",
      "Epoch 21: val_macro_f1: 0.6066840660856134\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2870 - accuracy: 0.9024 - val_loss: 0.2931 - val_accuracy: 0.9001\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2867 - accura\n",
      "Epoch 22: val_macro_f1: 0.6104007807095722\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2865 - accuracy: 0.9020 - val_loss: 0.2922 - val_accuracy: 0.9002\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2859 - accu\n",
      "Epoch 23: val_macro_f1: 0.6117037041284634\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2859 - accuracy: 0.9029 - val_loss: 0.2918 - val_accuracy: 0.8999\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2854 - accu\n",
      "Epoch 24: val_macro_f1: 0.6170293116623572\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2854 - accuracy: 0.9027 - val_loss: 0.2913 - val_accuracy: 0.9007\n",
      "Epoch 25/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2859 - accu\n",
      "Epoch 25: val_macro_f1: 0.6106128546875368\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2857 - accuracy: 0.9027 - val_loss: 0.2920 - val_accuracy: 0.9004\n",
      "Epoch 26/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2853 - accura\n",
      "Epoch 26: val_macro_f1: 0.6002787452813501\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2853 - accuracy: 0.9031 - val_loss: 0.2925 - val_accuracy: 0.8992\n",
      "Epoch 27/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2865 - accu\n",
      "Epoch 27: val_macro_f1: 0.6088983311464655\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2862 - accuracy: 0.9031 - val_loss: 0.2924 - val_accuracy: 0.8997\n",
      "Epoch 28/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2853 - accu\n",
      "Epoch 28: val_macro_f1: 0.6075667257051182\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2844 - accuracy: 0.9026 - val_loss: 0.2931 - val_accuracy: 0.9001\n",
      "189/189 [==============================] - 0s 1ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 3\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3463 - accurac\n",
      "Epoch 1: val_macro_f1: 0.47458321732389774\n",
      "1134/1134 [==============================] - 5s 4ms/step - loss: 0.3464 - accuracy: 0.8873 - val_loss: 0.3060 - val_accuracy: 0.8923\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3125 - accur\n",
      "Epoch 2: val_macro_f1: 0.5398571333665988\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.3125 - accuracy: 0.8948 - val_loss: 0.2982 - val_accuracy: 0.8961\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3053 - accura\n",
      "Epoch 3: val_macro_f1: 0.5651804192932199\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.3051 - accuracy: 0.8990 - val_loss: 0.2932 - val_accuracy: 0.8989\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2996 - accur\n",
      "Epoch 4: val_macro_f1: 0.5703454631450924\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2999 - accuracy: 0.8990 - val_loss: 0.2916 - val_accuracy: 0.8997\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2985 - accura\n",
      "Epoch 5: val_macro_f1: 0.598095998690122\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2982 - accuracy: 0.9015 - val_loss: 0.2916 - val_accuracy: 0.9012\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2951 - ac\n",
      "Epoch 6: val_macro_f1: 0.587886875194061\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2947 - accuracy: 0.9022 - val_loss: 0.2906 - val_accuracy: 0.8999\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2961 - accura\n",
      "Epoch 7: val_macro_f1: 0.6151351166855015\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2958 - accuracy: 0.9012 - val_loss: 0.2889 - val_accuracy: 0.9012\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2933 - accu\n",
      "Epoch 8: val_macro_f1: 0.5779692928715725\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2931 - accuracy: 0.9022 - val_loss: 0.2904 - val_accuracy: 0.8991\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2918 - accu\n",
      "Epoch 9: val_macro_f1: 0.6067877975172232\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2916 - accuracy: 0.9020 - val_loss: 0.2890 - val_accuracy: 0.9016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2909 - accu\n",
      "Epoch 10: val_macro_f1: 0.5994424107548116\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2910 - accuracy: 0.9018 - val_loss: 0.2892 - val_accuracy: 0.9016\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2905 - accura\n",
      "Epoch 11: val_macro_f1: 0.6058856001028416\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2905 - accuracy: 0.9029 - val_loss: 0.2914 - val_accuracy: 0.9016\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 882us/steposs: 0.2909 - accuracy\n",
      "Epoch 12: val_macro_f1: 0.5960052007325379\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.2908 - accuracy: 0.9022 - val_loss: 0.2898 - val_accuracy: 0.9011\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2901 - accu\n",
      "Epoch 13: val_macro_f1: 0.6168617959548528\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2903 - accuracy: 0.9033 - val_loss: 0.2891 - val_accuracy: 0.9019\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2901 - accu\n",
      "Epoch 14: val_macro_f1: 0.6192244478158657\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2901 - accuracy: 0.9025 - val_loss: 0.2888 - val_accuracy: 0.9024\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2894 - accu\n",
      "Epoch 15: val_macro_f1: 0.6034434028509233\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2896 - accuracy: 0.9023 - val_loss: 0.2894 - val_accuracy: 0.9011\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2891 - accurac\n",
      "Epoch 16: val_macro_f1: 0.5997616938341602\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2890 - accuracy: 0.9016 - val_loss: 0.2900 - val_accuracy: 0.9011\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2892 - accu\n",
      "Epoch 17: val_macro_f1: 0.6078973258518463\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2887 - accuracy: 0.9026 - val_loss: 0.2898 - val_accuracy: 0.9017\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2884 - accura\n",
      "Epoch 18: val_macro_f1: 0.6072631332044263\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2884 - accuracy: 0.9031 - val_loss: 0.2895 - val_accuracy: 0.9012\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2880 - accu\n",
      "Epoch 19: val_macro_f1: 0.6025298648718198\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2878 - accuracy: 0.9035 - val_loss: 0.2898 - val_accuracy: 0.9011\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2878 - accura\n",
      "Epoch 20: val_macro_f1: 0.6023233019913625\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2879 - accuracy: 0.9027 - val_loss: 0.2892 - val_accuracy: 0.9009\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2882 - \n",
      "Epoch 21: val_macro_f1: 0.6058197797250121\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2880 - accuracy: 0.9020 - val_loss: 0.2891 - val_accuracy: 0.9022\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2868 - accu\n",
      "Epoch 22: val_macro_f1: 0.6049789059847424\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2869 - accuracy: 0.9039 - val_loss: 0.2884 - val_accuracy: 0.9016\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2859 - accurac\n",
      "Epoch 23: val_macro_f1: 0.6033600210001312\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2859 - accuracy: 0.9036 - val_loss: 0.2887 - val_accuracy: 0.9017\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2866 - accu\n",
      "Epoch 24: val_macro_f1: 0.6083667320725309\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2864 - accuracy: 0.9033 - val_loss: 0.2888 - val_accuracy: 0.9014\n",
      "Epoch 25/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2851 - accu\n",
      "Epoch 25: val_macro_f1: 0.6123347148213933\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2858 - accuracy: 0.9035 - val_loss: 0.2890 - val_accuracy: 0.9011\n",
      "Epoch 26/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2870 - accu\n",
      "Epoch 26: val_macro_f1: 0.6144982899382171\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2867 - accuracy: 0.9020 - val_loss: 0.2892 - val_accuracy: 0.9021\n",
      "Epoch 27/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2856 - accur\n",
      "Epoch 27: val_macro_f1: 0.6201139513132717\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2852 - accuracy: 0.9041 - val_loss: 0.2884 - val_accuracy: 0.9030\n",
      "Epoch 28/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2862 - accu\n",
      "Epoch 28: val_macro_f1: 0.6162243330673325\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2864 - accuracy: 0.9030 - val_loss: 0.2879 - val_accuracy: 0.9021\n",
      "Epoch 29/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2852 - ac\n",
      "Epoch 29: val_macro_f1: 0.6131781699481177\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2851 - accuracy: 0.9037 - val_loss: 0.2891 - val_accuracy: 0.9030\n",
      "Epoch 30/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2871 - accu\n",
      "Epoch 30: val_macro_f1: 0.6080602764671525\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2869 - accuracy: 0.9036 - val_loss: 0.2889 - val_accuracy: 0.9025\n",
      "Epoch 31/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2849 - accu\n",
      "Epoch 31: val_macro_f1: 0.6188174118979587\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2853 - accuracy: 0.9033 - val_loss: 0.2874 - val_accuracy: 0.9027\n",
      "Epoch 32/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2855 - ac\n",
      "Epoch 32: val_macro_f1: 0.6047696790955692\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2854 - accuracy: 0.9031 - val_loss: 0.2898 - val_accuracy: 0.9014\n",
      "Epoch 33/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2848 - ac\n",
      "Epoch 33: val_macro_f1: 0.6136312542367064\n",
      "1134/1134 [==============================] - 5s 4ms/step - loss: 0.2853 - accuracy: 0.9032 - val_loss: 0.2895 - val_accuracy: 0.9014\n",
      "Epoch 34/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2860 - ac\n",
      "Epoch 34: val_macro_f1: 0.6039366927796427\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2859 - accuracy: 0.9035 - val_loss: 0.2877 - val_accuracy: 0.9007\n",
      "Epoch 35/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2832 - accu\n",
      "Epoch 35: val_macro_f1: 0.6033600210001312\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2835 - accuracy: 0.9045 - val_loss: 0.2894 - val_accuracy: 0.9017\n",
      "Epoch 36/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2839 - accu\n",
      "Epoch 36: val_macro_f1: 0.6118773904799508\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2852 - accuracy: 0.9028 - val_loss: 0.2911 - val_accuracy: 0.9021\n",
      "Epoch 37/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2856 - accu\n",
      "Epoch 37: val_macro_f1: 0.6142809252069663\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2855 - accuracy: 0.9034 - val_loss: 0.2889 - val_accuracy: 0.9019\n",
      "Epoch 38/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2833 - accu\n",
      "Epoch 38: val_macro_f1: 0.6123236247296626\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2833 - accuracy: 0.9035 - val_loss: 0.2891 - val_accuracy: 0.9017\n",
      "Epoch 39/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2832 - accu\n",
      "Epoch 39: val_macro_f1: 0.6103229395930323\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2835 - accuracy: 0.9038 - val_loss: 0.2887 - val_accuracy: 0.9022\n",
      "Epoch 40/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2830 - accu\n",
      "Epoch 40: val_macro_f1: 0.6157714439283095\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2836 - accuracy: 0.9034 - val_loss: 0.2896 - val_accuracy: 0.9011\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 1ms/step loss: 0.2853 - accura\n",
      "Epoch 41: val_macro_f1: 0.6168382006027978\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2847 - accuracy: 0.9030 - val_loss: 0.2879 - val_accuracy: 0.9012\n",
      "189/189 [==============================] - 0s 1ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 4\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3533 - accurac\n",
      "Epoch 1: val_macro_f1: 0.4834702623670243\n",
      "1134/1134 [==============================] - 5s 4ms/step - loss: 0.3533 - accuracy: 0.8835 - val_loss: 0.2988 - val_accuracy: 0.8961\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3141 - accura\n",
      "Epoch 2: val_macro_f1: 0.5938369048252101\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.3138 - accuracy: 0.8947 - val_loss: 0.2866 - val_accuracy: 0.9049\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3049 - accura\n",
      "Epoch 3: val_macro_f1: 0.6149092934529816\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.3044 - accuracy: 0.8983 - val_loss: 0.2830 - val_accuracy: 0.9064\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3005 - ac\n",
      "Epoch 4: val_macro_f1: 0.6363549486663194\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.3006 - accuracy: 0.9001 - val_loss: 0.2812 - val_accuracy: 0.9092\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2975 - accura\n",
      "Epoch 5: val_macro_f1: 0.6245556831386676\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.2981 - accuracy: 0.9002 - val_loss: 0.2817 - val_accuracy: 0.9075\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2947 - accu\n",
      "Epoch 6: val_macro_f1: 0.6095738921705208\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2948 - accuracy: 0.9010 - val_loss: 0.2818 - val_accuracy: 0.9065\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2960 - accu\n",
      "Epoch 7: val_macro_f1: 0.6476212686567164\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2953 - accuracy: 0.9001 - val_loss: 0.2798 - val_accuracy: 0.9097\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2956 - accu\n",
      "Epoch 8: val_macro_f1: 0.6089145365199259\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2953 - accuracy: 0.9009 - val_loss: 0.2822 - val_accuracy: 0.9060\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2931 - accu\n",
      "Epoch 9: val_macro_f1: 0.6251948972360029\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2933 - accuracy: 0.9006 - val_loss: 0.2812 - val_accuracy: 0.9073\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2936 - accur\n",
      "Epoch 10: val_macro_f1: 0.6144611652666098\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2936 - accuracy: 0.9006 - val_loss: 0.2811 - val_accuracy: 0.9060\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2914 - accura\n",
      "Epoch 11: val_macro_f1: 0.6148939257888675\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2915 - accuracy: 0.9012 - val_loss: 0.2811 - val_accuracy: 0.9070\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2912 - accurac\n",
      "Epoch 12: val_macro_f1: 0.6460790269017425\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2910 - accuracy: 0.9017 - val_loss: 0.2796 - val_accuracy: 0.9092\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2924 - accu\n",
      "Epoch 13: val_macro_f1: 0.6325009512875399\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2926 - accuracy: 0.9015 - val_loss: 0.2799 - val_accuracy: 0.9077\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2897 - accu\n",
      "Epoch 14: val_macro_f1: 0.6126312520762021\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2899 - accuracy: 0.9017 - val_loss: 0.2808 - val_accuracy: 0.9060\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2898 - accu\n",
      "Epoch 15: val_macro_f1: 0.6315349459185412\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2898 - accuracy: 0.9021 - val_loss: 0.2797 - val_accuracy: 0.9082\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2899 - accu\n",
      "Epoch 16: val_macro_f1: 0.6089145365199259\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2903 - accuracy: 0.9010 - val_loss: 0.2807 - val_accuracy: 0.9060\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2900 - ac\n",
      "Epoch 17: val_macro_f1: 0.6221000503758609\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2904 - accuracy: 0.9017 - val_loss: 0.2813 - val_accuracy: 0.9070\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2885 - accu\n",
      "Epoch 18: val_macro_f1: 0.6028760231283322\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2892 - accuracy: 0.9019 - val_loss: 0.2818 - val_accuracy: 0.9050\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2874 - ac\n",
      "Epoch 19: val_macro_f1: 0.6275515399284713\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2879 - accuracy: 0.9016 - val_loss: 0.2802 - val_accuracy: 0.9072\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2889 - accu\n",
      "Epoch 20: val_macro_f1: 0.5802420052292179\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2888 - accuracy: 0.9023 - val_loss: 0.2833 - val_accuracy: 0.9039\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2881 - accu\n",
      "Epoch 21: val_macro_f1: 0.6214086813051704\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2883 - accuracy: 0.9018 - val_loss: 0.2807 - val_accuracy: 0.9065\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2881 - accu\n",
      "Epoch 22: val_macro_f1: 0.5804321016024757\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2884 - accuracy: 0.9021 - val_loss: 0.2829 - val_accuracy: 0.9040\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 5\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3448 - acc\n",
      "Epoch 1: val_macro_f1: 0.4736002673804069\n",
      "1134/1134 [==============================] - 5s 3ms/step - loss: 0.3446 - accuracy: 0.8890 - val_loss: 0.3007 - val_accuracy: 0.8941\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3137 - accu\n",
      "Epoch 2: val_macro_f1: 0.5315676811359906\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3137 - accuracy: 0.8942 - val_loss: 0.2925 - val_accuracy: 0.8979\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3050 - accu\n",
      "Epoch 3: val_macro_f1: 0.5870093749923867\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3053 - accuracy: 0.8967 - val_loss: 0.2903 - val_accuracy: 0.9025\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3013 - accu\n",
      "Epoch 4: val_macro_f1: 0.605171057379074\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3014 - accuracy: 0.8990 - val_loss: 0.2870 - val_accuracy: 0.9039\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2997 - accu\n",
      "Epoch 5: val_macro_f1: 0.5900229028284135\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2995 - accuracy: 0.8996 - val_loss: 0.2861 - val_accuracy: 0.9025\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2951 - ac\n",
      "Epoch 6: val_macro_f1: 0.6049584475090967\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2952 - accuracy: 0.9010 - val_loss: 0.2859 - val_accuracy: 0.9037\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2942 - accu\n",
      "Epoch 7: val_macro_f1: 0.5987249014188722\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2944 - accuracy: 0.9011 - val_loss: 0.2853 - val_accuracy: 0.9040\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189/189 [==============================] - 0s 2ms/step loss: 0.2945 - accu\n",
      "Epoch 8: val_macro_f1: 0.6074581114718924\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.2946 - accuracy: 0.9009 - val_loss: 0.2842 - val_accuracy: 0.9042\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2918 - accu\n",
      "Epoch 9: val_macro_f1: 0.5953467178780907\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2917 - accuracy: 0.9024 - val_loss: 0.2840 - val_accuracy: 0.9029\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2919 - accu\n",
      "Epoch 10: val_macro_f1: 0.6106494018322116\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2920 - accuracy: 0.9017 - val_loss: 0.2836 - val_accuracy: 0.9045\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2916 - accu\n",
      "Epoch 11: val_macro_f1: 0.6042351644425611\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2916 - accuracy: 0.9015 - val_loss: 0.2844 - val_accuracy: 0.9039\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2905 - accura\n",
      "Epoch 12: val_macro_f1: 0.5870093749923867\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2908 - accuracy: 0.9022 - val_loss: 0.2837 - val_accuracy: 0.9025\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2903 - accu\n",
      "Epoch 13: val_macro_f1: 0.6184818435391716\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2901 - accuracy: 0.9025 - val_loss: 0.2834 - val_accuracy: 0.9050\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2890 - accu\n",
      "Epoch 14: val_macro_f1: 0.5829923059768065\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2894 - accuracy: 0.9018 - val_loss: 0.2863 - val_accuracy: 0.9017\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2887 - accu\n",
      "Epoch 15: val_macro_f1: 0.6078893289289599\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2889 - accuracy: 0.9027 - val_loss: 0.2862 - val_accuracy: 0.9045\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2888 - accu\n",
      "Epoch 16: val_macro_f1: 0.6056758297152607\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2888 - accuracy: 0.9024 - val_loss: 0.2841 - val_accuracy: 0.9035\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2884 - ac\n",
      "Epoch 17: val_macro_f1: 0.6063159786173128\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2888 - accuracy: 0.9010 - val_loss: 0.2851 - val_accuracy: 0.9040\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2872 - accu\n",
      "Epoch 18: val_macro_f1: 0.6029703465572178\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2879 - accuracy: 0.9026 - val_loss: 0.2861 - val_accuracy: 0.9029\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2883 - accu\n",
      "Epoch 19: val_macro_f1: 0.5876552435269791\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2883 - accuracy: 0.9022 - val_loss: 0.2872 - val_accuracy: 0.9014\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2878 - accu\n",
      "Epoch 20: val_macro_f1: 0.5931373807153411\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2877 - accuracy: 0.9026 - val_loss: 0.2853 - val_accuracy: 0.9011\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2876 - ac\n",
      "Epoch 21: val_macro_f1: 0.6088672952076396\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2876 - accuracy: 0.9030 - val_loss: 0.2850 - val_accuracy: 0.9039\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2878 - ac\n",
      "Epoch 22: val_macro_f1: 0.599528323076232\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2878 - accuracy: 0.9030 - val_loss: 0.2855 - val_accuracy: 0.9024\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2872 - accu\n",
      "Epoch 23: val_macro_f1: 0.5989915074309979\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2868 - accuracy: 0.9032 - val_loss: 0.2848 - val_accuracy: 0.9027\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 6\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3412 - accur\n",
      "Epoch 1: val_macro_f1: 0.500237207324184\n",
      "1134/1134 [==============================] - 5s 4ms/step - loss: 0.3408 - accuracy: 0.8888 - val_loss: 0.3128 - val_accuracy: 0.8847\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3128 - accu\n",
      "Epoch 2: val_macro_f1: 0.5305379299120988\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3128 - accuracy: 0.8950 - val_loss: 0.3044 - val_accuracy: 0.8888\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3012 - accur\n",
      "Epoch 3: val_macro_f1: 0.5674685459512988\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3016 - accuracy: 0.8984 - val_loss: 0.3015 - val_accuracy: 0.8930\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2993 - accu\n",
      "Epoch 4: val_macro_f1: 0.5794542089369459\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2995 - accuracy: 0.9001 - val_loss: 0.3007 - val_accuracy: 0.8941\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2967 - accu\n",
      "Epoch 5: val_macro_f1: 0.6038573916620723\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2965 - accuracy: 0.9011 - val_loss: 0.2991 - val_accuracy: 0.8971\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2934 - accu\n",
      "Epoch 6: val_macro_f1: 0.6253140038867826\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2934 - accuracy: 0.9018 - val_loss: 0.2964 - val_accuracy: 0.8984\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2930 - ac\n",
      "Epoch 7: val_macro_f1: 0.6263135731903934\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2932 - accuracy: 0.9009 - val_loss: 0.2973 - val_accuracy: 0.8986\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2906 - accu\n",
      "Epoch 8: val_macro_f1: 0.6292993886743887\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2906 - accuracy: 0.9026 - val_loss: 0.2969 - val_accuracy: 0.8991\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2912 - ac\n",
      "Epoch 9: val_macro_f1: 0.6226559572672977\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2912 - accuracy: 0.9016 - val_loss: 0.2959 - val_accuracy: 0.8976\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2901 - accu\n",
      "Epoch 10: val_macro_f1: 0.5993553889439879\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2904 - accuracy: 0.9030 - val_loss: 0.2984 - val_accuracy: 0.8963\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2894 - ac\n",
      "Epoch 11: val_macro_f1: 0.6177103099304238\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2896 - accuracy: 0.9030 - val_loss: 0.2958 - val_accuracy: 0.8981\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2892 - accu\n",
      "Epoch 12: val_macro_f1: 0.6273109888874246\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2895 - accuracy: 0.9020 - val_loss: 0.2953 - val_accuracy: 0.8987\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2891 - accu\n",
      "Epoch 13: val_macro_f1: 0.6270895848303124\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2894 - accuracy: 0.9024 - val_loss: 0.2956 - val_accuracy: 0.8986\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2881 - accu\n",
      "Epoch 14: val_macro_f1: 0.5163372043174651\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2881 - accuracy: 0.9024 - val_loss: 0.3014 - val_accuracy: 0.8888\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2877 - ac\n",
      "Epoch 15: val_macro_f1: 0.5886208896698895\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2877 - accuracy: 0.9020 - val_loss: 0.2981 - val_accuracy: 0.8948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2873 - accu\n",
      "Epoch 16: val_macro_f1: 0.5804079897080551\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2876 - accuracy: 0.9025 - val_loss: 0.2987 - val_accuracy: 0.8941\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2865 - accu\n",
      "Epoch 17: val_macro_f1: 0.6350502522543996\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2864 - accuracy: 0.9031 - val_loss: 0.2949 - val_accuracy: 0.8994\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2878 - accu\n",
      "Epoch 18: val_macro_f1: 0.584341664804542\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2878 - accuracy: 0.9021 - val_loss: 0.2984 - val_accuracy: 0.8951\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2860 - accu\n",
      "Epoch 19: val_macro_f1: 0.6215104654952327\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2860 - accuracy: 0.9029 - val_loss: 0.2958 - val_accuracy: 0.8979\n",
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2861 - ac\n",
      "Epoch 20: val_macro_f1: 0.5926940527727932\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2867 - accuracy: 0.9033 - val_loss: 0.2981 - val_accuracy: 0.8959\n",
      "Epoch 21/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2854 - accu\n",
      "Epoch 21: val_macro_f1: 0.5877161209784947\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2859 - accuracy: 0.9040 - val_loss: 0.2980 - val_accuracy: 0.8964\n",
      "Epoch 22/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2854 - accura\n",
      "Epoch 22: val_macro_f1: 0.6325720334985903\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2859 - accuracy: 0.9032 - val_loss: 0.2952 - val_accuracy: 0.8992\n",
      "Epoch 23/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2856 - accu\n",
      "Epoch 23: val_macro_f1: 0.6369923918994403\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2856 - accuracy: 0.9024 - val_loss: 0.2964 - val_accuracy: 0.8997\n",
      "Epoch 24/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2873 - accu\n",
      "Epoch 24: val_macro_f1: 0.6239642063996397\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2865 - accuracy: 0.9025 - val_loss: 0.2977 - val_accuracy: 0.8986\n",
      "Epoch 25/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2851 - ac\n",
      "Epoch 25: val_macro_f1: 0.6354423542344882\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2852 - accuracy: 0.9041 - val_loss: 0.2950 - val_accuracy: 0.9002\n",
      "Epoch 26/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2843 - accu\n",
      "Epoch 26: val_macro_f1: 0.6203476872683706\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2843 - accuracy: 0.9038 - val_loss: 0.2958 - val_accuracy: 0.8982\n",
      "Epoch 27/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2846 - accu\n",
      "Epoch 27: val_macro_f1: 0.6184697739049974\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2847 - accuracy: 0.9034 - val_loss: 0.2966 - val_accuracy: 0.8974\n",
      "189/189 [==============================] - 0s 1ms/step\n",
      "--------------------------------------------------\n",
      "neuralnetwork training fold 7\n",
      "Epoch 1/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3383 - accur\n",
      "Epoch 1: val_macro_f1: 0.48121574767322944\n",
      "1134/1134 [==============================] - 5s 4ms/step - loss: 0.3390 - accuracy: 0.8901 - val_loss: 0.2949 - val_accuracy: 0.8941\n",
      "Epoch 2/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3126 - accu\n",
      "Epoch 2: val_macro_f1: 0.5508771180468053\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3123 - accuracy: 0.8950 - val_loss: 0.2904 - val_accuracy: 0.8992\n",
      "Epoch 3/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.3044 - accura\n",
      "Epoch 3: val_macro_f1: 0.6075619626783187\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.3042 - accuracy: 0.8985 - val_loss: 0.2897 - val_accuracy: 0.9000\n",
      "Epoch 4/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.3001 - accu\n",
      "Epoch 4: val_macro_f1: 0.6033112831507975\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2998 - accuracy: 0.9003 - val_loss: 0.2879 - val_accuracy: 0.9002\n",
      "Epoch 5/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2965 - accu\n",
      "Epoch 5: val_macro_f1: 0.6151172825003367\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2960 - accuracy: 0.9013 - val_loss: 0.2873 - val_accuracy: 0.9005\n",
      "Epoch 6/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2952 - accu\n",
      "Epoch 6: val_macro_f1: 0.6195777362600777\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2953 - accuracy: 0.9018 - val_loss: 0.2869 - val_accuracy: 0.9014\n",
      "Epoch 7/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2935 - ac\n",
      "Epoch 7: val_macro_f1: 0.6127658883678965\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2938 - accuracy: 0.9019 - val_loss: 0.2874 - val_accuracy: 0.9007\n",
      "Epoch 8/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2928 - accu\n",
      "Epoch 8: val_macro_f1: 0.6057923267805795\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2929 - accuracy: 0.9018 - val_loss: 0.2868 - val_accuracy: 0.9000\n",
      "Epoch 9/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2919 - accu\n",
      "Epoch 9: val_macro_f1: 0.6108205772084664\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2919 - accuracy: 0.9022 - val_loss: 0.2875 - val_accuracy: 0.9005\n",
      "Epoch 10/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2909 - accu\n",
      "Epoch 10: val_macro_f1: 0.6188751472782354\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2910 - accuracy: 0.9025 - val_loss: 0.2865 - val_accuracy: 0.9002\n",
      "Epoch 11/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2898 - accu\n",
      "Epoch 11: val_macro_f1: 0.6064183245331732\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2903 - accuracy: 0.9027 - val_loss: 0.2879 - val_accuracy: 0.9005\n",
      "Epoch 12/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2892 - accu\n",
      "Epoch 12: val_macro_f1: 0.6080207824903023\n",
      "1134/1134 [==============================] - 3s 3ms/step - loss: 0.2894 - accuracy: 0.9038 - val_loss: 0.2868 - val_accuracy: 0.8997\n",
      "Epoch 13/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2898 - ac\n",
      "Epoch 13: val_macro_f1: 0.6060006065805885\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2895 - accuracy: 0.9031 - val_loss: 0.2871 - val_accuracy: 0.9002\n",
      "Epoch 14/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2904 - accur\n",
      "Epoch 14: val_macro_f1: 0.6171783460409994\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2903 - accuracy: 0.9028 - val_loss: 0.2879 - val_accuracy: 0.8996\n",
      "Epoch 15/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2889 - accu\n",
      "Epoch 15: val_macro_f1: 0.5923407412055797\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2892 - accuracy: 0.9027 - val_loss: 0.2874 - val_accuracy: 0.9004\n",
      "Epoch 16/100\n",
      "189/189 [==============================] - 0s 1ms/step loss: 0.2890 - accu\n",
      "Epoch 16: val_macro_f1: 0.6048350111515477\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2889 - accuracy: 0.9032 - val_loss: 0.2866 - val_accuracy: 0.9007\n",
      "Epoch 17/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2878 - accu\n",
      "Epoch 17: val_macro_f1: 0.6188751472782354\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2875 - accuracy: 0.9029 - val_loss: 0.2876 - val_accuracy: 0.9002\n",
      "Epoch 18/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2883 - accu\n",
      "Epoch 18: val_macro_f1: 0.5995661446335684\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2886 - accuracy: 0.9028 - val_loss: 0.2887 - val_accuracy: 0.8994\n",
      "Epoch 19/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2877 - accu\n",
      "Epoch 19: val_macro_f1: 0.6119115364167995\n",
      "1134/1134 [==============================] - 4s 4ms/step - loss: 0.2877 - accuracy: 0.9034 - val_loss: 0.2876 - val_accuracy: 0.9000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100\n",
      "189/189 [==============================] - 0s 2ms/step loss: 0.2879 - ac\n",
      "Epoch 20: val_macro_f1: 0.6157265863461906\n",
      "1134/1134 [==============================] - 4s 3ms/step - loss: 0.2879 - accuracy: 0.9032 - val_loss: 0.2871 - val_accuracy: 0.8997\n",
      "189/189 [==============================] - 0s 2ms/step\n",
      "neuralnetwork our out of folds CV f1score is 0.6240420904786952\n",
      "1323/1323 [==============================] - 2s 2ms/step\n",
      "1323/1323 [==============================] - 2s 2ms/step\n",
      "1323/1323 [==============================] - 2s 1ms/step\n",
      "1323/1323 [==============================] - 2s 2ms/step\n",
      "1323/1323 [==============================] - 2s 2ms/step\n",
      "1323/1323 [==============================] - 2s 2ms/step\n",
      "1323/1323 [==============================] - 2s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "def build_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(Dropout(0.5))  # Dropout層を追加\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.5))  \n",
    "    model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# モデルの学習と評価\n",
    "def nn_training(x_train: pd.DataFrame, y_train: pd.DataFrame, x_valid: pd.DataFrame, y_valid: pd.DataFrame, features: list, categorical_features: list):\n",
    "    model = build_model(x_train.shape[1])\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    model.fit(x_train, y_train, epochs=100, batch_size=32, verbose=1,\n",
    "          validation_data=(x_valid, y_valid),\n",
    "          callbacks=[MacroF1ScoreCallback(validation_data=(x_valid, y_valid)), early_stopping])\n",
    "    valid_pred = model.predict(x_valid)\n",
    "    valid_pred = valid_pred.flatten()  # 1 次元の配列に変換する\n",
    "    return  model, valid_pred\n",
    "\n",
    "\n",
    "#任意のモデルでのクロスバリデーション学習メソッドの定義\n",
    "def gradient_boosting_model_cv_training(method: str, train_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    # Create a numpy array to store out of folds predictions\n",
    "    oof_predictions = np.zeros(len(train_df))\n",
    "    oof_fold = np.zeros(len(train_df))\n",
    "    kfold = KFold(n_splits=CFG.n_folds, shuffle=True, random_state=CFG.seed)\n",
    "    for fold, (train_index, valid_index) in enumerate(kfold.split(train_df)):\n",
    "        print('-'*50)\n",
    "        print(f'{method} training fold {fold+1}')\n",
    "\n",
    "        x_train = train_df[features].iloc[train_index]\n",
    "        y_train = train_df[CFG.target_col].iloc[train_index]\n",
    "        x_valid = train_df[features].iloc[valid_index]\n",
    "        y_valid = train_df[CFG.target_col].iloc[valid_index]\n",
    "        \n",
    "        model = None  # モデル変数を初期化する\n",
    "        valid_pred = None\n",
    "\n",
    "        if method == 'neuralnetwork':\n",
    "            model, valid_pred = nn_training(x_train, y_train, x_valid, y_valid, features, categorical_features)\n",
    "            model.save(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.h5')\n",
    "        # Save best model\n",
    "        #pickle.dump(model, open(f'{method}_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.pkl', 'wb'))\n",
    "        # Add to out of folds array\n",
    "        oof_predictions[valid_index] = valid_pred\n",
    "        oof_fold[valid_index] = fold + 1\n",
    "        del x_train, x_valid, y_train, y_valid, model, valid_pred\n",
    "        gc.collect()\n",
    "\n",
    "    # Compute out of folds metric\n",
    "    score = f1_score(train_df[CFG.target_col], oof_predictions >= 0.5, average='macro')\n",
    "    print(f'{method} our out of folds CV f1score is {score}')\n",
    "    # Create a dataframe to store out of folds predictions\n",
    "    oof_df = pd.DataFrame({CFG.target_col: train_df[CFG.target_col], f'{method}_prediction': oof_predictions, 'fold': oof_fold})\n",
    "    oof_df.to_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv', index = False)\n",
    "#学習メソッドの定義\n",
    "def Learning(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        gradient_boosting_model_cv_training(method, input_df, features, categorical_features)\n",
    "        \n",
    "Learning(train_df, features, categorical_features)\n",
    "\n",
    "def nn_inference( x_test: pd.DataFrame):\n",
    "    test_pred = np.zeros((x_test.shape[0],))\n",
    "    for fold in range(CFG.n_folds):\n",
    "        model = load_model(f'neuralnetwork_fold{fold + 1}_seed{CFG.seed}_ver{CFG.VER}.h5')\n",
    "        # Predict\n",
    "        pred = model.predict(x_test)\n",
    "        pred = pred.flatten()  # 1 次元の配列に変換する\n",
    "        test_pred += pred\n",
    "    return test_pred / CFG.n_folds\n",
    "\n",
    "def gradient_boosting_model_inference(method: str, test_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    x_test = test_df[features]\n",
    "    if method == 'neuralnetwork':\n",
    "        test_pred = nn_inference(x_test)\n",
    "    return test_pred\n",
    "\n",
    "def Predicting(input_df: pd.DataFrame, features: list, categorical_features: list):\n",
    "    output_df = input_df.copy()\n",
    "    output_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        output_df[f'{method}_pred_prob'] = gradient_boosting_model_inference(method, input_df, features, categorical_features)\n",
    "        output_df['pred_prob'] += CFG.model_weight_dict[method] * output_df[f'{method}_pred_prob']\n",
    "    return output_df\n",
    "\n",
    "test_df = Predicting(test_df, features, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224d47d277f94b2abf05fdbc1e70ab5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6715518088217877 0.792\n"
     ]
    }
   ],
   "source": [
    "#後処理の定義\n",
    "def Postprocessing(train_df: pd.DataFrame(), test_df: pd.DataFrame()) -> (pd.DataFrame(), pd.DataFrame()):\n",
    "    train_df['pred_prob'] = 0\n",
    "    for method in CFG.METHOD_LIST:\n",
    "        oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "        train_df['pred_prob'] += CFG.model_weight_dict[method] * oof_df[f'{method}_prediction']\n",
    "    best_score = 0\n",
    "    best_v = 0\n",
    "    for v in tqdm(np.arange(1000) / 1000):\n",
    "        score = f1_score(oof_df[CFG.target_col], train_df[f'pred_prob'] >= v, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_v = v\n",
    "    print(best_score, best_v)\n",
    "    test_df['target'] = np.where(test_df['pred_prob'] >= best_v, 1, 0)\n",
    "    return train_df, test_df\n",
    "\n",
    "#後処理\n",
    "train_df, test_df = Postprocessing(train_df, test_df)\n",
    "\n",
    "test_df[['target']].to_csv(f'seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}_submission.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.844, Best F1 Score: 0.6716592713247698\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# OOF予測を基に新たな特徴量を作成\n",
    "oof_features = np.zeros((train_df.shape[0], len(CFG.METHOD_LIST)))\n",
    "for i, method in enumerate(CFG.METHOD_LIST):\n",
    "    oof_df = pd.read_csv(f'oof_{method}_seed{CFG.seed}_ver{CFG.VER}.csv')\n",
    "    oof_features[:, i] = oof_df[f'{method}_prediction']\n",
    "\n",
    "# テストデータの予測を基に特徴量を作成\n",
    "test_features = np.zeros((test_df.shape[0], len(CFG.METHOD_LIST)))\n",
    "for i, method in enumerate(CFG.METHOD_LIST):\n",
    "    test_features[:, i] = test_df[f'{method}_pred_prob']\n",
    "\n",
    "# 特徴量の標準化\n",
    "scaler = StandardScaler()\n",
    "oof_features_scaled = scaler.fit_transform(oof_features)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "\n",
    "# ロジスティック回帰モデルをパラメータチューニング・学習\n",
    "'''\n",
    "logistic = LogisticRegression()\n",
    "param_grid = {'C': [1]}\n",
    "grid_search = GridSearchCV(estimator=logistic, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(oof_features_scaled, train_df[CFG.target_col])\n",
    "print('Best Parameter:',grid_search.best_params_)\n",
    "print('Best Score:',grid_search.best_score_)\n",
    "lr = LogisticRegression(C=grid_search.best_params_['C'])\n",
    "'''\n",
    "lr = LogisticRegression()\n",
    "lr.fit(oof_features_scaled, train_df[CFG.target_col])\n",
    "\n",
    "# 最適な閾値とその時のF1スコアを探索する関数\n",
    "def find_best_threshold_and_score(y_true, y_pred_proba):\n",
    "    best_threshold = 0\n",
    "    best_score = 0\n",
    "    for threshold in np.linspace(0, 1, 1001):  # 0.001刻みで閾値を変更\n",
    "        score = f1_score(y_true, y_pred_proba >= threshold, average='macro')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# 学習データに対する予測確率\n",
    "train_pred_proba = lr.predict_proba(oof_features_scaled)[:, 1]\n",
    "\n",
    "# 最適な閾値とスコアを求める\n",
    "best_threshold, best_score = find_best_threshold_and_score(train_df[CFG.target_col], train_pred_proba)\n",
    "print(f'Best Threshold: {best_threshold}, Best F1 Score: {best_score}')\n",
    "\n",
    "# テストデータに対する最終予測\n",
    "test_pred_proba = lr.predict_proba(test_features_scaled)[:, 1]\n",
    "test_final_predictions = (test_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# 最終予渲結果をコンペ提出用のフォーマットでCSVファイルに出力\n",
    "submission_df = pd.DataFrame({'Id': test_df.index, 'target': test_final_predictions}).reset_index(drop=True)\n",
    "# ここで、インデックスの開始が42307であるため、その値から始めるように調整\n",
    "submission_df['Id'] = submission_df.index + 42307\n",
    "\n",
    "submission_df.to_csv(f'stacking_lr_submission_best_score{best_score:.4f}_seed{CFG.seed}_ver{CFG.VER}_{CFG.AUTHOR}.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "13858cd0c554419bb867071b5c810b30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4074a8c3b85548ed9424375a19416c7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "573ab758539147f1a2bc21ac9f0347ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5de7c5cebd814e1caa8437775031ea12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6762ef5aab7e4d18b98e7d837dedc03f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6f14799525cf44158bbffc0e9a08891b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b7dceec9910a46cea90915015ca58358",
      "placeholder": "​",
      "style": "IPY_MODEL_573ab758539147f1a2bc21ac9f0347ce",
      "value": "100%"
     }
    },
    "76ddf1599bb144b2a6b4573027c6f662": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4074a8c3b85548ed9424375a19416c7d",
      "placeholder": "​",
      "style": "IPY_MODEL_13858cd0c554419bb867071b5c810b30",
      "value": " 1000/1000 [00:19&lt;00:00, 37.91it/s]"
     }
    },
    "b0ab4a4e03b242e2ae3610b6a52b5c14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "b7dceec9910a46cea90915015ca58358": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d239d2ff297a4c00aa350f8699ca6bb1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5de7c5cebd814e1caa8437775031ea12",
      "max": 1000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b0ab4a4e03b242e2ae3610b6a52b5c14",
      "value": 1000
     }
    },
    "ef58b4abcf0f43cd90a523a3875a2f28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f14799525cf44158bbffc0e9a08891b",
       "IPY_MODEL_d239d2ff297a4c00aa350f8699ca6bb1",
       "IPY_MODEL_76ddf1599bb144b2a6b4573027c6f662"
      ],
      "layout": "IPY_MODEL_6762ef5aab7e4d18b98e7d837dedc03f"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
